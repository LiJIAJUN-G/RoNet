{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 38745,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0023228803716608595,
      "grad_norm": 1.0170745849609375,
      "learning_rate": 4.99883855981417e-05,
      "loss": 2.6147,
      "step": 10
    },
    {
      "epoch": 0.004645760743321719,
      "grad_norm": 0.7309001088142395,
      "learning_rate": 4.997677119628339e-05,
      "loss": 2.585,
      "step": 20
    },
    {
      "epoch": 0.006968641114982578,
      "grad_norm": 1.0844060182571411,
      "learning_rate": 4.9965156794425086e-05,
      "loss": 2.549,
      "step": 30
    },
    {
      "epoch": 0.009291521486643438,
      "grad_norm": 0.8976786732673645,
      "learning_rate": 4.995354239256679e-05,
      "loss": 2.5201,
      "step": 40
    },
    {
      "epoch": 0.011614401858304297,
      "grad_norm": 1.425079584121704,
      "learning_rate": 4.994192799070848e-05,
      "loss": 2.4598,
      "step": 50
    },
    {
      "epoch": 0.013937282229965157,
      "grad_norm": 1.7059502601623535,
      "learning_rate": 4.993031358885018e-05,
      "loss": 2.4592,
      "step": 60
    },
    {
      "epoch": 0.016260162601626018,
      "grad_norm": 1.4069890975952148,
      "learning_rate": 4.991869918699187e-05,
      "loss": 2.3939,
      "step": 70
    },
    {
      "epoch": 0.018583042973286876,
      "grad_norm": 1.9776957035064697,
      "learning_rate": 4.9907084785133567e-05,
      "loss": 2.3637,
      "step": 80
    },
    {
      "epoch": 0.020905923344947737,
      "grad_norm": 2.8793141841888428,
      "learning_rate": 4.989547038327526e-05,
      "loss": 2.1951,
      "step": 90
    },
    {
      "epoch": 0.023228803716608595,
      "grad_norm": 2.2587242126464844,
      "learning_rate": 4.988385598141696e-05,
      "loss": 2.2501,
      "step": 100
    },
    {
      "epoch": 0.025551684088269456,
      "grad_norm": 2.3465182781219482,
      "learning_rate": 4.987224157955865e-05,
      "loss": 2.1104,
      "step": 110
    },
    {
      "epoch": 0.027874564459930314,
      "grad_norm": 2.480545997619629,
      "learning_rate": 4.986062717770035e-05,
      "loss": 2.1029,
      "step": 120
    },
    {
      "epoch": 0.030197444831591175,
      "grad_norm": 3.0560925006866455,
      "learning_rate": 4.984901277584205e-05,
      "loss": 2.0545,
      "step": 130
    },
    {
      "epoch": 0.032520325203252036,
      "grad_norm": 5.264778137207031,
      "learning_rate": 4.983739837398374e-05,
      "loss": 2.0121,
      "step": 140
    },
    {
      "epoch": 0.03484320557491289,
      "grad_norm": 3.6190059185028076,
      "learning_rate": 4.9825783972125436e-05,
      "loss": 1.9973,
      "step": 150
    },
    {
      "epoch": 0.03716608594657375,
      "grad_norm": 3.83161997795105,
      "learning_rate": 4.981416957026713e-05,
      "loss": 1.9293,
      "step": 160
    },
    {
      "epoch": 0.03948896631823461,
      "grad_norm": 3.9130897521972656,
      "learning_rate": 4.980255516840883e-05,
      "loss": 1.8587,
      "step": 170
    },
    {
      "epoch": 0.041811846689895474,
      "grad_norm": 4.103598594665527,
      "learning_rate": 4.979094076655053e-05,
      "loss": 1.935,
      "step": 180
    },
    {
      "epoch": 0.04413472706155633,
      "grad_norm": 4.09823751449585,
      "learning_rate": 4.977932636469222e-05,
      "loss": 1.8789,
      "step": 190
    },
    {
      "epoch": 0.04645760743321719,
      "grad_norm": 4.2242865562438965,
      "learning_rate": 4.9767711962833916e-05,
      "loss": 1.7951,
      "step": 200
    },
    {
      "epoch": 0.04878048780487805,
      "grad_norm": 3.7172772884368896,
      "learning_rate": 4.975609756097561e-05,
      "loss": 1.7086,
      "step": 210
    },
    {
      "epoch": 0.05110336817653891,
      "grad_norm": 4.828609943389893,
      "learning_rate": 4.9744483159117306e-05,
      "loss": 1.6954,
      "step": 220
    },
    {
      "epoch": 0.053426248548199766,
      "grad_norm": 4.445600509643555,
      "learning_rate": 4.973286875725901e-05,
      "loss": 1.7779,
      "step": 230
    },
    {
      "epoch": 0.05574912891986063,
      "grad_norm": 4.444073677062988,
      "learning_rate": 4.9721254355400695e-05,
      "loss": 1.6601,
      "step": 240
    },
    {
      "epoch": 0.05807200929152149,
      "grad_norm": 4.487905025482178,
      "learning_rate": 4.9709639953542396e-05,
      "loss": 1.5892,
      "step": 250
    },
    {
      "epoch": 0.06039488966318235,
      "grad_norm": 3.9481472969055176,
      "learning_rate": 4.969802555168409e-05,
      "loss": 1.4983,
      "step": 260
    },
    {
      "epoch": 0.0627177700348432,
      "grad_norm": 4.762413501739502,
      "learning_rate": 4.9686411149825786e-05,
      "loss": 1.537,
      "step": 270
    },
    {
      "epoch": 0.06504065040650407,
      "grad_norm": 6.6108222007751465,
      "learning_rate": 4.967479674796748e-05,
      "loss": 1.494,
      "step": 280
    },
    {
      "epoch": 0.06736353077816493,
      "grad_norm": 4.107273101806641,
      "learning_rate": 4.9663182346109175e-05,
      "loss": 1.358,
      "step": 290
    },
    {
      "epoch": 0.06968641114982578,
      "grad_norm": 4.973257541656494,
      "learning_rate": 4.965156794425087e-05,
      "loss": 1.3974,
      "step": 300
    },
    {
      "epoch": 0.07200929152148665,
      "grad_norm": 5.326593399047852,
      "learning_rate": 4.963995354239257e-05,
      "loss": 1.2583,
      "step": 310
    },
    {
      "epoch": 0.0743321718931475,
      "grad_norm": 4.635058879852295,
      "learning_rate": 4.9628339140534266e-05,
      "loss": 1.2886,
      "step": 320
    },
    {
      "epoch": 0.07665505226480836,
      "grad_norm": 6.18398904800415,
      "learning_rate": 4.961672473867596e-05,
      "loss": 1.3025,
      "step": 330
    },
    {
      "epoch": 0.07897793263646923,
      "grad_norm": 5.476873874664307,
      "learning_rate": 4.9605110336817655e-05,
      "loss": 1.2057,
      "step": 340
    },
    {
      "epoch": 0.08130081300813008,
      "grad_norm": 5.281773090362549,
      "learning_rate": 4.959349593495935e-05,
      "loss": 1.2642,
      "step": 350
    },
    {
      "epoch": 0.08362369337979095,
      "grad_norm": 4.532435417175293,
      "learning_rate": 4.958188153310105e-05,
      "loss": 1.0964,
      "step": 360
    },
    {
      "epoch": 0.0859465737514518,
      "grad_norm": 4.828183174133301,
      "learning_rate": 4.957026713124274e-05,
      "loss": 1.1112,
      "step": 370
    },
    {
      "epoch": 0.08826945412311266,
      "grad_norm": 4.343795299530029,
      "learning_rate": 4.955865272938444e-05,
      "loss": 1.204,
      "step": 380
    },
    {
      "epoch": 0.09059233449477352,
      "grad_norm": 4.746907711029053,
      "learning_rate": 4.9547038327526135e-05,
      "loss": 1.0984,
      "step": 390
    },
    {
      "epoch": 0.09291521486643438,
      "grad_norm": 4.5493597984313965,
      "learning_rate": 4.953542392566783e-05,
      "loss": 1.0856,
      "step": 400
    },
    {
      "epoch": 0.09523809523809523,
      "grad_norm": 4.927189826965332,
      "learning_rate": 4.9523809523809525e-05,
      "loss": 1.0921,
      "step": 410
    },
    {
      "epoch": 0.0975609756097561,
      "grad_norm": 4.972969055175781,
      "learning_rate": 4.951219512195122e-05,
      "loss": 1.0391,
      "step": 420
    },
    {
      "epoch": 0.09988385598141696,
      "grad_norm": 4.352423191070557,
      "learning_rate": 4.9500580720092914e-05,
      "loss": 1.1219,
      "step": 430
    },
    {
      "epoch": 0.10220673635307782,
      "grad_norm": 4.295955181121826,
      "learning_rate": 4.9488966318234615e-05,
      "loss": 0.9626,
      "step": 440
    },
    {
      "epoch": 0.10452961672473868,
      "grad_norm": 4.705641746520996,
      "learning_rate": 4.947735191637631e-05,
      "loss": 0.9854,
      "step": 450
    },
    {
      "epoch": 0.10685249709639953,
      "grad_norm": 4.647184371948242,
      "learning_rate": 4.9465737514518005e-05,
      "loss": 0.8507,
      "step": 460
    },
    {
      "epoch": 0.1091753774680604,
      "grad_norm": 4.14623498916626,
      "learning_rate": 4.94541231126597e-05,
      "loss": 0.9889,
      "step": 470
    },
    {
      "epoch": 0.11149825783972125,
      "grad_norm": 5.379075527191162,
      "learning_rate": 4.9442508710801394e-05,
      "loss": 0.9851,
      "step": 480
    },
    {
      "epoch": 0.11382113821138211,
      "grad_norm": 4.883697986602783,
      "learning_rate": 4.9430894308943096e-05,
      "loss": 0.8614,
      "step": 490
    },
    {
      "epoch": 0.11614401858304298,
      "grad_norm": 4.879951477050781,
      "learning_rate": 4.9419279907084783e-05,
      "loss": 1.0794,
      "step": 500
    },
    {
      "epoch": 0.11846689895470383,
      "grad_norm": 3.8940813541412354,
      "learning_rate": 4.9407665505226485e-05,
      "loss": 1.084,
      "step": 510
    },
    {
      "epoch": 0.1207897793263647,
      "grad_norm": 4.646535396575928,
      "learning_rate": 4.939605110336818e-05,
      "loss": 0.8712,
      "step": 520
    },
    {
      "epoch": 0.12311265969802555,
      "grad_norm": 4.788023948669434,
      "learning_rate": 4.9384436701509874e-05,
      "loss": 0.9527,
      "step": 530
    },
    {
      "epoch": 0.1254355400696864,
      "grad_norm": 3.721606492996216,
      "learning_rate": 4.937282229965157e-05,
      "loss": 0.8468,
      "step": 540
    },
    {
      "epoch": 0.12775842044134728,
      "grad_norm": 3.960266590118408,
      "learning_rate": 4.9361207897793264e-05,
      "loss": 0.8006,
      "step": 550
    },
    {
      "epoch": 0.13008130081300814,
      "grad_norm": 4.225877285003662,
      "learning_rate": 4.934959349593496e-05,
      "loss": 0.7849,
      "step": 560
    },
    {
      "epoch": 0.13240418118466898,
      "grad_norm": 4.673048973083496,
      "learning_rate": 4.933797909407666e-05,
      "loss": 0.7628,
      "step": 570
    },
    {
      "epoch": 0.13472706155632985,
      "grad_norm": 3.8308560848236084,
      "learning_rate": 4.9326364692218354e-05,
      "loss": 0.7861,
      "step": 580
    },
    {
      "epoch": 0.13704994192799072,
      "grad_norm": 4.687866687774658,
      "learning_rate": 4.931475029036005e-05,
      "loss": 0.7832,
      "step": 590
    },
    {
      "epoch": 0.13937282229965156,
      "grad_norm": 4.832542419433594,
      "learning_rate": 4.9303135888501744e-05,
      "loss": 0.6842,
      "step": 600
    },
    {
      "epoch": 0.14169570267131243,
      "grad_norm": 5.032644748687744,
      "learning_rate": 4.929152148664344e-05,
      "loss": 0.7627,
      "step": 610
    },
    {
      "epoch": 0.1440185830429733,
      "grad_norm": 5.385623931884766,
      "learning_rate": 4.927990708478514e-05,
      "loss": 0.6388,
      "step": 620
    },
    {
      "epoch": 0.14634146341463414,
      "grad_norm": 4.78049898147583,
      "learning_rate": 4.926829268292683e-05,
      "loss": 0.6935,
      "step": 630
    },
    {
      "epoch": 0.148664343786295,
      "grad_norm": 4.113974571228027,
      "learning_rate": 4.925667828106852e-05,
      "loss": 0.724,
      "step": 640
    },
    {
      "epoch": 0.15098722415795587,
      "grad_norm": 4.487897872924805,
      "learning_rate": 4.9245063879210224e-05,
      "loss": 0.7012,
      "step": 650
    },
    {
      "epoch": 0.15331010452961671,
      "grad_norm": 4.042518615722656,
      "learning_rate": 4.923344947735192e-05,
      "loss": 0.608,
      "step": 660
    },
    {
      "epoch": 0.15563298490127758,
      "grad_norm": 4.721157073974609,
      "learning_rate": 4.922183507549361e-05,
      "loss": 0.6468,
      "step": 670
    },
    {
      "epoch": 0.15795586527293845,
      "grad_norm": 5.82615327835083,
      "learning_rate": 4.921022067363531e-05,
      "loss": 0.6116,
      "step": 680
    },
    {
      "epoch": 0.1602787456445993,
      "grad_norm": 4.195526599884033,
      "learning_rate": 4.9198606271777e-05,
      "loss": 0.6616,
      "step": 690
    },
    {
      "epoch": 0.16260162601626016,
      "grad_norm": 4.1002326011657715,
      "learning_rate": 4.9186991869918704e-05,
      "loss": 0.7822,
      "step": 700
    },
    {
      "epoch": 0.16492450638792103,
      "grad_norm": 3.829524040222168,
      "learning_rate": 4.91753774680604e-05,
      "loss": 0.5856,
      "step": 710
    },
    {
      "epoch": 0.1672473867595819,
      "grad_norm": 4.138582706451416,
      "learning_rate": 4.916376306620209e-05,
      "loss": 0.5467,
      "step": 720
    },
    {
      "epoch": 0.16957026713124274,
      "grad_norm": 3.9932141304016113,
      "learning_rate": 4.915214866434379e-05,
      "loss": 0.5641,
      "step": 730
    },
    {
      "epoch": 0.1718931475029036,
      "grad_norm": 3.9727931022644043,
      "learning_rate": 4.914053426248548e-05,
      "loss": 0.5267,
      "step": 740
    },
    {
      "epoch": 0.17421602787456447,
      "grad_norm": 4.286433696746826,
      "learning_rate": 4.9128919860627184e-05,
      "loss": 0.6582,
      "step": 750
    },
    {
      "epoch": 0.1765389082462253,
      "grad_norm": 4.551760196685791,
      "learning_rate": 4.911730545876887e-05,
      "loss": 0.5817,
      "step": 760
    },
    {
      "epoch": 0.17886178861788618,
      "grad_norm": 3.872277021408081,
      "learning_rate": 4.910569105691057e-05,
      "loss": 0.5633,
      "step": 770
    },
    {
      "epoch": 0.18118466898954705,
      "grad_norm": 3.2890758514404297,
      "learning_rate": 4.909407665505227e-05,
      "loss": 0.5589,
      "step": 780
    },
    {
      "epoch": 0.1835075493612079,
      "grad_norm": 3.07098388671875,
      "learning_rate": 4.908246225319396e-05,
      "loss": 0.4424,
      "step": 790
    },
    {
      "epoch": 0.18583042973286876,
      "grad_norm": 3.063959836959839,
      "learning_rate": 4.907084785133566e-05,
      "loss": 0.5642,
      "step": 800
    },
    {
      "epoch": 0.18815331010452963,
      "grad_norm": 3.638185977935791,
      "learning_rate": 4.905923344947735e-05,
      "loss": 0.5128,
      "step": 810
    },
    {
      "epoch": 0.19047619047619047,
      "grad_norm": 4.342662334442139,
      "learning_rate": 4.904761904761905e-05,
      "loss": 0.515,
      "step": 820
    },
    {
      "epoch": 0.19279907084785133,
      "grad_norm": 3.115900754928589,
      "learning_rate": 4.903600464576075e-05,
      "loss": 0.5269,
      "step": 830
    },
    {
      "epoch": 0.1951219512195122,
      "grad_norm": 2.8269853591918945,
      "learning_rate": 4.902439024390244e-05,
      "loss": 0.5985,
      "step": 840
    },
    {
      "epoch": 0.19744483159117304,
      "grad_norm": 4.040099143981934,
      "learning_rate": 4.901277584204414e-05,
      "loss": 0.4938,
      "step": 850
    },
    {
      "epoch": 0.1997677119628339,
      "grad_norm": 3.319010019302368,
      "learning_rate": 4.900116144018583e-05,
      "loss": 0.5348,
      "step": 860
    },
    {
      "epoch": 0.20209059233449478,
      "grad_norm": 3.49912691116333,
      "learning_rate": 4.898954703832753e-05,
      "loss": 0.5229,
      "step": 870
    },
    {
      "epoch": 0.20441347270615565,
      "grad_norm": 2.8602867126464844,
      "learning_rate": 4.897793263646923e-05,
      "loss": 0.4487,
      "step": 880
    },
    {
      "epoch": 0.2067363530778165,
      "grad_norm": 3.2578611373901367,
      "learning_rate": 4.8966318234610916e-05,
      "loss": 0.4189,
      "step": 890
    },
    {
      "epoch": 0.20905923344947736,
      "grad_norm": 3.67592453956604,
      "learning_rate": 4.895470383275261e-05,
      "loss": 0.5094,
      "step": 900
    },
    {
      "epoch": 0.21138211382113822,
      "grad_norm": 3.0505177974700928,
      "learning_rate": 4.894308943089431e-05,
      "loss": 0.4223,
      "step": 910
    },
    {
      "epoch": 0.21370499419279906,
      "grad_norm": 3.1308765411376953,
      "learning_rate": 4.893147502903601e-05,
      "loss": 0.4871,
      "step": 920
    },
    {
      "epoch": 0.21602787456445993,
      "grad_norm": 2.8005337715148926,
      "learning_rate": 4.89198606271777e-05,
      "loss": 0.508,
      "step": 930
    },
    {
      "epoch": 0.2183507549361208,
      "grad_norm": 3.082641124725342,
      "learning_rate": 4.8908246225319396e-05,
      "loss": 0.542,
      "step": 940
    },
    {
      "epoch": 0.22067363530778164,
      "grad_norm": 3.780801296234131,
      "learning_rate": 4.889663182346109e-05,
      "loss": 0.5055,
      "step": 950
    },
    {
      "epoch": 0.2229965156794425,
      "grad_norm": 3.2550559043884277,
      "learning_rate": 4.888501742160279e-05,
      "loss": 0.4873,
      "step": 960
    },
    {
      "epoch": 0.22531939605110338,
      "grad_norm": 2.9215643405914307,
      "learning_rate": 4.887340301974449e-05,
      "loss": 0.4253,
      "step": 970
    },
    {
      "epoch": 0.22764227642276422,
      "grad_norm": 3.1817233562469482,
      "learning_rate": 4.886178861788618e-05,
      "loss": 0.494,
      "step": 980
    },
    {
      "epoch": 0.22996515679442509,
      "grad_norm": 3.051518678665161,
      "learning_rate": 4.885017421602788e-05,
      "loss": 0.4973,
      "step": 990
    },
    {
      "epoch": 0.23228803716608595,
      "grad_norm": 3.5564041137695312,
      "learning_rate": 4.883855981416957e-05,
      "loss": 0.3664,
      "step": 1000
    },
    {
      "epoch": 0.2346109175377468,
      "grad_norm": 3.2592732906341553,
      "learning_rate": 4.882694541231127e-05,
      "loss": 0.3917,
      "step": 1010
    },
    {
      "epoch": 0.23693379790940766,
      "grad_norm": 3.023231267929077,
      "learning_rate": 4.881533101045296e-05,
      "loss": 0.4458,
      "step": 1020
    },
    {
      "epoch": 0.23925667828106853,
      "grad_norm": 2.918576240539551,
      "learning_rate": 4.8803716608594655e-05,
      "loss": 0.3593,
      "step": 1030
    },
    {
      "epoch": 0.2415795586527294,
      "grad_norm": 3.4286670684814453,
      "learning_rate": 4.879210220673636e-05,
      "loss": 0.4161,
      "step": 1040
    },
    {
      "epoch": 0.24390243902439024,
      "grad_norm": 3.2877583503723145,
      "learning_rate": 4.878048780487805e-05,
      "loss": 0.3542,
      "step": 1050
    },
    {
      "epoch": 0.2462253193960511,
      "grad_norm": 3.780341386795044,
      "learning_rate": 4.8768873403019746e-05,
      "loss": 0.4649,
      "step": 1060
    },
    {
      "epoch": 0.24854819976771197,
      "grad_norm": 3.2792489528656006,
      "learning_rate": 4.875725900116144e-05,
      "loss": 0.3184,
      "step": 1070
    },
    {
      "epoch": 0.2508710801393728,
      "grad_norm": 2.829632043838501,
      "learning_rate": 4.8745644599303135e-05,
      "loss": 0.4406,
      "step": 1080
    },
    {
      "epoch": 0.25319396051103366,
      "grad_norm": 3.543605089187622,
      "learning_rate": 4.873403019744484e-05,
      "loss": 0.4897,
      "step": 1090
    },
    {
      "epoch": 0.25551684088269455,
      "grad_norm": 3.1735432147979736,
      "learning_rate": 4.872241579558653e-05,
      "loss": 0.3254,
      "step": 1100
    },
    {
      "epoch": 0.2578397212543554,
      "grad_norm": 2.6501283645629883,
      "learning_rate": 4.871080139372822e-05,
      "loss": 0.3859,
      "step": 1110
    },
    {
      "epoch": 0.2601626016260163,
      "grad_norm": 2.995797872543335,
      "learning_rate": 4.869918699186992e-05,
      "loss": 0.4042,
      "step": 1120
    },
    {
      "epoch": 0.26248548199767713,
      "grad_norm": 2.6728522777557373,
      "learning_rate": 4.8687572590011616e-05,
      "loss": 0.3136,
      "step": 1130
    },
    {
      "epoch": 0.26480836236933797,
      "grad_norm": 2.5943048000335693,
      "learning_rate": 4.867595818815332e-05,
      "loss": 0.4799,
      "step": 1140
    },
    {
      "epoch": 0.26713124274099886,
      "grad_norm": 2.36509108543396,
      "learning_rate": 4.8664343786295005e-05,
      "loss": 0.4609,
      "step": 1150
    },
    {
      "epoch": 0.2694541231126597,
      "grad_norm": 2.944246768951416,
      "learning_rate": 4.86527293844367e-05,
      "loss": 0.5295,
      "step": 1160
    },
    {
      "epoch": 0.27177700348432055,
      "grad_norm": 3.4564876556396484,
      "learning_rate": 4.86411149825784e-05,
      "loss": 0.3153,
      "step": 1170
    },
    {
      "epoch": 0.27409988385598144,
      "grad_norm": 3.45503306388855,
      "learning_rate": 4.8629500580720096e-05,
      "loss": 0.5474,
      "step": 1180
    },
    {
      "epoch": 0.2764227642276423,
      "grad_norm": 2.6247599124908447,
      "learning_rate": 4.861788617886179e-05,
      "loss": 0.3208,
      "step": 1190
    },
    {
      "epoch": 0.2787456445993031,
      "grad_norm": 3.097536563873291,
      "learning_rate": 4.8606271777003485e-05,
      "loss": 0.4279,
      "step": 1200
    },
    {
      "epoch": 0.281068524970964,
      "grad_norm": 3.184919834136963,
      "learning_rate": 4.859465737514518e-05,
      "loss": 0.4655,
      "step": 1210
    },
    {
      "epoch": 0.28339140534262486,
      "grad_norm": 3.2030081748962402,
      "learning_rate": 4.858304297328688e-05,
      "loss": 0.4616,
      "step": 1220
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 2.8136534690856934,
      "learning_rate": 4.8571428571428576e-05,
      "loss": 0.3278,
      "step": 1230
    },
    {
      "epoch": 0.2880371660859466,
      "grad_norm": 3.522275686264038,
      "learning_rate": 4.8559814169570264e-05,
      "loss": 0.3891,
      "step": 1240
    },
    {
      "epoch": 0.29036004645760743,
      "grad_norm": 3.47194504737854,
      "learning_rate": 4.8548199767711965e-05,
      "loss": 0.4115,
      "step": 1250
    },
    {
      "epoch": 0.2926829268292683,
      "grad_norm": 3.036341905593872,
      "learning_rate": 4.853658536585366e-05,
      "loss": 0.34,
      "step": 1260
    },
    {
      "epoch": 0.29500580720092917,
      "grad_norm": 2.451205253601074,
      "learning_rate": 4.852497096399536e-05,
      "loss": 0.372,
      "step": 1270
    },
    {
      "epoch": 0.29732868757259,
      "grad_norm": 2.9984869956970215,
      "learning_rate": 4.851335656213705e-05,
      "loss": 0.3399,
      "step": 1280
    },
    {
      "epoch": 0.29965156794425085,
      "grad_norm": 2.7966973781585693,
      "learning_rate": 4.8501742160278744e-05,
      "loss": 0.426,
      "step": 1290
    },
    {
      "epoch": 0.30197444831591175,
      "grad_norm": 2.7437992095947266,
      "learning_rate": 4.8490127758420445e-05,
      "loss": 0.3464,
      "step": 1300
    },
    {
      "epoch": 0.3042973286875726,
      "grad_norm": 3.4798190593719482,
      "learning_rate": 4.847851335656214e-05,
      "loss": 0.3964,
      "step": 1310
    },
    {
      "epoch": 0.30662020905923343,
      "grad_norm": 2.6257920265197754,
      "learning_rate": 4.8466898954703835e-05,
      "loss": 0.4185,
      "step": 1320
    },
    {
      "epoch": 0.3089430894308943,
      "grad_norm": 3.55505108833313,
      "learning_rate": 4.845528455284553e-05,
      "loss": 0.3447,
      "step": 1330
    },
    {
      "epoch": 0.31126596980255516,
      "grad_norm": 3.085900068283081,
      "learning_rate": 4.8443670150987224e-05,
      "loss": 0.3625,
      "step": 1340
    },
    {
      "epoch": 0.313588850174216,
      "grad_norm": 3.015092372894287,
      "learning_rate": 4.8432055749128926e-05,
      "loss": 0.4291,
      "step": 1350
    },
    {
      "epoch": 0.3159117305458769,
      "grad_norm": 2.7983057498931885,
      "learning_rate": 4.842044134727062e-05,
      "loss": 0.3348,
      "step": 1360
    },
    {
      "epoch": 0.31823461091753774,
      "grad_norm": 2.766915798187256,
      "learning_rate": 4.840882694541231e-05,
      "loss": 0.4555,
      "step": 1370
    },
    {
      "epoch": 0.3205574912891986,
      "grad_norm": 4.4340691566467285,
      "learning_rate": 4.839721254355401e-05,
      "loss": 0.3635,
      "step": 1380
    },
    {
      "epoch": 0.3228803716608595,
      "grad_norm": 2.4849143028259277,
      "learning_rate": 4.8385598141695704e-05,
      "loss": 0.4654,
      "step": 1390
    },
    {
      "epoch": 0.3252032520325203,
      "grad_norm": 2.2566518783569336,
      "learning_rate": 4.8373983739837406e-05,
      "loss": 0.2756,
      "step": 1400
    },
    {
      "epoch": 0.32752613240418116,
      "grad_norm": 3.395189046859741,
      "learning_rate": 4.8362369337979094e-05,
      "loss": 0.3534,
      "step": 1410
    },
    {
      "epoch": 0.32984901277584205,
      "grad_norm": 2.9909777641296387,
      "learning_rate": 4.835075493612079e-05,
      "loss": 0.2231,
      "step": 1420
    },
    {
      "epoch": 0.3321718931475029,
      "grad_norm": 2.4950859546661377,
      "learning_rate": 4.833914053426249e-05,
      "loss": 0.2626,
      "step": 1430
    },
    {
      "epoch": 0.3344947735191638,
      "grad_norm": 3.1465561389923096,
      "learning_rate": 4.8327526132404184e-05,
      "loss": 0.2896,
      "step": 1440
    },
    {
      "epoch": 0.33681765389082463,
      "grad_norm": 2.2299017906188965,
      "learning_rate": 4.831591173054588e-05,
      "loss": 0.3758,
      "step": 1450
    },
    {
      "epoch": 0.33914053426248547,
      "grad_norm": 2.7283942699432373,
      "learning_rate": 4.8304297328687574e-05,
      "loss": 0.2636,
      "step": 1460
    },
    {
      "epoch": 0.34146341463414637,
      "grad_norm": 2.5789008140563965,
      "learning_rate": 4.829268292682927e-05,
      "loss": 0.2761,
      "step": 1470
    },
    {
      "epoch": 0.3437862950058072,
      "grad_norm": 1.9922031164169312,
      "learning_rate": 4.828106852497097e-05,
      "loss": 0.4016,
      "step": 1480
    },
    {
      "epoch": 0.34610917537746805,
      "grad_norm": 2.671720504760742,
      "learning_rate": 4.8269454123112664e-05,
      "loss": 0.2995,
      "step": 1490
    },
    {
      "epoch": 0.34843205574912894,
      "grad_norm": 2.886042356491089,
      "learning_rate": 4.825783972125435e-05,
      "loss": 0.2447,
      "step": 1500
    },
    {
      "epoch": 0.3507549361207898,
      "grad_norm": 2.1006863117218018,
      "learning_rate": 4.8246225319396054e-05,
      "loss": 0.3131,
      "step": 1510
    },
    {
      "epoch": 0.3530778164924506,
      "grad_norm": 2.6097002029418945,
      "learning_rate": 4.823461091753775e-05,
      "loss": 0.3567,
      "step": 1520
    },
    {
      "epoch": 0.3554006968641115,
      "grad_norm": 2.085557699203491,
      "learning_rate": 4.822299651567945e-05,
      "loss": 0.2345,
      "step": 1530
    },
    {
      "epoch": 0.35772357723577236,
      "grad_norm": 2.713329315185547,
      "learning_rate": 4.821138211382114e-05,
      "loss": 0.3072,
      "step": 1540
    },
    {
      "epoch": 0.3600464576074332,
      "grad_norm": 1.9893908500671387,
      "learning_rate": 4.819976771196283e-05,
      "loss": 0.2992,
      "step": 1550
    },
    {
      "epoch": 0.3623693379790941,
      "grad_norm": 2.045503854751587,
      "learning_rate": 4.8188153310104534e-05,
      "loss": 0.2499,
      "step": 1560
    },
    {
      "epoch": 0.36469221835075494,
      "grad_norm": 2.607300043106079,
      "learning_rate": 4.817653890824623e-05,
      "loss": 0.3817,
      "step": 1570
    },
    {
      "epoch": 0.3670150987224158,
      "grad_norm": 2.534834623336792,
      "learning_rate": 4.816492450638792e-05,
      "loss": 0.2245,
      "step": 1580
    },
    {
      "epoch": 0.3693379790940767,
      "grad_norm": 2.3900277614593506,
      "learning_rate": 4.815331010452962e-05,
      "loss": 0.3269,
      "step": 1590
    },
    {
      "epoch": 0.3716608594657375,
      "grad_norm": 2.4380953311920166,
      "learning_rate": 4.814169570267131e-05,
      "loss": 0.2831,
      "step": 1600
    },
    {
      "epoch": 0.37398373983739835,
      "grad_norm": 4.69244909286499,
      "learning_rate": 4.8130081300813014e-05,
      "loss": 0.2947,
      "step": 1610
    },
    {
      "epoch": 0.37630662020905925,
      "grad_norm": 2.2753961086273193,
      "learning_rate": 4.811846689895471e-05,
      "loss": 0.3215,
      "step": 1620
    },
    {
      "epoch": 0.3786295005807201,
      "grad_norm": 2.2686350345611572,
      "learning_rate": 4.81068524970964e-05,
      "loss": 0.241,
      "step": 1630
    },
    {
      "epoch": 0.38095238095238093,
      "grad_norm": 2.2250571250915527,
      "learning_rate": 4.80952380952381e-05,
      "loss": 0.2129,
      "step": 1640
    },
    {
      "epoch": 0.3832752613240418,
      "grad_norm": 2.013033151626587,
      "learning_rate": 4.808362369337979e-05,
      "loss": 0.3909,
      "step": 1650
    },
    {
      "epoch": 0.38559814169570267,
      "grad_norm": 2.529144048690796,
      "learning_rate": 4.8072009291521494e-05,
      "loss": 0.3176,
      "step": 1660
    },
    {
      "epoch": 0.3879210220673635,
      "grad_norm": 2.602053642272949,
      "learning_rate": 4.806039488966318e-05,
      "loss": 0.2837,
      "step": 1670
    },
    {
      "epoch": 0.3902439024390244,
      "grad_norm": 2.5347509384155273,
      "learning_rate": 4.804878048780488e-05,
      "loss": 0.3505,
      "step": 1680
    },
    {
      "epoch": 0.39256678281068524,
      "grad_norm": 2.090784788131714,
      "learning_rate": 4.803716608594658e-05,
      "loss": 0.3425,
      "step": 1690
    },
    {
      "epoch": 0.3948896631823461,
      "grad_norm": 3.2423601150512695,
      "learning_rate": 4.802555168408827e-05,
      "loss": 0.3567,
      "step": 1700
    },
    {
      "epoch": 0.397212543554007,
      "grad_norm": 2.2712459564208984,
      "learning_rate": 4.801393728222997e-05,
      "loss": 0.2249,
      "step": 1710
    },
    {
      "epoch": 0.3995354239256678,
      "grad_norm": 3.080427646636963,
      "learning_rate": 4.800232288037166e-05,
      "loss": 0.3387,
      "step": 1720
    },
    {
      "epoch": 0.40185830429732866,
      "grad_norm": 3.521620512008667,
      "learning_rate": 4.799070847851336e-05,
      "loss": 0.3644,
      "step": 1730
    },
    {
      "epoch": 0.40418118466898956,
      "grad_norm": 2.4708714485168457,
      "learning_rate": 4.797909407665506e-05,
      "loss": 0.1877,
      "step": 1740
    },
    {
      "epoch": 0.4065040650406504,
      "grad_norm": 2.1116626262664795,
      "learning_rate": 4.796747967479675e-05,
      "loss": 0.3467,
      "step": 1750
    },
    {
      "epoch": 0.4088269454123113,
      "grad_norm": 2.32407283782959,
      "learning_rate": 4.795586527293844e-05,
      "loss": 0.313,
      "step": 1760
    },
    {
      "epoch": 0.41114982578397213,
      "grad_norm": 2.2957637310028076,
      "learning_rate": 4.794425087108014e-05,
      "loss": 0.2686,
      "step": 1770
    },
    {
      "epoch": 0.413472706155633,
      "grad_norm": 2.316514730453491,
      "learning_rate": 4.793263646922184e-05,
      "loss": 0.3721,
      "step": 1780
    },
    {
      "epoch": 0.41579558652729387,
      "grad_norm": 4.198129653930664,
      "learning_rate": 4.792102206736354e-05,
      "loss": 0.2111,
      "step": 1790
    },
    {
      "epoch": 0.4181184668989547,
      "grad_norm": 1.8195319175720215,
      "learning_rate": 4.7909407665505226e-05,
      "loss": 0.3127,
      "step": 1800
    },
    {
      "epoch": 0.42044134727061555,
      "grad_norm": 1.9397276639938354,
      "learning_rate": 4.789779326364692e-05,
      "loss": 0.4038,
      "step": 1810
    },
    {
      "epoch": 0.42276422764227645,
      "grad_norm": 2.1001129150390625,
      "learning_rate": 4.788617886178862e-05,
      "loss": 0.286,
      "step": 1820
    },
    {
      "epoch": 0.4250871080139373,
      "grad_norm": 1.8488035202026367,
      "learning_rate": 4.787456445993032e-05,
      "loss": 0.3687,
      "step": 1830
    },
    {
      "epoch": 0.4274099883855981,
      "grad_norm": 2.372579336166382,
      "learning_rate": 4.786295005807201e-05,
      "loss": 0.2696,
      "step": 1840
    },
    {
      "epoch": 0.429732868757259,
      "grad_norm": 1.8044930696487427,
      "learning_rate": 4.7851335656213707e-05,
      "loss": 0.2392,
      "step": 1850
    },
    {
      "epoch": 0.43205574912891986,
      "grad_norm": 1.8736649751663208,
      "learning_rate": 4.78397212543554e-05,
      "loss": 0.2322,
      "step": 1860
    },
    {
      "epoch": 0.4343786295005807,
      "grad_norm": 2.0094494819641113,
      "learning_rate": 4.78281068524971e-05,
      "loss": 0.2008,
      "step": 1870
    },
    {
      "epoch": 0.4367015098722416,
      "grad_norm": 1.9307982921600342,
      "learning_rate": 4.78164924506388e-05,
      "loss": 0.2599,
      "step": 1880
    },
    {
      "epoch": 0.43902439024390244,
      "grad_norm": 2.327982187271118,
      "learning_rate": 4.7804878048780485e-05,
      "loss": 0.2609,
      "step": 1890
    },
    {
      "epoch": 0.4413472706155633,
      "grad_norm": 2.0614190101623535,
      "learning_rate": 4.779326364692219e-05,
      "loss": 0.3425,
      "step": 1900
    },
    {
      "epoch": 0.4436701509872242,
      "grad_norm": 1.9750339984893799,
      "learning_rate": 4.778164924506388e-05,
      "loss": 0.1837,
      "step": 1910
    },
    {
      "epoch": 0.445993031358885,
      "grad_norm": 2.329068422317505,
      "learning_rate": 4.7770034843205576e-05,
      "loss": 0.2599,
      "step": 1920
    },
    {
      "epoch": 0.44831591173054586,
      "grad_norm": 2.582120418548584,
      "learning_rate": 4.775842044134727e-05,
      "loss": 0.3201,
      "step": 1930
    },
    {
      "epoch": 0.45063879210220675,
      "grad_norm": 2.2360095977783203,
      "learning_rate": 4.7746806039488965e-05,
      "loss": 0.3181,
      "step": 1940
    },
    {
      "epoch": 0.4529616724738676,
      "grad_norm": 2.411498785018921,
      "learning_rate": 4.773519163763067e-05,
      "loss": 0.3377,
      "step": 1950
    },
    {
      "epoch": 0.45528455284552843,
      "grad_norm": 1.785799264907837,
      "learning_rate": 4.772357723577236e-05,
      "loss": 0.3458,
      "step": 1960
    },
    {
      "epoch": 0.45760743321718933,
      "grad_norm": 4.245331287384033,
      "learning_rate": 4.7711962833914056e-05,
      "loss": 0.2889,
      "step": 1970
    },
    {
      "epoch": 0.45993031358885017,
      "grad_norm": 2.81764817237854,
      "learning_rate": 4.770034843205575e-05,
      "loss": 0.3104,
      "step": 1980
    },
    {
      "epoch": 0.462253193960511,
      "grad_norm": 2.5169808864593506,
      "learning_rate": 4.7688734030197446e-05,
      "loss": 0.304,
      "step": 1990
    },
    {
      "epoch": 0.4645760743321719,
      "grad_norm": 1.9075855016708374,
      "learning_rate": 4.767711962833915e-05,
      "loss": 0.3203,
      "step": 2000
    },
    {
      "epoch": 0.46689895470383275,
      "grad_norm": 2.066666603088379,
      "learning_rate": 4.766550522648084e-05,
      "loss": 0.2736,
      "step": 2010
    },
    {
      "epoch": 0.4692218350754936,
      "grad_norm": 2.2257936000823975,
      "learning_rate": 4.765389082462253e-05,
      "loss": 0.2803,
      "step": 2020
    },
    {
      "epoch": 0.4715447154471545,
      "grad_norm": 1.9377577304840088,
      "learning_rate": 4.764227642276423e-05,
      "loss": 0.2956,
      "step": 2030
    },
    {
      "epoch": 0.4738675958188153,
      "grad_norm": 2.3989171981811523,
      "learning_rate": 4.7630662020905926e-05,
      "loss": 0.3217,
      "step": 2040
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 3.152517795562744,
      "learning_rate": 4.761904761904762e-05,
      "loss": 0.4072,
      "step": 2050
    },
    {
      "epoch": 0.47851335656213706,
      "grad_norm": 1.932955026626587,
      "learning_rate": 4.7607433217189315e-05,
      "loss": 0.4823,
      "step": 2060
    },
    {
      "epoch": 0.4808362369337979,
      "grad_norm": 2.2821176052093506,
      "learning_rate": 4.759581881533101e-05,
      "loss": 0.2654,
      "step": 2070
    },
    {
      "epoch": 0.4831591173054588,
      "grad_norm": 2.461207866668701,
      "learning_rate": 4.758420441347271e-05,
      "loss": 0.1672,
      "step": 2080
    },
    {
      "epoch": 0.48548199767711964,
      "grad_norm": 2.1671230792999268,
      "learning_rate": 4.7572590011614406e-05,
      "loss": 0.2454,
      "step": 2090
    },
    {
      "epoch": 0.4878048780487805,
      "grad_norm": 1.7450239658355713,
      "learning_rate": 4.75609756097561e-05,
      "loss": 0.2659,
      "step": 2100
    },
    {
      "epoch": 0.4901277584204414,
      "grad_norm": 4.372551441192627,
      "learning_rate": 4.7549361207897795e-05,
      "loss": 0.2649,
      "step": 2110
    },
    {
      "epoch": 0.4924506387921022,
      "grad_norm": 1.5860718488693237,
      "learning_rate": 4.753774680603949e-05,
      "loss": 0.3061,
      "step": 2120
    },
    {
      "epoch": 0.49477351916376305,
      "grad_norm": 1.6396676301956177,
      "learning_rate": 4.752613240418119e-05,
      "loss": 0.2833,
      "step": 2130
    },
    {
      "epoch": 0.49709639953542395,
      "grad_norm": 4.135105609893799,
      "learning_rate": 4.7514518002322886e-05,
      "loss": 0.3057,
      "step": 2140
    },
    {
      "epoch": 0.4994192799070848,
      "grad_norm": 1.8814595937728882,
      "learning_rate": 4.7502903600464574e-05,
      "loss": 0.2635,
      "step": 2150
    },
    {
      "epoch": 0.5017421602787456,
      "grad_norm": 1.844626784324646,
      "learning_rate": 4.7491289198606275e-05,
      "loss": 0.2522,
      "step": 2160
    },
    {
      "epoch": 0.5040650406504065,
      "grad_norm": 2.5577170848846436,
      "learning_rate": 4.747967479674797e-05,
      "loss": 0.3134,
      "step": 2170
    },
    {
      "epoch": 0.5063879210220673,
      "grad_norm": 1.784026026725769,
      "learning_rate": 4.7468060394889665e-05,
      "loss": 0.2713,
      "step": 2180
    },
    {
      "epoch": 0.5087108013937283,
      "grad_norm": 2.8532819747924805,
      "learning_rate": 4.745644599303136e-05,
      "loss": 0.2538,
      "step": 2190
    },
    {
      "epoch": 0.5110336817653891,
      "grad_norm": 1.6566853523254395,
      "learning_rate": 4.7444831591173054e-05,
      "loss": 0.2776,
      "step": 2200
    },
    {
      "epoch": 0.5133565621370499,
      "grad_norm": 2.460451602935791,
      "learning_rate": 4.7433217189314755e-05,
      "loss": 0.2416,
      "step": 2210
    },
    {
      "epoch": 0.5156794425087108,
      "grad_norm": 1.918418049812317,
      "learning_rate": 4.742160278745645e-05,
      "loss": 0.283,
      "step": 2220
    },
    {
      "epoch": 0.5180023228803716,
      "grad_norm": 2.064039468765259,
      "learning_rate": 4.7409988385598145e-05,
      "loss": 0.3357,
      "step": 2230
    },
    {
      "epoch": 0.5203252032520326,
      "grad_norm": 1.4305291175842285,
      "learning_rate": 4.739837398373984e-05,
      "loss": 0.2763,
      "step": 2240
    },
    {
      "epoch": 0.5226480836236934,
      "grad_norm": 2.261945962905884,
      "learning_rate": 4.7386759581881534e-05,
      "loss": 0.3659,
      "step": 2250
    },
    {
      "epoch": 0.5249709639953543,
      "grad_norm": 2.5329809188842773,
      "learning_rate": 4.7375145180023236e-05,
      "loss": 0.3399,
      "step": 2260
    },
    {
      "epoch": 0.5272938443670151,
      "grad_norm": 2.1608998775482178,
      "learning_rate": 4.736353077816493e-05,
      "loss": 0.2827,
      "step": 2270
    },
    {
      "epoch": 0.5296167247386759,
      "grad_norm": 2.7972168922424316,
      "learning_rate": 4.735191637630662e-05,
      "loss": 0.2244,
      "step": 2280
    },
    {
      "epoch": 0.5319396051103368,
      "grad_norm": 2.036932945251465,
      "learning_rate": 4.734030197444832e-05,
      "loss": 0.371,
      "step": 2290
    },
    {
      "epoch": 0.5342624854819977,
      "grad_norm": 2.663971185684204,
      "learning_rate": 4.7328687572590014e-05,
      "loss": 0.342,
      "step": 2300
    },
    {
      "epoch": 0.5365853658536586,
      "grad_norm": 2.544069290161133,
      "learning_rate": 4.731707317073171e-05,
      "loss": 0.2287,
      "step": 2310
    },
    {
      "epoch": 0.5389082462253194,
      "grad_norm": 1.8778550624847412,
      "learning_rate": 4.7305458768873404e-05,
      "loss": 0.241,
      "step": 2320
    },
    {
      "epoch": 0.5412311265969802,
      "grad_norm": 2.8132026195526123,
      "learning_rate": 4.72938443670151e-05,
      "loss": 0.2687,
      "step": 2330
    },
    {
      "epoch": 0.5435540069686411,
      "grad_norm": 1.5789079666137695,
      "learning_rate": 4.72822299651568e-05,
      "loss": 0.2032,
      "step": 2340
    },
    {
      "epoch": 0.5458768873403019,
      "grad_norm": 2.12758207321167,
      "learning_rate": 4.7270615563298494e-05,
      "loss": 0.2983,
      "step": 2350
    },
    {
      "epoch": 0.5481997677119629,
      "grad_norm": 1.986830472946167,
      "learning_rate": 4.725900116144019e-05,
      "loss": 0.2419,
      "step": 2360
    },
    {
      "epoch": 0.5505226480836237,
      "grad_norm": 2.047462224960327,
      "learning_rate": 4.7247386759581884e-05,
      "loss": 0.1372,
      "step": 2370
    },
    {
      "epoch": 0.5528455284552846,
      "grad_norm": 2.2129547595977783,
      "learning_rate": 4.723577235772358e-05,
      "loss": 0.3956,
      "step": 2380
    },
    {
      "epoch": 0.5551684088269454,
      "grad_norm": 2.2628722190856934,
      "learning_rate": 4.722415795586527e-05,
      "loss": 0.2843,
      "step": 2390
    },
    {
      "epoch": 0.5574912891986062,
      "grad_norm": 1.844970464706421,
      "learning_rate": 4.7212543554006975e-05,
      "loss": 0.3062,
      "step": 2400
    },
    {
      "epoch": 0.5598141695702671,
      "grad_norm": 1.6893956661224365,
      "learning_rate": 4.720092915214866e-05,
      "loss": 0.2847,
      "step": 2410
    },
    {
      "epoch": 0.562137049941928,
      "grad_norm": 2.3803205490112305,
      "learning_rate": 4.7189314750290364e-05,
      "loss": 0.1641,
      "step": 2420
    },
    {
      "epoch": 0.5644599303135889,
      "grad_norm": 1.7447556257247925,
      "learning_rate": 4.717770034843206e-05,
      "loss": 0.3174,
      "step": 2430
    },
    {
      "epoch": 0.5667828106852497,
      "grad_norm": 1.7547310590744019,
      "learning_rate": 4.716608594657375e-05,
      "loss": 0.2518,
      "step": 2440
    },
    {
      "epoch": 0.5691056910569106,
      "grad_norm": 3.8481810092926025,
      "learning_rate": 4.715447154471545e-05,
      "loss": 0.2588,
      "step": 2450
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 2.8274683952331543,
      "learning_rate": 4.714285714285714e-05,
      "loss": 0.2297,
      "step": 2460
    },
    {
      "epoch": 0.5737514518002322,
      "grad_norm": 1.7356330156326294,
      "learning_rate": 4.7131242740998844e-05,
      "loss": 0.2701,
      "step": 2470
    },
    {
      "epoch": 0.5760743321718932,
      "grad_norm": 3.129699468612671,
      "learning_rate": 4.711962833914054e-05,
      "loss": 0.2835,
      "step": 2480
    },
    {
      "epoch": 0.578397212543554,
      "grad_norm": 1.4041754007339478,
      "learning_rate": 4.7108013937282233e-05,
      "loss": 0.1886,
      "step": 2490
    },
    {
      "epoch": 0.5807200929152149,
      "grad_norm": 2.3138129711151123,
      "learning_rate": 4.709639953542393e-05,
      "loss": 0.2656,
      "step": 2500
    },
    {
      "epoch": 0.5830429732868757,
      "grad_norm": 1.6719448566436768,
      "learning_rate": 4.708478513356562e-05,
      "loss": 0.2368,
      "step": 2510
    },
    {
      "epoch": 0.5853658536585366,
      "grad_norm": 2.0831282138824463,
      "learning_rate": 4.707317073170732e-05,
      "loss": 0.2584,
      "step": 2520
    },
    {
      "epoch": 0.5876887340301974,
      "grad_norm": 2.628906726837158,
      "learning_rate": 4.706155632984902e-05,
      "loss": 0.2931,
      "step": 2530
    },
    {
      "epoch": 0.5900116144018583,
      "grad_norm": 1.8193124532699585,
      "learning_rate": 4.704994192799071e-05,
      "loss": 0.2752,
      "step": 2540
    },
    {
      "epoch": 0.5923344947735192,
      "grad_norm": 1.9201078414916992,
      "learning_rate": 4.703832752613241e-05,
      "loss": 0.2477,
      "step": 2550
    },
    {
      "epoch": 0.59465737514518,
      "grad_norm": 2.8134429454803467,
      "learning_rate": 4.70267131242741e-05,
      "loss": 0.2397,
      "step": 2560
    },
    {
      "epoch": 0.5969802555168409,
      "grad_norm": 2.207895040512085,
      "learning_rate": 4.70150987224158e-05,
      "loss": 0.2359,
      "step": 2570
    },
    {
      "epoch": 0.5993031358885017,
      "grad_norm": 5.765288352966309,
      "learning_rate": 4.700348432055749e-05,
      "loss": 0.3528,
      "step": 2580
    },
    {
      "epoch": 0.6016260162601627,
      "grad_norm": 2.013547420501709,
      "learning_rate": 4.699186991869919e-05,
      "loss": 0.2284,
      "step": 2590
    },
    {
      "epoch": 0.6039488966318235,
      "grad_norm": 1.7699416875839233,
      "learning_rate": 4.698025551684089e-05,
      "loss": 0.2214,
      "step": 2600
    },
    {
      "epoch": 0.6062717770034843,
      "grad_norm": 3.639312267303467,
      "learning_rate": 4.696864111498258e-05,
      "loss": 0.3168,
      "step": 2610
    },
    {
      "epoch": 0.6085946573751452,
      "grad_norm": 1.931194543838501,
      "learning_rate": 4.695702671312428e-05,
      "loss": 0.2963,
      "step": 2620
    },
    {
      "epoch": 0.610917537746806,
      "grad_norm": 2.239736795425415,
      "learning_rate": 4.694541231126597e-05,
      "loss": 0.324,
      "step": 2630
    },
    {
      "epoch": 0.6132404181184669,
      "grad_norm": 1.585084319114685,
      "learning_rate": 4.693379790940767e-05,
      "loss": 0.3875,
      "step": 2640
    },
    {
      "epoch": 0.6155632984901278,
      "grad_norm": 1.6591172218322754,
      "learning_rate": 4.692218350754936e-05,
      "loss": 0.2437,
      "step": 2650
    },
    {
      "epoch": 0.6178861788617886,
      "grad_norm": 3.0280821323394775,
      "learning_rate": 4.691056910569106e-05,
      "loss": 0.299,
      "step": 2660
    },
    {
      "epoch": 0.6202090592334495,
      "grad_norm": 1.7260488271713257,
      "learning_rate": 4.689895470383275e-05,
      "loss": 0.239,
      "step": 2670
    },
    {
      "epoch": 0.6225319396051103,
      "grad_norm": 1.7138012647628784,
      "learning_rate": 4.688734030197445e-05,
      "loss": 0.1607,
      "step": 2680
    },
    {
      "epoch": 0.6248548199767712,
      "grad_norm": 1.629726767539978,
      "learning_rate": 4.687572590011615e-05,
      "loss": 0.2936,
      "step": 2690
    },
    {
      "epoch": 0.627177700348432,
      "grad_norm": 2.4897074699401855,
      "learning_rate": 4.686411149825784e-05,
      "loss": 0.3319,
      "step": 2700
    },
    {
      "epoch": 0.629500580720093,
      "grad_norm": 2.1149940490722656,
      "learning_rate": 4.6852497096399537e-05,
      "loss": 0.2109,
      "step": 2710
    },
    {
      "epoch": 0.6318234610917538,
      "grad_norm": 2.3169829845428467,
      "learning_rate": 4.684088269454123e-05,
      "loss": 0.1832,
      "step": 2720
    },
    {
      "epoch": 0.6341463414634146,
      "grad_norm": 1.5737274885177612,
      "learning_rate": 4.682926829268293e-05,
      "loss": 0.181,
      "step": 2730
    },
    {
      "epoch": 0.6364692218350755,
      "grad_norm": 1.9933782815933228,
      "learning_rate": 4.681765389082463e-05,
      "loss": 0.2442,
      "step": 2740
    },
    {
      "epoch": 0.6387921022067363,
      "grad_norm": 1.9535194635391235,
      "learning_rate": 4.680603948896632e-05,
      "loss": 0.197,
      "step": 2750
    },
    {
      "epoch": 0.6411149825783972,
      "grad_norm": 3.166293144226074,
      "learning_rate": 4.679442508710802e-05,
      "loss": 0.1835,
      "step": 2760
    },
    {
      "epoch": 0.6434378629500581,
      "grad_norm": 2.3762118816375732,
      "learning_rate": 4.678281068524971e-05,
      "loss": 0.3385,
      "step": 2770
    },
    {
      "epoch": 0.645760743321719,
      "grad_norm": 2.610551595687866,
      "learning_rate": 4.6771196283391406e-05,
      "loss": 0.2197,
      "step": 2780
    },
    {
      "epoch": 0.6480836236933798,
      "grad_norm": 1.2178497314453125,
      "learning_rate": 4.675958188153311e-05,
      "loss": 0.1587,
      "step": 2790
    },
    {
      "epoch": 0.6504065040650406,
      "grad_norm": 1.883383870124817,
      "learning_rate": 4.6747967479674795e-05,
      "loss": 0.2275,
      "step": 2800
    },
    {
      "epoch": 0.6527293844367015,
      "grad_norm": 1.2977325916290283,
      "learning_rate": 4.67363530778165e-05,
      "loss": 0.2664,
      "step": 2810
    },
    {
      "epoch": 0.6550522648083623,
      "grad_norm": 2.030795097351074,
      "learning_rate": 4.672473867595819e-05,
      "loss": 0.244,
      "step": 2820
    },
    {
      "epoch": 0.6573751451800233,
      "grad_norm": 2.5156710147857666,
      "learning_rate": 4.6713124274099886e-05,
      "loss": 0.3198,
      "step": 2830
    },
    {
      "epoch": 0.6596980255516841,
      "grad_norm": 2.2827060222625732,
      "learning_rate": 4.670150987224158e-05,
      "loss": 0.2617,
      "step": 2840
    },
    {
      "epoch": 0.662020905923345,
      "grad_norm": 1.8768857717514038,
      "learning_rate": 4.6689895470383275e-05,
      "loss": 0.2389,
      "step": 2850
    },
    {
      "epoch": 0.6643437862950058,
      "grad_norm": 1.6834971904754639,
      "learning_rate": 4.667828106852497e-05,
      "loss": 0.1916,
      "step": 2860
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 2.4338176250457764,
      "learning_rate": 4.666666666666667e-05,
      "loss": 0.271,
      "step": 2870
    },
    {
      "epoch": 0.6689895470383276,
      "grad_norm": 1.8339930772781372,
      "learning_rate": 4.6655052264808366e-05,
      "loss": 0.196,
      "step": 2880
    },
    {
      "epoch": 0.6713124274099884,
      "grad_norm": 1.3152450323104858,
      "learning_rate": 4.664343786295006e-05,
      "loss": 0.2839,
      "step": 2890
    },
    {
      "epoch": 0.6736353077816493,
      "grad_norm": 2.308129072189331,
      "learning_rate": 4.6631823461091756e-05,
      "loss": 0.3141,
      "step": 2900
    },
    {
      "epoch": 0.6759581881533101,
      "grad_norm": 2.8243978023529053,
      "learning_rate": 4.662020905923345e-05,
      "loss": 0.252,
      "step": 2910
    },
    {
      "epoch": 0.6782810685249709,
      "grad_norm": 1.9813275337219238,
      "learning_rate": 4.660859465737515e-05,
      "loss": 0.432,
      "step": 2920
    },
    {
      "epoch": 0.6806039488966318,
      "grad_norm": 2.973088026046753,
      "learning_rate": 4.659698025551684e-05,
      "loss": 0.2896,
      "step": 2930
    },
    {
      "epoch": 0.6829268292682927,
      "grad_norm": 1.7218540906906128,
      "learning_rate": 4.658536585365854e-05,
      "loss": 0.2873,
      "step": 2940
    },
    {
      "epoch": 0.6852497096399536,
      "grad_norm": 1.900380253791809,
      "learning_rate": 4.6573751451800236e-05,
      "loss": 0.2743,
      "step": 2950
    },
    {
      "epoch": 0.6875725900116144,
      "grad_norm": 2.1048552989959717,
      "learning_rate": 4.656213704994193e-05,
      "loss": 0.251,
      "step": 2960
    },
    {
      "epoch": 0.6898954703832753,
      "grad_norm": 1.8383122682571411,
      "learning_rate": 4.6550522648083625e-05,
      "loss": 0.2761,
      "step": 2970
    },
    {
      "epoch": 0.6922183507549361,
      "grad_norm": 1.9355645179748535,
      "learning_rate": 4.653890824622532e-05,
      "loss": 0.3043,
      "step": 2980
    },
    {
      "epoch": 0.6945412311265969,
      "grad_norm": 2.0018203258514404,
      "learning_rate": 4.6527293844367014e-05,
      "loss": 0.2028,
      "step": 2990
    },
    {
      "epoch": 0.6968641114982579,
      "grad_norm": 2.1149444580078125,
      "learning_rate": 4.6515679442508716e-05,
      "loss": 0.2044,
      "step": 3000
    },
    {
      "epoch": 0.6991869918699187,
      "grad_norm": 1.8017840385437012,
      "learning_rate": 4.650406504065041e-05,
      "loss": 0.2345,
      "step": 3010
    },
    {
      "epoch": 0.7015098722415796,
      "grad_norm": 1.3242769241333008,
      "learning_rate": 4.6492450638792105e-05,
      "loss": 0.2783,
      "step": 3020
    },
    {
      "epoch": 0.7038327526132404,
      "grad_norm": 1.5849740505218506,
      "learning_rate": 4.64808362369338e-05,
      "loss": 0.189,
      "step": 3030
    },
    {
      "epoch": 0.7061556329849012,
      "grad_norm": 1.58822762966156,
      "learning_rate": 4.6469221835075495e-05,
      "loss": 0.2568,
      "step": 3040
    },
    {
      "epoch": 0.7084785133565621,
      "grad_norm": 2.003847122192383,
      "learning_rate": 4.6457607433217196e-05,
      "loss": 0.1234,
      "step": 3050
    },
    {
      "epoch": 0.710801393728223,
      "grad_norm": 1.4180172681808472,
      "learning_rate": 4.6445993031358884e-05,
      "loss": 0.1479,
      "step": 3060
    },
    {
      "epoch": 0.7131242740998839,
      "grad_norm": 2.1391851902008057,
      "learning_rate": 4.6434378629500585e-05,
      "loss": 0.2748,
      "step": 3070
    },
    {
      "epoch": 0.7154471544715447,
      "grad_norm": 1.635695219039917,
      "learning_rate": 4.642276422764228e-05,
      "loss": 0.227,
      "step": 3080
    },
    {
      "epoch": 0.7177700348432056,
      "grad_norm": 1.8728066682815552,
      "learning_rate": 4.6411149825783975e-05,
      "loss": 0.2759,
      "step": 3090
    },
    {
      "epoch": 0.7200929152148664,
      "grad_norm": 2.0029470920562744,
      "learning_rate": 4.639953542392567e-05,
      "loss": 0.2588,
      "step": 3100
    },
    {
      "epoch": 0.7224157955865272,
      "grad_norm": 1.8543530702590942,
      "learning_rate": 4.6387921022067364e-05,
      "loss": 0.2636,
      "step": 3110
    },
    {
      "epoch": 0.7247386759581882,
      "grad_norm": 1.3826947212219238,
      "learning_rate": 4.637630662020906e-05,
      "loss": 0.1748,
      "step": 3120
    },
    {
      "epoch": 0.727061556329849,
      "grad_norm": 2.7427732944488525,
      "learning_rate": 4.636469221835076e-05,
      "loss": 0.2226,
      "step": 3130
    },
    {
      "epoch": 0.7293844367015099,
      "grad_norm": 1.6245756149291992,
      "learning_rate": 4.6353077816492455e-05,
      "loss": 0.2826,
      "step": 3140
    },
    {
      "epoch": 0.7317073170731707,
      "grad_norm": 1.7272120714187622,
      "learning_rate": 4.634146341463415e-05,
      "loss": 0.1621,
      "step": 3150
    },
    {
      "epoch": 0.7340301974448316,
      "grad_norm": 2.374110460281372,
      "learning_rate": 4.6329849012775844e-05,
      "loss": 0.1471,
      "step": 3160
    },
    {
      "epoch": 0.7363530778164924,
      "grad_norm": 1.819745421409607,
      "learning_rate": 4.631823461091754e-05,
      "loss": 0.3529,
      "step": 3170
    },
    {
      "epoch": 0.7386759581881533,
      "grad_norm": 1.3006469011306763,
      "learning_rate": 4.630662020905924e-05,
      "loss": 0.2044,
      "step": 3180
    },
    {
      "epoch": 0.7409988385598142,
      "grad_norm": 1.8984397649765015,
      "learning_rate": 4.629500580720093e-05,
      "loss": 0.2589,
      "step": 3190
    },
    {
      "epoch": 0.743321718931475,
      "grad_norm": 1.9469425678253174,
      "learning_rate": 4.628339140534262e-05,
      "loss": 0.2215,
      "step": 3200
    },
    {
      "epoch": 0.7456445993031359,
      "grad_norm": 1.6282590627670288,
      "learning_rate": 4.6271777003484324e-05,
      "loss": 0.2529,
      "step": 3210
    },
    {
      "epoch": 0.7479674796747967,
      "grad_norm": 1.7567896842956543,
      "learning_rate": 4.626016260162602e-05,
      "loss": 0.2022,
      "step": 3220
    },
    {
      "epoch": 0.7502903600464577,
      "grad_norm": 2.4786362648010254,
      "learning_rate": 4.6248548199767714e-05,
      "loss": 0.2712,
      "step": 3230
    },
    {
      "epoch": 0.7526132404181185,
      "grad_norm": 2.192037343978882,
      "learning_rate": 4.623693379790941e-05,
      "loss": 0.2267,
      "step": 3240
    },
    {
      "epoch": 0.7549361207897793,
      "grad_norm": 2.892643451690674,
      "learning_rate": 4.62253193960511e-05,
      "loss": 0.193,
      "step": 3250
    },
    {
      "epoch": 0.7572590011614402,
      "grad_norm": 2.0097224712371826,
      "learning_rate": 4.6213704994192805e-05,
      "loss": 0.249,
      "step": 3260
    },
    {
      "epoch": 0.759581881533101,
      "grad_norm": 1.2044323682785034,
      "learning_rate": 4.62020905923345e-05,
      "loss": 0.1912,
      "step": 3270
    },
    {
      "epoch": 0.7619047619047619,
      "grad_norm": 2.002574920654297,
      "learning_rate": 4.6190476190476194e-05,
      "loss": 0.1789,
      "step": 3280
    },
    {
      "epoch": 0.7642276422764228,
      "grad_norm": 3.0719425678253174,
      "learning_rate": 4.617886178861789e-05,
      "loss": 0.1841,
      "step": 3290
    },
    {
      "epoch": 0.7665505226480837,
      "grad_norm": 1.9300400018692017,
      "learning_rate": 4.616724738675958e-05,
      "loss": 0.2444,
      "step": 3300
    },
    {
      "epoch": 0.7688734030197445,
      "grad_norm": 1.4715040922164917,
      "learning_rate": 4.6155632984901285e-05,
      "loss": 0.2147,
      "step": 3310
    },
    {
      "epoch": 0.7711962833914053,
      "grad_norm": 2.0784904956817627,
      "learning_rate": 4.614401858304297e-05,
      "loss": 0.2273,
      "step": 3320
    },
    {
      "epoch": 0.7735191637630662,
      "grad_norm": 1.5108293294906616,
      "learning_rate": 4.613240418118467e-05,
      "loss": 0.2123,
      "step": 3330
    },
    {
      "epoch": 0.775842044134727,
      "grad_norm": 1.0830752849578857,
      "learning_rate": 4.612078977932637e-05,
      "loss": 0.2368,
      "step": 3340
    },
    {
      "epoch": 0.778164924506388,
      "grad_norm": 1.463663935661316,
      "learning_rate": 4.610917537746806e-05,
      "loss": 0.2063,
      "step": 3350
    },
    {
      "epoch": 0.7804878048780488,
      "grad_norm": 1.7736048698425293,
      "learning_rate": 4.609756097560976e-05,
      "loss": 0.1841,
      "step": 3360
    },
    {
      "epoch": 0.7828106852497096,
      "grad_norm": 1.251162052154541,
      "learning_rate": 4.608594657375145e-05,
      "loss": 0.2218,
      "step": 3370
    },
    {
      "epoch": 0.7851335656213705,
      "grad_norm": 1.8109052181243896,
      "learning_rate": 4.607433217189315e-05,
      "loss": 0.1559,
      "step": 3380
    },
    {
      "epoch": 0.7874564459930313,
      "grad_norm": 1.9727261066436768,
      "learning_rate": 4.606271777003485e-05,
      "loss": 0.237,
      "step": 3390
    },
    {
      "epoch": 0.7897793263646922,
      "grad_norm": 2.0521795749664307,
      "learning_rate": 4.6051103368176543e-05,
      "loss": 0.2616,
      "step": 3400
    },
    {
      "epoch": 0.7921022067363531,
      "grad_norm": 1.9156663417816162,
      "learning_rate": 4.603948896631824e-05,
      "loss": 0.2907,
      "step": 3410
    },
    {
      "epoch": 0.794425087108014,
      "grad_norm": 2.003121852874756,
      "learning_rate": 4.602787456445993e-05,
      "loss": 0.2091,
      "step": 3420
    },
    {
      "epoch": 0.7967479674796748,
      "grad_norm": 2.4502224922180176,
      "learning_rate": 4.601626016260163e-05,
      "loss": 0.1877,
      "step": 3430
    },
    {
      "epoch": 0.7990708478513356,
      "grad_norm": 2.2511703968048096,
      "learning_rate": 4.600464576074333e-05,
      "loss": 0.2636,
      "step": 3440
    },
    {
      "epoch": 0.8013937282229965,
      "grad_norm": 2.634474277496338,
      "learning_rate": 4.599303135888502e-05,
      "loss": 0.2543,
      "step": 3450
    },
    {
      "epoch": 0.8037166085946573,
      "grad_norm": 1.349189281463623,
      "learning_rate": 4.598141695702671e-05,
      "loss": 0.198,
      "step": 3460
    },
    {
      "epoch": 0.8060394889663183,
      "grad_norm": 1.1216545104980469,
      "learning_rate": 4.596980255516841e-05,
      "loss": 0.2574,
      "step": 3470
    },
    {
      "epoch": 0.8083623693379791,
      "grad_norm": 1.8017566204071045,
      "learning_rate": 4.595818815331011e-05,
      "loss": 0.211,
      "step": 3480
    },
    {
      "epoch": 0.81068524970964,
      "grad_norm": 1.5076041221618652,
      "learning_rate": 4.59465737514518e-05,
      "loss": 0.1859,
      "step": 3490
    },
    {
      "epoch": 0.8130081300813008,
      "grad_norm": 1.2964394092559814,
      "learning_rate": 4.59349593495935e-05,
      "loss": 0.1847,
      "step": 3500
    },
    {
      "epoch": 0.8153310104529616,
      "grad_norm": 1.5227447748184204,
      "learning_rate": 4.592334494773519e-05,
      "loss": 0.2502,
      "step": 3510
    },
    {
      "epoch": 0.8176538908246226,
      "grad_norm": 1.3263542652130127,
      "learning_rate": 4.591173054587689e-05,
      "loss": 0.1747,
      "step": 3520
    },
    {
      "epoch": 0.8199767711962834,
      "grad_norm": 1.4643445014953613,
      "learning_rate": 4.590011614401859e-05,
      "loss": 0.2844,
      "step": 3530
    },
    {
      "epoch": 0.8222996515679443,
      "grad_norm": 1.1375343799591064,
      "learning_rate": 4.588850174216028e-05,
      "loss": 0.1904,
      "step": 3540
    },
    {
      "epoch": 0.8246225319396051,
      "grad_norm": 1.2738219499588013,
      "learning_rate": 4.587688734030198e-05,
      "loss": 0.203,
      "step": 3550
    },
    {
      "epoch": 0.826945412311266,
      "grad_norm": 1.5541298389434814,
      "learning_rate": 4.586527293844367e-05,
      "loss": 0.2713,
      "step": 3560
    },
    {
      "epoch": 0.8292682926829268,
      "grad_norm": 1.970036268234253,
      "learning_rate": 4.585365853658537e-05,
      "loss": 0.1518,
      "step": 3570
    },
    {
      "epoch": 0.8315911730545877,
      "grad_norm": 2.526655673980713,
      "learning_rate": 4.584204413472706e-05,
      "loss": 0.3109,
      "step": 3580
    },
    {
      "epoch": 0.8339140534262486,
      "grad_norm": 1.8867827653884888,
      "learning_rate": 4.5830429732868756e-05,
      "loss": 0.2305,
      "step": 3590
    },
    {
      "epoch": 0.8362369337979094,
      "grad_norm": 1.1801999807357788,
      "learning_rate": 4.581881533101046e-05,
      "loss": 0.1953,
      "step": 3600
    },
    {
      "epoch": 0.8385598141695703,
      "grad_norm": 2.8708763122558594,
      "learning_rate": 4.580720092915215e-05,
      "loss": 0.2995,
      "step": 3610
    },
    {
      "epoch": 0.8408826945412311,
      "grad_norm": 1.8953040838241577,
      "learning_rate": 4.5795586527293847e-05,
      "loss": 0.3022,
      "step": 3620
    },
    {
      "epoch": 0.8432055749128919,
      "grad_norm": 1.3866300582885742,
      "learning_rate": 4.578397212543554e-05,
      "loss": 0.2379,
      "step": 3630
    },
    {
      "epoch": 0.8455284552845529,
      "grad_norm": 1.739108920097351,
      "learning_rate": 4.5772357723577236e-05,
      "loss": 0.1521,
      "step": 3640
    },
    {
      "epoch": 0.8478513356562137,
      "grad_norm": 2.3207247257232666,
      "learning_rate": 4.576074332171894e-05,
      "loss": 0.1746,
      "step": 3650
    },
    {
      "epoch": 0.8501742160278746,
      "grad_norm": 2.003016471862793,
      "learning_rate": 4.574912891986063e-05,
      "loss": 0.2382,
      "step": 3660
    },
    {
      "epoch": 0.8524970963995354,
      "grad_norm": 0.938021183013916,
      "learning_rate": 4.573751451800232e-05,
      "loss": 0.2522,
      "step": 3670
    },
    {
      "epoch": 0.8548199767711963,
      "grad_norm": 1.4521832466125488,
      "learning_rate": 4.572590011614402e-05,
      "loss": 0.2186,
      "step": 3680
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 2.308324098587036,
      "learning_rate": 4.5714285714285716e-05,
      "loss": 0.2254,
      "step": 3690
    },
    {
      "epoch": 0.859465737514518,
      "grad_norm": 1.54531991481781,
      "learning_rate": 4.570267131242742e-05,
      "loss": 0.1835,
      "step": 3700
    },
    {
      "epoch": 0.8617886178861789,
      "grad_norm": 1.216578483581543,
      "learning_rate": 4.5691056910569105e-05,
      "loss": 0.2296,
      "step": 3710
    },
    {
      "epoch": 0.8641114982578397,
      "grad_norm": 1.5574662685394287,
      "learning_rate": 4.56794425087108e-05,
      "loss": 0.1592,
      "step": 3720
    },
    {
      "epoch": 0.8664343786295006,
      "grad_norm": 1.8871058225631714,
      "learning_rate": 4.56678281068525e-05,
      "loss": 0.1684,
      "step": 3730
    },
    {
      "epoch": 0.8687572590011614,
      "grad_norm": 1.4677003622055054,
      "learning_rate": 4.5656213704994196e-05,
      "loss": 0.1363,
      "step": 3740
    },
    {
      "epoch": 0.8710801393728222,
      "grad_norm": 1.8705286979675293,
      "learning_rate": 4.564459930313589e-05,
      "loss": 0.2455,
      "step": 3750
    },
    {
      "epoch": 0.8734030197444832,
      "grad_norm": 1.1499794721603394,
      "learning_rate": 4.5632984901277586e-05,
      "loss": 0.221,
      "step": 3760
    },
    {
      "epoch": 0.875725900116144,
      "grad_norm": 1.6902313232421875,
      "learning_rate": 4.562137049941928e-05,
      "loss": 0.1627,
      "step": 3770
    },
    {
      "epoch": 0.8780487804878049,
      "grad_norm": 1.8419888019561768,
      "learning_rate": 4.560975609756098e-05,
      "loss": 0.1756,
      "step": 3780
    },
    {
      "epoch": 0.8803716608594657,
      "grad_norm": 1.661551594734192,
      "learning_rate": 4.5598141695702676e-05,
      "loss": 0.2128,
      "step": 3790
    },
    {
      "epoch": 0.8826945412311266,
      "grad_norm": 1.2238528728485107,
      "learning_rate": 4.5586527293844364e-05,
      "loss": 0.3339,
      "step": 3800
    },
    {
      "epoch": 0.8850174216027874,
      "grad_norm": 1.2625911235809326,
      "learning_rate": 4.5574912891986066e-05,
      "loss": 0.1087,
      "step": 3810
    },
    {
      "epoch": 0.8873403019744484,
      "grad_norm": 2.366434097290039,
      "learning_rate": 4.556329849012776e-05,
      "loss": 0.3051,
      "step": 3820
    },
    {
      "epoch": 0.8896631823461092,
      "grad_norm": 2.0757853984832764,
      "learning_rate": 4.5551684088269455e-05,
      "loss": 0.2591,
      "step": 3830
    },
    {
      "epoch": 0.89198606271777,
      "grad_norm": 1.315237283706665,
      "learning_rate": 4.554006968641115e-05,
      "loss": 0.3022,
      "step": 3840
    },
    {
      "epoch": 0.8943089430894309,
      "grad_norm": 2.3372933864593506,
      "learning_rate": 4.5528455284552844e-05,
      "loss": 0.2049,
      "step": 3850
    },
    {
      "epoch": 0.8966318234610917,
      "grad_norm": 1.4384303092956543,
      "learning_rate": 4.5516840882694546e-05,
      "loss": 0.1788,
      "step": 3860
    },
    {
      "epoch": 0.8989547038327527,
      "grad_norm": 2.2389116287231445,
      "learning_rate": 4.550522648083624e-05,
      "loss": 0.2396,
      "step": 3870
    },
    {
      "epoch": 0.9012775842044135,
      "grad_norm": 2.3420863151550293,
      "learning_rate": 4.5493612078977935e-05,
      "loss": 0.2096,
      "step": 3880
    },
    {
      "epoch": 0.9036004645760743,
      "grad_norm": 1.8146339654922485,
      "learning_rate": 4.548199767711963e-05,
      "loss": 0.1927,
      "step": 3890
    },
    {
      "epoch": 0.9059233449477352,
      "grad_norm": 1.2510921955108643,
      "learning_rate": 4.5470383275261325e-05,
      "loss": 0.0936,
      "step": 3900
    },
    {
      "epoch": 0.908246225319396,
      "grad_norm": 2.0957255363464355,
      "learning_rate": 4.5458768873403026e-05,
      "loss": 0.2021,
      "step": 3910
    },
    {
      "epoch": 0.9105691056910569,
      "grad_norm": 1.3351842164993286,
      "learning_rate": 4.544715447154472e-05,
      "loss": 0.2623,
      "step": 3920
    },
    {
      "epoch": 0.9128919860627178,
      "grad_norm": 2.120230197906494,
      "learning_rate": 4.543554006968641e-05,
      "loss": 0.2416,
      "step": 3930
    },
    {
      "epoch": 0.9152148664343787,
      "grad_norm": 1.8269879817962646,
      "learning_rate": 4.542392566782811e-05,
      "loss": 0.1752,
      "step": 3940
    },
    {
      "epoch": 0.9175377468060395,
      "grad_norm": 2.1104419231414795,
      "learning_rate": 4.5412311265969805e-05,
      "loss": 0.1915,
      "step": 3950
    },
    {
      "epoch": 0.9198606271777003,
      "grad_norm": 2.9723010063171387,
      "learning_rate": 4.54006968641115e-05,
      "loss": 0.2873,
      "step": 3960
    },
    {
      "epoch": 0.9221835075493612,
      "grad_norm": 2.1664299964904785,
      "learning_rate": 4.5389082462253194e-05,
      "loss": 0.2858,
      "step": 3970
    },
    {
      "epoch": 0.924506387921022,
      "grad_norm": 1.8502229452133179,
      "learning_rate": 4.537746806039489e-05,
      "loss": 0.2016,
      "step": 3980
    },
    {
      "epoch": 0.926829268292683,
      "grad_norm": 1.6960386037826538,
      "learning_rate": 4.536585365853659e-05,
      "loss": 0.159,
      "step": 3990
    },
    {
      "epoch": 0.9291521486643438,
      "grad_norm": 1.9729599952697754,
      "learning_rate": 4.5354239256678285e-05,
      "loss": 0.2518,
      "step": 4000
    },
    {
      "epoch": 0.9314750290360047,
      "grad_norm": 1.7948459386825562,
      "learning_rate": 4.534262485481998e-05,
      "loss": 0.1527,
      "step": 4010
    },
    {
      "epoch": 0.9337979094076655,
      "grad_norm": 1.7203859090805054,
      "learning_rate": 4.5331010452961674e-05,
      "loss": 0.2633,
      "step": 4020
    },
    {
      "epoch": 0.9361207897793263,
      "grad_norm": 1.4599287509918213,
      "learning_rate": 4.531939605110337e-05,
      "loss": 0.3216,
      "step": 4030
    },
    {
      "epoch": 0.9384436701509872,
      "grad_norm": 1.7823036909103394,
      "learning_rate": 4.530778164924507e-05,
      "loss": 0.1949,
      "step": 4040
    },
    {
      "epoch": 0.9407665505226481,
      "grad_norm": 2.2666027545928955,
      "learning_rate": 4.529616724738676e-05,
      "loss": 0.2306,
      "step": 4050
    },
    {
      "epoch": 0.943089430894309,
      "grad_norm": 2.025132894515991,
      "learning_rate": 4.528455284552845e-05,
      "loss": 0.2316,
      "step": 4060
    },
    {
      "epoch": 0.9454123112659698,
      "grad_norm": 2.407696008682251,
      "learning_rate": 4.5272938443670154e-05,
      "loss": 0.2346,
      "step": 4070
    },
    {
      "epoch": 0.9477351916376306,
      "grad_norm": 2.786482572555542,
      "learning_rate": 4.526132404181185e-05,
      "loss": 0.234,
      "step": 4080
    },
    {
      "epoch": 0.9500580720092915,
      "grad_norm": 1.595674753189087,
      "learning_rate": 4.5249709639953544e-05,
      "loss": 0.1543,
      "step": 4090
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 1.3590400218963623,
      "learning_rate": 4.523809523809524e-05,
      "loss": 0.1821,
      "step": 4100
    },
    {
      "epoch": 0.9547038327526133,
      "grad_norm": 1.3085517883300781,
      "learning_rate": 4.522648083623693e-05,
      "loss": 0.2245,
      "step": 4110
    },
    {
      "epoch": 0.9570267131242741,
      "grad_norm": 1.4335792064666748,
      "learning_rate": 4.5214866434378634e-05,
      "loss": 0.115,
      "step": 4120
    },
    {
      "epoch": 0.959349593495935,
      "grad_norm": 1.8640176057815552,
      "learning_rate": 4.520325203252033e-05,
      "loss": 0.1305,
      "step": 4130
    },
    {
      "epoch": 0.9616724738675958,
      "grad_norm": 1.387835144996643,
      "learning_rate": 4.519163763066202e-05,
      "loss": 0.1766,
      "step": 4140
    },
    {
      "epoch": 0.9639953542392566,
      "grad_norm": 1.4349867105484009,
      "learning_rate": 4.518118466898955e-05,
      "loss": 0.1587,
      "step": 4150
    },
    {
      "epoch": 0.9663182346109176,
      "grad_norm": 1.1876479387283325,
      "learning_rate": 4.516957026713125e-05,
      "loss": 0.1514,
      "step": 4160
    },
    {
      "epoch": 0.9686411149825784,
      "grad_norm": 1.923635482788086,
      "learning_rate": 4.515795586527294e-05,
      "loss": 0.2381,
      "step": 4170
    },
    {
      "epoch": 0.9709639953542393,
      "grad_norm": 1.93232262134552,
      "learning_rate": 4.5146341463414636e-05,
      "loss": 0.2108,
      "step": 4180
    },
    {
      "epoch": 0.9732868757259001,
      "grad_norm": 1.2012296915054321,
      "learning_rate": 4.513472706155633e-05,
      "loss": 0.2346,
      "step": 4190
    },
    {
      "epoch": 0.975609756097561,
      "grad_norm": 1.5047701597213745,
      "learning_rate": 4.512311265969803e-05,
      "loss": 0.2168,
      "step": 4200
    },
    {
      "epoch": 0.9779326364692218,
      "grad_norm": 1.7129912376403809,
      "learning_rate": 4.511149825783973e-05,
      "loss": 0.1762,
      "step": 4210
    },
    {
      "epoch": 0.9802555168408827,
      "grad_norm": 1.7187578678131104,
      "learning_rate": 4.5099883855981415e-05,
      "loss": 0.1654,
      "step": 4220
    },
    {
      "epoch": 0.9825783972125436,
      "grad_norm": 2.042097568511963,
      "learning_rate": 4.5088269454123117e-05,
      "loss": 0.2957,
      "step": 4230
    },
    {
      "epoch": 0.9849012775842044,
      "grad_norm": 1.3198026418685913,
      "learning_rate": 4.507665505226481e-05,
      "loss": 0.2794,
      "step": 4240
    },
    {
      "epoch": 0.9872241579558653,
      "grad_norm": 1.7898447513580322,
      "learning_rate": 4.5065040650406506e-05,
      "loss": 0.1855,
      "step": 4250
    },
    {
      "epoch": 0.9895470383275261,
      "grad_norm": 1.224027156829834,
      "learning_rate": 4.50534262485482e-05,
      "loss": 0.2338,
      "step": 4260
    },
    {
      "epoch": 0.991869918699187,
      "grad_norm": 1.7412300109863281,
      "learning_rate": 4.5041811846689895e-05,
      "loss": 0.2383,
      "step": 4270
    },
    {
      "epoch": 0.9941927990708479,
      "grad_norm": 1.494630217552185,
      "learning_rate": 4.50301974448316e-05,
      "loss": 0.1544,
      "step": 4280
    },
    {
      "epoch": 0.9965156794425087,
      "grad_norm": 1.9921579360961914,
      "learning_rate": 4.501858304297329e-05,
      "loss": 0.2648,
      "step": 4290
    },
    {
      "epoch": 0.9988385598141696,
      "grad_norm": 2.1750662326812744,
      "learning_rate": 4.5006968641114986e-05,
      "loss": 0.1432,
      "step": 4300
    },
    {
      "epoch": 1.0011614401858304,
      "grad_norm": 1.6034836769104004,
      "learning_rate": 4.499535423925668e-05,
      "loss": 0.1438,
      "step": 4310
    },
    {
      "epoch": 1.0034843205574913,
      "grad_norm": 2.3506786823272705,
      "learning_rate": 4.4983739837398375e-05,
      "loss": 0.2372,
      "step": 4320
    },
    {
      "epoch": 1.005807200929152,
      "grad_norm": 2.5400266647338867,
      "learning_rate": 4.497212543554008e-05,
      "loss": 0.3015,
      "step": 4330
    },
    {
      "epoch": 1.008130081300813,
      "grad_norm": 1.5319862365722656,
      "learning_rate": 4.4960511033681765e-05,
      "loss": 0.256,
      "step": 4340
    },
    {
      "epoch": 1.0104529616724738,
      "grad_norm": 1.6406716108322144,
      "learning_rate": 4.494889663182346e-05,
      "loss": 0.2126,
      "step": 4350
    },
    {
      "epoch": 1.0127758420441346,
      "grad_norm": 1.717923641204834,
      "learning_rate": 4.493728222996516e-05,
      "loss": 0.1557,
      "step": 4360
    },
    {
      "epoch": 1.0150987224157957,
      "grad_norm": 1.5434895753860474,
      "learning_rate": 4.4925667828106856e-05,
      "loss": 0.2068,
      "step": 4370
    },
    {
      "epoch": 1.0174216027874565,
      "grad_norm": 1.2767566442489624,
      "learning_rate": 4.491405342624855e-05,
      "loss": 0.3016,
      "step": 4380
    },
    {
      "epoch": 1.0197444831591174,
      "grad_norm": 1.2244846820831299,
      "learning_rate": 4.4902439024390245e-05,
      "loss": 0.1797,
      "step": 4390
    },
    {
      "epoch": 1.0220673635307782,
      "grad_norm": 1.209612488746643,
      "learning_rate": 4.489082462253194e-05,
      "loss": 0.1468,
      "step": 4400
    },
    {
      "epoch": 1.024390243902439,
      "grad_norm": 1.007674217224121,
      "learning_rate": 4.487921022067364e-05,
      "loss": 0.1145,
      "step": 4410
    },
    {
      "epoch": 1.0267131242740999,
      "grad_norm": 2.4144959449768066,
      "learning_rate": 4.4867595818815336e-05,
      "loss": 0.1917,
      "step": 4420
    },
    {
      "epoch": 1.0290360046457607,
      "grad_norm": 2.324997663497925,
      "learning_rate": 4.4855981416957024e-05,
      "loss": 0.1535,
      "step": 4430
    },
    {
      "epoch": 1.0313588850174216,
      "grad_norm": 1.3721028566360474,
      "learning_rate": 4.4844367015098725e-05,
      "loss": 0.1752,
      "step": 4440
    },
    {
      "epoch": 1.0336817653890824,
      "grad_norm": 3.0219433307647705,
      "learning_rate": 4.483275261324042e-05,
      "loss": 0.234,
      "step": 4450
    },
    {
      "epoch": 1.0360046457607432,
      "grad_norm": 1.469892144203186,
      "learning_rate": 4.4821138211382114e-05,
      "loss": 0.2201,
      "step": 4460
    },
    {
      "epoch": 1.038327526132404,
      "grad_norm": 2.0092720985412598,
      "learning_rate": 4.480952380952381e-05,
      "loss": 0.2689,
      "step": 4470
    },
    {
      "epoch": 1.040650406504065,
      "grad_norm": 2.8849215507507324,
      "learning_rate": 4.4797909407665504e-05,
      "loss": 0.3026,
      "step": 4480
    },
    {
      "epoch": 1.042973286875726,
      "grad_norm": 1.7277623414993286,
      "learning_rate": 4.4786295005807205e-05,
      "loss": 0.1687,
      "step": 4490
    },
    {
      "epoch": 1.0452961672473868,
      "grad_norm": 2.210359811782837,
      "learning_rate": 4.47746806039489e-05,
      "loss": 0.2213,
      "step": 4500
    },
    {
      "epoch": 1.0476190476190477,
      "grad_norm": 1.4691393375396729,
      "learning_rate": 4.4763066202090594e-05,
      "loss": 0.1072,
      "step": 4510
    },
    {
      "epoch": 1.0499419279907085,
      "grad_norm": 1.387010097503662,
      "learning_rate": 4.475145180023229e-05,
      "loss": 0.2173,
      "step": 4520
    },
    {
      "epoch": 1.0522648083623694,
      "grad_norm": 1.715471863746643,
      "learning_rate": 4.4739837398373984e-05,
      "loss": 0.183,
      "step": 4530
    },
    {
      "epoch": 1.0545876887340302,
      "grad_norm": 1.8508630990982056,
      "learning_rate": 4.4728222996515685e-05,
      "loss": 0.1743,
      "step": 4540
    },
    {
      "epoch": 1.056910569105691,
      "grad_norm": 1.1498520374298096,
      "learning_rate": 4.471660859465738e-05,
      "loss": 0.1132,
      "step": 4550
    },
    {
      "epoch": 1.0592334494773519,
      "grad_norm": 2.384498357772827,
      "learning_rate": 4.470499419279907e-05,
      "loss": 0.1575,
      "step": 4560
    },
    {
      "epoch": 1.0615563298490127,
      "grad_norm": 3.939133882522583,
      "learning_rate": 4.469337979094077e-05,
      "loss": 0.2564,
      "step": 4570
    },
    {
      "epoch": 1.0638792102206736,
      "grad_norm": 1.016298532485962,
      "learning_rate": 4.4681765389082464e-05,
      "loss": 0.1636,
      "step": 4580
    },
    {
      "epoch": 1.0662020905923344,
      "grad_norm": 1.2957892417907715,
      "learning_rate": 4.467015098722416e-05,
      "loss": 0.1939,
      "step": 4590
    },
    {
      "epoch": 1.0685249709639955,
      "grad_norm": 2.650505781173706,
      "learning_rate": 4.465853658536585e-05,
      "loss": 0.1344,
      "step": 4600
    },
    {
      "epoch": 1.0708478513356563,
      "grad_norm": 1.1287397146224976,
      "learning_rate": 4.464692218350755e-05,
      "loss": 0.1474,
      "step": 4610
    },
    {
      "epoch": 1.0731707317073171,
      "grad_norm": 2.0185978412628174,
      "learning_rate": 4.463530778164925e-05,
      "loss": 0.1183,
      "step": 4620
    },
    {
      "epoch": 1.075493612078978,
      "grad_norm": 1.720781922340393,
      "learning_rate": 4.4623693379790944e-05,
      "loss": 0.2056,
      "step": 4630
    },
    {
      "epoch": 1.0778164924506388,
      "grad_norm": 2.2815256118774414,
      "learning_rate": 4.461207897793264e-05,
      "loss": 0.1894,
      "step": 4640
    },
    {
      "epoch": 1.0801393728222997,
      "grad_norm": 1.0484058856964111,
      "learning_rate": 4.4600464576074333e-05,
      "loss": 0.3332,
      "step": 4650
    },
    {
      "epoch": 1.0824622531939605,
      "grad_norm": 1.251259207725525,
      "learning_rate": 4.458885017421603e-05,
      "loss": 0.1692,
      "step": 4660
    },
    {
      "epoch": 1.0847851335656213,
      "grad_norm": 1.3373104333877563,
      "learning_rate": 4.457723577235773e-05,
      "loss": 0.2836,
      "step": 4670
    },
    {
      "epoch": 1.0871080139372822,
      "grad_norm": 1.7479218244552612,
      "learning_rate": 4.4565621370499424e-05,
      "loss": 0.1203,
      "step": 4680
    },
    {
      "epoch": 1.089430894308943,
      "grad_norm": 1.7117786407470703,
      "learning_rate": 4.455400696864111e-05,
      "loss": 0.1597,
      "step": 4690
    },
    {
      "epoch": 1.0917537746806039,
      "grad_norm": 1.1838315725326538,
      "learning_rate": 4.4542392566782814e-05,
      "loss": 0.1961,
      "step": 4700
    },
    {
      "epoch": 1.0940766550522647,
      "grad_norm": 1.3385449647903442,
      "learning_rate": 4.453077816492451e-05,
      "loss": 0.2066,
      "step": 4710
    },
    {
      "epoch": 1.0963995354239258,
      "grad_norm": 1.810031533241272,
      "learning_rate": 4.45191637630662e-05,
      "loss": 0.2183,
      "step": 4720
    },
    {
      "epoch": 1.0987224157955866,
      "grad_norm": 1.5897741317749023,
      "learning_rate": 4.45075493612079e-05,
      "loss": 0.3017,
      "step": 4730
    },
    {
      "epoch": 1.1010452961672474,
      "grad_norm": 1.4620602130889893,
      "learning_rate": 4.449593495934959e-05,
      "loss": 0.2146,
      "step": 4740
    },
    {
      "epoch": 1.1033681765389083,
      "grad_norm": 1.2325164079666138,
      "learning_rate": 4.4484320557491294e-05,
      "loss": 0.2088,
      "step": 4750
    },
    {
      "epoch": 1.1056910569105691,
      "grad_norm": 1.3361262083053589,
      "learning_rate": 4.447270615563299e-05,
      "loss": 0.1412,
      "step": 4760
    },
    {
      "epoch": 1.10801393728223,
      "grad_norm": 2.0742344856262207,
      "learning_rate": 4.446109175377468e-05,
      "loss": 0.2353,
      "step": 4770
    },
    {
      "epoch": 1.1103368176538908,
      "grad_norm": 1.3095558881759644,
      "learning_rate": 4.444947735191638e-05,
      "loss": 0.1174,
      "step": 4780
    },
    {
      "epoch": 1.1126596980255516,
      "grad_norm": 1.4715625047683716,
      "learning_rate": 4.443786295005807e-05,
      "loss": 0.2054,
      "step": 4790
    },
    {
      "epoch": 1.1149825783972125,
      "grad_norm": 2.5471739768981934,
      "learning_rate": 4.4426248548199774e-05,
      "loss": 0.1837,
      "step": 4800
    },
    {
      "epoch": 1.1173054587688733,
      "grad_norm": 2.2602944374084473,
      "learning_rate": 4.441463414634147e-05,
      "loss": 0.169,
      "step": 4810
    },
    {
      "epoch": 1.1196283391405342,
      "grad_norm": 1.937394618988037,
      "learning_rate": 4.4403019744483156e-05,
      "loss": 0.2374,
      "step": 4820
    },
    {
      "epoch": 1.1219512195121952,
      "grad_norm": 1.557693362236023,
      "learning_rate": 4.439140534262486e-05,
      "loss": 0.1892,
      "step": 4830
    },
    {
      "epoch": 1.124274099883856,
      "grad_norm": 1.3266770839691162,
      "learning_rate": 4.437979094076655e-05,
      "loss": 0.2883,
      "step": 4840
    },
    {
      "epoch": 1.126596980255517,
      "grad_norm": 1.6635090112686157,
      "learning_rate": 4.436817653890825e-05,
      "loss": 0.1444,
      "step": 4850
    },
    {
      "epoch": 1.1289198606271778,
      "grad_norm": 2.0926918983459473,
      "learning_rate": 4.435656213704994e-05,
      "loss": 0.1395,
      "step": 4860
    },
    {
      "epoch": 1.1312427409988386,
      "grad_norm": 1.852215051651001,
      "learning_rate": 4.4344947735191637e-05,
      "loss": 0.151,
      "step": 4870
    },
    {
      "epoch": 1.1335656213704994,
      "grad_norm": 1.8063379526138306,
      "learning_rate": 4.433333333333334e-05,
      "loss": 0.3365,
      "step": 4880
    },
    {
      "epoch": 1.1358885017421603,
      "grad_norm": 1.2776201963424683,
      "learning_rate": 4.432171893147503e-05,
      "loss": 0.2663,
      "step": 4890
    },
    {
      "epoch": 1.1382113821138211,
      "grad_norm": 2.0171432495117188,
      "learning_rate": 4.431010452961673e-05,
      "loss": 0.1723,
      "step": 4900
    },
    {
      "epoch": 1.140534262485482,
      "grad_norm": 1.362019658088684,
      "learning_rate": 4.429849012775842e-05,
      "loss": 0.1256,
      "step": 4910
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 1.974906325340271,
      "learning_rate": 4.428687572590012e-05,
      "loss": 0.2272,
      "step": 4920
    },
    {
      "epoch": 1.1451800232288036,
      "grad_norm": 2.1278765201568604,
      "learning_rate": 4.427526132404181e-05,
      "loss": 0.2195,
      "step": 4930
    },
    {
      "epoch": 1.1475029036004645,
      "grad_norm": 1.8348621129989624,
      "learning_rate": 4.426364692218351e-05,
      "loss": 0.1915,
      "step": 4940
    },
    {
      "epoch": 1.1498257839721253,
      "grad_norm": 1.2834311723709106,
      "learning_rate": 4.42520325203252e-05,
      "loss": 0.2922,
      "step": 4950
    },
    {
      "epoch": 1.1521486643437864,
      "grad_norm": 1.2135860919952393,
      "learning_rate": 4.42404181184669e-05,
      "loss": 0.2386,
      "step": 4960
    },
    {
      "epoch": 1.1544715447154472,
      "grad_norm": 1.8605384826660156,
      "learning_rate": 4.42288037166086e-05,
      "loss": 0.2234,
      "step": 4970
    },
    {
      "epoch": 1.156794425087108,
      "grad_norm": 2.6300477981567383,
      "learning_rate": 4.421718931475029e-05,
      "loss": 0.2681,
      "step": 4980
    },
    {
      "epoch": 1.159117305458769,
      "grad_norm": 3.1766231060028076,
      "learning_rate": 4.4205574912891986e-05,
      "loss": 0.1466,
      "step": 4990
    },
    {
      "epoch": 1.1614401858304297,
      "grad_norm": 1.6216472387313843,
      "learning_rate": 4.419396051103368e-05,
      "loss": 0.2017,
      "step": 5000
    },
    {
      "epoch": 1.1637630662020906,
      "grad_norm": 1.7421348094940186,
      "learning_rate": 4.418234610917538e-05,
      "loss": 0.1428,
      "step": 5010
    },
    {
      "epoch": 1.1660859465737514,
      "grad_norm": 1.1697851419448853,
      "learning_rate": 4.417073170731708e-05,
      "loss": 0.1687,
      "step": 5020
    },
    {
      "epoch": 1.1684088269454123,
      "grad_norm": 2.1292166709899902,
      "learning_rate": 4.415911730545877e-05,
      "loss": 0.1593,
      "step": 5030
    },
    {
      "epoch": 1.170731707317073,
      "grad_norm": 1.5419870615005493,
      "learning_rate": 4.4147502903600466e-05,
      "loss": 0.1606,
      "step": 5040
    },
    {
      "epoch": 1.173054587688734,
      "grad_norm": 1.4529715776443481,
      "learning_rate": 4.413588850174216e-05,
      "loss": 0.1518,
      "step": 5050
    },
    {
      "epoch": 1.175377468060395,
      "grad_norm": 1.5632246732711792,
      "learning_rate": 4.4124274099883856e-05,
      "loss": 0.1557,
      "step": 5060
    },
    {
      "epoch": 1.1777003484320558,
      "grad_norm": 1.0526891946792603,
      "learning_rate": 4.411265969802556e-05,
      "loss": 0.1312,
      "step": 5070
    },
    {
      "epoch": 1.1800232288037167,
      "grad_norm": 2.0394089221954346,
      "learning_rate": 4.4101045296167245e-05,
      "loss": 0.206,
      "step": 5080
    },
    {
      "epoch": 1.1823461091753775,
      "grad_norm": 1.7277952432632446,
      "learning_rate": 4.4089430894308946e-05,
      "loss": 0.215,
      "step": 5090
    },
    {
      "epoch": 1.1846689895470384,
      "grad_norm": 1.4628955125808716,
      "learning_rate": 4.407781649245064e-05,
      "loss": 0.2083,
      "step": 5100
    },
    {
      "epoch": 1.1869918699186992,
      "grad_norm": 1.628236174583435,
      "learning_rate": 4.4066202090592336e-05,
      "loss": 0.1619,
      "step": 5110
    },
    {
      "epoch": 1.18931475029036,
      "grad_norm": 2.7910332679748535,
      "learning_rate": 4.405458768873403e-05,
      "loss": 0.168,
      "step": 5120
    },
    {
      "epoch": 1.1916376306620209,
      "grad_norm": 1.8627543449401855,
      "learning_rate": 4.4042973286875725e-05,
      "loss": 0.1909,
      "step": 5130
    },
    {
      "epoch": 1.1939605110336817,
      "grad_norm": 2.6426634788513184,
      "learning_rate": 4.403135888501743e-05,
      "loss": 0.134,
      "step": 5140
    },
    {
      "epoch": 1.1962833914053426,
      "grad_norm": 2.789008140563965,
      "learning_rate": 4.401974448315912e-05,
      "loss": 0.1526,
      "step": 5150
    },
    {
      "epoch": 1.1986062717770034,
      "grad_norm": 1.656469702720642,
      "learning_rate": 4.4008130081300816e-05,
      "loss": 0.2855,
      "step": 5160
    },
    {
      "epoch": 1.2009291521486642,
      "grad_norm": 1.1508468389511108,
      "learning_rate": 4.399651567944251e-05,
      "loss": 0.1936,
      "step": 5170
    },
    {
      "epoch": 1.203252032520325,
      "grad_norm": 1.7009563446044922,
      "learning_rate": 4.3984901277584205e-05,
      "loss": 0.1862,
      "step": 5180
    },
    {
      "epoch": 1.2055749128919862,
      "grad_norm": 2.360327959060669,
      "learning_rate": 4.39732868757259e-05,
      "loss": 0.1614,
      "step": 5190
    },
    {
      "epoch": 1.207897793263647,
      "grad_norm": 1.2968993186950684,
      "learning_rate": 4.39616724738676e-05,
      "loss": 0.2098,
      "step": 5200
    },
    {
      "epoch": 1.2102206736353078,
      "grad_norm": 1.9176712036132812,
      "learning_rate": 4.395005807200929e-05,
      "loss": 0.1723,
      "step": 5210
    },
    {
      "epoch": 1.2125435540069687,
      "grad_norm": 1.5420478582382202,
      "learning_rate": 4.393844367015099e-05,
      "loss": 0.2404,
      "step": 5220
    },
    {
      "epoch": 1.2148664343786295,
      "grad_norm": 3.326040506362915,
      "learning_rate": 4.3926829268292685e-05,
      "loss": 0.1758,
      "step": 5230
    },
    {
      "epoch": 1.2171893147502904,
      "grad_norm": 1.5514650344848633,
      "learning_rate": 4.391521486643438e-05,
      "loss": 0.1766,
      "step": 5240
    },
    {
      "epoch": 1.2195121951219512,
      "grad_norm": 2.3423781394958496,
      "learning_rate": 4.3903600464576075e-05,
      "loss": 0.2587,
      "step": 5250
    },
    {
      "epoch": 1.221835075493612,
      "grad_norm": 1.7978178262710571,
      "learning_rate": 4.389198606271777e-05,
      "loss": 0.1961,
      "step": 5260
    },
    {
      "epoch": 1.2241579558652729,
      "grad_norm": 1.725867748260498,
      "learning_rate": 4.388037166085947e-05,
      "loss": 0.2494,
      "step": 5270
    },
    {
      "epoch": 1.2264808362369337,
      "grad_norm": 1.5704189538955688,
      "learning_rate": 4.3868757259001166e-05,
      "loss": 0.1645,
      "step": 5280
    },
    {
      "epoch": 1.2288037166085948,
      "grad_norm": 1.6508901119232178,
      "learning_rate": 4.385714285714286e-05,
      "loss": 0.2179,
      "step": 5290
    },
    {
      "epoch": 1.2311265969802556,
      "grad_norm": 1.2674278020858765,
      "learning_rate": 4.3845528455284555e-05,
      "loss": 0.1849,
      "step": 5300
    },
    {
      "epoch": 1.2334494773519165,
      "grad_norm": 2.735536575317383,
      "learning_rate": 4.383391405342625e-05,
      "loss": 0.2094,
      "step": 5310
    },
    {
      "epoch": 1.2357723577235773,
      "grad_norm": 1.9861563444137573,
      "learning_rate": 4.3822299651567944e-05,
      "loss": 0.273,
      "step": 5320
    },
    {
      "epoch": 1.2380952380952381,
      "grad_norm": 2.2437710762023926,
      "learning_rate": 4.3810685249709646e-05,
      "loss": 0.2798,
      "step": 5330
    },
    {
      "epoch": 1.240418118466899,
      "grad_norm": 2.1870007514953613,
      "learning_rate": 4.3799070847851334e-05,
      "loss": 0.17,
      "step": 5340
    },
    {
      "epoch": 1.2427409988385598,
      "grad_norm": 1.462978720664978,
      "learning_rate": 4.3787456445993035e-05,
      "loss": 0.2126,
      "step": 5350
    },
    {
      "epoch": 1.2450638792102207,
      "grad_norm": 1.5443769693374634,
      "learning_rate": 4.377584204413473e-05,
      "loss": 0.1782,
      "step": 5360
    },
    {
      "epoch": 1.2473867595818815,
      "grad_norm": 1.8557075262069702,
      "learning_rate": 4.3764227642276424e-05,
      "loss": 0.1432,
      "step": 5370
    },
    {
      "epoch": 1.2497096399535423,
      "grad_norm": 2.0485637187957764,
      "learning_rate": 4.375261324041812e-05,
      "loss": 0.1733,
      "step": 5380
    },
    {
      "epoch": 1.2520325203252032,
      "grad_norm": 1.3381541967391968,
      "learning_rate": 4.3740998838559814e-05,
      "loss": 0.1366,
      "step": 5390
    },
    {
      "epoch": 1.254355400696864,
      "grad_norm": 1.9676603078842163,
      "learning_rate": 4.372938443670151e-05,
      "loss": 0.3001,
      "step": 5400
    },
    {
      "epoch": 1.2566782810685249,
      "grad_norm": 1.5180027484893799,
      "learning_rate": 4.371777003484321e-05,
      "loss": 0.13,
      "step": 5410
    },
    {
      "epoch": 1.2590011614401857,
      "grad_norm": 1.5439287424087524,
      "learning_rate": 4.3706155632984905e-05,
      "loss": 0.1482,
      "step": 5420
    },
    {
      "epoch": 1.2613240418118468,
      "grad_norm": 1.978543758392334,
      "learning_rate": 4.36945412311266e-05,
      "loss": 0.1695,
      "step": 5430
    },
    {
      "epoch": 1.2636469221835076,
      "grad_norm": 1.7616482973098755,
      "learning_rate": 4.3682926829268294e-05,
      "loss": 0.2013,
      "step": 5440
    },
    {
      "epoch": 1.2659698025551684,
      "grad_norm": 1.0598080158233643,
      "learning_rate": 4.367131242740999e-05,
      "loss": 0.1762,
      "step": 5450
    },
    {
      "epoch": 1.2682926829268293,
      "grad_norm": 1.905522346496582,
      "learning_rate": 4.365969802555169e-05,
      "loss": 0.1775,
      "step": 5460
    },
    {
      "epoch": 1.2706155632984901,
      "grad_norm": 1.1934292316436768,
      "learning_rate": 4.364808362369338e-05,
      "loss": 0.1577,
      "step": 5470
    },
    {
      "epoch": 1.272938443670151,
      "grad_norm": 2.548903226852417,
      "learning_rate": 4.363646922183508e-05,
      "loss": 0.1416,
      "step": 5480
    },
    {
      "epoch": 1.2752613240418118,
      "grad_norm": 1.2739239931106567,
      "learning_rate": 4.3624854819976774e-05,
      "loss": 0.2408,
      "step": 5490
    },
    {
      "epoch": 1.2775842044134726,
      "grad_norm": 1.462555170059204,
      "learning_rate": 4.361324041811847e-05,
      "loss": 0.14,
      "step": 5500
    },
    {
      "epoch": 1.2799070847851335,
      "grad_norm": 2.605090856552124,
      "learning_rate": 4.3601626016260163e-05,
      "loss": 0.2994,
      "step": 5510
    },
    {
      "epoch": 1.2822299651567945,
      "grad_norm": 1.6525946855545044,
      "learning_rate": 4.359001161440186e-05,
      "loss": 0.1185,
      "step": 5520
    },
    {
      "epoch": 1.2845528455284554,
      "grad_norm": 1.7534970045089722,
      "learning_rate": 4.357839721254355e-05,
      "loss": 0.121,
      "step": 5530
    },
    {
      "epoch": 1.2868757259001162,
      "grad_norm": 1.560789942741394,
      "learning_rate": 4.3566782810685254e-05,
      "loss": 0.2202,
      "step": 5540
    },
    {
      "epoch": 1.289198606271777,
      "grad_norm": 1.3101426362991333,
      "learning_rate": 4.355516840882695e-05,
      "loss": 0.1624,
      "step": 5550
    },
    {
      "epoch": 1.291521486643438,
      "grad_norm": 1.646942377090454,
      "learning_rate": 4.3543554006968644e-05,
      "loss": 0.1428,
      "step": 5560
    },
    {
      "epoch": 1.2938443670150988,
      "grad_norm": 1.223587989807129,
      "learning_rate": 4.353193960511034e-05,
      "loss": 0.1363,
      "step": 5570
    },
    {
      "epoch": 1.2961672473867596,
      "grad_norm": 1.5396727323532104,
      "learning_rate": 4.352032520325203e-05,
      "loss": 0.1883,
      "step": 5580
    },
    {
      "epoch": 1.2984901277584204,
      "grad_norm": 0.7862326502799988,
      "learning_rate": 4.3508710801393734e-05,
      "loss": 0.164,
      "step": 5590
    },
    {
      "epoch": 1.3008130081300813,
      "grad_norm": 1.7857975959777832,
      "learning_rate": 4.349709639953542e-05,
      "loss": 0.1546,
      "step": 5600
    },
    {
      "epoch": 1.3031358885017421,
      "grad_norm": 1.5901081562042236,
      "learning_rate": 4.3485481997677124e-05,
      "loss": 0.1944,
      "step": 5610
    },
    {
      "epoch": 1.305458768873403,
      "grad_norm": 0.8772972226142883,
      "learning_rate": 4.347386759581882e-05,
      "loss": 0.1838,
      "step": 5620
    },
    {
      "epoch": 1.3077816492450638,
      "grad_norm": 1.2851001024246216,
      "learning_rate": 4.346225319396051e-05,
      "loss": 0.168,
      "step": 5630
    },
    {
      "epoch": 1.3101045296167246,
      "grad_norm": 1.6851766109466553,
      "learning_rate": 4.345063879210221e-05,
      "loss": 0.1205,
      "step": 5640
    },
    {
      "epoch": 1.3124274099883855,
      "grad_norm": 2.182215929031372,
      "learning_rate": 4.34390243902439e-05,
      "loss": 0.2625,
      "step": 5650
    },
    {
      "epoch": 1.3147502903600465,
      "grad_norm": 1.1798617839813232,
      "learning_rate": 4.34274099883856e-05,
      "loss": 0.1921,
      "step": 5660
    },
    {
      "epoch": 1.3170731707317074,
      "grad_norm": 1.6054397821426392,
      "learning_rate": 4.34157955865273e-05,
      "loss": 0.193,
      "step": 5670
    },
    {
      "epoch": 1.3193960511033682,
      "grad_norm": 1.168591022491455,
      "learning_rate": 4.340418118466899e-05,
      "loss": 0.1652,
      "step": 5680
    },
    {
      "epoch": 1.321718931475029,
      "grad_norm": 1.433370590209961,
      "learning_rate": 4.339256678281069e-05,
      "loss": 0.1301,
      "step": 5690
    },
    {
      "epoch": 1.32404181184669,
      "grad_norm": 1.5318787097930908,
      "learning_rate": 4.338095238095238e-05,
      "loss": 0.1803,
      "step": 5700
    },
    {
      "epoch": 1.3263646922183507,
      "grad_norm": 1.7269638776779175,
      "learning_rate": 4.336933797909408e-05,
      "loss": 0.1415,
      "step": 5710
    },
    {
      "epoch": 1.3286875725900116,
      "grad_norm": 1.5601240396499634,
      "learning_rate": 4.335772357723578e-05,
      "loss": 0.1891,
      "step": 5720
    },
    {
      "epoch": 1.3310104529616724,
      "grad_norm": 1.2670210599899292,
      "learning_rate": 4.3346109175377467e-05,
      "loss": 0.21,
      "step": 5730
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 1.3615144491195679,
      "learning_rate": 4.333449477351916e-05,
      "loss": 0.1853,
      "step": 5740
    },
    {
      "epoch": 1.3356562137049943,
      "grad_norm": 2.7326557636260986,
      "learning_rate": 4.332288037166086e-05,
      "loss": 0.2169,
      "step": 5750
    },
    {
      "epoch": 1.3379790940766552,
      "grad_norm": 1.7811493873596191,
      "learning_rate": 4.331126596980256e-05,
      "loss": 0.2154,
      "step": 5760
    },
    {
      "epoch": 1.340301974448316,
      "grad_norm": 1.2277568578720093,
      "learning_rate": 4.329965156794425e-05,
      "loss": 0.1393,
      "step": 5770
    },
    {
      "epoch": 1.3426248548199768,
      "grad_norm": 1.2060325145721436,
      "learning_rate": 4.328803716608595e-05,
      "loss": 0.1663,
      "step": 5780
    },
    {
      "epoch": 1.3449477351916377,
      "grad_norm": 1.4319651126861572,
      "learning_rate": 4.327642276422764e-05,
      "loss": 0.311,
      "step": 5790
    },
    {
      "epoch": 1.3472706155632985,
      "grad_norm": 1.5348832607269287,
      "learning_rate": 4.326480836236934e-05,
      "loss": 0.1602,
      "step": 5800
    },
    {
      "epoch": 1.3495934959349594,
      "grad_norm": 0.9861860275268555,
      "learning_rate": 4.325319396051104e-05,
      "loss": 0.199,
      "step": 5810
    },
    {
      "epoch": 1.3519163763066202,
      "grad_norm": 1.3110172748565674,
      "learning_rate": 4.324157955865273e-05,
      "loss": 0.1682,
      "step": 5820
    },
    {
      "epoch": 1.354239256678281,
      "grad_norm": 1.8654807806015015,
      "learning_rate": 4.322996515679443e-05,
      "loss": 0.1206,
      "step": 5830
    },
    {
      "epoch": 1.3565621370499419,
      "grad_norm": 1.3179682493209839,
      "learning_rate": 4.321835075493612e-05,
      "loss": 0.1229,
      "step": 5840
    },
    {
      "epoch": 1.3588850174216027,
      "grad_norm": 1.4618821144104004,
      "learning_rate": 4.320673635307782e-05,
      "loss": 0.2267,
      "step": 5850
    },
    {
      "epoch": 1.3612078977932636,
      "grad_norm": 1.954134464263916,
      "learning_rate": 4.319512195121951e-05,
      "loss": 0.182,
      "step": 5860
    },
    {
      "epoch": 1.3635307781649244,
      "grad_norm": 1.164913296699524,
      "learning_rate": 4.3183507549361205e-05,
      "loss": 0.1572,
      "step": 5870
    },
    {
      "epoch": 1.3658536585365852,
      "grad_norm": 1.861180067062378,
      "learning_rate": 4.317189314750291e-05,
      "loss": 0.1582,
      "step": 5880
    },
    {
      "epoch": 1.368176538908246,
      "grad_norm": 1.3984018564224243,
      "learning_rate": 4.31602787456446e-05,
      "loss": 0.1189,
      "step": 5890
    },
    {
      "epoch": 1.3704994192799071,
      "grad_norm": 1.045912742614746,
      "learning_rate": 4.3148664343786296e-05,
      "loss": 0.1759,
      "step": 5900
    },
    {
      "epoch": 1.372822299651568,
      "grad_norm": 1.1755176782608032,
      "learning_rate": 4.313704994192799e-05,
      "loss": 0.2606,
      "step": 5910
    },
    {
      "epoch": 1.3751451800232288,
      "grad_norm": 1.6544424295425415,
      "learning_rate": 4.3125435540069686e-05,
      "loss": 0.1897,
      "step": 5920
    },
    {
      "epoch": 1.3774680603948897,
      "grad_norm": 1.7906900644302368,
      "learning_rate": 4.311382113821139e-05,
      "loss": 0.1251,
      "step": 5930
    },
    {
      "epoch": 1.3797909407665505,
      "grad_norm": 2.0484249591827393,
      "learning_rate": 4.310220673635308e-05,
      "loss": 0.1419,
      "step": 5940
    },
    {
      "epoch": 1.3821138211382114,
      "grad_norm": 1.9201595783233643,
      "learning_rate": 4.3090592334494776e-05,
      "loss": 0.2161,
      "step": 5950
    },
    {
      "epoch": 1.3844367015098722,
      "grad_norm": 1.1148191690444946,
      "learning_rate": 4.307897793263647e-05,
      "loss": 0.2228,
      "step": 5960
    },
    {
      "epoch": 1.386759581881533,
      "grad_norm": 2.6176905632019043,
      "learning_rate": 4.3067363530778166e-05,
      "loss": 0.2199,
      "step": 5970
    },
    {
      "epoch": 1.389082462253194,
      "grad_norm": 2.2891507148742676,
      "learning_rate": 4.305574912891987e-05,
      "loss": 0.1834,
      "step": 5980
    },
    {
      "epoch": 1.391405342624855,
      "grad_norm": 0.9219794869422913,
      "learning_rate": 4.3044134727061555e-05,
      "loss": 0.1967,
      "step": 5990
    },
    {
      "epoch": 1.3937282229965158,
      "grad_norm": 1.2810496091842651,
      "learning_rate": 4.303252032520325e-05,
      "loss": 0.1407,
      "step": 6000
    },
    {
      "epoch": 1.3960511033681766,
      "grad_norm": 1.076405644416809,
      "learning_rate": 4.302090592334495e-05,
      "loss": 0.2105,
      "step": 6010
    },
    {
      "epoch": 1.3983739837398375,
      "grad_norm": 1.7735178470611572,
      "learning_rate": 4.3009291521486646e-05,
      "loss": 0.1715,
      "step": 6020
    },
    {
      "epoch": 1.4006968641114983,
      "grad_norm": 1.4960622787475586,
      "learning_rate": 4.299767711962834e-05,
      "loss": 0.1733,
      "step": 6030
    },
    {
      "epoch": 1.4030197444831591,
      "grad_norm": 2.0100767612457275,
      "learning_rate": 4.2986062717770035e-05,
      "loss": 0.1262,
      "step": 6040
    },
    {
      "epoch": 1.40534262485482,
      "grad_norm": 1.387114405632019,
      "learning_rate": 4.297444831591173e-05,
      "loss": 0.158,
      "step": 6050
    },
    {
      "epoch": 1.4076655052264808,
      "grad_norm": 1.9968022108078003,
      "learning_rate": 4.296283391405343e-05,
      "loss": 0.1632,
      "step": 6060
    },
    {
      "epoch": 1.4099883855981417,
      "grad_norm": 2.324716329574585,
      "learning_rate": 4.2951219512195126e-05,
      "loss": 0.1449,
      "step": 6070
    },
    {
      "epoch": 1.4123112659698025,
      "grad_norm": 2.2938051223754883,
      "learning_rate": 4.293960511033682e-05,
      "loss": 0.3034,
      "step": 6080
    },
    {
      "epoch": 1.4146341463414633,
      "grad_norm": 0.7902980446815491,
      "learning_rate": 4.2927990708478515e-05,
      "loss": 0.1487,
      "step": 6090
    },
    {
      "epoch": 1.4169570267131242,
      "grad_norm": 1.6274861097335815,
      "learning_rate": 4.291637630662021e-05,
      "loss": 0.2608,
      "step": 6100
    },
    {
      "epoch": 1.419279907084785,
      "grad_norm": 1.5854827165603638,
      "learning_rate": 4.290476190476191e-05,
      "loss": 0.1902,
      "step": 6110
    },
    {
      "epoch": 1.4216027874564459,
      "grad_norm": 1.1564956903457642,
      "learning_rate": 4.28931475029036e-05,
      "loss": 0.1302,
      "step": 6120
    },
    {
      "epoch": 1.423925667828107,
      "grad_norm": 1.4511959552764893,
      "learning_rate": 4.2881533101045294e-05,
      "loss": 0.2417,
      "step": 6130
    },
    {
      "epoch": 1.4262485481997678,
      "grad_norm": 1.663481593132019,
      "learning_rate": 4.2869918699186996e-05,
      "loss": 0.1991,
      "step": 6140
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 2.391494035720825,
      "learning_rate": 4.285830429732869e-05,
      "loss": 0.1827,
      "step": 6150
    },
    {
      "epoch": 1.4308943089430894,
      "grad_norm": 1.690198540687561,
      "learning_rate": 4.2846689895470385e-05,
      "loss": 0.2471,
      "step": 6160
    },
    {
      "epoch": 1.4332171893147503,
      "grad_norm": 1.958881139755249,
      "learning_rate": 4.283507549361208e-05,
      "loss": 0.2164,
      "step": 6170
    },
    {
      "epoch": 1.4355400696864111,
      "grad_norm": 1.8542048931121826,
      "learning_rate": 4.2823461091753774e-05,
      "loss": 0.166,
      "step": 6180
    },
    {
      "epoch": 1.437862950058072,
      "grad_norm": 1.1566213369369507,
      "learning_rate": 4.2811846689895476e-05,
      "loss": 0.2173,
      "step": 6190
    },
    {
      "epoch": 1.4401858304297328,
      "grad_norm": 1.0291757583618164,
      "learning_rate": 4.280023228803717e-05,
      "loss": 0.1396,
      "step": 6200
    },
    {
      "epoch": 1.4425087108013936,
      "grad_norm": 1.3495686054229736,
      "learning_rate": 4.278861788617886e-05,
      "loss": 0.1794,
      "step": 6210
    },
    {
      "epoch": 1.4448315911730547,
      "grad_norm": 1.048649549484253,
      "learning_rate": 4.277700348432056e-05,
      "loss": 0.1348,
      "step": 6220
    },
    {
      "epoch": 1.4471544715447155,
      "grad_norm": 0.9523850083351135,
      "learning_rate": 4.2765389082462254e-05,
      "loss": 0.2001,
      "step": 6230
    },
    {
      "epoch": 1.4494773519163764,
      "grad_norm": 0.9496129155158997,
      "learning_rate": 4.2753774680603956e-05,
      "loss": 0.1353,
      "step": 6240
    },
    {
      "epoch": 1.4518002322880372,
      "grad_norm": 2.202633857727051,
      "learning_rate": 4.2742160278745644e-05,
      "loss": 0.1688,
      "step": 6250
    },
    {
      "epoch": 1.454123112659698,
      "grad_norm": 1.315065860748291,
      "learning_rate": 4.273054587688734e-05,
      "loss": 0.2728,
      "step": 6260
    },
    {
      "epoch": 1.456445993031359,
      "grad_norm": 1.2110984325408936,
      "learning_rate": 4.271893147502904e-05,
      "loss": 0.1817,
      "step": 6270
    },
    {
      "epoch": 1.4587688734030198,
      "grad_norm": 0.8133216500282288,
      "learning_rate": 4.2707317073170735e-05,
      "loss": 0.1858,
      "step": 6280
    },
    {
      "epoch": 1.4610917537746806,
      "grad_norm": 1.3491123914718628,
      "learning_rate": 4.269570267131243e-05,
      "loss": 0.1626,
      "step": 6290
    },
    {
      "epoch": 1.4634146341463414,
      "grad_norm": 2.0094525814056396,
      "learning_rate": 4.2684088269454124e-05,
      "loss": 0.1388,
      "step": 6300
    },
    {
      "epoch": 1.4657375145180023,
      "grad_norm": 1.6901432275772095,
      "learning_rate": 4.267247386759582e-05,
      "loss": 0.2147,
      "step": 6310
    },
    {
      "epoch": 1.4680603948896631,
      "grad_norm": 2.594198703765869,
      "learning_rate": 4.266085946573752e-05,
      "loss": 0.2242,
      "step": 6320
    },
    {
      "epoch": 1.470383275261324,
      "grad_norm": 0.8580862879753113,
      "learning_rate": 4.2649245063879215e-05,
      "loss": 0.1491,
      "step": 6330
    },
    {
      "epoch": 1.4727061556329848,
      "grad_norm": 2.8336334228515625,
      "learning_rate": 4.26376306620209e-05,
      "loss": 0.161,
      "step": 6340
    },
    {
      "epoch": 1.4750290360046456,
      "grad_norm": 2.18862247467041,
      "learning_rate": 4.2626016260162604e-05,
      "loss": 0.2344,
      "step": 6350
    },
    {
      "epoch": 1.4773519163763067,
      "grad_norm": 1.3370281457901,
      "learning_rate": 4.26144018583043e-05,
      "loss": 0.1284,
      "step": 6360
    },
    {
      "epoch": 1.4796747967479675,
      "grad_norm": 0.840071976184845,
      "learning_rate": 4.2602787456446e-05,
      "loss": 0.1163,
      "step": 6370
    },
    {
      "epoch": 1.4819976771196284,
      "grad_norm": 1.9704185724258423,
      "learning_rate": 4.259117305458769e-05,
      "loss": 0.2728,
      "step": 6380
    },
    {
      "epoch": 1.4843205574912892,
      "grad_norm": 0.8535187244415283,
      "learning_rate": 4.257955865272938e-05,
      "loss": 0.1533,
      "step": 6390
    },
    {
      "epoch": 1.48664343786295,
      "grad_norm": 1.3007234334945679,
      "learning_rate": 4.2567944250871084e-05,
      "loss": 0.1182,
      "step": 6400
    },
    {
      "epoch": 1.488966318234611,
      "grad_norm": 1.9285496473312378,
      "learning_rate": 4.255632984901278e-05,
      "loss": 0.1852,
      "step": 6410
    },
    {
      "epoch": 1.4912891986062717,
      "grad_norm": 1.5414193868637085,
      "learning_rate": 4.2544715447154473e-05,
      "loss": 0.1824,
      "step": 6420
    },
    {
      "epoch": 1.4936120789779326,
      "grad_norm": 1.4802075624465942,
      "learning_rate": 4.253310104529617e-05,
      "loss": 0.1879,
      "step": 6430
    },
    {
      "epoch": 1.4959349593495934,
      "grad_norm": 1.7274320125579834,
      "learning_rate": 4.252148664343786e-05,
      "loss": 0.1657,
      "step": 6440
    },
    {
      "epoch": 1.4982578397212545,
      "grad_norm": 1.077274203300476,
      "learning_rate": 4.2509872241579564e-05,
      "loss": 0.1584,
      "step": 6450
    },
    {
      "epoch": 1.5005807200929153,
      "grad_norm": 1.4057180881500244,
      "learning_rate": 4.249825783972126e-05,
      "loss": 0.2115,
      "step": 6460
    },
    {
      "epoch": 1.5029036004645762,
      "grad_norm": 1.749128818511963,
      "learning_rate": 4.248664343786295e-05,
      "loss": 0.1759,
      "step": 6470
    },
    {
      "epoch": 1.505226480836237,
      "grad_norm": 1.5313206911087036,
      "learning_rate": 4.247502903600465e-05,
      "loss": 0.169,
      "step": 6480
    },
    {
      "epoch": 1.5075493612078978,
      "grad_norm": 1.5987749099731445,
      "learning_rate": 4.246341463414634e-05,
      "loss": 0.2079,
      "step": 6490
    },
    {
      "epoch": 1.5098722415795587,
      "grad_norm": 2.1548826694488525,
      "learning_rate": 4.2451800232288044e-05,
      "loss": 0.2365,
      "step": 6500
    },
    {
      "epoch": 1.5121951219512195,
      "grad_norm": 1.592284917831421,
      "learning_rate": 4.244018583042973e-05,
      "loss": 0.3191,
      "step": 6510
    },
    {
      "epoch": 1.5145180023228804,
      "grad_norm": 1.2903035879135132,
      "learning_rate": 4.242857142857143e-05,
      "loss": 0.0971,
      "step": 6520
    },
    {
      "epoch": 1.5168408826945412,
      "grad_norm": 1.3802484273910522,
      "learning_rate": 4.241695702671313e-05,
      "loss": 0.1988,
      "step": 6530
    },
    {
      "epoch": 1.519163763066202,
      "grad_norm": 1.8273273706436157,
      "learning_rate": 4.240534262485482e-05,
      "loss": 0.1313,
      "step": 6540
    },
    {
      "epoch": 1.5214866434378629,
      "grad_norm": 1.1978262662887573,
      "learning_rate": 4.239372822299652e-05,
      "loss": 0.1245,
      "step": 6550
    },
    {
      "epoch": 1.5238095238095237,
      "grad_norm": 1.4983266592025757,
      "learning_rate": 4.238211382113821e-05,
      "loss": 0.1963,
      "step": 6560
    },
    {
      "epoch": 1.5261324041811846,
      "grad_norm": 0.8688780069351196,
      "learning_rate": 4.237049941927991e-05,
      "loss": 0.2014,
      "step": 6570
    },
    {
      "epoch": 1.5284552845528454,
      "grad_norm": 0.7078522443771362,
      "learning_rate": 4.235888501742161e-05,
      "loss": 0.1197,
      "step": 6580
    },
    {
      "epoch": 1.5307781649245062,
      "grad_norm": 1.3964552879333496,
      "learning_rate": 4.23472706155633e-05,
      "loss": 0.086,
      "step": 6590
    },
    {
      "epoch": 1.533101045296167,
      "grad_norm": 0.9910948872566223,
      "learning_rate": 4.233565621370499e-05,
      "loss": 0.1766,
      "step": 6600
    },
    {
      "epoch": 1.5354239256678281,
      "grad_norm": 1.456468105316162,
      "learning_rate": 4.232404181184669e-05,
      "loss": 0.2339,
      "step": 6610
    },
    {
      "epoch": 1.537746806039489,
      "grad_norm": 1.2673814296722412,
      "learning_rate": 4.231242740998839e-05,
      "loss": 0.2116,
      "step": 6620
    },
    {
      "epoch": 1.5400696864111498,
      "grad_norm": 0.79963618516922,
      "learning_rate": 4.230081300813009e-05,
      "loss": 0.2422,
      "step": 6630
    },
    {
      "epoch": 1.5423925667828107,
      "grad_norm": 2.0080723762512207,
      "learning_rate": 4.2289198606271777e-05,
      "loss": 0.151,
      "step": 6640
    },
    {
      "epoch": 1.5447154471544715,
      "grad_norm": 1.2096624374389648,
      "learning_rate": 4.227758420441347e-05,
      "loss": 0.1615,
      "step": 6650
    },
    {
      "epoch": 1.5470383275261324,
      "grad_norm": 1.2089836597442627,
      "learning_rate": 4.226596980255517e-05,
      "loss": 0.1355,
      "step": 6660
    },
    {
      "epoch": 1.5493612078977934,
      "grad_norm": 0.9302932620048523,
      "learning_rate": 4.225435540069687e-05,
      "loss": 0.111,
      "step": 6670
    },
    {
      "epoch": 1.5516840882694543,
      "grad_norm": 2.313074827194214,
      "learning_rate": 4.224274099883856e-05,
      "loss": 0.1779,
      "step": 6680
    },
    {
      "epoch": 1.554006968641115,
      "grad_norm": 0.9512494802474976,
      "learning_rate": 4.223112659698026e-05,
      "loss": 0.1303,
      "step": 6690
    },
    {
      "epoch": 1.556329849012776,
      "grad_norm": 1.7819342613220215,
      "learning_rate": 4.221951219512195e-05,
      "loss": 0.2298,
      "step": 6700
    },
    {
      "epoch": 1.5586527293844368,
      "grad_norm": 1.1811208724975586,
      "learning_rate": 4.220789779326365e-05,
      "loss": 0.2201,
      "step": 6710
    },
    {
      "epoch": 1.5609756097560976,
      "grad_norm": 2.44240403175354,
      "learning_rate": 4.219628339140535e-05,
      "loss": 0.2118,
      "step": 6720
    },
    {
      "epoch": 1.5632984901277585,
      "grad_norm": 1.3714406490325928,
      "learning_rate": 4.2184668989547035e-05,
      "loss": 0.1569,
      "step": 6730
    },
    {
      "epoch": 1.5656213704994193,
      "grad_norm": 1.3035781383514404,
      "learning_rate": 4.217305458768874e-05,
      "loss": 0.1545,
      "step": 6740
    },
    {
      "epoch": 1.5679442508710801,
      "grad_norm": 1.1255117654800415,
      "learning_rate": 4.216144018583043e-05,
      "loss": 0.1528,
      "step": 6750
    },
    {
      "epoch": 1.570267131242741,
      "grad_norm": 1.4541780948638916,
      "learning_rate": 4.214982578397213e-05,
      "loss": 0.164,
      "step": 6760
    },
    {
      "epoch": 1.5725900116144018,
      "grad_norm": 1.2906538248062134,
      "learning_rate": 4.213821138211382e-05,
      "loss": 0.1849,
      "step": 6770
    },
    {
      "epoch": 1.5749128919860627,
      "grad_norm": 1.7287557125091553,
      "learning_rate": 4.2126596980255516e-05,
      "loss": 0.2678,
      "step": 6780
    },
    {
      "epoch": 1.5772357723577235,
      "grad_norm": 1.4979749917984009,
      "learning_rate": 4.211498257839722e-05,
      "loss": 0.1356,
      "step": 6790
    },
    {
      "epoch": 1.5795586527293843,
      "grad_norm": 1.7273354530334473,
      "learning_rate": 4.210336817653891e-05,
      "loss": 0.1695,
      "step": 6800
    },
    {
      "epoch": 1.5818815331010452,
      "grad_norm": 0.8042834997177124,
      "learning_rate": 4.2091753774680606e-05,
      "loss": 0.2215,
      "step": 6810
    },
    {
      "epoch": 1.584204413472706,
      "grad_norm": 1.5485131740570068,
      "learning_rate": 4.20801393728223e-05,
      "loss": 0.231,
      "step": 6820
    },
    {
      "epoch": 1.5865272938443669,
      "grad_norm": 1.6210310459136963,
      "learning_rate": 4.2068524970963996e-05,
      "loss": 0.207,
      "step": 6830
    },
    {
      "epoch": 1.588850174216028,
      "grad_norm": 2.9506638050079346,
      "learning_rate": 4.20569105691057e-05,
      "loss": 0.1224,
      "step": 6840
    },
    {
      "epoch": 1.5911730545876888,
      "grad_norm": 1.2959392070770264,
      "learning_rate": 4.204529616724739e-05,
      "loss": 0.2378,
      "step": 6850
    },
    {
      "epoch": 1.5934959349593496,
      "grad_norm": 2.0324487686157227,
      "learning_rate": 4.203368176538908e-05,
      "loss": 0.1756,
      "step": 6860
    },
    {
      "epoch": 1.5958188153310104,
      "grad_norm": 1.6198161840438843,
      "learning_rate": 4.202206736353078e-05,
      "loss": 0.2357,
      "step": 6870
    },
    {
      "epoch": 1.5981416957026713,
      "grad_norm": 2.261669635772705,
      "learning_rate": 4.2010452961672476e-05,
      "loss": 0.1886,
      "step": 6880
    },
    {
      "epoch": 1.6004645760743321,
      "grad_norm": 1.9293826818466187,
      "learning_rate": 4.199883855981418e-05,
      "loss": 0.1047,
      "step": 6890
    },
    {
      "epoch": 1.6027874564459932,
      "grad_norm": 2.9580037593841553,
      "learning_rate": 4.1987224157955865e-05,
      "loss": 0.1851,
      "step": 6900
    },
    {
      "epoch": 1.605110336817654,
      "grad_norm": 1.9383368492126465,
      "learning_rate": 4.197560975609756e-05,
      "loss": 0.1851,
      "step": 6910
    },
    {
      "epoch": 1.6074332171893149,
      "grad_norm": 1.6337963342666626,
      "learning_rate": 4.196399535423926e-05,
      "loss": 0.2217,
      "step": 6920
    },
    {
      "epoch": 1.6097560975609757,
      "grad_norm": 2.0505592823028564,
      "learning_rate": 4.1952380952380956e-05,
      "loss": 0.2045,
      "step": 6930
    },
    {
      "epoch": 1.6120789779326365,
      "grad_norm": 1.1487131118774414,
      "learning_rate": 4.194076655052265e-05,
      "loss": 0.1501,
      "step": 6940
    },
    {
      "epoch": 1.6144018583042974,
      "grad_norm": 1.4092962741851807,
      "learning_rate": 4.1929152148664345e-05,
      "loss": 0.1763,
      "step": 6950
    },
    {
      "epoch": 1.6167247386759582,
      "grad_norm": 1.1162124872207642,
      "learning_rate": 4.191753774680604e-05,
      "loss": 0.1724,
      "step": 6960
    },
    {
      "epoch": 1.619047619047619,
      "grad_norm": 1.1990727186203003,
      "learning_rate": 4.190592334494774e-05,
      "loss": 0.2574,
      "step": 6970
    },
    {
      "epoch": 1.62137049941928,
      "grad_norm": 1.8076987266540527,
      "learning_rate": 4.1894308943089436e-05,
      "loss": 0.1963,
      "step": 6980
    },
    {
      "epoch": 1.6236933797909407,
      "grad_norm": 1.2909409999847412,
      "learning_rate": 4.1882694541231124e-05,
      "loss": 0.1643,
      "step": 6990
    },
    {
      "epoch": 1.6260162601626016,
      "grad_norm": 1.3171050548553467,
      "learning_rate": 4.1871080139372825e-05,
      "loss": 0.1616,
      "step": 7000
    },
    {
      "epoch": 1.6283391405342624,
      "grad_norm": 0.9250301718711853,
      "learning_rate": 4.185946573751452e-05,
      "loss": 0.1884,
      "step": 7010
    },
    {
      "epoch": 1.6306620209059233,
      "grad_norm": 1.0288171768188477,
      "learning_rate": 4.1847851335656215e-05,
      "loss": 0.173,
      "step": 7020
    },
    {
      "epoch": 1.6329849012775841,
      "grad_norm": 1.5027285814285278,
      "learning_rate": 4.183623693379791e-05,
      "loss": 0.1308,
      "step": 7030
    },
    {
      "epoch": 1.635307781649245,
      "grad_norm": 1.030720591545105,
      "learning_rate": 4.1824622531939604e-05,
      "loss": 0.2975,
      "step": 7040
    },
    {
      "epoch": 1.6376306620209058,
      "grad_norm": 1.9769179821014404,
      "learning_rate": 4.1813008130081306e-05,
      "loss": 0.1937,
      "step": 7050
    },
    {
      "epoch": 1.6399535423925666,
      "grad_norm": 1.267447590827942,
      "learning_rate": 4.1801393728223e-05,
      "loss": 0.2507,
      "step": 7060
    },
    {
      "epoch": 1.6422764227642277,
      "grad_norm": 1.419512152671814,
      "learning_rate": 4.1789779326364695e-05,
      "loss": 0.2305,
      "step": 7070
    },
    {
      "epoch": 1.6445993031358885,
      "grad_norm": 2.537057876586914,
      "learning_rate": 4.177816492450639e-05,
      "loss": 0.1714,
      "step": 7080
    },
    {
      "epoch": 1.6469221835075494,
      "grad_norm": 1.4144537448883057,
      "learning_rate": 4.1766550522648084e-05,
      "loss": 0.1678,
      "step": 7090
    },
    {
      "epoch": 1.6492450638792102,
      "grad_norm": 1.5823149681091309,
      "learning_rate": 4.1754936120789786e-05,
      "loss": 0.1638,
      "step": 7100
    },
    {
      "epoch": 1.651567944250871,
      "grad_norm": 1.2245696783065796,
      "learning_rate": 4.174332171893148e-05,
      "loss": 0.2129,
      "step": 7110
    },
    {
      "epoch": 1.653890824622532,
      "grad_norm": 1.6732913255691528,
      "learning_rate": 4.173170731707317e-05,
      "loss": 0.2053,
      "step": 7120
    },
    {
      "epoch": 1.656213704994193,
      "grad_norm": 1.5933653116226196,
      "learning_rate": 4.172009291521487e-05,
      "loss": 0.2289,
      "step": 7130
    },
    {
      "epoch": 1.6585365853658538,
      "grad_norm": 1.6146799325942993,
      "learning_rate": 4.1708478513356564e-05,
      "loss": 0.2329,
      "step": 7140
    },
    {
      "epoch": 1.6608594657375146,
      "grad_norm": 2.0590343475341797,
      "learning_rate": 4.169686411149826e-05,
      "loss": 0.1832,
      "step": 7150
    },
    {
      "epoch": 1.6631823461091755,
      "grad_norm": 0.920990526676178,
      "learning_rate": 4.1685249709639954e-05,
      "loss": 0.1453,
      "step": 7160
    },
    {
      "epoch": 1.6655052264808363,
      "grad_norm": 1.0139347314834595,
      "learning_rate": 4.167363530778165e-05,
      "loss": 0.1196,
      "step": 7170
    },
    {
      "epoch": 1.6678281068524972,
      "grad_norm": 0.6233535408973694,
      "learning_rate": 4.166202090592335e-05,
      "loss": 0.1754,
      "step": 7180
    },
    {
      "epoch": 1.670150987224158,
      "grad_norm": 1.3767492771148682,
      "learning_rate": 4.1650406504065045e-05,
      "loss": 0.1804,
      "step": 7190
    },
    {
      "epoch": 1.6724738675958188,
      "grad_norm": 0.971084713935852,
      "learning_rate": 4.163879210220674e-05,
      "loss": 0.2345,
      "step": 7200
    },
    {
      "epoch": 1.6747967479674797,
      "grad_norm": 1.6315083503723145,
      "learning_rate": 4.1627177700348434e-05,
      "loss": 0.1543,
      "step": 7210
    },
    {
      "epoch": 1.6771196283391405,
      "grad_norm": 1.7023248672485352,
      "learning_rate": 4.161556329849013e-05,
      "loss": 0.1773,
      "step": 7220
    },
    {
      "epoch": 1.6794425087108014,
      "grad_norm": 0.9918646812438965,
      "learning_rate": 4.160394889663183e-05,
      "loss": 0.1077,
      "step": 7230
    },
    {
      "epoch": 1.6817653890824622,
      "grad_norm": 1.403193473815918,
      "learning_rate": 4.1592334494773525e-05,
      "loss": 0.1127,
      "step": 7240
    },
    {
      "epoch": 1.684088269454123,
      "grad_norm": 1.103590965270996,
      "learning_rate": 4.158072009291521e-05,
      "loss": 0.1169,
      "step": 7250
    },
    {
      "epoch": 1.6864111498257839,
      "grad_norm": 1.6976622343063354,
      "learning_rate": 4.1569105691056914e-05,
      "loss": 0.1194,
      "step": 7260
    },
    {
      "epoch": 1.6887340301974447,
      "grad_norm": 1.7180922031402588,
      "learning_rate": 4.155749128919861e-05,
      "loss": 0.1615,
      "step": 7270
    },
    {
      "epoch": 1.6910569105691056,
      "grad_norm": 1.5599949359893799,
      "learning_rate": 4.1545876887340303e-05,
      "loss": 0.1995,
      "step": 7280
    },
    {
      "epoch": 1.6933797909407664,
      "grad_norm": 1.2265267372131348,
      "learning_rate": 4.1534262485482e-05,
      "loss": 0.2276,
      "step": 7290
    },
    {
      "epoch": 1.6957026713124272,
      "grad_norm": 1.1824735403060913,
      "learning_rate": 4.152264808362369e-05,
      "loss": 0.1648,
      "step": 7300
    },
    {
      "epoch": 1.6980255516840883,
      "grad_norm": 1.6308356523513794,
      "learning_rate": 4.1511033681765394e-05,
      "loss": 0.1877,
      "step": 7310
    },
    {
      "epoch": 1.7003484320557491,
      "grad_norm": 1.7576839923858643,
      "learning_rate": 4.149941927990709e-05,
      "loss": 0.2489,
      "step": 7320
    },
    {
      "epoch": 1.70267131242741,
      "grad_norm": 0.768233060836792,
      "learning_rate": 4.1487804878048784e-05,
      "loss": 0.0931,
      "step": 7330
    },
    {
      "epoch": 1.7049941927990708,
      "grad_norm": 1.7838671207427979,
      "learning_rate": 4.147619047619048e-05,
      "loss": 0.2561,
      "step": 7340
    },
    {
      "epoch": 1.7073170731707317,
      "grad_norm": 1.0180892944335938,
      "learning_rate": 4.146457607433217e-05,
      "loss": 0.0946,
      "step": 7350
    },
    {
      "epoch": 1.7096399535423927,
      "grad_norm": 1.8515030145645142,
      "learning_rate": 4.1452961672473874e-05,
      "loss": 0.127,
      "step": 7360
    },
    {
      "epoch": 1.7119628339140536,
      "grad_norm": 1.4961808919906616,
      "learning_rate": 4.144134727061557e-05,
      "loss": 0.2326,
      "step": 7370
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 2.6229403018951416,
      "learning_rate": 4.142973286875726e-05,
      "loss": 0.1416,
      "step": 7380
    },
    {
      "epoch": 1.7166085946573753,
      "grad_norm": 1.6567085981369019,
      "learning_rate": 4.141811846689896e-05,
      "loss": 0.1458,
      "step": 7390
    },
    {
      "epoch": 1.718931475029036,
      "grad_norm": 0.8299915790557861,
      "learning_rate": 4.140650406504065e-05,
      "loss": 0.1472,
      "step": 7400
    },
    {
      "epoch": 1.721254355400697,
      "grad_norm": 1.4205275774002075,
      "learning_rate": 4.139488966318235e-05,
      "loss": 0.1397,
      "step": 7410
    },
    {
      "epoch": 1.7235772357723578,
      "grad_norm": 1.241594910621643,
      "learning_rate": 4.138327526132404e-05,
      "loss": 0.1835,
      "step": 7420
    },
    {
      "epoch": 1.7259001161440186,
      "grad_norm": 1.547166109085083,
      "learning_rate": 4.137166085946574e-05,
      "loss": 0.2123,
      "step": 7430
    },
    {
      "epoch": 1.7282229965156795,
      "grad_norm": 0.9567543864250183,
      "learning_rate": 4.136004645760744e-05,
      "loss": 0.1532,
      "step": 7440
    },
    {
      "epoch": 1.7305458768873403,
      "grad_norm": 1.643644094467163,
      "learning_rate": 4.134843205574913e-05,
      "loss": 0.1356,
      "step": 7450
    },
    {
      "epoch": 1.7328687572590011,
      "grad_norm": 1.379193663597107,
      "learning_rate": 4.133681765389083e-05,
      "loss": 0.1504,
      "step": 7460
    },
    {
      "epoch": 1.735191637630662,
      "grad_norm": 1.1991703510284424,
      "learning_rate": 4.132520325203252e-05,
      "loss": 0.126,
      "step": 7470
    },
    {
      "epoch": 1.7375145180023228,
      "grad_norm": 0.9881410002708435,
      "learning_rate": 4.131358885017422e-05,
      "loss": 0.147,
      "step": 7480
    },
    {
      "epoch": 1.7398373983739837,
      "grad_norm": 1.3884066343307495,
      "learning_rate": 4.130197444831591e-05,
      "loss": 0.1209,
      "step": 7490
    },
    {
      "epoch": 1.7421602787456445,
      "grad_norm": 1.580269455909729,
      "learning_rate": 4.129036004645761e-05,
      "loss": 0.1189,
      "step": 7500
    },
    {
      "epoch": 1.7444831591173053,
      "grad_norm": 1.4866689443588257,
      "learning_rate": 4.12787456445993e-05,
      "loss": 0.1774,
      "step": 7510
    },
    {
      "epoch": 1.7468060394889662,
      "grad_norm": 2.2095603942871094,
      "learning_rate": 4.1267131242741e-05,
      "loss": 0.1201,
      "step": 7520
    },
    {
      "epoch": 1.749128919860627,
      "grad_norm": 1.2582401037216187,
      "learning_rate": 4.12555168408827e-05,
      "loss": 0.1285,
      "step": 7530
    },
    {
      "epoch": 1.751451800232288,
      "grad_norm": 1.4630606174468994,
      "learning_rate": 4.124390243902439e-05,
      "loss": 0.1489,
      "step": 7540
    },
    {
      "epoch": 1.753774680603949,
      "grad_norm": 2.48398756980896,
      "learning_rate": 4.123228803716609e-05,
      "loss": 0.354,
      "step": 7550
    },
    {
      "epoch": 1.7560975609756098,
      "grad_norm": 2.078535318374634,
      "learning_rate": 4.122067363530778e-05,
      "loss": 0.2291,
      "step": 7560
    },
    {
      "epoch": 1.7584204413472706,
      "grad_norm": 0.8586981296539307,
      "learning_rate": 4.120905923344948e-05,
      "loss": 0.1718,
      "step": 7570
    },
    {
      "epoch": 1.7607433217189314,
      "grad_norm": 0.8469703197479248,
      "learning_rate": 4.119744483159118e-05,
      "loss": 0.1695,
      "step": 7580
    },
    {
      "epoch": 1.7630662020905923,
      "grad_norm": 0.8878419995307922,
      "learning_rate": 4.118583042973287e-05,
      "loss": 0.1396,
      "step": 7590
    },
    {
      "epoch": 1.7653890824622533,
      "grad_norm": 1.205744743347168,
      "learning_rate": 4.117421602787457e-05,
      "loss": 0.0908,
      "step": 7600
    },
    {
      "epoch": 1.7677119628339142,
      "grad_norm": 0.9623342752456665,
      "learning_rate": 4.116260162601626e-05,
      "loss": 0.2992,
      "step": 7610
    },
    {
      "epoch": 1.770034843205575,
      "grad_norm": 2.0285837650299072,
      "learning_rate": 4.1150987224157956e-05,
      "loss": 0.1786,
      "step": 7620
    },
    {
      "epoch": 1.7723577235772359,
      "grad_norm": 3.064944267272949,
      "learning_rate": 4.113937282229966e-05,
      "loss": 0.3041,
      "step": 7630
    },
    {
      "epoch": 1.7746806039488967,
      "grad_norm": 3.0376572608947754,
      "learning_rate": 4.1127758420441346e-05,
      "loss": 0.2148,
      "step": 7640
    },
    {
      "epoch": 1.7770034843205575,
      "grad_norm": 2.126690626144409,
      "learning_rate": 4.111614401858305e-05,
      "loss": 0.169,
      "step": 7650
    },
    {
      "epoch": 1.7793263646922184,
      "grad_norm": 1.4895914793014526,
      "learning_rate": 4.110452961672474e-05,
      "loss": 0.1019,
      "step": 7660
    },
    {
      "epoch": 1.7816492450638792,
      "grad_norm": 1.237601399421692,
      "learning_rate": 4.1092915214866436e-05,
      "loss": 0.1284,
      "step": 7670
    },
    {
      "epoch": 1.78397212543554,
      "grad_norm": 1.5419150590896606,
      "learning_rate": 4.108130081300813e-05,
      "loss": 0.1105,
      "step": 7680
    },
    {
      "epoch": 1.786295005807201,
      "grad_norm": 1.1093945503234863,
      "learning_rate": 4.1069686411149826e-05,
      "loss": 0.1471,
      "step": 7690
    },
    {
      "epoch": 1.7886178861788617,
      "grad_norm": 1.3024389743804932,
      "learning_rate": 4.105807200929153e-05,
      "loss": 0.102,
      "step": 7700
    },
    {
      "epoch": 1.7909407665505226,
      "grad_norm": 1.481388807296753,
      "learning_rate": 4.104645760743322e-05,
      "loss": 0.1342,
      "step": 7710
    },
    {
      "epoch": 1.7932636469221834,
      "grad_norm": 1.3106051683425903,
      "learning_rate": 4.1034843205574916e-05,
      "loss": 0.1683,
      "step": 7720
    },
    {
      "epoch": 1.7955865272938443,
      "grad_norm": 1.4364631175994873,
      "learning_rate": 4.102322880371661e-05,
      "loss": 0.1855,
      "step": 7730
    },
    {
      "epoch": 1.797909407665505,
      "grad_norm": 1.2025651931762695,
      "learning_rate": 4.1011614401858306e-05,
      "loss": 0.116,
      "step": 7740
    },
    {
      "epoch": 1.800232288037166,
      "grad_norm": 1.2859054803848267,
      "learning_rate": 4.1e-05,
      "loss": 0.2106,
      "step": 7750
    },
    {
      "epoch": 1.8025551684088268,
      "grad_norm": 2.034851551055908,
      "learning_rate": 4.098954703832753e-05,
      "loss": 0.1539,
      "step": 7760
    },
    {
      "epoch": 1.8048780487804879,
      "grad_norm": 2.017076015472412,
      "learning_rate": 4.0977932636469224e-05,
      "loss": 0.1737,
      "step": 7770
    },
    {
      "epoch": 1.8072009291521487,
      "grad_norm": 1.3269069194793701,
      "learning_rate": 4.096631823461092e-05,
      "loss": 0.1672,
      "step": 7780
    },
    {
      "epoch": 1.8095238095238095,
      "grad_norm": 1.4486504793167114,
      "learning_rate": 4.095470383275262e-05,
      "loss": 0.2117,
      "step": 7790
    },
    {
      "epoch": 1.8118466898954704,
      "grad_norm": 1.9147206544876099,
      "learning_rate": 4.094308943089431e-05,
      "loss": 0.1372,
      "step": 7800
    },
    {
      "epoch": 1.8141695702671312,
      "grad_norm": 1.7205018997192383,
      "learning_rate": 4.0931475029036e-05,
      "loss": 0.2011,
      "step": 7810
    },
    {
      "epoch": 1.816492450638792,
      "grad_norm": 0.9290485978126526,
      "learning_rate": 4.0919860627177704e-05,
      "loss": 0.1437,
      "step": 7820
    },
    {
      "epoch": 1.8188153310104531,
      "grad_norm": 2.07006573677063,
      "learning_rate": 4.09082462253194e-05,
      "loss": 0.1605,
      "step": 7830
    },
    {
      "epoch": 1.821138211382114,
      "grad_norm": 0.8565208315849304,
      "learning_rate": 4.089663182346109e-05,
      "loss": 0.1733,
      "step": 7840
    },
    {
      "epoch": 1.8234610917537748,
      "grad_norm": 1.922123908996582,
      "learning_rate": 4.088501742160279e-05,
      "loss": 0.1854,
      "step": 7850
    },
    {
      "epoch": 1.8257839721254356,
      "grad_norm": 1.052046775817871,
      "learning_rate": 4.087340301974448e-05,
      "loss": 0.131,
      "step": 7860
    },
    {
      "epoch": 1.8281068524970965,
      "grad_norm": 1.9978561401367188,
      "learning_rate": 4.0861788617886184e-05,
      "loss": 0.1639,
      "step": 7870
    },
    {
      "epoch": 1.8304297328687573,
      "grad_norm": 2.5002756118774414,
      "learning_rate": 4.085017421602788e-05,
      "loss": 0.121,
      "step": 7880
    },
    {
      "epoch": 1.8327526132404182,
      "grad_norm": 1.3289754390716553,
      "learning_rate": 4.083855981416957e-05,
      "loss": 0.095,
      "step": 7890
    },
    {
      "epoch": 1.835075493612079,
      "grad_norm": 1.4741262197494507,
      "learning_rate": 4.082694541231127e-05,
      "loss": 0.1133,
      "step": 7900
    },
    {
      "epoch": 1.8373983739837398,
      "grad_norm": 1.558182954788208,
      "learning_rate": 4.081533101045296e-05,
      "loss": 0.1051,
      "step": 7910
    },
    {
      "epoch": 1.8397212543554007,
      "grad_norm": 1.5996267795562744,
      "learning_rate": 4.0803716608594664e-05,
      "loss": 0.2106,
      "step": 7920
    },
    {
      "epoch": 1.8420441347270615,
      "grad_norm": 1.0616592168807983,
      "learning_rate": 4.079210220673635e-05,
      "loss": 0.1128,
      "step": 7930
    },
    {
      "epoch": 1.8443670150987224,
      "grad_norm": 1.5053355693817139,
      "learning_rate": 4.078048780487805e-05,
      "loss": 0.1036,
      "step": 7940
    },
    {
      "epoch": 1.8466898954703832,
      "grad_norm": 0.8262499570846558,
      "learning_rate": 4.076887340301975e-05,
      "loss": 0.1735,
      "step": 7950
    },
    {
      "epoch": 1.849012775842044,
      "grad_norm": 1.0599267482757568,
      "learning_rate": 4.075725900116144e-05,
      "loss": 0.1502,
      "step": 7960
    },
    {
      "epoch": 1.8513356562137049,
      "grad_norm": 0.8853293657302856,
      "learning_rate": 4.074564459930314e-05,
      "loss": 0.1315,
      "step": 7970
    },
    {
      "epoch": 1.8536585365853657,
      "grad_norm": 1.372170090675354,
      "learning_rate": 4.073403019744483e-05,
      "loss": 0.1517,
      "step": 7980
    },
    {
      "epoch": 1.8559814169570266,
      "grad_norm": 0.9647092819213867,
      "learning_rate": 4.072241579558653e-05,
      "loss": 0.1704,
      "step": 7990
    },
    {
      "epoch": 1.8583042973286876,
      "grad_norm": 0.9458023309707642,
      "learning_rate": 4.071080139372823e-05,
      "loss": 0.101,
      "step": 8000
    },
    {
      "epoch": 1.8606271777003485,
      "grad_norm": 1.1111273765563965,
      "learning_rate": 4.069918699186992e-05,
      "loss": 0.1742,
      "step": 8010
    },
    {
      "epoch": 1.8629500580720093,
      "grad_norm": 2.0055670738220215,
      "learning_rate": 4.068757259001162e-05,
      "loss": 0.1701,
      "step": 8020
    },
    {
      "epoch": 1.8652729384436701,
      "grad_norm": 0.9180110096931458,
      "learning_rate": 4.067595818815331e-05,
      "loss": 0.1972,
      "step": 8030
    },
    {
      "epoch": 1.867595818815331,
      "grad_norm": 1.3744548559188843,
      "learning_rate": 4.066434378629501e-05,
      "loss": 0.193,
      "step": 8040
    },
    {
      "epoch": 1.8699186991869918,
      "grad_norm": 1.8777180910110474,
      "learning_rate": 4.065272938443671e-05,
      "loss": 0.1839,
      "step": 8050
    },
    {
      "epoch": 1.872241579558653,
      "grad_norm": 0.5275930762290955,
      "learning_rate": 4.0641114982578396e-05,
      "loss": 0.1672,
      "step": 8060
    },
    {
      "epoch": 1.8745644599303137,
      "grad_norm": 1.3083187341690063,
      "learning_rate": 4.062950058072009e-05,
      "loss": 0.2806,
      "step": 8070
    },
    {
      "epoch": 1.8768873403019746,
      "grad_norm": 2.1562416553497314,
      "learning_rate": 4.061788617886179e-05,
      "loss": 0.1264,
      "step": 8080
    },
    {
      "epoch": 1.8792102206736354,
      "grad_norm": 1.4753367900848389,
      "learning_rate": 4.060627177700349e-05,
      "loss": 0.1295,
      "step": 8090
    },
    {
      "epoch": 1.8815331010452963,
      "grad_norm": 1.0851377248764038,
      "learning_rate": 4.059465737514518e-05,
      "loss": 0.1327,
      "step": 8100
    },
    {
      "epoch": 1.883855981416957,
      "grad_norm": 2.6343846321105957,
      "learning_rate": 4.0583042973286876e-05,
      "loss": 0.2668,
      "step": 8110
    },
    {
      "epoch": 1.886178861788618,
      "grad_norm": 1.0658845901489258,
      "learning_rate": 4.057142857142857e-05,
      "loss": 0.1474,
      "step": 8120
    },
    {
      "epoch": 1.8885017421602788,
      "grad_norm": 1.3379640579223633,
      "learning_rate": 4.055981416957027e-05,
      "loss": 0.1979,
      "step": 8130
    },
    {
      "epoch": 1.8908246225319396,
      "grad_norm": 1.1668555736541748,
      "learning_rate": 4.054819976771197e-05,
      "loss": 0.1611,
      "step": 8140
    },
    {
      "epoch": 1.8931475029036005,
      "grad_norm": 0.9924445152282715,
      "learning_rate": 4.053658536585366e-05,
      "loss": 0.205,
      "step": 8150
    },
    {
      "epoch": 1.8954703832752613,
      "grad_norm": 1.702853798866272,
      "learning_rate": 4.052497096399536e-05,
      "loss": 0.1588,
      "step": 8160
    },
    {
      "epoch": 1.8977932636469221,
      "grad_norm": 1.0392152070999146,
      "learning_rate": 4.051335656213705e-05,
      "loss": 0.1431,
      "step": 8170
    },
    {
      "epoch": 1.900116144018583,
      "grad_norm": 0.7680487632751465,
      "learning_rate": 4.050174216027875e-05,
      "loss": 0.1901,
      "step": 8180
    },
    {
      "epoch": 1.9024390243902438,
      "grad_norm": 1.706992268562317,
      "learning_rate": 4.049012775842044e-05,
      "loss": 0.2689,
      "step": 8190
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 1.788360357284546,
      "learning_rate": 4.0478513356562135e-05,
      "loss": 0.13,
      "step": 8200
    },
    {
      "epoch": 1.9070847851335655,
      "grad_norm": 2.526332139968872,
      "learning_rate": 4.046689895470384e-05,
      "loss": 0.1437,
      "step": 8210
    },
    {
      "epoch": 1.9094076655052263,
      "grad_norm": 1.5198348760604858,
      "learning_rate": 4.045528455284553e-05,
      "loss": 0.1757,
      "step": 8220
    },
    {
      "epoch": 1.9117305458768872,
      "grad_norm": 0.9811563491821289,
      "learning_rate": 4.0443670150987226e-05,
      "loss": 0.1691,
      "step": 8230
    },
    {
      "epoch": 1.9140534262485482,
      "grad_norm": 1.2261767387390137,
      "learning_rate": 4.043205574912892e-05,
      "loss": 0.1323,
      "step": 8240
    },
    {
      "epoch": 1.916376306620209,
      "grad_norm": 1.1644545793533325,
      "learning_rate": 4.0420441347270615e-05,
      "loss": 0.1273,
      "step": 8250
    },
    {
      "epoch": 1.91869918699187,
      "grad_norm": 1.7820791006088257,
      "learning_rate": 4.040882694541232e-05,
      "loss": 0.1357,
      "step": 8260
    },
    {
      "epoch": 1.9210220673635308,
      "grad_norm": 2.5035340785980225,
      "learning_rate": 4.039721254355401e-05,
      "loss": 0.195,
      "step": 8270
    },
    {
      "epoch": 1.9233449477351916,
      "grad_norm": 1.0718626976013184,
      "learning_rate": 4.03855981416957e-05,
      "loss": 0.1357,
      "step": 8280
    },
    {
      "epoch": 1.9256678281068524,
      "grad_norm": 1.5772335529327393,
      "learning_rate": 4.03739837398374e-05,
      "loss": 0.1984,
      "step": 8290
    },
    {
      "epoch": 1.9279907084785135,
      "grad_norm": 1.2076622247695923,
      "learning_rate": 4.0362369337979096e-05,
      "loss": 0.1557,
      "step": 8300
    },
    {
      "epoch": 1.9303135888501743,
      "grad_norm": 1.099572777748108,
      "learning_rate": 4.03507549361208e-05,
      "loss": 0.1456,
      "step": 8310
    },
    {
      "epoch": 1.9326364692218352,
      "grad_norm": 1.6247434616088867,
      "learning_rate": 4.0339140534262485e-05,
      "loss": 0.1517,
      "step": 8320
    },
    {
      "epoch": 1.934959349593496,
      "grad_norm": 0.9606117010116577,
      "learning_rate": 4.032752613240418e-05,
      "loss": 0.2558,
      "step": 8330
    },
    {
      "epoch": 1.9372822299651569,
      "grad_norm": 0.8059461116790771,
      "learning_rate": 4.031591173054588e-05,
      "loss": 0.1344,
      "step": 8340
    },
    {
      "epoch": 1.9396051103368177,
      "grad_norm": 1.4142937660217285,
      "learning_rate": 4.0304297328687576e-05,
      "loss": 0.1973,
      "step": 8350
    },
    {
      "epoch": 1.9419279907084785,
      "grad_norm": 1.9862632751464844,
      "learning_rate": 4.029268292682927e-05,
      "loss": 0.175,
      "step": 8360
    },
    {
      "epoch": 1.9442508710801394,
      "grad_norm": 0.7260828614234924,
      "learning_rate": 4.0281068524970965e-05,
      "loss": 0.1199,
      "step": 8370
    },
    {
      "epoch": 1.9465737514518002,
      "grad_norm": 1.6425679922103882,
      "learning_rate": 4.026945412311266e-05,
      "loss": 0.1876,
      "step": 8380
    },
    {
      "epoch": 1.948896631823461,
      "grad_norm": 0.6937680244445801,
      "learning_rate": 4.025783972125436e-05,
      "loss": 0.1339,
      "step": 8390
    },
    {
      "epoch": 1.951219512195122,
      "grad_norm": 0.8207258582115173,
      "learning_rate": 4.0246225319396056e-05,
      "loss": 0.1337,
      "step": 8400
    },
    {
      "epoch": 1.9535423925667827,
      "grad_norm": 1.3568109273910522,
      "learning_rate": 4.0234610917537744e-05,
      "loss": 0.1861,
      "step": 8410
    },
    {
      "epoch": 1.9558652729384436,
      "grad_norm": 2.025710105895996,
      "learning_rate": 4.0222996515679445e-05,
      "loss": 0.1591,
      "step": 8420
    },
    {
      "epoch": 1.9581881533101044,
      "grad_norm": 1.6451756954193115,
      "learning_rate": 4.021138211382114e-05,
      "loss": 0.1562,
      "step": 8430
    },
    {
      "epoch": 1.9605110336817653,
      "grad_norm": 1.1638308763504028,
      "learning_rate": 4.019976771196284e-05,
      "loss": 0.1153,
      "step": 8440
    },
    {
      "epoch": 1.962833914053426,
      "grad_norm": 2.3635733127593994,
      "learning_rate": 4.018815331010453e-05,
      "loss": 0.1214,
      "step": 8450
    },
    {
      "epoch": 1.965156794425087,
      "grad_norm": 1.1335736513137817,
      "learning_rate": 4.0176538908246224e-05,
      "loss": 0.2015,
      "step": 8460
    },
    {
      "epoch": 1.967479674796748,
      "grad_norm": 1.2857122421264648,
      "learning_rate": 4.0164924506387925e-05,
      "loss": 0.1648,
      "step": 8470
    },
    {
      "epoch": 1.9698025551684089,
      "grad_norm": 0.9564072489738464,
      "learning_rate": 4.015331010452962e-05,
      "loss": 0.2066,
      "step": 8480
    },
    {
      "epoch": 1.9721254355400697,
      "grad_norm": 1.9416123628616333,
      "learning_rate": 4.0141695702671315e-05,
      "loss": 0.1648,
      "step": 8490
    },
    {
      "epoch": 1.9744483159117305,
      "grad_norm": 1.5793207883834839,
      "learning_rate": 4.013008130081301e-05,
      "loss": 0.0796,
      "step": 8500
    },
    {
      "epoch": 1.9767711962833914,
      "grad_norm": 0.873602032661438,
      "learning_rate": 4.0118466898954704e-05,
      "loss": 0.2174,
      "step": 8510
    },
    {
      "epoch": 1.9790940766550522,
      "grad_norm": 0.8570618629455566,
      "learning_rate": 4.0106852497096406e-05,
      "loss": 0.1523,
      "step": 8520
    },
    {
      "epoch": 1.9814169570267133,
      "grad_norm": 1.8236051797866821,
      "learning_rate": 4.00952380952381e-05,
      "loss": 0.0989,
      "step": 8530
    },
    {
      "epoch": 1.9837398373983741,
      "grad_norm": 1.5133945941925049,
      "learning_rate": 4.008362369337979e-05,
      "loss": 0.0893,
      "step": 8540
    },
    {
      "epoch": 1.986062717770035,
      "grad_norm": 1.6082807779312134,
      "learning_rate": 4.007200929152149e-05,
      "loss": 0.1697,
      "step": 8550
    },
    {
      "epoch": 1.9883855981416958,
      "grad_norm": 0.9245434999465942,
      "learning_rate": 4.0060394889663184e-05,
      "loss": 0.1358,
      "step": 8560
    },
    {
      "epoch": 1.9907084785133566,
      "grad_norm": 1.4360202550888062,
      "learning_rate": 4.004878048780488e-05,
      "loss": 0.192,
      "step": 8570
    },
    {
      "epoch": 1.9930313588850175,
      "grad_norm": 1.7440166473388672,
      "learning_rate": 4.0037166085946574e-05,
      "loss": 0.1868,
      "step": 8580
    },
    {
      "epoch": 1.9953542392566783,
      "grad_norm": 1.3675731420516968,
      "learning_rate": 4.002555168408827e-05,
      "loss": 0.1455,
      "step": 8590
    },
    {
      "epoch": 1.9976771196283392,
      "grad_norm": 0.8164685368537903,
      "learning_rate": 4.001393728222997e-05,
      "loss": 0.3166,
      "step": 8600
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.074733018875122,
      "learning_rate": 4.0002322880371664e-05,
      "loss": 0.1707,
      "step": 8610
    },
    {
      "epoch": 2.002322880371661,
      "grad_norm": 1.308431625366211,
      "learning_rate": 3.999070847851336e-05,
      "loss": 0.1364,
      "step": 8620
    },
    {
      "epoch": 2.0046457607433217,
      "grad_norm": 1.3691047430038452,
      "learning_rate": 3.9979094076655054e-05,
      "loss": 0.1247,
      "step": 8630
    },
    {
      "epoch": 2.0069686411149825,
      "grad_norm": 0.6295063495635986,
      "learning_rate": 3.996747967479675e-05,
      "loss": 0.181,
      "step": 8640
    },
    {
      "epoch": 2.0092915214866434,
      "grad_norm": 0.9772472977638245,
      "learning_rate": 3.995586527293845e-05,
      "loss": 0.1668,
      "step": 8650
    },
    {
      "epoch": 2.011614401858304,
      "grad_norm": 1.0107461214065552,
      "learning_rate": 3.994425087108014e-05,
      "loss": 0.1266,
      "step": 8660
    },
    {
      "epoch": 2.013937282229965,
      "grad_norm": 1.9906200170516968,
      "learning_rate": 3.993263646922183e-05,
      "loss": 0.1773,
      "step": 8670
    },
    {
      "epoch": 2.016260162601626,
      "grad_norm": 2.2946951389312744,
      "learning_rate": 3.9921022067363534e-05,
      "loss": 0.2706,
      "step": 8680
    },
    {
      "epoch": 2.0185830429732867,
      "grad_norm": 1.1882094144821167,
      "learning_rate": 3.990940766550523e-05,
      "loss": 0.1202,
      "step": 8690
    },
    {
      "epoch": 2.0209059233449476,
      "grad_norm": 3.3542206287384033,
      "learning_rate": 3.989779326364692e-05,
      "loss": 0.1227,
      "step": 8700
    },
    {
      "epoch": 2.0232288037166084,
      "grad_norm": 1.5591481924057007,
      "learning_rate": 3.988617886178862e-05,
      "loss": 0.1134,
      "step": 8710
    },
    {
      "epoch": 2.0255516840882692,
      "grad_norm": 0.9856518507003784,
      "learning_rate": 3.987456445993031e-05,
      "loss": 0.1957,
      "step": 8720
    },
    {
      "epoch": 2.0278745644599305,
      "grad_norm": 1.2590093612670898,
      "learning_rate": 3.9862950058072014e-05,
      "loss": 0.1209,
      "step": 8730
    },
    {
      "epoch": 2.0301974448315914,
      "grad_norm": 2.4936912059783936,
      "learning_rate": 3.985133565621371e-05,
      "loss": 0.0876,
      "step": 8740
    },
    {
      "epoch": 2.032520325203252,
      "grad_norm": 1.2179421186447144,
      "learning_rate": 3.98397212543554e-05,
      "loss": 0.1298,
      "step": 8750
    },
    {
      "epoch": 2.034843205574913,
      "grad_norm": 1.401353120803833,
      "learning_rate": 3.98281068524971e-05,
      "loss": 0.1476,
      "step": 8760
    },
    {
      "epoch": 2.037166085946574,
      "grad_norm": 1.5991030931472778,
      "learning_rate": 3.981649245063879e-05,
      "loss": 0.1538,
      "step": 8770
    },
    {
      "epoch": 2.0394889663182347,
      "grad_norm": 2.10093092918396,
      "learning_rate": 3.9804878048780494e-05,
      "loss": 0.1241,
      "step": 8780
    },
    {
      "epoch": 2.0418118466898956,
      "grad_norm": 1.7565380334854126,
      "learning_rate": 3.979326364692218e-05,
      "loss": 0.1507,
      "step": 8790
    },
    {
      "epoch": 2.0441347270615564,
      "grad_norm": 1.407865285873413,
      "learning_rate": 3.978164924506388e-05,
      "loss": 0.1721,
      "step": 8800
    },
    {
      "epoch": 2.0464576074332173,
      "grad_norm": 1.9610730409622192,
      "learning_rate": 3.977003484320558e-05,
      "loss": 0.1163,
      "step": 8810
    },
    {
      "epoch": 2.048780487804878,
      "grad_norm": 1.1975445747375488,
      "learning_rate": 3.975842044134727e-05,
      "loss": 0.1358,
      "step": 8820
    },
    {
      "epoch": 2.051103368176539,
      "grad_norm": 1.4519537687301636,
      "learning_rate": 3.974680603948897e-05,
      "loss": 0.1766,
      "step": 8830
    },
    {
      "epoch": 2.0534262485481998,
      "grad_norm": 1.9632011651992798,
      "learning_rate": 3.973519163763066e-05,
      "loss": 0.1559,
      "step": 8840
    },
    {
      "epoch": 2.0557491289198606,
      "grad_norm": 1.4555003643035889,
      "learning_rate": 3.972357723577236e-05,
      "loss": 0.2006,
      "step": 8850
    },
    {
      "epoch": 2.0580720092915215,
      "grad_norm": 0.7908818125724792,
      "learning_rate": 3.971196283391406e-05,
      "loss": 0.1264,
      "step": 8860
    },
    {
      "epoch": 2.0603948896631823,
      "grad_norm": 0.9782846570014954,
      "learning_rate": 3.970034843205575e-05,
      "loss": 0.168,
      "step": 8870
    },
    {
      "epoch": 2.062717770034843,
      "grad_norm": 1.291510820388794,
      "learning_rate": 3.968873403019744e-05,
      "loss": 0.1566,
      "step": 8880
    },
    {
      "epoch": 2.065040650406504,
      "grad_norm": 2.05448842048645,
      "learning_rate": 3.967711962833914e-05,
      "loss": 0.1418,
      "step": 8890
    },
    {
      "epoch": 2.067363530778165,
      "grad_norm": 1.0137089490890503,
      "learning_rate": 3.966550522648084e-05,
      "loss": 0.1493,
      "step": 8900
    },
    {
      "epoch": 2.0696864111498257,
      "grad_norm": 1.784949541091919,
      "learning_rate": 3.965389082462254e-05,
      "loss": 0.1454,
      "step": 8910
    },
    {
      "epoch": 2.0720092915214865,
      "grad_norm": 1.206875205039978,
      "learning_rate": 3.9642276422764226e-05,
      "loss": 0.1113,
      "step": 8920
    },
    {
      "epoch": 2.0743321718931473,
      "grad_norm": 0.8671866655349731,
      "learning_rate": 3.963066202090592e-05,
      "loss": 0.1588,
      "step": 8930
    },
    {
      "epoch": 2.076655052264808,
      "grad_norm": 1.2775828838348389,
      "learning_rate": 3.961904761904762e-05,
      "loss": 0.1509,
      "step": 8940
    },
    {
      "epoch": 2.078977932636469,
      "grad_norm": 1.4816081523895264,
      "learning_rate": 3.960743321718932e-05,
      "loss": 0.1584,
      "step": 8950
    },
    {
      "epoch": 2.08130081300813,
      "grad_norm": 2.242158889770508,
      "learning_rate": 3.959581881533101e-05,
      "loss": 0.1535,
      "step": 8960
    },
    {
      "epoch": 2.083623693379791,
      "grad_norm": 1.1565728187561035,
      "learning_rate": 3.9584204413472706e-05,
      "loss": 0.1484,
      "step": 8970
    },
    {
      "epoch": 2.085946573751452,
      "grad_norm": 1.0745311975479126,
      "learning_rate": 3.95725900116144e-05,
      "loss": 0.1379,
      "step": 8980
    },
    {
      "epoch": 2.088269454123113,
      "grad_norm": 1.6766636371612549,
      "learning_rate": 3.95609756097561e-05,
      "loss": 0.161,
      "step": 8990
    },
    {
      "epoch": 2.0905923344947737,
      "grad_norm": 2.0465590953826904,
      "learning_rate": 3.95493612078978e-05,
      "loss": 0.2147,
      "step": 9000
    },
    {
      "epoch": 2.0929152148664345,
      "grad_norm": 3.1161887645721436,
      "learning_rate": 3.9537746806039485e-05,
      "loss": 0.2553,
      "step": 9010
    },
    {
      "epoch": 2.0952380952380953,
      "grad_norm": 1.3677181005477905,
      "learning_rate": 3.9526132404181187e-05,
      "loss": 0.1656,
      "step": 9020
    },
    {
      "epoch": 2.097560975609756,
      "grad_norm": 2.8152642250061035,
      "learning_rate": 3.951451800232288e-05,
      "loss": 0.1406,
      "step": 9030
    },
    {
      "epoch": 2.099883855981417,
      "grad_norm": 0.9562216997146606,
      "learning_rate": 3.950290360046458e-05,
      "loss": 0.1849,
      "step": 9040
    },
    {
      "epoch": 2.102206736353078,
      "grad_norm": 0.9819220304489136,
      "learning_rate": 3.949128919860627e-05,
      "loss": 0.2021,
      "step": 9050
    },
    {
      "epoch": 2.1045296167247387,
      "grad_norm": 1.560179591178894,
      "learning_rate": 3.9479674796747965e-05,
      "loss": 0.0923,
      "step": 9060
    },
    {
      "epoch": 2.1068524970963995,
      "grad_norm": 1.8707261085510254,
      "learning_rate": 3.946806039488967e-05,
      "loss": 0.1604,
      "step": 9070
    },
    {
      "epoch": 2.1091753774680604,
      "grad_norm": 1.5252925157546997,
      "learning_rate": 3.945644599303136e-05,
      "loss": 0.1232,
      "step": 9080
    },
    {
      "epoch": 2.1114982578397212,
      "grad_norm": 1.680383563041687,
      "learning_rate": 3.9444831591173056e-05,
      "loss": 0.1875,
      "step": 9090
    },
    {
      "epoch": 2.113821138211382,
      "grad_norm": 2.088778257369995,
      "learning_rate": 3.943321718931475e-05,
      "loss": 0.1963,
      "step": 9100
    },
    {
      "epoch": 2.116144018583043,
      "grad_norm": 1.5314042568206787,
      "learning_rate": 3.9421602787456445e-05,
      "loss": 0.1283,
      "step": 9110
    },
    {
      "epoch": 2.1184668989547037,
      "grad_norm": 2.1797680854797363,
      "learning_rate": 3.940998838559815e-05,
      "loss": 0.147,
      "step": 9120
    },
    {
      "epoch": 2.1207897793263646,
      "grad_norm": 0.8903153538703918,
      "learning_rate": 3.939837398373984e-05,
      "loss": 0.1579,
      "step": 9130
    },
    {
      "epoch": 2.1231126596980254,
      "grad_norm": 1.0613112449645996,
      "learning_rate": 3.938675958188153e-05,
      "loss": 0.1379,
      "step": 9140
    },
    {
      "epoch": 2.1254355400696863,
      "grad_norm": 1.424386978149414,
      "learning_rate": 3.937514518002323e-05,
      "loss": 0.1922,
      "step": 9150
    },
    {
      "epoch": 2.127758420441347,
      "grad_norm": 2.251638174057007,
      "learning_rate": 3.9363530778164926e-05,
      "loss": 0.2553,
      "step": 9160
    },
    {
      "epoch": 2.130081300813008,
      "grad_norm": 1.4336373805999756,
      "learning_rate": 3.935191637630663e-05,
      "loss": 0.0981,
      "step": 9170
    },
    {
      "epoch": 2.132404181184669,
      "grad_norm": 3.091628074645996,
      "learning_rate": 3.9340301974448315e-05,
      "loss": 0.1376,
      "step": 9180
    },
    {
      "epoch": 2.1347270615563296,
      "grad_norm": 1.1251078844070435,
      "learning_rate": 3.932868757259001e-05,
      "loss": 0.1599,
      "step": 9190
    },
    {
      "epoch": 2.137049941927991,
      "grad_norm": 0.9265355467796326,
      "learning_rate": 3.931707317073171e-05,
      "loss": 0.0698,
      "step": 9200
    },
    {
      "epoch": 2.1393728222996518,
      "grad_norm": 0.9107894897460938,
      "learning_rate": 3.9305458768873406e-05,
      "loss": 0.1561,
      "step": 9210
    },
    {
      "epoch": 2.1416957026713126,
      "grad_norm": 1.019512414932251,
      "learning_rate": 3.92938443670151e-05,
      "loss": 0.1386,
      "step": 9220
    },
    {
      "epoch": 2.1440185830429734,
      "grad_norm": 1.2349662780761719,
      "learning_rate": 3.9282229965156795e-05,
      "loss": 0.1275,
      "step": 9230
    },
    {
      "epoch": 2.1463414634146343,
      "grad_norm": 0.8035757541656494,
      "learning_rate": 3.927061556329849e-05,
      "loss": 0.1032,
      "step": 9240
    },
    {
      "epoch": 2.148664343786295,
      "grad_norm": 1.7330724000930786,
      "learning_rate": 3.925900116144019e-05,
      "loss": 0.1427,
      "step": 9250
    },
    {
      "epoch": 2.150987224157956,
      "grad_norm": 3.2261388301849365,
      "learning_rate": 3.9247386759581886e-05,
      "loss": 0.1839,
      "step": 9260
    },
    {
      "epoch": 2.153310104529617,
      "grad_norm": 1.9915202856063843,
      "learning_rate": 3.9235772357723574e-05,
      "loss": 0.1766,
      "step": 9270
    },
    {
      "epoch": 2.1556329849012776,
      "grad_norm": 1.7997804880142212,
      "learning_rate": 3.9224157955865275e-05,
      "loss": 0.1567,
      "step": 9280
    },
    {
      "epoch": 2.1579558652729385,
      "grad_norm": 1.4788823127746582,
      "learning_rate": 3.921254355400697e-05,
      "loss": 0.1734,
      "step": 9290
    },
    {
      "epoch": 2.1602787456445993,
      "grad_norm": 2.26056170463562,
      "learning_rate": 3.920092915214867e-05,
      "loss": 0.1641,
      "step": 9300
    },
    {
      "epoch": 2.16260162601626,
      "grad_norm": 1.6576792001724243,
      "learning_rate": 3.918931475029036e-05,
      "loss": 0.1077,
      "step": 9310
    },
    {
      "epoch": 2.164924506387921,
      "grad_norm": 1.4609683752059937,
      "learning_rate": 3.9177700348432054e-05,
      "loss": 0.1665,
      "step": 9320
    },
    {
      "epoch": 2.167247386759582,
      "grad_norm": 1.2319493293762207,
      "learning_rate": 3.9166085946573755e-05,
      "loss": 0.1166,
      "step": 9330
    },
    {
      "epoch": 2.1695702671312427,
      "grad_norm": 0.8036938309669495,
      "learning_rate": 3.915447154471545e-05,
      "loss": 0.0905,
      "step": 9340
    },
    {
      "epoch": 2.1718931475029035,
      "grad_norm": 1.5267795324325562,
      "learning_rate": 3.9142857142857145e-05,
      "loss": 0.1847,
      "step": 9350
    },
    {
      "epoch": 2.1742160278745644,
      "grad_norm": 1.4457987546920776,
      "learning_rate": 3.913124274099884e-05,
      "loss": 0.1704,
      "step": 9360
    },
    {
      "epoch": 2.176538908246225,
      "grad_norm": 1.245389699935913,
      "learning_rate": 3.9119628339140534e-05,
      "loss": 0.1568,
      "step": 9370
    },
    {
      "epoch": 2.178861788617886,
      "grad_norm": 1.8181670904159546,
      "learning_rate": 3.9108013937282235e-05,
      "loss": 0.2549,
      "step": 9380
    },
    {
      "epoch": 2.181184668989547,
      "grad_norm": 2.3818273544311523,
      "learning_rate": 3.909639953542393e-05,
      "loss": 0.1799,
      "step": 9390
    },
    {
      "epoch": 2.1835075493612077,
      "grad_norm": 2.9878926277160645,
      "learning_rate": 3.908478513356562e-05,
      "loss": 0.1664,
      "step": 9400
    },
    {
      "epoch": 2.1858304297328686,
      "grad_norm": 0.802793562412262,
      "learning_rate": 3.907317073170732e-05,
      "loss": 0.0753,
      "step": 9410
    },
    {
      "epoch": 2.1881533101045294,
      "grad_norm": 1.6160657405853271,
      "learning_rate": 3.9061556329849014e-05,
      "loss": 0.1079,
      "step": 9420
    },
    {
      "epoch": 2.1904761904761907,
      "grad_norm": 0.9081760048866272,
      "learning_rate": 3.9049941927990716e-05,
      "loss": 0.0686,
      "step": 9430
    },
    {
      "epoch": 2.1927990708478515,
      "grad_norm": 1.0814249515533447,
      "learning_rate": 3.9038327526132403e-05,
      "loss": 0.152,
      "step": 9440
    },
    {
      "epoch": 2.1951219512195124,
      "grad_norm": 1.0416760444641113,
      "learning_rate": 3.90267131242741e-05,
      "loss": 0.1111,
      "step": 9450
    },
    {
      "epoch": 2.197444831591173,
      "grad_norm": 1.0818058252334595,
      "learning_rate": 3.90150987224158e-05,
      "loss": 0.1243,
      "step": 9460
    },
    {
      "epoch": 2.199767711962834,
      "grad_norm": 0.7188239097595215,
      "learning_rate": 3.9003484320557494e-05,
      "loss": 0.1064,
      "step": 9470
    },
    {
      "epoch": 2.202090592334495,
      "grad_norm": 0.8896481990814209,
      "learning_rate": 3.899186991869919e-05,
      "loss": 0.1275,
      "step": 9480
    },
    {
      "epoch": 2.2044134727061557,
      "grad_norm": 1.767481803894043,
      "learning_rate": 3.8980255516840884e-05,
      "loss": 0.1548,
      "step": 9490
    },
    {
      "epoch": 2.2067363530778166,
      "grad_norm": 1.4380710124969482,
      "learning_rate": 3.896864111498258e-05,
      "loss": 0.1586,
      "step": 9500
    },
    {
      "epoch": 2.2090592334494774,
      "grad_norm": 1.2009947299957275,
      "learning_rate": 3.895702671312428e-05,
      "loss": 0.1386,
      "step": 9510
    },
    {
      "epoch": 2.2113821138211383,
      "grad_norm": 0.7244241833686829,
      "learning_rate": 3.8945412311265974e-05,
      "loss": 0.1253,
      "step": 9520
    },
    {
      "epoch": 2.213704994192799,
      "grad_norm": 1.0009034872055054,
      "learning_rate": 3.893379790940766e-05,
      "loss": 0.1909,
      "step": 9530
    },
    {
      "epoch": 2.21602787456446,
      "grad_norm": 0.7756819725036621,
      "learning_rate": 3.8922183507549364e-05,
      "loss": 0.2197,
      "step": 9540
    },
    {
      "epoch": 2.2183507549361208,
      "grad_norm": 2.0324079990386963,
      "learning_rate": 3.891056910569106e-05,
      "loss": 0.1627,
      "step": 9550
    },
    {
      "epoch": 2.2206736353077816,
      "grad_norm": 2.5681021213531494,
      "learning_rate": 3.889895470383275e-05,
      "loss": 0.145,
      "step": 9560
    },
    {
      "epoch": 2.2229965156794425,
      "grad_norm": 0.8924788236618042,
      "learning_rate": 3.888734030197445e-05,
      "loss": 0.1678,
      "step": 9570
    },
    {
      "epoch": 2.2253193960511033,
      "grad_norm": 1.257422924041748,
      "learning_rate": 3.887572590011614e-05,
      "loss": 0.1473,
      "step": 9580
    },
    {
      "epoch": 2.227642276422764,
      "grad_norm": 1.352448582649231,
      "learning_rate": 3.8864111498257844e-05,
      "loss": 0.2194,
      "step": 9590
    },
    {
      "epoch": 2.229965156794425,
      "grad_norm": 1.0403574705123901,
      "learning_rate": 3.885249709639954e-05,
      "loss": 0.1435,
      "step": 9600
    },
    {
      "epoch": 2.232288037166086,
      "grad_norm": 1.6937193870544434,
      "learning_rate": 3.884088269454123e-05,
      "loss": 0.1154,
      "step": 9610
    },
    {
      "epoch": 2.2346109175377467,
      "grad_norm": 1.1569167375564575,
      "learning_rate": 3.882926829268293e-05,
      "loss": 0.1718,
      "step": 9620
    },
    {
      "epoch": 2.2369337979094075,
      "grad_norm": 0.8127579092979431,
      "learning_rate": 3.881765389082462e-05,
      "loss": 0.0776,
      "step": 9630
    },
    {
      "epoch": 2.2392566782810683,
      "grad_norm": 1.3015776872634888,
      "learning_rate": 3.8806039488966324e-05,
      "loss": 0.1689,
      "step": 9640
    },
    {
      "epoch": 2.241579558652729,
      "grad_norm": 1.8979594707489014,
      "learning_rate": 3.879442508710802e-05,
      "loss": 0.1534,
      "step": 9650
    },
    {
      "epoch": 2.2439024390243905,
      "grad_norm": 1.4386333227157593,
      "learning_rate": 3.878281068524971e-05,
      "loss": 0.136,
      "step": 9660
    },
    {
      "epoch": 2.2462253193960513,
      "grad_norm": 0.9261158108711243,
      "learning_rate": 3.877119628339141e-05,
      "loss": 0.1219,
      "step": 9670
    },
    {
      "epoch": 2.248548199767712,
      "grad_norm": 3.0610618591308594,
      "learning_rate": 3.87595818815331e-05,
      "loss": 0.1825,
      "step": 9680
    },
    {
      "epoch": 2.250871080139373,
      "grad_norm": 0.7475335001945496,
      "learning_rate": 3.87479674796748e-05,
      "loss": 0.2181,
      "step": 9690
    },
    {
      "epoch": 2.253193960511034,
      "grad_norm": 1.8505909442901611,
      "learning_rate": 3.873635307781649e-05,
      "loss": 0.1257,
      "step": 9700
    },
    {
      "epoch": 2.2555168408826947,
      "grad_norm": 2.2088592052459717,
      "learning_rate": 3.872473867595819e-05,
      "loss": 0.1954,
      "step": 9710
    },
    {
      "epoch": 2.2578397212543555,
      "grad_norm": 1.2662937641143799,
      "learning_rate": 3.871312427409989e-05,
      "loss": 0.1432,
      "step": 9720
    },
    {
      "epoch": 2.2601626016260163,
      "grad_norm": 1.103434443473816,
      "learning_rate": 3.870150987224158e-05,
      "loss": 0.1536,
      "step": 9730
    },
    {
      "epoch": 2.262485481997677,
      "grad_norm": 1.9734469652175903,
      "learning_rate": 3.868989547038328e-05,
      "loss": 0.1768,
      "step": 9740
    },
    {
      "epoch": 2.264808362369338,
      "grad_norm": 0.993069589138031,
      "learning_rate": 3.867828106852497e-05,
      "loss": 0.2496,
      "step": 9750
    },
    {
      "epoch": 2.267131242740999,
      "grad_norm": 0.5879948735237122,
      "learning_rate": 3.866666666666667e-05,
      "loss": 0.145,
      "step": 9760
    },
    {
      "epoch": 2.2694541231126597,
      "grad_norm": 0.952353835105896,
      "learning_rate": 3.865505226480837e-05,
      "loss": 0.11,
      "step": 9770
    },
    {
      "epoch": 2.2717770034843205,
      "grad_norm": 1.0959972143173218,
      "learning_rate": 3.864343786295006e-05,
      "loss": 0.0984,
      "step": 9780
    },
    {
      "epoch": 2.2740998838559814,
      "grad_norm": 2.1486029624938965,
      "learning_rate": 3.863182346109175e-05,
      "loss": 0.1969,
      "step": 9790
    },
    {
      "epoch": 2.2764227642276422,
      "grad_norm": 0.9521176218986511,
      "learning_rate": 3.862020905923345e-05,
      "loss": 0.1208,
      "step": 9800
    },
    {
      "epoch": 2.278745644599303,
      "grad_norm": 1.6985162496566772,
      "learning_rate": 3.860859465737515e-05,
      "loss": 0.1731,
      "step": 9810
    },
    {
      "epoch": 2.281068524970964,
      "grad_norm": 1.5736072063446045,
      "learning_rate": 3.859698025551684e-05,
      "loss": 0.0802,
      "step": 9820
    },
    {
      "epoch": 2.2833914053426247,
      "grad_norm": 1.7393795251846313,
      "learning_rate": 3.8585365853658536e-05,
      "loss": 0.1744,
      "step": 9830
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.9711102247238159,
      "learning_rate": 3.857375145180023e-05,
      "loss": 0.1169,
      "step": 9840
    },
    {
      "epoch": 2.2880371660859464,
      "grad_norm": 1.7850929498672485,
      "learning_rate": 3.856213704994193e-05,
      "loss": 0.1862,
      "step": 9850
    },
    {
      "epoch": 2.2903600464576073,
      "grad_norm": 1.2980374097824097,
      "learning_rate": 3.855052264808363e-05,
      "loss": 0.1846,
      "step": 9860
    },
    {
      "epoch": 2.292682926829268,
      "grad_norm": 0.6703545451164246,
      "learning_rate": 3.853890824622532e-05,
      "loss": 0.1534,
      "step": 9870
    },
    {
      "epoch": 2.295005807200929,
      "grad_norm": 1.0279438495635986,
      "learning_rate": 3.8527293844367017e-05,
      "loss": 0.115,
      "step": 9880
    },
    {
      "epoch": 2.2973286875725902,
      "grad_norm": 1.1809325218200684,
      "learning_rate": 3.851567944250871e-05,
      "loss": 0.1595,
      "step": 9890
    },
    {
      "epoch": 2.2996515679442506,
      "grad_norm": 1.7776429653167725,
      "learning_rate": 3.850406504065041e-05,
      "loss": 0.145,
      "step": 9900
    },
    {
      "epoch": 2.301974448315912,
      "grad_norm": 1.088011622428894,
      "learning_rate": 3.849245063879211e-05,
      "loss": 0.108,
      "step": 9910
    },
    {
      "epoch": 2.3042973286875728,
      "grad_norm": 1.203615665435791,
      "learning_rate": 3.8480836236933795e-05,
      "loss": 0.1713,
      "step": 9920
    },
    {
      "epoch": 2.3066202090592336,
      "grad_norm": 0.8406001329421997,
      "learning_rate": 3.84692218350755e-05,
      "loss": 0.1007,
      "step": 9930
    },
    {
      "epoch": 2.3089430894308944,
      "grad_norm": 0.8409660458564758,
      "learning_rate": 3.845760743321719e-05,
      "loss": 0.0883,
      "step": 9940
    },
    {
      "epoch": 2.3112659698025553,
      "grad_norm": 1.415909767150879,
      "learning_rate": 3.8445993031358886e-05,
      "loss": 0.1815,
      "step": 9950
    },
    {
      "epoch": 2.313588850174216,
      "grad_norm": 0.7355484366416931,
      "learning_rate": 3.843437862950058e-05,
      "loss": 0.1966,
      "step": 9960
    },
    {
      "epoch": 2.315911730545877,
      "grad_norm": 2.1661458015441895,
      "learning_rate": 3.8422764227642275e-05,
      "loss": 0.0743,
      "step": 9970
    },
    {
      "epoch": 2.318234610917538,
      "grad_norm": 1.1139506101608276,
      "learning_rate": 3.841114982578398e-05,
      "loss": 0.0858,
      "step": 9980
    },
    {
      "epoch": 2.3205574912891986,
      "grad_norm": 1.9390279054641724,
      "learning_rate": 3.839953542392567e-05,
      "loss": 0.1384,
      "step": 9990
    },
    {
      "epoch": 2.3228803716608595,
      "grad_norm": 1.5755349397659302,
      "learning_rate": 3.8387921022067366e-05,
      "loss": 0.1637,
      "step": 10000
    },
    {
      "epoch": 2.3252032520325203,
      "grad_norm": 1.4887299537658691,
      "learning_rate": 3.837746806039489e-05,
      "loss": 0.2431,
      "step": 10010
    },
    {
      "epoch": 2.327526132404181,
      "grad_norm": 1.4899452924728394,
      "learning_rate": 3.836585365853659e-05,
      "loss": 0.1558,
      "step": 10020
    },
    {
      "epoch": 2.329849012775842,
      "grad_norm": 1.0496001243591309,
      "learning_rate": 3.8354239256678284e-05,
      "loss": 0.1738,
      "step": 10030
    },
    {
      "epoch": 2.332171893147503,
      "grad_norm": 1.5048130750656128,
      "learning_rate": 3.834262485481998e-05,
      "loss": 0.1131,
      "step": 10040
    },
    {
      "epoch": 2.3344947735191637,
      "grad_norm": 0.9311802387237549,
      "learning_rate": 3.8331010452961673e-05,
      "loss": 0.1269,
      "step": 10050
    },
    {
      "epoch": 2.3368176538908245,
      "grad_norm": 1.446037769317627,
      "learning_rate": 3.831939605110337e-05,
      "loss": 0.1568,
      "step": 10060
    },
    {
      "epoch": 2.3391405342624854,
      "grad_norm": 0.6165661215782166,
      "learning_rate": 3.830778164924507e-05,
      "loss": 0.1421,
      "step": 10070
    },
    {
      "epoch": 2.341463414634146,
      "grad_norm": 1.4002748727798462,
      "learning_rate": 3.829616724738676e-05,
      "loss": 0.0981,
      "step": 10080
    },
    {
      "epoch": 2.343786295005807,
      "grad_norm": 1.332279086112976,
      "learning_rate": 3.828455284552846e-05,
      "loss": 0.1508,
      "step": 10090
    },
    {
      "epoch": 2.346109175377468,
      "grad_norm": 1.1360865831375122,
      "learning_rate": 3.8272938443670154e-05,
      "loss": 0.1441,
      "step": 10100
    },
    {
      "epoch": 2.3484320557491287,
      "grad_norm": 2.6013123989105225,
      "learning_rate": 3.826132404181185e-05,
      "loss": 0.1737,
      "step": 10110
    },
    {
      "epoch": 2.35075493612079,
      "grad_norm": 1.271207571029663,
      "learning_rate": 3.824970963995354e-05,
      "loss": 0.0818,
      "step": 10120
    },
    {
      "epoch": 2.3530778164924504,
      "grad_norm": 1.345971703529358,
      "learning_rate": 3.823809523809524e-05,
      "loss": 0.1148,
      "step": 10130
    },
    {
      "epoch": 2.3554006968641117,
      "grad_norm": 1.4783432483673096,
      "learning_rate": 3.822648083623693e-05,
      "loss": 0.1305,
      "step": 10140
    },
    {
      "epoch": 2.3577235772357725,
      "grad_norm": 1.4675836563110352,
      "learning_rate": 3.8214866434378634e-05,
      "loss": 0.1675,
      "step": 10150
    },
    {
      "epoch": 2.3600464576074334,
      "grad_norm": 1.5123509168624878,
      "learning_rate": 3.820325203252033e-05,
      "loss": 0.1267,
      "step": 10160
    },
    {
      "epoch": 2.362369337979094,
      "grad_norm": 1.1840360164642334,
      "learning_rate": 3.819163763066202e-05,
      "loss": 0.1007,
      "step": 10170
    },
    {
      "epoch": 2.364692218350755,
      "grad_norm": 0.5275079607963562,
      "learning_rate": 3.818002322880372e-05,
      "loss": 0.1046,
      "step": 10180
    },
    {
      "epoch": 2.367015098722416,
      "grad_norm": 1.4482228755950928,
      "learning_rate": 3.816840882694541e-05,
      "loss": 0.1191,
      "step": 10190
    },
    {
      "epoch": 2.3693379790940767,
      "grad_norm": 0.8147991299629211,
      "learning_rate": 3.8156794425087114e-05,
      "loss": 0.1073,
      "step": 10200
    },
    {
      "epoch": 2.3716608594657376,
      "grad_norm": 0.9528371691703796,
      "learning_rate": 3.81451800232288e-05,
      "loss": 0.1349,
      "step": 10210
    },
    {
      "epoch": 2.3739837398373984,
      "grad_norm": 1.001129150390625,
      "learning_rate": 3.81335656213705e-05,
      "loss": 0.1429,
      "step": 10220
    },
    {
      "epoch": 2.3763066202090593,
      "grad_norm": 1.3098654747009277,
      "learning_rate": 3.81219512195122e-05,
      "loss": 0.1518,
      "step": 10230
    },
    {
      "epoch": 2.37862950058072,
      "grad_norm": 0.9404122233390808,
      "learning_rate": 3.811033681765389e-05,
      "loss": 0.2188,
      "step": 10240
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 1.143157958984375,
      "learning_rate": 3.809872241579559e-05,
      "loss": 0.158,
      "step": 10250
    },
    {
      "epoch": 2.3832752613240418,
      "grad_norm": 1.6712089776992798,
      "learning_rate": 3.808710801393728e-05,
      "loss": 0.1467,
      "step": 10260
    },
    {
      "epoch": 2.3855981416957026,
      "grad_norm": 1.1064258813858032,
      "learning_rate": 3.8075493612078977e-05,
      "loss": 0.2096,
      "step": 10270
    },
    {
      "epoch": 2.3879210220673635,
      "grad_norm": 1.0774461030960083,
      "learning_rate": 3.806387921022068e-05,
      "loss": 0.1827,
      "step": 10280
    },
    {
      "epoch": 2.3902439024390243,
      "grad_norm": 2.2078449726104736,
      "learning_rate": 3.805226480836237e-05,
      "loss": 0.1406,
      "step": 10290
    },
    {
      "epoch": 2.392566782810685,
      "grad_norm": 1.0882781744003296,
      "learning_rate": 3.804065040650407e-05,
      "loss": 0.1542,
      "step": 10300
    },
    {
      "epoch": 2.394889663182346,
      "grad_norm": 0.6941062211990356,
      "learning_rate": 3.802903600464576e-05,
      "loss": 0.2273,
      "step": 10310
    },
    {
      "epoch": 2.397212543554007,
      "grad_norm": 1.1344856023788452,
      "learning_rate": 3.801742160278746e-05,
      "loss": 0.0965,
      "step": 10320
    },
    {
      "epoch": 2.3995354239256677,
      "grad_norm": 1.7134120464324951,
      "learning_rate": 3.800580720092916e-05,
      "loss": 0.1515,
      "step": 10330
    },
    {
      "epoch": 2.4018583042973285,
      "grad_norm": 0.8041976094245911,
      "learning_rate": 3.7994192799070846e-05,
      "loss": 0.2014,
      "step": 10340
    },
    {
      "epoch": 2.40418118466899,
      "grad_norm": 2.505230188369751,
      "learning_rate": 3.798257839721254e-05,
      "loss": 0.1363,
      "step": 10350
    },
    {
      "epoch": 2.40650406504065,
      "grad_norm": 1.317694902420044,
      "learning_rate": 3.797096399535424e-05,
      "loss": 0.1258,
      "step": 10360
    },
    {
      "epoch": 2.4088269454123115,
      "grad_norm": 0.6425970196723938,
      "learning_rate": 3.795934959349594e-05,
      "loss": 0.1879,
      "step": 10370
    },
    {
      "epoch": 2.4111498257839723,
      "grad_norm": 1.1594536304473877,
      "learning_rate": 3.794773519163763e-05,
      "loss": 0.156,
      "step": 10380
    },
    {
      "epoch": 2.413472706155633,
      "grad_norm": 2.172667980194092,
      "learning_rate": 3.7936120789779326e-05,
      "loss": 0.1527,
      "step": 10390
    },
    {
      "epoch": 2.415795586527294,
      "grad_norm": 2.116297960281372,
      "learning_rate": 3.792450638792102e-05,
      "loss": 0.1612,
      "step": 10400
    },
    {
      "epoch": 2.418118466898955,
      "grad_norm": 0.7715927362442017,
      "learning_rate": 3.791289198606272e-05,
      "loss": 0.0879,
      "step": 10410
    },
    {
      "epoch": 2.4204413472706157,
      "grad_norm": 0.8615419268608093,
      "learning_rate": 3.790127758420442e-05,
      "loss": 0.1514,
      "step": 10420
    },
    {
      "epoch": 2.4227642276422765,
      "grad_norm": 1.5751280784606934,
      "learning_rate": 3.788966318234611e-05,
      "loss": 0.2373,
      "step": 10430
    },
    {
      "epoch": 2.4250871080139373,
      "grad_norm": 0.9809516072273254,
      "learning_rate": 3.7878048780487806e-05,
      "loss": 0.1516,
      "step": 10440
    },
    {
      "epoch": 2.427409988385598,
      "grad_norm": 1.1010624170303345,
      "learning_rate": 3.78664343786295e-05,
      "loss": 0.0958,
      "step": 10450
    },
    {
      "epoch": 2.429732868757259,
      "grad_norm": 1.4815661907196045,
      "learning_rate": 3.78548199767712e-05,
      "loss": 0.1905,
      "step": 10460
    },
    {
      "epoch": 2.43205574912892,
      "grad_norm": 1.2167633771896362,
      "learning_rate": 3.784320557491289e-05,
      "loss": 0.1726,
      "step": 10470
    },
    {
      "epoch": 2.4343786295005807,
      "grad_norm": 1.1620502471923828,
      "learning_rate": 3.7831591173054585e-05,
      "loss": 0.1531,
      "step": 10480
    },
    {
      "epoch": 2.4367015098722415,
      "grad_norm": 1.369168758392334,
      "learning_rate": 3.7819976771196286e-05,
      "loss": 0.0905,
      "step": 10490
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 1.4783916473388672,
      "learning_rate": 3.780836236933798e-05,
      "loss": 0.1522,
      "step": 10500
    },
    {
      "epoch": 2.4413472706155632,
      "grad_norm": 1.131440281867981,
      "learning_rate": 3.7796747967479676e-05,
      "loss": 0.209,
      "step": 10510
    },
    {
      "epoch": 2.443670150987224,
      "grad_norm": 1.3201265335083008,
      "learning_rate": 3.778513356562137e-05,
      "loss": 0.0914,
      "step": 10520
    },
    {
      "epoch": 2.445993031358885,
      "grad_norm": 1.0663259029388428,
      "learning_rate": 3.7773519163763065e-05,
      "loss": 0.2198,
      "step": 10530
    },
    {
      "epoch": 2.4483159117305457,
      "grad_norm": 1.950553297996521,
      "learning_rate": 3.7761904761904767e-05,
      "loss": 0.1506,
      "step": 10540
    },
    {
      "epoch": 2.4506387921022066,
      "grad_norm": 1.362614393234253,
      "learning_rate": 3.775029036004646e-05,
      "loss": 0.1248,
      "step": 10550
    },
    {
      "epoch": 2.4529616724738674,
      "grad_norm": 0.819377601146698,
      "learning_rate": 3.7738675958188156e-05,
      "loss": 0.1956,
      "step": 10560
    },
    {
      "epoch": 2.4552845528455283,
      "grad_norm": 0.8389003276824951,
      "learning_rate": 3.772706155632985e-05,
      "loss": 0.1347,
      "step": 10570
    },
    {
      "epoch": 2.4576074332171896,
      "grad_norm": 2.336965799331665,
      "learning_rate": 3.7715447154471545e-05,
      "loss": 0.1453,
      "step": 10580
    },
    {
      "epoch": 2.45993031358885,
      "grad_norm": 2.698920726776123,
      "learning_rate": 3.770383275261325e-05,
      "loss": 0.2082,
      "step": 10590
    },
    {
      "epoch": 2.4622531939605112,
      "grad_norm": 0.9828333854675293,
      "learning_rate": 3.7692218350754935e-05,
      "loss": 0.1447,
      "step": 10600
    },
    {
      "epoch": 2.464576074332172,
      "grad_norm": 0.870895266532898,
      "learning_rate": 3.768060394889663e-05,
      "loss": 0.079,
      "step": 10610
    },
    {
      "epoch": 2.466898954703833,
      "grad_norm": 0.9989071488380432,
      "learning_rate": 3.766898954703833e-05,
      "loss": 0.1614,
      "step": 10620
    },
    {
      "epoch": 2.4692218350754938,
      "grad_norm": 0.9867353439331055,
      "learning_rate": 3.7657375145180025e-05,
      "loss": 0.1433,
      "step": 10630
    },
    {
      "epoch": 2.4715447154471546,
      "grad_norm": 1.1984927654266357,
      "learning_rate": 3.764576074332172e-05,
      "loss": 0.1648,
      "step": 10640
    },
    {
      "epoch": 2.4738675958188154,
      "grad_norm": 0.9273417592048645,
      "learning_rate": 3.7634146341463415e-05,
      "loss": 0.0792,
      "step": 10650
    },
    {
      "epoch": 2.4761904761904763,
      "grad_norm": 1.0845810174942017,
      "learning_rate": 3.762253193960511e-05,
      "loss": 0.1477,
      "step": 10660
    },
    {
      "epoch": 2.478513356562137,
      "grad_norm": 1.5316493511199951,
      "learning_rate": 3.761091753774681e-05,
      "loss": 0.1297,
      "step": 10670
    },
    {
      "epoch": 2.480836236933798,
      "grad_norm": 1.8233296871185303,
      "learning_rate": 3.7599303135888506e-05,
      "loss": 0.1883,
      "step": 10680
    },
    {
      "epoch": 2.483159117305459,
      "grad_norm": 0.9992696046829224,
      "learning_rate": 3.75876887340302e-05,
      "loss": 0.1051,
      "step": 10690
    },
    {
      "epoch": 2.4854819976771196,
      "grad_norm": 1.1190329790115356,
      "learning_rate": 3.7576074332171895e-05,
      "loss": 0.0794,
      "step": 10700
    },
    {
      "epoch": 2.4878048780487805,
      "grad_norm": 1.0171229839324951,
      "learning_rate": 3.756445993031359e-05,
      "loss": 0.1145,
      "step": 10710
    },
    {
      "epoch": 2.4901277584204413,
      "grad_norm": 1.3684515953063965,
      "learning_rate": 3.755284552845529e-05,
      "loss": 0.1801,
      "step": 10720
    },
    {
      "epoch": 2.492450638792102,
      "grad_norm": 1.0859521627426147,
      "learning_rate": 3.754123112659698e-05,
      "loss": 0.0942,
      "step": 10730
    },
    {
      "epoch": 2.494773519163763,
      "grad_norm": 1.5773335695266724,
      "learning_rate": 3.7529616724738674e-05,
      "loss": 0.1216,
      "step": 10740
    },
    {
      "epoch": 2.497096399535424,
      "grad_norm": 0.7504284977912903,
      "learning_rate": 3.7518002322880375e-05,
      "loss": 0.1321,
      "step": 10750
    },
    {
      "epoch": 2.4994192799070847,
      "grad_norm": 0.9058561325073242,
      "learning_rate": 3.750638792102207e-05,
      "loss": 0.2016,
      "step": 10760
    },
    {
      "epoch": 2.5017421602787455,
      "grad_norm": 0.8167767524719238,
      "learning_rate": 3.7494773519163764e-05,
      "loss": 0.0938,
      "step": 10770
    },
    {
      "epoch": 2.5040650406504064,
      "grad_norm": 1.7870970964431763,
      "learning_rate": 3.748315911730546e-05,
      "loss": 0.1714,
      "step": 10780
    },
    {
      "epoch": 2.506387921022067,
      "grad_norm": 1.112412929534912,
      "learning_rate": 3.7471544715447154e-05,
      "loss": 0.1201,
      "step": 10790
    },
    {
      "epoch": 2.508710801393728,
      "grad_norm": 1.1410174369812012,
      "learning_rate": 3.7459930313588855e-05,
      "loss": 0.1324,
      "step": 10800
    },
    {
      "epoch": 2.5110336817653893,
      "grad_norm": 2.7123234272003174,
      "learning_rate": 3.744831591173055e-05,
      "loss": 0.1569,
      "step": 10810
    },
    {
      "epoch": 2.5133565621370497,
      "grad_norm": 2.148256301879883,
      "learning_rate": 3.743670150987224e-05,
      "loss": 0.128,
      "step": 10820
    },
    {
      "epoch": 2.515679442508711,
      "grad_norm": 1.1769567728042603,
      "learning_rate": 3.742508710801394e-05,
      "loss": 0.0897,
      "step": 10830
    },
    {
      "epoch": 2.5180023228803714,
      "grad_norm": 2.0983376502990723,
      "learning_rate": 3.7413472706155634e-05,
      "loss": 0.1482,
      "step": 10840
    },
    {
      "epoch": 2.5203252032520327,
      "grad_norm": 1.2171330451965332,
      "learning_rate": 3.7401858304297335e-05,
      "loss": 0.1546,
      "step": 10850
    },
    {
      "epoch": 2.5226480836236935,
      "grad_norm": 0.9368894100189209,
      "learning_rate": 3.739024390243902e-05,
      "loss": 0.1266,
      "step": 10860
    },
    {
      "epoch": 2.5249709639953544,
      "grad_norm": 1.4207059144973755,
      "learning_rate": 3.737862950058072e-05,
      "loss": 0.1366,
      "step": 10870
    },
    {
      "epoch": 2.527293844367015,
      "grad_norm": 1.3935576677322388,
      "learning_rate": 3.736701509872242e-05,
      "loss": 0.1705,
      "step": 10880
    },
    {
      "epoch": 2.529616724738676,
      "grad_norm": 2.0521433353424072,
      "learning_rate": 3.7355400696864114e-05,
      "loss": 0.2267,
      "step": 10890
    },
    {
      "epoch": 2.531939605110337,
      "grad_norm": 0.7665364146232605,
      "learning_rate": 3.734378629500581e-05,
      "loss": 0.1375,
      "step": 10900
    },
    {
      "epoch": 2.5342624854819977,
      "grad_norm": 2.1028640270233154,
      "learning_rate": 3.73321718931475e-05,
      "loss": 0.1122,
      "step": 10910
    },
    {
      "epoch": 2.5365853658536586,
      "grad_norm": 1.7271124124526978,
      "learning_rate": 3.73205574912892e-05,
      "loss": 0.0875,
      "step": 10920
    },
    {
      "epoch": 2.5389082462253194,
      "grad_norm": 1.593762993812561,
      "learning_rate": 3.73089430894309e-05,
      "loss": 0.1316,
      "step": 10930
    },
    {
      "epoch": 2.5412311265969802,
      "grad_norm": 1.5509339570999146,
      "learning_rate": 3.7297328687572594e-05,
      "loss": 0.1615,
      "step": 10940
    },
    {
      "epoch": 2.543554006968641,
      "grad_norm": 2.1499831676483154,
      "learning_rate": 3.728571428571428e-05,
      "loss": 0.1453,
      "step": 10950
    },
    {
      "epoch": 2.545876887340302,
      "grad_norm": 1.6704763174057007,
      "learning_rate": 3.7274099883855984e-05,
      "loss": 0.2206,
      "step": 10960
    },
    {
      "epoch": 2.5481997677119628,
      "grad_norm": 1.4611153602600098,
      "learning_rate": 3.726248548199768e-05,
      "loss": 0.1268,
      "step": 10970
    },
    {
      "epoch": 2.5505226480836236,
      "grad_norm": 0.7913931012153625,
      "learning_rate": 3.725087108013938e-05,
      "loss": 0.1242,
      "step": 10980
    },
    {
      "epoch": 2.5528455284552845,
      "grad_norm": 0.9428759813308716,
      "learning_rate": 3.723925667828107e-05,
      "loss": 0.1237,
      "step": 10990
    },
    {
      "epoch": 2.5551684088269453,
      "grad_norm": 0.8700153827667236,
      "learning_rate": 3.722764227642276e-05,
      "loss": 0.203,
      "step": 11000
    },
    {
      "epoch": 2.557491289198606,
      "grad_norm": 0.9392284750938416,
      "learning_rate": 3.7216027874564464e-05,
      "loss": 0.1537,
      "step": 11010
    },
    {
      "epoch": 2.559814169570267,
      "grad_norm": 1.2889822721481323,
      "learning_rate": 3.720441347270616e-05,
      "loss": 0.2116,
      "step": 11020
    },
    {
      "epoch": 2.562137049941928,
      "grad_norm": 1.4849801063537598,
      "learning_rate": 3.719279907084785e-05,
      "loss": 0.1964,
      "step": 11030
    },
    {
      "epoch": 2.564459930313589,
      "grad_norm": 1.3671035766601562,
      "learning_rate": 3.718118466898955e-05,
      "loss": 0.156,
      "step": 11040
    },
    {
      "epoch": 2.5667828106852495,
      "grad_norm": 0.727150559425354,
      "learning_rate": 3.716957026713124e-05,
      "loss": 0.1347,
      "step": 11050
    },
    {
      "epoch": 2.569105691056911,
      "grad_norm": 0.7930856347084045,
      "learning_rate": 3.7157955865272944e-05,
      "loss": 0.1907,
      "step": 11060
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 1.1124639511108398,
      "learning_rate": 3.714634146341464e-05,
      "loss": 0.1186,
      "step": 11070
    },
    {
      "epoch": 2.5737514518002325,
      "grad_norm": 2.317669153213501,
      "learning_rate": 3.7134727061556326e-05,
      "loss": 0.1247,
      "step": 11080
    },
    {
      "epoch": 2.5760743321718933,
      "grad_norm": 0.88015216588974,
      "learning_rate": 3.712311265969803e-05,
      "loss": 0.1047,
      "step": 11090
    },
    {
      "epoch": 2.578397212543554,
      "grad_norm": 1.2813135385513306,
      "learning_rate": 3.711149825783972e-05,
      "loss": 0.1779,
      "step": 11100
    },
    {
      "epoch": 2.580720092915215,
      "grad_norm": 0.7553074359893799,
      "learning_rate": 3.7099883855981424e-05,
      "loss": 0.1732,
      "step": 11110
    },
    {
      "epoch": 2.583042973286876,
      "grad_norm": 2.8263437747955322,
      "learning_rate": 3.708826945412311e-05,
      "loss": 0.1198,
      "step": 11120
    },
    {
      "epoch": 2.5853658536585367,
      "grad_norm": 0.8674353957176208,
      "learning_rate": 3.7076655052264806e-05,
      "loss": 0.1023,
      "step": 11130
    },
    {
      "epoch": 2.5876887340301975,
      "grad_norm": 0.8657965064048767,
      "learning_rate": 3.706504065040651e-05,
      "loss": 0.1335,
      "step": 11140
    },
    {
      "epoch": 2.5900116144018583,
      "grad_norm": 1.0631294250488281,
      "learning_rate": 3.70534262485482e-05,
      "loss": 0.1313,
      "step": 11150
    },
    {
      "epoch": 2.592334494773519,
      "grad_norm": 1.6930460929870605,
      "learning_rate": 3.70418118466899e-05,
      "loss": 0.2044,
      "step": 11160
    },
    {
      "epoch": 2.59465737514518,
      "grad_norm": 3.50942063331604,
      "learning_rate": 3.703019744483159e-05,
      "loss": 0.2172,
      "step": 11170
    },
    {
      "epoch": 2.596980255516841,
      "grad_norm": 1.6417794227600098,
      "learning_rate": 3.701858304297329e-05,
      "loss": 0.1274,
      "step": 11180
    },
    {
      "epoch": 2.5993031358885017,
      "grad_norm": 2.9468274116516113,
      "learning_rate": 3.700696864111499e-05,
      "loss": 0.1563,
      "step": 11190
    },
    {
      "epoch": 2.6016260162601625,
      "grad_norm": 1.0119061470031738,
      "learning_rate": 3.699535423925668e-05,
      "loss": 0.1143,
      "step": 11200
    },
    {
      "epoch": 2.6039488966318234,
      "grad_norm": 1.1687697172164917,
      "learning_rate": 3.698373983739837e-05,
      "loss": 0.1874,
      "step": 11210
    },
    {
      "epoch": 2.6062717770034842,
      "grad_norm": 0.5310073494911194,
      "learning_rate": 3.697212543554007e-05,
      "loss": 0.1662,
      "step": 11220
    },
    {
      "epoch": 2.608594657375145,
      "grad_norm": 1.2175235748291016,
      "learning_rate": 3.696051103368177e-05,
      "loss": 0.1528,
      "step": 11230
    },
    {
      "epoch": 2.610917537746806,
      "grad_norm": 0.7815139293670654,
      "learning_rate": 3.694889663182347e-05,
      "loss": 0.1571,
      "step": 11240
    },
    {
      "epoch": 2.6132404181184667,
      "grad_norm": 1.2342764139175415,
      "learning_rate": 3.6937282229965156e-05,
      "loss": 0.1795,
      "step": 11250
    },
    {
      "epoch": 2.6155632984901276,
      "grad_norm": 2.6862378120422363,
      "learning_rate": 3.692566782810685e-05,
      "loss": 0.1096,
      "step": 11260
    },
    {
      "epoch": 2.617886178861789,
      "grad_norm": 1.3395129442214966,
      "learning_rate": 3.691405342624855e-05,
      "loss": 0.3084,
      "step": 11270
    },
    {
      "epoch": 2.6202090592334493,
      "grad_norm": 1.1029912233352661,
      "learning_rate": 3.690243902439025e-05,
      "loss": 0.0824,
      "step": 11280
    },
    {
      "epoch": 2.6225319396051106,
      "grad_norm": 1.1720913648605347,
      "learning_rate": 3.689082462253194e-05,
      "loss": 0.1277,
      "step": 11290
    },
    {
      "epoch": 2.624854819976771,
      "grad_norm": 1.4369704723358154,
      "learning_rate": 3.6879210220673636e-05,
      "loss": 0.1636,
      "step": 11300
    },
    {
      "epoch": 2.6271777003484322,
      "grad_norm": 1.6646045446395874,
      "learning_rate": 3.686759581881533e-05,
      "loss": 0.1661,
      "step": 11310
    },
    {
      "epoch": 2.629500580720093,
      "grad_norm": 1.1558722257614136,
      "learning_rate": 3.685598141695703e-05,
      "loss": 0.1293,
      "step": 11320
    },
    {
      "epoch": 2.631823461091754,
      "grad_norm": 1.2915078401565552,
      "learning_rate": 3.684436701509873e-05,
      "loss": 0.1268,
      "step": 11330
    },
    {
      "epoch": 2.6341463414634148,
      "grad_norm": 1.6763224601745605,
      "learning_rate": 3.6832752613240415e-05,
      "loss": 0.1534,
      "step": 11340
    },
    {
      "epoch": 2.6364692218350756,
      "grad_norm": 0.7828540205955505,
      "learning_rate": 3.6821138211382116e-05,
      "loss": 0.1384,
      "step": 11350
    },
    {
      "epoch": 2.6387921022067364,
      "grad_norm": 1.4879794120788574,
      "learning_rate": 3.680952380952381e-05,
      "loss": 0.1624,
      "step": 11360
    },
    {
      "epoch": 2.6411149825783973,
      "grad_norm": 0.8140003681182861,
      "learning_rate": 3.679790940766551e-05,
      "loss": 0.134,
      "step": 11370
    },
    {
      "epoch": 2.643437862950058,
      "grad_norm": 1.139478325843811,
      "learning_rate": 3.67862950058072e-05,
      "loss": 0.1144,
      "step": 11380
    },
    {
      "epoch": 2.645760743321719,
      "grad_norm": 0.6826459765434265,
      "learning_rate": 3.6774680603948895e-05,
      "loss": 0.1097,
      "step": 11390
    },
    {
      "epoch": 2.64808362369338,
      "grad_norm": 1.3639600276947021,
      "learning_rate": 3.6763066202090597e-05,
      "loss": 0.203,
      "step": 11400
    },
    {
      "epoch": 2.6504065040650406,
      "grad_norm": 0.9022831916809082,
      "learning_rate": 3.675145180023229e-05,
      "loss": 0.1134,
      "step": 11410
    },
    {
      "epoch": 2.6527293844367015,
      "grad_norm": 1.7210787534713745,
      "learning_rate": 3.6739837398373986e-05,
      "loss": 0.1465,
      "step": 11420
    },
    {
      "epoch": 2.6550522648083623,
      "grad_norm": 1.1812396049499512,
      "learning_rate": 3.672822299651568e-05,
      "loss": 0.076,
      "step": 11430
    },
    {
      "epoch": 2.657375145180023,
      "grad_norm": 0.861160397529602,
      "learning_rate": 3.6716608594657375e-05,
      "loss": 0.1249,
      "step": 11440
    },
    {
      "epoch": 2.659698025551684,
      "grad_norm": 0.9068092703819275,
      "learning_rate": 3.670499419279908e-05,
      "loss": 0.1546,
      "step": 11450
    },
    {
      "epoch": 2.662020905923345,
      "grad_norm": 1.4897407293319702,
      "learning_rate": 3.669337979094077e-05,
      "loss": 0.1351,
      "step": 11460
    },
    {
      "epoch": 2.6643437862950057,
      "grad_norm": 1.1844696998596191,
      "learning_rate": 3.668176538908246e-05,
      "loss": 0.1646,
      "step": 11470
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 2.33156156539917,
      "learning_rate": 3.667015098722416e-05,
      "loss": 0.1332,
      "step": 11480
    },
    {
      "epoch": 2.6689895470383274,
      "grad_norm": 0.7763646245002747,
      "learning_rate": 3.6658536585365855e-05,
      "loss": 0.1649,
      "step": 11490
    },
    {
      "epoch": 2.6713124274099886,
      "grad_norm": 1.1954563856124878,
      "learning_rate": 3.664692218350756e-05,
      "loss": 0.1221,
      "step": 11500
    },
    {
      "epoch": 2.673635307781649,
      "grad_norm": 1.001632571220398,
      "learning_rate": 3.6635307781649245e-05,
      "loss": 0.1434,
      "step": 11510
    },
    {
      "epoch": 2.6759581881533103,
      "grad_norm": 1.0392173528671265,
      "learning_rate": 3.662369337979094e-05,
      "loss": 0.1667,
      "step": 11520
    },
    {
      "epoch": 2.6782810685249707,
      "grad_norm": 1.1268666982650757,
      "learning_rate": 3.661207897793264e-05,
      "loss": 0.1665,
      "step": 11530
    },
    {
      "epoch": 2.680603948896632,
      "grad_norm": 0.6179687976837158,
      "learning_rate": 3.6600464576074336e-05,
      "loss": 0.1305,
      "step": 11540
    },
    {
      "epoch": 2.682926829268293,
      "grad_norm": 1.2639119625091553,
      "learning_rate": 3.658885017421603e-05,
      "loss": 0.1505,
      "step": 11550
    },
    {
      "epoch": 2.6852497096399537,
      "grad_norm": 1.425102710723877,
      "learning_rate": 3.6577235772357725e-05,
      "loss": 0.1112,
      "step": 11560
    },
    {
      "epoch": 2.6875725900116145,
      "grad_norm": 1.608436107635498,
      "learning_rate": 3.656562137049942e-05,
      "loss": 0.1514,
      "step": 11570
    },
    {
      "epoch": 2.6898954703832754,
      "grad_norm": 0.6076316237449646,
      "learning_rate": 3.655400696864112e-05,
      "loss": 0.1327,
      "step": 11580
    },
    {
      "epoch": 2.692218350754936,
      "grad_norm": 1.1109580993652344,
      "learning_rate": 3.6542392566782816e-05,
      "loss": 0.1186,
      "step": 11590
    },
    {
      "epoch": 2.694541231126597,
      "grad_norm": 1.8574106693267822,
      "learning_rate": 3.6530778164924504e-05,
      "loss": 0.1881,
      "step": 11600
    },
    {
      "epoch": 2.696864111498258,
      "grad_norm": 0.8977140784263611,
      "learning_rate": 3.6519163763066205e-05,
      "loss": 0.1799,
      "step": 11610
    },
    {
      "epoch": 2.6991869918699187,
      "grad_norm": 1.2599858045578003,
      "learning_rate": 3.65075493612079e-05,
      "loss": 0.104,
      "step": 11620
    },
    {
      "epoch": 2.7015098722415796,
      "grad_norm": 0.8518458604812622,
      "learning_rate": 3.6495934959349594e-05,
      "loss": 0.1001,
      "step": 11630
    },
    {
      "epoch": 2.7038327526132404,
      "grad_norm": 1.3639594316482544,
      "learning_rate": 3.648432055749129e-05,
      "loss": 0.1242,
      "step": 11640
    },
    {
      "epoch": 2.7061556329849012,
      "grad_norm": 0.6338986158370972,
      "learning_rate": 3.6472706155632984e-05,
      "loss": 0.1259,
      "step": 11650
    },
    {
      "epoch": 2.708478513356562,
      "grad_norm": 1.3017574548721313,
      "learning_rate": 3.6461091753774685e-05,
      "loss": 0.137,
      "step": 11660
    },
    {
      "epoch": 2.710801393728223,
      "grad_norm": 1.1683231592178345,
      "learning_rate": 3.644947735191638e-05,
      "loss": 0.1336,
      "step": 11670
    },
    {
      "epoch": 2.7131242740998838,
      "grad_norm": 3.040072441101074,
      "learning_rate": 3.6437862950058074e-05,
      "loss": 0.1503,
      "step": 11680
    },
    {
      "epoch": 2.7154471544715446,
      "grad_norm": 1.4621461629867554,
      "learning_rate": 3.642624854819977e-05,
      "loss": 0.1298,
      "step": 11690
    },
    {
      "epoch": 2.7177700348432055,
      "grad_norm": 1.8205636739730835,
      "learning_rate": 3.6414634146341464e-05,
      "loss": 0.1475,
      "step": 11700
    },
    {
      "epoch": 2.7200929152148663,
      "grad_norm": 0.9406410455703735,
      "learning_rate": 3.6403019744483165e-05,
      "loss": 0.1371,
      "step": 11710
    },
    {
      "epoch": 2.722415795586527,
      "grad_norm": 1.9145146608352661,
      "learning_rate": 3.639140534262486e-05,
      "loss": 0.2581,
      "step": 11720
    },
    {
      "epoch": 2.7247386759581884,
      "grad_norm": 1.2698475122451782,
      "learning_rate": 3.637979094076655e-05,
      "loss": 0.1316,
      "step": 11730
    },
    {
      "epoch": 2.727061556329849,
      "grad_norm": 1.2541152238845825,
      "learning_rate": 3.636817653890825e-05,
      "loss": 0.1054,
      "step": 11740
    },
    {
      "epoch": 2.72938443670151,
      "grad_norm": 2.503221035003662,
      "learning_rate": 3.6356562137049944e-05,
      "loss": 0.1842,
      "step": 11750
    },
    {
      "epoch": 2.7317073170731705,
      "grad_norm": 1.599916934967041,
      "learning_rate": 3.634494773519164e-05,
      "loss": 0.1391,
      "step": 11760
    },
    {
      "epoch": 2.7340301974448318,
      "grad_norm": 1.6805423498153687,
      "learning_rate": 3.633333333333333e-05,
      "loss": 0.1639,
      "step": 11770
    },
    {
      "epoch": 2.736353077816492,
      "grad_norm": 0.8074846863746643,
      "learning_rate": 3.632171893147503e-05,
      "loss": 0.1082,
      "step": 11780
    },
    {
      "epoch": 2.7386759581881535,
      "grad_norm": 1.1001750230789185,
      "learning_rate": 3.631010452961673e-05,
      "loss": 0.1176,
      "step": 11790
    },
    {
      "epoch": 2.7409988385598143,
      "grad_norm": 1.3366645574569702,
      "learning_rate": 3.6298490127758424e-05,
      "loss": 0.097,
      "step": 11800
    },
    {
      "epoch": 2.743321718931475,
      "grad_norm": 1.078762173652649,
      "learning_rate": 3.628687572590012e-05,
      "loss": 0.18,
      "step": 11810
    },
    {
      "epoch": 2.745644599303136,
      "grad_norm": 0.6423373818397522,
      "learning_rate": 3.6275261324041813e-05,
      "loss": 0.0778,
      "step": 11820
    },
    {
      "epoch": 2.747967479674797,
      "grad_norm": 0.7479262948036194,
      "learning_rate": 3.626364692218351e-05,
      "loss": 0.1625,
      "step": 11830
    },
    {
      "epoch": 2.7502903600464577,
      "grad_norm": 0.7233719229698181,
      "learning_rate": 3.625203252032521e-05,
      "loss": 0.1329,
      "step": 11840
    },
    {
      "epoch": 2.7526132404181185,
      "grad_norm": 0.9975402355194092,
      "learning_rate": 3.6240418118466904e-05,
      "loss": 0.0987,
      "step": 11850
    },
    {
      "epoch": 2.7549361207897793,
      "grad_norm": 1.0313559770584106,
      "learning_rate": 3.622880371660859e-05,
      "loss": 0.1465,
      "step": 11860
    },
    {
      "epoch": 2.75725900116144,
      "grad_norm": 0.6008889675140381,
      "learning_rate": 3.6217189314750294e-05,
      "loss": 0.1068,
      "step": 11870
    },
    {
      "epoch": 2.759581881533101,
      "grad_norm": 1.122719168663025,
      "learning_rate": 3.620557491289199e-05,
      "loss": 0.1116,
      "step": 11880
    },
    {
      "epoch": 2.761904761904762,
      "grad_norm": 0.9005579352378845,
      "learning_rate": 3.619396051103368e-05,
      "loss": 0.2054,
      "step": 11890
    },
    {
      "epoch": 2.7642276422764227,
      "grad_norm": 1.5388633012771606,
      "learning_rate": 3.618234610917538e-05,
      "loss": 0.1354,
      "step": 11900
    },
    {
      "epoch": 2.7665505226480835,
      "grad_norm": 1.635032296180725,
      "learning_rate": 3.617073170731707e-05,
      "loss": 0.1534,
      "step": 11910
    },
    {
      "epoch": 2.7688734030197444,
      "grad_norm": 0.7305298447608948,
      "learning_rate": 3.6159117305458774e-05,
      "loss": 0.1991,
      "step": 11920
    },
    {
      "epoch": 2.7711962833914052,
      "grad_norm": 2.092144727706909,
      "learning_rate": 3.614750290360047e-05,
      "loss": 0.1073,
      "step": 11930
    },
    {
      "epoch": 2.773519163763066,
      "grad_norm": 1.457086443901062,
      "learning_rate": 3.613588850174216e-05,
      "loss": 0.1562,
      "step": 11940
    },
    {
      "epoch": 2.775842044134727,
      "grad_norm": 1.4962059259414673,
      "learning_rate": 3.612427409988386e-05,
      "loss": 0.1533,
      "step": 11950
    },
    {
      "epoch": 2.778164924506388,
      "grad_norm": 0.6585270762443542,
      "learning_rate": 3.611265969802555e-05,
      "loss": 0.1183,
      "step": 11960
    },
    {
      "epoch": 2.7804878048780486,
      "grad_norm": 1.099130630493164,
      "learning_rate": 3.6101045296167254e-05,
      "loss": 0.1207,
      "step": 11970
    },
    {
      "epoch": 2.78281068524971,
      "grad_norm": 1.6331770420074463,
      "learning_rate": 3.608943089430895e-05,
      "loss": 0.1709,
      "step": 11980
    },
    {
      "epoch": 2.7851335656213703,
      "grad_norm": 1.5291049480438232,
      "learning_rate": 3.6077816492450636e-05,
      "loss": 0.1156,
      "step": 11990
    },
    {
      "epoch": 2.7874564459930316,
      "grad_norm": 0.8616056442260742,
      "learning_rate": 3.606620209059234e-05,
      "loss": 0.1512,
      "step": 12000
    },
    {
      "epoch": 2.789779326364692,
      "grad_norm": 1.2837576866149902,
      "learning_rate": 3.605458768873403e-05,
      "loss": 0.1078,
      "step": 12010
    },
    {
      "epoch": 2.7921022067363532,
      "grad_norm": 0.7004193663597107,
      "learning_rate": 3.604297328687573e-05,
      "loss": 0.0811,
      "step": 12020
    },
    {
      "epoch": 2.794425087108014,
      "grad_norm": 1.1240123510360718,
      "learning_rate": 3.603135888501742e-05,
      "loss": 0.0753,
      "step": 12030
    },
    {
      "epoch": 2.796747967479675,
      "grad_norm": 1.1497403383255005,
      "learning_rate": 3.6019744483159117e-05,
      "loss": 0.1308,
      "step": 12040
    },
    {
      "epoch": 2.7990708478513358,
      "grad_norm": 0.8119636178016663,
      "learning_rate": 3.600813008130082e-05,
      "loss": 0.1253,
      "step": 12050
    },
    {
      "epoch": 2.8013937282229966,
      "grad_norm": 0.641825258731842,
      "learning_rate": 3.599651567944251e-05,
      "loss": 0.1709,
      "step": 12060
    },
    {
      "epoch": 2.8037166085946574,
      "grad_norm": 2.0012810230255127,
      "learning_rate": 3.598490127758421e-05,
      "loss": 0.1403,
      "step": 12070
    },
    {
      "epoch": 2.8060394889663183,
      "grad_norm": 1.0475808382034302,
      "learning_rate": 3.59732868757259e-05,
      "loss": 0.0944,
      "step": 12080
    },
    {
      "epoch": 2.808362369337979,
      "grad_norm": 2.5520811080932617,
      "learning_rate": 3.59616724738676e-05,
      "loss": 0.1388,
      "step": 12090
    },
    {
      "epoch": 2.81068524970964,
      "grad_norm": 1.1349374055862427,
      "learning_rate": 3.595005807200929e-05,
      "loss": 0.1026,
      "step": 12100
    },
    {
      "epoch": 2.813008130081301,
      "grad_norm": 2.545736312866211,
      "learning_rate": 3.593844367015099e-05,
      "loss": 0.1917,
      "step": 12110
    },
    {
      "epoch": 2.8153310104529616,
      "grad_norm": 0.5015550255775452,
      "learning_rate": 3.592682926829268e-05,
      "loss": 0.1058,
      "step": 12120
    },
    {
      "epoch": 2.8176538908246225,
      "grad_norm": 1.8716427087783813,
      "learning_rate": 3.591521486643438e-05,
      "loss": 0.2031,
      "step": 12130
    },
    {
      "epoch": 2.8199767711962833,
      "grad_norm": 1.1307141780853271,
      "learning_rate": 3.590360046457608e-05,
      "loss": 0.0778,
      "step": 12140
    },
    {
      "epoch": 2.822299651567944,
      "grad_norm": 0.9361185431480408,
      "learning_rate": 3.589198606271777e-05,
      "loss": 0.1131,
      "step": 12150
    },
    {
      "epoch": 2.824622531939605,
      "grad_norm": 1.4039156436920166,
      "learning_rate": 3.5880371660859466e-05,
      "loss": 0.1348,
      "step": 12160
    },
    {
      "epoch": 2.826945412311266,
      "grad_norm": 1.4666551351547241,
      "learning_rate": 3.586875725900116e-05,
      "loss": 0.1555,
      "step": 12170
    },
    {
      "epoch": 2.8292682926829267,
      "grad_norm": 0.9897943139076233,
      "learning_rate": 3.585714285714286e-05,
      "loss": 0.1453,
      "step": 12180
    },
    {
      "epoch": 2.831591173054588,
      "grad_norm": 1.3592076301574707,
      "learning_rate": 3.584552845528456e-05,
      "loss": 0.2054,
      "step": 12190
    },
    {
      "epoch": 2.8339140534262484,
      "grad_norm": 0.5710552334785461,
      "learning_rate": 3.583391405342625e-05,
      "loss": 0.0607,
      "step": 12200
    },
    {
      "epoch": 2.8362369337979096,
      "grad_norm": 1.625193476676941,
      "learning_rate": 3.5822299651567946e-05,
      "loss": 0.1753,
      "step": 12210
    },
    {
      "epoch": 2.83855981416957,
      "grad_norm": 1.9796148538589478,
      "learning_rate": 3.581068524970964e-05,
      "loss": 0.127,
      "step": 12220
    },
    {
      "epoch": 2.8408826945412313,
      "grad_norm": 1.0654137134552002,
      "learning_rate": 3.5799070847851336e-05,
      "loss": 0.1446,
      "step": 12230
    },
    {
      "epoch": 2.8432055749128917,
      "grad_norm": 1.7840567827224731,
      "learning_rate": 3.578745644599304e-05,
      "loss": 0.1141,
      "step": 12240
    },
    {
      "epoch": 2.845528455284553,
      "grad_norm": 1.4781132936477661,
      "learning_rate": 3.5775842044134725e-05,
      "loss": 0.1607,
      "step": 12250
    },
    {
      "epoch": 2.847851335656214,
      "grad_norm": 0.8486888408660889,
      "learning_rate": 3.5764227642276426e-05,
      "loss": 0.1461,
      "step": 12260
    },
    {
      "epoch": 2.8501742160278747,
      "grad_norm": 1.3034626245498657,
      "learning_rate": 3.575261324041812e-05,
      "loss": 0.1881,
      "step": 12270
    },
    {
      "epoch": 2.8524970963995355,
      "grad_norm": 1.65889310836792,
      "learning_rate": 3.5740998838559816e-05,
      "loss": 0.1304,
      "step": 12280
    },
    {
      "epoch": 2.8548199767711964,
      "grad_norm": 2.152254581451416,
      "learning_rate": 3.572938443670151e-05,
      "loss": 0.1186,
      "step": 12290
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 1.4330992698669434,
      "learning_rate": 3.5717770034843205e-05,
      "loss": 0.1156,
      "step": 12300
    },
    {
      "epoch": 2.859465737514518,
      "grad_norm": 1.7214471101760864,
      "learning_rate": 3.570615563298491e-05,
      "loss": 0.2137,
      "step": 12310
    },
    {
      "epoch": 2.861788617886179,
      "grad_norm": 2.3450770378112793,
      "learning_rate": 3.56945412311266e-05,
      "loss": 0.1217,
      "step": 12320
    },
    {
      "epoch": 2.8641114982578397,
      "grad_norm": 0.9130822420120239,
      "learning_rate": 3.5682926829268296e-05,
      "loss": 0.0982,
      "step": 12330
    },
    {
      "epoch": 2.8664343786295006,
      "grad_norm": 0.705327033996582,
      "learning_rate": 3.567131242740999e-05,
      "loss": 0.0774,
      "step": 12340
    },
    {
      "epoch": 2.8687572590011614,
      "grad_norm": 0.6991010308265686,
      "learning_rate": 3.5659698025551685e-05,
      "loss": 0.103,
      "step": 12350
    },
    {
      "epoch": 2.8710801393728222,
      "grad_norm": 2.145766019821167,
      "learning_rate": 3.564808362369338e-05,
      "loss": 0.1466,
      "step": 12360
    },
    {
      "epoch": 2.873403019744483,
      "grad_norm": 1.9343804121017456,
      "learning_rate": 3.563646922183508e-05,
      "loss": 0.1367,
      "step": 12370
    },
    {
      "epoch": 2.875725900116144,
      "grad_norm": 0.9610934257507324,
      "learning_rate": 3.562485481997677e-05,
      "loss": 0.074,
      "step": 12380
    },
    {
      "epoch": 2.8780487804878048,
      "grad_norm": 1.3987141847610474,
      "learning_rate": 3.561324041811847e-05,
      "loss": 0.1248,
      "step": 12390
    },
    {
      "epoch": 2.8803716608594656,
      "grad_norm": 1.3665400743484497,
      "learning_rate": 3.5601626016260165e-05,
      "loss": 0.0842,
      "step": 12400
    },
    {
      "epoch": 2.8826945412311265,
      "grad_norm": 1.4419095516204834,
      "learning_rate": 3.559001161440186e-05,
      "loss": 0.2029,
      "step": 12410
    },
    {
      "epoch": 2.8850174216027873,
      "grad_norm": 1.0406113862991333,
      "learning_rate": 3.5578397212543555e-05,
      "loss": 0.1703,
      "step": 12420
    },
    {
      "epoch": 2.887340301974448,
      "grad_norm": 1.2604551315307617,
      "learning_rate": 3.556678281068525e-05,
      "loss": 0.1231,
      "step": 12430
    },
    {
      "epoch": 2.8896631823461094,
      "grad_norm": 0.6600381731987,
      "learning_rate": 3.555516840882695e-05,
      "loss": 0.1084,
      "step": 12440
    },
    {
      "epoch": 2.89198606271777,
      "grad_norm": 0.6769660711288452,
      "learning_rate": 3.5543554006968646e-05,
      "loss": 0.1177,
      "step": 12450
    },
    {
      "epoch": 2.894308943089431,
      "grad_norm": 2.496830940246582,
      "learning_rate": 3.553193960511034e-05,
      "loss": 0.2101,
      "step": 12460
    },
    {
      "epoch": 2.8966318234610915,
      "grad_norm": 0.8427985310554504,
      "learning_rate": 3.5520325203252035e-05,
      "loss": 0.111,
      "step": 12470
    },
    {
      "epoch": 2.8989547038327528,
      "grad_norm": 1.6142412424087524,
      "learning_rate": 3.550871080139373e-05,
      "loss": 0.193,
      "step": 12480
    },
    {
      "epoch": 2.9012775842044136,
      "grad_norm": 1.27207612991333,
      "learning_rate": 3.5497096399535424e-05,
      "loss": 0.2191,
      "step": 12490
    },
    {
      "epoch": 2.9036004645760745,
      "grad_norm": 0.7632535099983215,
      "learning_rate": 3.5485481997677126e-05,
      "loss": 0.1883,
      "step": 12500
    },
    {
      "epoch": 2.9059233449477353,
      "grad_norm": 0.9048358201980591,
      "learning_rate": 3.5473867595818814e-05,
      "loss": 0.1433,
      "step": 12510
    },
    {
      "epoch": 2.908246225319396,
      "grad_norm": 0.631837010383606,
      "learning_rate": 3.5462253193960515e-05,
      "loss": 0.0888,
      "step": 12520
    },
    {
      "epoch": 2.910569105691057,
      "grad_norm": 1.2496590614318848,
      "learning_rate": 3.545063879210221e-05,
      "loss": 0.1573,
      "step": 12530
    },
    {
      "epoch": 2.912891986062718,
      "grad_norm": 1.2126542329788208,
      "learning_rate": 3.5439024390243904e-05,
      "loss": 0.1134,
      "step": 12540
    },
    {
      "epoch": 2.9152148664343787,
      "grad_norm": 0.9656468033790588,
      "learning_rate": 3.54274099883856e-05,
      "loss": 0.1179,
      "step": 12550
    },
    {
      "epoch": 2.9175377468060395,
      "grad_norm": 0.9797545075416565,
      "learning_rate": 3.5415795586527294e-05,
      "loss": 0.1693,
      "step": 12560
    },
    {
      "epoch": 2.9198606271777003,
      "grad_norm": 0.5682016015052795,
      "learning_rate": 3.540418118466899e-05,
      "loss": 0.187,
      "step": 12570
    },
    {
      "epoch": 2.922183507549361,
      "grad_norm": 1.653144121170044,
      "learning_rate": 3.539256678281069e-05,
      "loss": 0.1987,
      "step": 12580
    },
    {
      "epoch": 2.924506387921022,
      "grad_norm": 0.8614988923072815,
      "learning_rate": 3.5380952380952385e-05,
      "loss": 0.1538,
      "step": 12590
    },
    {
      "epoch": 2.926829268292683,
      "grad_norm": 1.1414687633514404,
      "learning_rate": 3.536933797909408e-05,
      "loss": 0.1347,
      "step": 12600
    },
    {
      "epoch": 2.9291521486643437,
      "grad_norm": 2.073507785797119,
      "learning_rate": 3.5357723577235774e-05,
      "loss": 0.1006,
      "step": 12610
    },
    {
      "epoch": 2.9314750290360045,
      "grad_norm": 1.538135051727295,
      "learning_rate": 3.534610917537747e-05,
      "loss": 0.1183,
      "step": 12620
    },
    {
      "epoch": 2.9337979094076654,
      "grad_norm": 0.8682656288146973,
      "learning_rate": 3.533449477351917e-05,
      "loss": 0.1871,
      "step": 12630
    },
    {
      "epoch": 2.9361207897793262,
      "grad_norm": 1.1586658954620361,
      "learning_rate": 3.532288037166086e-05,
      "loss": 0.1683,
      "step": 12640
    },
    {
      "epoch": 2.938443670150987,
      "grad_norm": 0.8015413880348206,
      "learning_rate": 3.531126596980256e-05,
      "loss": 0.1088,
      "step": 12650
    },
    {
      "epoch": 2.940766550522648,
      "grad_norm": 0.8808286786079407,
      "learning_rate": 3.5299651567944254e-05,
      "loss": 0.1225,
      "step": 12660
    },
    {
      "epoch": 2.943089430894309,
      "grad_norm": 1.388858675956726,
      "learning_rate": 3.528803716608595e-05,
      "loss": 0.1018,
      "step": 12670
    },
    {
      "epoch": 2.9454123112659696,
      "grad_norm": 0.9640051126480103,
      "learning_rate": 3.5276422764227643e-05,
      "loss": 0.0868,
      "step": 12680
    },
    {
      "epoch": 2.947735191637631,
      "grad_norm": 0.8752129077911377,
      "learning_rate": 3.526480836236934e-05,
      "loss": 0.1487,
      "step": 12690
    },
    {
      "epoch": 2.9500580720092913,
      "grad_norm": 1.6023608446121216,
      "learning_rate": 3.525319396051103e-05,
      "loss": 0.1335,
      "step": 12700
    },
    {
      "epoch": 2.9523809523809526,
      "grad_norm": 0.9413257241249084,
      "learning_rate": 3.5241579558652734e-05,
      "loss": 0.1343,
      "step": 12710
    },
    {
      "epoch": 2.9547038327526134,
      "grad_norm": 0.8337846398353577,
      "learning_rate": 3.522996515679443e-05,
      "loss": 0.1985,
      "step": 12720
    },
    {
      "epoch": 2.9570267131242742,
      "grad_norm": 1.5664892196655273,
      "learning_rate": 3.5218350754936124e-05,
      "loss": 0.1756,
      "step": 12730
    },
    {
      "epoch": 2.959349593495935,
      "grad_norm": 1.0441049337387085,
      "learning_rate": 3.520673635307782e-05,
      "loss": 0.0738,
      "step": 12740
    },
    {
      "epoch": 2.961672473867596,
      "grad_norm": 0.8541749119758606,
      "learning_rate": 3.519512195121951e-05,
      "loss": 0.1077,
      "step": 12750
    },
    {
      "epoch": 2.9639953542392568,
      "grad_norm": 1.3649992942810059,
      "learning_rate": 3.5183507549361214e-05,
      "loss": 0.1848,
      "step": 12760
    },
    {
      "epoch": 2.9663182346109176,
      "grad_norm": 1.2852646112442017,
      "learning_rate": 3.51718931475029e-05,
      "loss": 0.1567,
      "step": 12770
    },
    {
      "epoch": 2.9686411149825784,
      "grad_norm": 1.5285524129867554,
      "learning_rate": 3.5160278745644604e-05,
      "loss": 0.1387,
      "step": 12780
    },
    {
      "epoch": 2.9709639953542393,
      "grad_norm": 1.4305890798568726,
      "learning_rate": 3.51486643437863e-05,
      "loss": 0.2284,
      "step": 12790
    },
    {
      "epoch": 2.9732868757259,
      "grad_norm": 0.873525083065033,
      "learning_rate": 3.513704994192799e-05,
      "loss": 0.0948,
      "step": 12800
    },
    {
      "epoch": 2.975609756097561,
      "grad_norm": 1.7490978240966797,
      "learning_rate": 3.512543554006969e-05,
      "loss": 0.1987,
      "step": 12810
    },
    {
      "epoch": 2.977932636469222,
      "grad_norm": 1.0390914678573608,
      "learning_rate": 3.511382113821138e-05,
      "loss": 0.2627,
      "step": 12820
    },
    {
      "epoch": 2.9802555168408826,
      "grad_norm": 0.9604960680007935,
      "learning_rate": 3.510220673635308e-05,
      "loss": 0.1022,
      "step": 12830
    },
    {
      "epoch": 2.9825783972125435,
      "grad_norm": 0.7113779187202454,
      "learning_rate": 3.509059233449478e-05,
      "loss": 0.1144,
      "step": 12840
    },
    {
      "epoch": 2.9849012775842043,
      "grad_norm": 0.9255521893501282,
      "learning_rate": 3.507897793263647e-05,
      "loss": 0.0713,
      "step": 12850
    },
    {
      "epoch": 2.987224157955865,
      "grad_norm": 1.7143092155456543,
      "learning_rate": 3.506736353077817e-05,
      "loss": 0.1641,
      "step": 12860
    },
    {
      "epoch": 2.989547038327526,
      "grad_norm": 0.5609777569770813,
      "learning_rate": 3.505574912891986e-05,
      "loss": 0.0996,
      "step": 12870
    },
    {
      "epoch": 2.991869918699187,
      "grad_norm": 1.6342452764511108,
      "learning_rate": 3.504413472706156e-05,
      "loss": 0.1616,
      "step": 12880
    },
    {
      "epoch": 2.9941927990708477,
      "grad_norm": 0.8502321839332581,
      "learning_rate": 3.503252032520325e-05,
      "loss": 0.133,
      "step": 12890
    },
    {
      "epoch": 2.996515679442509,
      "grad_norm": 0.9553207159042358,
      "learning_rate": 3.5020905923344947e-05,
      "loss": 0.15,
      "step": 12900
    },
    {
      "epoch": 2.9988385598141694,
      "grad_norm": 0.8049799799919128,
      "learning_rate": 3.500929152148664e-05,
      "loss": 0.1985,
      "step": 12910
    },
    {
      "epoch": 3.0011614401858306,
      "grad_norm": 1.0779485702514648,
      "learning_rate": 3.499767711962834e-05,
      "loss": 0.1247,
      "step": 12920
    },
    {
      "epoch": 3.0034843205574915,
      "grad_norm": 1.2234703302383423,
      "learning_rate": 3.498606271777004e-05,
      "loss": 0.1267,
      "step": 12930
    },
    {
      "epoch": 3.0058072009291523,
      "grad_norm": 1.3613263368606567,
      "learning_rate": 3.497444831591173e-05,
      "loss": 0.1631,
      "step": 12940
    },
    {
      "epoch": 3.008130081300813,
      "grad_norm": 0.825233519077301,
      "learning_rate": 3.496283391405343e-05,
      "loss": 0.1107,
      "step": 12950
    },
    {
      "epoch": 3.010452961672474,
      "grad_norm": 2.371699571609497,
      "learning_rate": 3.495121951219512e-05,
      "loss": 0.1363,
      "step": 12960
    },
    {
      "epoch": 3.012775842044135,
      "grad_norm": 1.0845637321472168,
      "learning_rate": 3.493960511033682e-05,
      "loss": 0.1193,
      "step": 12970
    },
    {
      "epoch": 3.0150987224157957,
      "grad_norm": 1.621789813041687,
      "learning_rate": 3.492799070847851e-05,
      "loss": 0.1289,
      "step": 12980
    },
    {
      "epoch": 3.0174216027874565,
      "grad_norm": 0.840042233467102,
      "learning_rate": 3.491637630662021e-05,
      "loss": 0.1595,
      "step": 12990
    },
    {
      "epoch": 3.0197444831591174,
      "grad_norm": 1.3322168588638306,
      "learning_rate": 3.490476190476191e-05,
      "loss": 0.1548,
      "step": 13000
    },
    {
      "epoch": 3.022067363530778,
      "grad_norm": 0.6789169311523438,
      "learning_rate": 3.48931475029036e-05,
      "loss": 0.1007,
      "step": 13010
    },
    {
      "epoch": 3.024390243902439,
      "grad_norm": 1.2929551601409912,
      "learning_rate": 3.4881533101045296e-05,
      "loss": 0.1824,
      "step": 13020
    },
    {
      "epoch": 3.0267131242741,
      "grad_norm": 0.7171021699905396,
      "learning_rate": 3.486991869918699e-05,
      "loss": 0.1025,
      "step": 13030
    },
    {
      "epoch": 3.0290360046457607,
      "grad_norm": 0.9707374572753906,
      "learning_rate": 3.4858304297328685e-05,
      "loss": 0.2389,
      "step": 13040
    },
    {
      "epoch": 3.0313588850174216,
      "grad_norm": 1.1777243614196777,
      "learning_rate": 3.484668989547039e-05,
      "loss": 0.1135,
      "step": 13050
    },
    {
      "epoch": 3.0336817653890824,
      "grad_norm": 2.9771759510040283,
      "learning_rate": 3.483507549361208e-05,
      "loss": 0.1598,
      "step": 13060
    },
    {
      "epoch": 3.0360046457607432,
      "grad_norm": 1.3790780305862427,
      "learning_rate": 3.4823461091753776e-05,
      "loss": 0.068,
      "step": 13070
    },
    {
      "epoch": 3.038327526132404,
      "grad_norm": 0.7497863173484802,
      "learning_rate": 3.481184668989547e-05,
      "loss": 0.0981,
      "step": 13080
    },
    {
      "epoch": 3.040650406504065,
      "grad_norm": 2.6813554763793945,
      "learning_rate": 3.4800232288037166e-05,
      "loss": 0.123,
      "step": 13090
    },
    {
      "epoch": 3.0429732868757258,
      "grad_norm": 0.6793310642242432,
      "learning_rate": 3.478861788617887e-05,
      "loss": 0.0949,
      "step": 13100
    },
    {
      "epoch": 3.0452961672473866,
      "grad_norm": 2.7700397968292236,
      "learning_rate": 3.4777003484320555e-05,
      "loss": 0.1361,
      "step": 13110
    },
    {
      "epoch": 3.0476190476190474,
      "grad_norm": 1.3993176221847534,
      "learning_rate": 3.4765389082462256e-05,
      "loss": 0.1243,
      "step": 13120
    },
    {
      "epoch": 3.0499419279907083,
      "grad_norm": 1.1878063678741455,
      "learning_rate": 3.475377468060395e-05,
      "loss": 0.1723,
      "step": 13130
    },
    {
      "epoch": 3.052264808362369,
      "grad_norm": 1.3176558017730713,
      "learning_rate": 3.4742160278745646e-05,
      "loss": 0.1442,
      "step": 13140
    },
    {
      "epoch": 3.0545876887340304,
      "grad_norm": 0.8721266984939575,
      "learning_rate": 3.473054587688734e-05,
      "loss": 0.1406,
      "step": 13150
    },
    {
      "epoch": 3.0569105691056913,
      "grad_norm": 0.81986004114151,
      "learning_rate": 3.4718931475029035e-05,
      "loss": 0.0996,
      "step": 13160
    },
    {
      "epoch": 3.059233449477352,
      "grad_norm": 1.6368743181228638,
      "learning_rate": 3.470731707317073e-05,
      "loss": 0.1617,
      "step": 13170
    },
    {
      "epoch": 3.061556329849013,
      "grad_norm": 0.8022399544715881,
      "learning_rate": 3.469686411149826e-05,
      "loss": 0.1385,
      "step": 13180
    },
    {
      "epoch": 3.0638792102206738,
      "grad_norm": 2.537604808807373,
      "learning_rate": 3.468524970963995e-05,
      "loss": 0.1319,
      "step": 13190
    },
    {
      "epoch": 3.0662020905923346,
      "grad_norm": 1.3908673524856567,
      "learning_rate": 3.467363530778165e-05,
      "loss": 0.0774,
      "step": 13200
    },
    {
      "epoch": 3.0685249709639955,
      "grad_norm": 0.718062698841095,
      "learning_rate": 3.466202090592335e-05,
      "loss": 0.1268,
      "step": 13210
    },
    {
      "epoch": 3.0708478513356563,
      "grad_norm": 1.6287329196929932,
      "learning_rate": 3.4650406504065044e-05,
      "loss": 0.1685,
      "step": 13220
    },
    {
      "epoch": 3.073170731707317,
      "grad_norm": 1.3717050552368164,
      "learning_rate": 3.463879210220674e-05,
      "loss": 0.1649,
      "step": 13230
    },
    {
      "epoch": 3.075493612078978,
      "grad_norm": 1.1001547574996948,
      "learning_rate": 3.462717770034843e-05,
      "loss": 0.1526,
      "step": 13240
    },
    {
      "epoch": 3.077816492450639,
      "grad_norm": 0.9051828384399414,
      "learning_rate": 3.461556329849013e-05,
      "loss": 0.303,
      "step": 13250
    },
    {
      "epoch": 3.0801393728222997,
      "grad_norm": 0.8232926726341248,
      "learning_rate": 3.460394889663183e-05,
      "loss": 0.0541,
      "step": 13260
    },
    {
      "epoch": 3.0824622531939605,
      "grad_norm": 1.2702126502990723,
      "learning_rate": 3.4592334494773524e-05,
      "loss": 0.0828,
      "step": 13270
    },
    {
      "epoch": 3.0847851335656213,
      "grad_norm": 1.266534447669983,
      "learning_rate": 3.458072009291521e-05,
      "loss": 0.1571,
      "step": 13280
    },
    {
      "epoch": 3.087108013937282,
      "grad_norm": 1.5584604740142822,
      "learning_rate": 3.456910569105691e-05,
      "loss": 0.271,
      "step": 13290
    },
    {
      "epoch": 3.089430894308943,
      "grad_norm": 2.4710209369659424,
      "learning_rate": 3.455749128919861e-05,
      "loss": 0.1591,
      "step": 13300
    },
    {
      "epoch": 3.091753774680604,
      "grad_norm": 1.882560133934021,
      "learning_rate": 3.45458768873403e-05,
      "loss": 0.1764,
      "step": 13310
    },
    {
      "epoch": 3.0940766550522647,
      "grad_norm": 0.6610315442085266,
      "learning_rate": 3.4534262485482e-05,
      "loss": 0.1377,
      "step": 13320
    },
    {
      "epoch": 3.0963995354239255,
      "grad_norm": 1.1775743961334229,
      "learning_rate": 3.452264808362369e-05,
      "loss": 0.1245,
      "step": 13330
    },
    {
      "epoch": 3.0987224157955864,
      "grad_norm": 0.8248530030250549,
      "learning_rate": 3.4511033681765393e-05,
      "loss": 0.1035,
      "step": 13340
    },
    {
      "epoch": 3.1010452961672472,
      "grad_norm": 0.5433346629142761,
      "learning_rate": 3.449941927990709e-05,
      "loss": 0.1199,
      "step": 13350
    },
    {
      "epoch": 3.103368176538908,
      "grad_norm": 0.7735803723335266,
      "learning_rate": 3.448780487804878e-05,
      "loss": 0.1896,
      "step": 13360
    },
    {
      "epoch": 3.105691056910569,
      "grad_norm": 0.8469178676605225,
      "learning_rate": 3.447619047619048e-05,
      "loss": 0.1127,
      "step": 13370
    },
    {
      "epoch": 3.10801393728223,
      "grad_norm": 2.0946900844573975,
      "learning_rate": 3.446457607433217e-05,
      "loss": 0.0903,
      "step": 13380
    },
    {
      "epoch": 3.110336817653891,
      "grad_norm": 1.6049537658691406,
      "learning_rate": 3.4452961672473874e-05,
      "loss": 0.159,
      "step": 13390
    },
    {
      "epoch": 3.112659698025552,
      "grad_norm": 1.8965996503829956,
      "learning_rate": 3.444134727061556e-05,
      "loss": 0.2045,
      "step": 13400
    },
    {
      "epoch": 3.1149825783972127,
      "grad_norm": 0.6823437213897705,
      "learning_rate": 3.4429732868757256e-05,
      "loss": 0.0914,
      "step": 13410
    },
    {
      "epoch": 3.1173054587688735,
      "grad_norm": 0.6081922054290771,
      "learning_rate": 3.441811846689896e-05,
      "loss": 0.2253,
      "step": 13420
    },
    {
      "epoch": 3.1196283391405344,
      "grad_norm": 3.4731132984161377,
      "learning_rate": 3.440650406504065e-05,
      "loss": 0.1661,
      "step": 13430
    },
    {
      "epoch": 3.1219512195121952,
      "grad_norm": 1.3726588487625122,
      "learning_rate": 3.439488966318235e-05,
      "loss": 0.0737,
      "step": 13440
    },
    {
      "epoch": 3.124274099883856,
      "grad_norm": 1.1319807767868042,
      "learning_rate": 3.438327526132404e-05,
      "loss": 0.1875,
      "step": 13450
    },
    {
      "epoch": 3.126596980255517,
      "grad_norm": 1.8177381753921509,
      "learning_rate": 3.4371660859465736e-05,
      "loss": 0.178,
      "step": 13460
    },
    {
      "epoch": 3.1289198606271778,
      "grad_norm": 1.1122653484344482,
      "learning_rate": 3.436004645760744e-05,
      "loss": 0.1515,
      "step": 13470
    },
    {
      "epoch": 3.1312427409988386,
      "grad_norm": 2.000199317932129,
      "learning_rate": 3.434843205574913e-05,
      "loss": 0.1236,
      "step": 13480
    },
    {
      "epoch": 3.1335656213704994,
      "grad_norm": 1.068104863166809,
      "learning_rate": 3.433681765389082e-05,
      "loss": 0.1185,
      "step": 13490
    },
    {
      "epoch": 3.1358885017421603,
      "grad_norm": 0.8394458293914795,
      "learning_rate": 3.432520325203252e-05,
      "loss": 0.0944,
      "step": 13500
    },
    {
      "epoch": 3.138211382113821,
      "grad_norm": 1.120029091835022,
      "learning_rate": 3.4313588850174216e-05,
      "loss": 0.1795,
      "step": 13510
    },
    {
      "epoch": 3.140534262485482,
      "grad_norm": 1.534572720527649,
      "learning_rate": 3.430197444831592e-05,
      "loss": 0.1457,
      "step": 13520
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 1.1881353855133057,
      "learning_rate": 3.4290360046457606e-05,
      "loss": 0.0859,
      "step": 13530
    },
    {
      "epoch": 3.1451800232288036,
      "grad_norm": 0.8995410203933716,
      "learning_rate": 3.42787456445993e-05,
      "loss": 0.1071,
      "step": 13540
    },
    {
      "epoch": 3.1475029036004645,
      "grad_norm": 0.7235673666000366,
      "learning_rate": 3.4267131242741e-05,
      "loss": 0.1032,
      "step": 13550
    },
    {
      "epoch": 3.1498257839721253,
      "grad_norm": 0.729840099811554,
      "learning_rate": 3.4255516840882697e-05,
      "loss": 0.1166,
      "step": 13560
    },
    {
      "epoch": 3.152148664343786,
      "grad_norm": 0.5325210690498352,
      "learning_rate": 3.424390243902439e-05,
      "loss": 0.0749,
      "step": 13570
    },
    {
      "epoch": 3.154471544715447,
      "grad_norm": 1.1815131902694702,
      "learning_rate": 3.4232288037166086e-05,
      "loss": 0.1368,
      "step": 13580
    },
    {
      "epoch": 3.156794425087108,
      "grad_norm": 1.7858240604400635,
      "learning_rate": 3.422067363530778e-05,
      "loss": 0.1667,
      "step": 13590
    },
    {
      "epoch": 3.1591173054587687,
      "grad_norm": 1.334820032119751,
      "learning_rate": 3.420905923344948e-05,
      "loss": 0.1061,
      "step": 13600
    },
    {
      "epoch": 3.16144018583043,
      "grad_norm": 0.5704818367958069,
      "learning_rate": 3.419744483159118e-05,
      "loss": 0.1284,
      "step": 13610
    },
    {
      "epoch": 3.1637630662020904,
      "grad_norm": 2.184898853302002,
      "learning_rate": 3.4185830429732865e-05,
      "loss": 0.1038,
      "step": 13620
    },
    {
      "epoch": 3.1660859465737516,
      "grad_norm": 1.1190805435180664,
      "learning_rate": 3.4174216027874566e-05,
      "loss": 0.1989,
      "step": 13630
    },
    {
      "epoch": 3.1684088269454125,
      "grad_norm": 2.034440279006958,
      "learning_rate": 3.416260162601626e-05,
      "loss": 0.1417,
      "step": 13640
    },
    {
      "epoch": 3.1707317073170733,
      "grad_norm": 1.1417515277862549,
      "learning_rate": 3.415098722415796e-05,
      "loss": 0.0674,
      "step": 13650
    },
    {
      "epoch": 3.173054587688734,
      "grad_norm": 0.9375304579734802,
      "learning_rate": 3.413937282229965e-05,
      "loss": 0.1117,
      "step": 13660
    },
    {
      "epoch": 3.175377468060395,
      "grad_norm": 1.3012034893035889,
      "learning_rate": 3.4127758420441345e-05,
      "loss": 0.15,
      "step": 13670
    },
    {
      "epoch": 3.177700348432056,
      "grad_norm": 1.941805362701416,
      "learning_rate": 3.4116144018583046e-05,
      "loss": 0.1089,
      "step": 13680
    },
    {
      "epoch": 3.1800232288037167,
      "grad_norm": 1.1827951669692993,
      "learning_rate": 3.410452961672474e-05,
      "loss": 0.1341,
      "step": 13690
    },
    {
      "epoch": 3.1823461091753775,
      "grad_norm": 1.0869892835617065,
      "learning_rate": 3.4092915214866436e-05,
      "loss": 0.1132,
      "step": 13700
    },
    {
      "epoch": 3.1846689895470384,
      "grad_norm": 0.7118644118309021,
      "learning_rate": 3.408130081300813e-05,
      "loss": 0.0832,
      "step": 13710
    },
    {
      "epoch": 3.186991869918699,
      "grad_norm": 0.9977982640266418,
      "learning_rate": 3.4069686411149825e-05,
      "loss": 0.0881,
      "step": 13720
    },
    {
      "epoch": 3.18931475029036,
      "grad_norm": 0.6288909316062927,
      "learning_rate": 3.4058072009291526e-05,
      "loss": 0.1237,
      "step": 13730
    },
    {
      "epoch": 3.191637630662021,
      "grad_norm": 2.0723068714141846,
      "learning_rate": 3.404645760743322e-05,
      "loss": 0.0993,
      "step": 13740
    },
    {
      "epoch": 3.1939605110336817,
      "grad_norm": 1.6774466037750244,
      "learning_rate": 3.403484320557491e-05,
      "loss": 0.0966,
      "step": 13750
    },
    {
      "epoch": 3.1962833914053426,
      "grad_norm": 0.8060097694396973,
      "learning_rate": 3.402322880371661e-05,
      "loss": 0.1081,
      "step": 13760
    },
    {
      "epoch": 3.1986062717770034,
      "grad_norm": 1.598836064338684,
      "learning_rate": 3.4011614401858305e-05,
      "loss": 0.0972,
      "step": 13770
    },
    {
      "epoch": 3.2009291521486642,
      "grad_norm": 1.8825994729995728,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0805,
      "step": 13780
    },
    {
      "epoch": 3.203252032520325,
      "grad_norm": 1.0829777717590332,
      "learning_rate": 3.3988385598141694e-05,
      "loss": 0.1415,
      "step": 13790
    },
    {
      "epoch": 3.205574912891986,
      "grad_norm": 2.49477219581604,
      "learning_rate": 3.397677119628339e-05,
      "loss": 0.117,
      "step": 13800
    },
    {
      "epoch": 3.2078977932636468,
      "grad_norm": 2.7810745239257812,
      "learning_rate": 3.396515679442509e-05,
      "loss": 0.2696,
      "step": 13810
    },
    {
      "epoch": 3.2102206736353076,
      "grad_norm": 1.986328363418579,
      "learning_rate": 3.3953542392566785e-05,
      "loss": 0.1538,
      "step": 13820
    },
    {
      "epoch": 3.2125435540069684,
      "grad_norm": 1.0592646598815918,
      "learning_rate": 3.394192799070848e-05,
      "loss": 0.078,
      "step": 13830
    },
    {
      "epoch": 3.2148664343786297,
      "grad_norm": 1.3092398643493652,
      "learning_rate": 3.3930313588850175e-05,
      "loss": 0.1053,
      "step": 13840
    },
    {
      "epoch": 3.21718931475029,
      "grad_norm": 0.8213280439376831,
      "learning_rate": 3.391869918699187e-05,
      "loss": 0.0957,
      "step": 13850
    },
    {
      "epoch": 3.2195121951219514,
      "grad_norm": 1.139125108718872,
      "learning_rate": 3.390708478513357e-05,
      "loss": 0.0931,
      "step": 13860
    },
    {
      "epoch": 3.2218350754936123,
      "grad_norm": 1.696065902709961,
      "learning_rate": 3.3895470383275265e-05,
      "loss": 0.0892,
      "step": 13870
    },
    {
      "epoch": 3.224157955865273,
      "grad_norm": 0.6866527795791626,
      "learning_rate": 3.388385598141695e-05,
      "loss": 0.1807,
      "step": 13880
    },
    {
      "epoch": 3.226480836236934,
      "grad_norm": 2.3968451023101807,
      "learning_rate": 3.3872241579558655e-05,
      "loss": 0.0887,
      "step": 13890
    },
    {
      "epoch": 3.2288037166085948,
      "grad_norm": 1.3386281728744507,
      "learning_rate": 3.386062717770035e-05,
      "loss": 0.1185,
      "step": 13900
    },
    {
      "epoch": 3.2311265969802556,
      "grad_norm": 0.73903888463974,
      "learning_rate": 3.384901277584205e-05,
      "loss": 0.0838,
      "step": 13910
    },
    {
      "epoch": 3.2334494773519165,
      "grad_norm": 1.0651222467422485,
      "learning_rate": 3.383739837398374e-05,
      "loss": 0.1319,
      "step": 13920
    },
    {
      "epoch": 3.2357723577235773,
      "grad_norm": 0.9289402961730957,
      "learning_rate": 3.382578397212543e-05,
      "loss": 0.1384,
      "step": 13930
    },
    {
      "epoch": 3.238095238095238,
      "grad_norm": 0.7546596527099609,
      "learning_rate": 3.3814169570267135e-05,
      "loss": 0.0849,
      "step": 13940
    },
    {
      "epoch": 3.240418118466899,
      "grad_norm": 2.2914137840270996,
      "learning_rate": 3.380255516840883e-05,
      "loss": 0.1526,
      "step": 13950
    },
    {
      "epoch": 3.24274099883856,
      "grad_norm": 1.1172575950622559,
      "learning_rate": 3.3790940766550524e-05,
      "loss": 0.0783,
      "step": 13960
    },
    {
      "epoch": 3.2450638792102207,
      "grad_norm": 0.35744625329971313,
      "learning_rate": 3.377932636469222e-05,
      "loss": 0.1041,
      "step": 13970
    },
    {
      "epoch": 3.2473867595818815,
      "grad_norm": 0.9682415127754211,
      "learning_rate": 3.3767711962833914e-05,
      "loss": 0.0851,
      "step": 13980
    },
    {
      "epoch": 3.2497096399535423,
      "grad_norm": 2.233374834060669,
      "learning_rate": 3.3756097560975615e-05,
      "loss": 0.1616,
      "step": 13990
    },
    {
      "epoch": 3.252032520325203,
      "grad_norm": 1.775560736656189,
      "learning_rate": 3.374448315911731e-05,
      "loss": 0.1263,
      "step": 14000
    },
    {
      "epoch": 3.254355400696864,
      "grad_norm": 0.6555585265159607,
      "learning_rate": 3.3732868757259e-05,
      "loss": 0.1006,
      "step": 14010
    },
    {
      "epoch": 3.256678281068525,
      "grad_norm": 1.1260534524917603,
      "learning_rate": 3.37212543554007e-05,
      "loss": 0.1256,
      "step": 14020
    },
    {
      "epoch": 3.2590011614401857,
      "grad_norm": 1.0938520431518555,
      "learning_rate": 3.3709639953542394e-05,
      "loss": 0.1288,
      "step": 14030
    },
    {
      "epoch": 3.2613240418118465,
      "grad_norm": 0.7777591943740845,
      "learning_rate": 3.3698025551684095e-05,
      "loss": 0.0932,
      "step": 14040
    },
    {
      "epoch": 3.2636469221835074,
      "grad_norm": 0.7432770729064941,
      "learning_rate": 3.368641114982578e-05,
      "loss": 0.0836,
      "step": 14050
    },
    {
      "epoch": 3.2659698025551682,
      "grad_norm": 0.6401882171630859,
      "learning_rate": 3.367479674796748e-05,
      "loss": 0.1709,
      "step": 14060
    },
    {
      "epoch": 3.2682926829268295,
      "grad_norm": 0.6625053286552429,
      "learning_rate": 3.366318234610918e-05,
      "loss": 0.1854,
      "step": 14070
    },
    {
      "epoch": 3.27061556329849,
      "grad_norm": 2.005800724029541,
      "learning_rate": 3.3651567944250874e-05,
      "loss": 0.1105,
      "step": 14080
    },
    {
      "epoch": 3.272938443670151,
      "grad_norm": 0.3917791247367859,
      "learning_rate": 3.363995354239257e-05,
      "loss": 0.1474,
      "step": 14090
    },
    {
      "epoch": 3.275261324041812,
      "grad_norm": 1.7705453634262085,
      "learning_rate": 3.362833914053426e-05,
      "loss": 0.1361,
      "step": 14100
    },
    {
      "epoch": 3.277584204413473,
      "grad_norm": 0.6817607283592224,
      "learning_rate": 3.361672473867596e-05,
      "loss": 0.1037,
      "step": 14110
    },
    {
      "epoch": 3.2799070847851337,
      "grad_norm": 1.8465569019317627,
      "learning_rate": 3.360511033681766e-05,
      "loss": 0.0953,
      "step": 14120
    },
    {
      "epoch": 3.2822299651567945,
      "grad_norm": 1.603103756904602,
      "learning_rate": 3.3593495934959354e-05,
      "loss": 0.0869,
      "step": 14130
    },
    {
      "epoch": 3.2845528455284554,
      "grad_norm": 0.7987947463989258,
      "learning_rate": 3.358188153310104e-05,
      "loss": 0.0813,
      "step": 14140
    },
    {
      "epoch": 3.2868757259001162,
      "grad_norm": 0.8370456695556641,
      "learning_rate": 3.357026713124274e-05,
      "loss": 0.1183,
      "step": 14150
    },
    {
      "epoch": 3.289198606271777,
      "grad_norm": 2.2497735023498535,
      "learning_rate": 3.355865272938444e-05,
      "loss": 0.1147,
      "step": 14160
    },
    {
      "epoch": 3.291521486643438,
      "grad_norm": 0.8838668465614319,
      "learning_rate": 3.354703832752613e-05,
      "loss": 0.0562,
      "step": 14170
    },
    {
      "epoch": 3.2938443670150988,
      "grad_norm": 1.314469575881958,
      "learning_rate": 3.353542392566783e-05,
      "loss": 0.167,
      "step": 14180
    },
    {
      "epoch": 3.2961672473867596,
      "grad_norm": 1.0064667463302612,
      "learning_rate": 3.352380952380952e-05,
      "loss": 0.1498,
      "step": 14190
    },
    {
      "epoch": 3.2984901277584204,
      "grad_norm": 1.5091674327850342,
      "learning_rate": 3.3512195121951223e-05,
      "loss": 0.1036,
      "step": 14200
    },
    {
      "epoch": 3.3008130081300813,
      "grad_norm": 1.0319470167160034,
      "learning_rate": 3.350058072009292e-05,
      "loss": 0.1362,
      "step": 14210
    },
    {
      "epoch": 3.303135888501742,
      "grad_norm": 0.7050612568855286,
      "learning_rate": 3.348896631823461e-05,
      "loss": 0.1336,
      "step": 14220
    },
    {
      "epoch": 3.305458768873403,
      "grad_norm": 1.8061678409576416,
      "learning_rate": 3.347735191637631e-05,
      "loss": 0.1596,
      "step": 14230
    },
    {
      "epoch": 3.307781649245064,
      "grad_norm": 2.2009634971618652,
      "learning_rate": 3.3465737514518e-05,
      "loss": 0.168,
      "step": 14240
    },
    {
      "epoch": 3.3101045296167246,
      "grad_norm": 0.5115388631820679,
      "learning_rate": 3.3454123112659704e-05,
      "loss": 0.164,
      "step": 14250
    },
    {
      "epoch": 3.3124274099883855,
      "grad_norm": 1.2581181526184082,
      "learning_rate": 3.34425087108014e-05,
      "loss": 0.0688,
      "step": 14260
    },
    {
      "epoch": 3.3147502903600463,
      "grad_norm": 1.30190110206604,
      "learning_rate": 3.3430894308943086e-05,
      "loss": 0.1126,
      "step": 14270
    },
    {
      "epoch": 3.317073170731707,
      "grad_norm": 2.190448045730591,
      "learning_rate": 3.341927990708479e-05,
      "loss": 0.1235,
      "step": 14280
    },
    {
      "epoch": 3.319396051103368,
      "grad_norm": 1.2307621240615845,
      "learning_rate": 3.340766550522648e-05,
      "loss": 0.0852,
      "step": 14290
    },
    {
      "epoch": 3.3217189314750293,
      "grad_norm": 1.1898609399795532,
      "learning_rate": 3.339605110336818e-05,
      "loss": 0.1423,
      "step": 14300
    },
    {
      "epoch": 3.3240418118466897,
      "grad_norm": 1.0853759050369263,
      "learning_rate": 3.338443670150987e-05,
      "loss": 0.1389,
      "step": 14310
    },
    {
      "epoch": 3.326364692218351,
      "grad_norm": 0.9673373103141785,
      "learning_rate": 3.3372822299651566e-05,
      "loss": 0.1433,
      "step": 14320
    },
    {
      "epoch": 3.328687572590012,
      "grad_norm": 0.8305113911628723,
      "learning_rate": 3.336120789779327e-05,
      "loss": 0.1472,
      "step": 14330
    },
    {
      "epoch": 3.3310104529616726,
      "grad_norm": 0.6750413179397583,
      "learning_rate": 3.334959349593496e-05,
      "loss": 0.2138,
      "step": 14340
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 1.373961329460144,
      "learning_rate": 3.333797909407666e-05,
      "loss": 0.0903,
      "step": 14350
    },
    {
      "epoch": 3.3356562137049943,
      "grad_norm": 1.3829083442687988,
      "learning_rate": 3.332636469221835e-05,
      "loss": 0.1035,
      "step": 14360
    },
    {
      "epoch": 3.337979094076655,
      "grad_norm": 1.0071814060211182,
      "learning_rate": 3.3314750290360046e-05,
      "loss": 0.1841,
      "step": 14370
    },
    {
      "epoch": 3.340301974448316,
      "grad_norm": 1.3686197996139526,
      "learning_rate": 3.330313588850175e-05,
      "loss": 0.1579,
      "step": 14380
    },
    {
      "epoch": 3.342624854819977,
      "grad_norm": 0.9399669766426086,
      "learning_rate": 3.329152148664344e-05,
      "loss": 0.0785,
      "step": 14390
    },
    {
      "epoch": 3.3449477351916377,
      "grad_norm": 1.4464924335479736,
      "learning_rate": 3.327990708478513e-05,
      "loss": 0.1559,
      "step": 14400
    },
    {
      "epoch": 3.3472706155632985,
      "grad_norm": 1.6457273960113525,
      "learning_rate": 3.326829268292683e-05,
      "loss": 0.0664,
      "step": 14410
    },
    {
      "epoch": 3.3495934959349594,
      "grad_norm": 1.1797876358032227,
      "learning_rate": 3.3256678281068527e-05,
      "loss": 0.1699,
      "step": 14420
    },
    {
      "epoch": 3.35191637630662,
      "grad_norm": 0.9195154309272766,
      "learning_rate": 3.324506387921022e-05,
      "loss": 0.1089,
      "step": 14430
    },
    {
      "epoch": 3.354239256678281,
      "grad_norm": 0.8512130379676819,
      "learning_rate": 3.3233449477351916e-05,
      "loss": 0.1349,
      "step": 14440
    },
    {
      "epoch": 3.356562137049942,
      "grad_norm": 1.366501808166504,
      "learning_rate": 3.322183507549361e-05,
      "loss": 0.1425,
      "step": 14450
    },
    {
      "epoch": 3.3588850174216027,
      "grad_norm": 1.1349232196807861,
      "learning_rate": 3.321022067363531e-05,
      "loss": 0.1234,
      "step": 14460
    },
    {
      "epoch": 3.3612078977932636,
      "grad_norm": 0.8996107578277588,
      "learning_rate": 3.319860627177701e-05,
      "loss": 0.0979,
      "step": 14470
    },
    {
      "epoch": 3.3635307781649244,
      "grad_norm": 0.5637457370758057,
      "learning_rate": 3.31869918699187e-05,
      "loss": 0.1494,
      "step": 14480
    },
    {
      "epoch": 3.3658536585365852,
      "grad_norm": 1.9312831163406372,
      "learning_rate": 3.3175377468060396e-05,
      "loss": 0.1741,
      "step": 14490
    },
    {
      "epoch": 3.368176538908246,
      "grad_norm": 2.1248393058776855,
      "learning_rate": 3.316376306620209e-05,
      "loss": 0.1233,
      "step": 14500
    },
    {
      "epoch": 3.370499419279907,
      "grad_norm": 1.1623767614364624,
      "learning_rate": 3.315214866434379e-05,
      "loss": 0.1475,
      "step": 14510
    },
    {
      "epoch": 3.3728222996515678,
      "grad_norm": 1.0128192901611328,
      "learning_rate": 3.314053426248549e-05,
      "loss": 0.1727,
      "step": 14520
    },
    {
      "epoch": 3.375145180023229,
      "grad_norm": 0.641769289970398,
      "learning_rate": 3.3128919860627175e-05,
      "loss": 0.1513,
      "step": 14530
    },
    {
      "epoch": 3.3774680603948894,
      "grad_norm": 0.9052311182022095,
      "learning_rate": 3.3117305458768876e-05,
      "loss": 0.1435,
      "step": 14540
    },
    {
      "epoch": 3.3797909407665507,
      "grad_norm": 1.1557707786560059,
      "learning_rate": 3.310569105691057e-05,
      "loss": 0.0768,
      "step": 14550
    },
    {
      "epoch": 3.3821138211382116,
      "grad_norm": 1.0077048540115356,
      "learning_rate": 3.3094076655052266e-05,
      "loss": 0.0937,
      "step": 14560
    },
    {
      "epoch": 3.3844367015098724,
      "grad_norm": 2.151845932006836,
      "learning_rate": 3.308246225319396e-05,
      "loss": 0.1077,
      "step": 14570
    },
    {
      "epoch": 3.3867595818815333,
      "grad_norm": 0.7041366696357727,
      "learning_rate": 3.3070847851335655e-05,
      "loss": 0.1384,
      "step": 14580
    },
    {
      "epoch": 3.389082462253194,
      "grad_norm": 0.9269605875015259,
      "learning_rate": 3.3059233449477356e-05,
      "loss": 0.1539,
      "step": 14590
    },
    {
      "epoch": 3.391405342624855,
      "grad_norm": 0.6322357654571533,
      "learning_rate": 3.304761904761905e-05,
      "loss": 0.0905,
      "step": 14600
    },
    {
      "epoch": 3.3937282229965158,
      "grad_norm": 1.0058436393737793,
      "learning_rate": 3.3036004645760746e-05,
      "loss": 0.0921,
      "step": 14610
    },
    {
      "epoch": 3.3960511033681766,
      "grad_norm": 0.9778088331222534,
      "learning_rate": 3.302439024390244e-05,
      "loss": 0.1443,
      "step": 14620
    },
    {
      "epoch": 3.3983739837398375,
      "grad_norm": 1.3392618894577026,
      "learning_rate": 3.3012775842044135e-05,
      "loss": 0.1065,
      "step": 14630
    },
    {
      "epoch": 3.4006968641114983,
      "grad_norm": 1.0976934432983398,
      "learning_rate": 3.300116144018583e-05,
      "loss": 0.1012,
      "step": 14640
    },
    {
      "epoch": 3.403019744483159,
      "grad_norm": 1.864183783531189,
      "learning_rate": 3.298954703832753e-05,
      "loss": 0.1474,
      "step": 14650
    },
    {
      "epoch": 3.40534262485482,
      "grad_norm": 1.1124722957611084,
      "learning_rate": 3.297793263646922e-05,
      "loss": 0.099,
      "step": 14660
    },
    {
      "epoch": 3.407665505226481,
      "grad_norm": 1.4037680625915527,
      "learning_rate": 3.296631823461092e-05,
      "loss": 0.1504,
      "step": 14670
    },
    {
      "epoch": 3.4099883855981417,
      "grad_norm": 2.7495310306549072,
      "learning_rate": 3.2954703832752615e-05,
      "loss": 0.2187,
      "step": 14680
    },
    {
      "epoch": 3.4123112659698025,
      "grad_norm": 1.504783034324646,
      "learning_rate": 3.294308943089431e-05,
      "loss": 0.0904,
      "step": 14690
    },
    {
      "epoch": 3.4146341463414633,
      "grad_norm": 1.6698185205459595,
      "learning_rate": 3.2931475029036004e-05,
      "loss": 0.1184,
      "step": 14700
    },
    {
      "epoch": 3.416957026713124,
      "grad_norm": 0.9379980564117432,
      "learning_rate": 3.29198606271777e-05,
      "loss": 0.0809,
      "step": 14710
    },
    {
      "epoch": 3.419279907084785,
      "grad_norm": 1.3105113506317139,
      "learning_rate": 3.29082462253194e-05,
      "loss": 0.1023,
      "step": 14720
    },
    {
      "epoch": 3.421602787456446,
      "grad_norm": 1.611098051071167,
      "learning_rate": 3.2896631823461095e-05,
      "loss": 0.1027,
      "step": 14730
    },
    {
      "epoch": 3.4239256678281067,
      "grad_norm": 2.5955638885498047,
      "learning_rate": 3.288501742160279e-05,
      "loss": 0.2186,
      "step": 14740
    },
    {
      "epoch": 3.4262485481997675,
      "grad_norm": 2.0035433769226074,
      "learning_rate": 3.2873403019744485e-05,
      "loss": 0.154,
      "step": 14750
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 2.118880271911621,
      "learning_rate": 3.286178861788618e-05,
      "loss": 0.2142,
      "step": 14760
    },
    {
      "epoch": 3.430894308943089,
      "grad_norm": 1.1687166690826416,
      "learning_rate": 3.2850174216027874e-05,
      "loss": 0.0692,
      "step": 14770
    },
    {
      "epoch": 3.4332171893147505,
      "grad_norm": 0.6504526138305664,
      "learning_rate": 3.2838559814169575e-05,
      "loss": 0.0869,
      "step": 14780
    },
    {
      "epoch": 3.435540069686411,
      "grad_norm": 1.0074577331542969,
      "learning_rate": 3.282694541231126e-05,
      "loss": 0.0936,
      "step": 14790
    },
    {
      "epoch": 3.437862950058072,
      "grad_norm": 1.2954721450805664,
      "learning_rate": 3.2815331010452965e-05,
      "loss": 0.1708,
      "step": 14800
    },
    {
      "epoch": 3.440185830429733,
      "grad_norm": 0.8534287214279175,
      "learning_rate": 3.280371660859466e-05,
      "loss": 0.0733,
      "step": 14810
    },
    {
      "epoch": 3.442508710801394,
      "grad_norm": 1.46576726436615,
      "learning_rate": 3.2792102206736354e-05,
      "loss": 0.087,
      "step": 14820
    },
    {
      "epoch": 3.4448315911730547,
      "grad_norm": 0.9156454801559448,
      "learning_rate": 3.278048780487805e-05,
      "loss": 0.1053,
      "step": 14830
    },
    {
      "epoch": 3.4471544715447155,
      "grad_norm": 1.283015251159668,
      "learning_rate": 3.2768873403019743e-05,
      "loss": 0.0979,
      "step": 14840
    },
    {
      "epoch": 3.4494773519163764,
      "grad_norm": 0.8003965020179749,
      "learning_rate": 3.2757259001161445e-05,
      "loss": 0.1358,
      "step": 14850
    },
    {
      "epoch": 3.4518002322880372,
      "grad_norm": 1.59463369846344,
      "learning_rate": 3.274564459930314e-05,
      "loss": 0.0831,
      "step": 14860
    },
    {
      "epoch": 3.454123112659698,
      "grad_norm": 0.6776490211486816,
      "learning_rate": 3.2734030197444834e-05,
      "loss": 0.1003,
      "step": 14870
    },
    {
      "epoch": 3.456445993031359,
      "grad_norm": 0.8276858329772949,
      "learning_rate": 3.272241579558653e-05,
      "loss": 0.1034,
      "step": 14880
    },
    {
      "epoch": 3.4587688734030198,
      "grad_norm": 0.913112461566925,
      "learning_rate": 3.2710801393728224e-05,
      "loss": 0.2028,
      "step": 14890
    },
    {
      "epoch": 3.4610917537746806,
      "grad_norm": 2.1178202629089355,
      "learning_rate": 3.269918699186992e-05,
      "loss": 0.1203,
      "step": 14900
    },
    {
      "epoch": 3.4634146341463414,
      "grad_norm": 0.7544150948524475,
      "learning_rate": 3.268757259001162e-05,
      "loss": 0.1871,
      "step": 14910
    },
    {
      "epoch": 3.4657375145180023,
      "grad_norm": 0.7881749272346497,
      "learning_rate": 3.267595818815331e-05,
      "loss": 0.0716,
      "step": 14920
    },
    {
      "epoch": 3.468060394889663,
      "grad_norm": 1.9296821355819702,
      "learning_rate": 3.266434378629501e-05,
      "loss": 0.0835,
      "step": 14930
    },
    {
      "epoch": 3.470383275261324,
      "grad_norm": 0.9816008806228638,
      "learning_rate": 3.2652729384436704e-05,
      "loss": 0.1571,
      "step": 14940
    },
    {
      "epoch": 3.472706155632985,
      "grad_norm": 1.0668251514434814,
      "learning_rate": 3.26411149825784e-05,
      "loss": 0.2116,
      "step": 14950
    },
    {
      "epoch": 3.4750290360046456,
      "grad_norm": 0.6095753312110901,
      "learning_rate": 3.262950058072009e-05,
      "loss": 0.095,
      "step": 14960
    },
    {
      "epoch": 3.4773519163763065,
      "grad_norm": 0.8387707471847534,
      "learning_rate": 3.261788617886179e-05,
      "loss": 0.1434,
      "step": 14970
    },
    {
      "epoch": 3.4796747967479673,
      "grad_norm": 0.6274626851081848,
      "learning_rate": 3.260627177700348e-05,
      "loss": 0.0862,
      "step": 14980
    },
    {
      "epoch": 3.481997677119628,
      "grad_norm": 1.404111385345459,
      "learning_rate": 3.2594657375145184e-05,
      "loss": 0.1049,
      "step": 14990
    },
    {
      "epoch": 3.484320557491289,
      "grad_norm": 1.250098705291748,
      "learning_rate": 3.258304297328688e-05,
      "loss": 0.0904,
      "step": 15000
    },
    {
      "epoch": 3.4866434378629503,
      "grad_norm": 1.9466345310211182,
      "learning_rate": 3.257142857142857e-05,
      "loss": 0.1573,
      "step": 15010
    },
    {
      "epoch": 3.4889663182346107,
      "grad_norm": 0.9427427053451538,
      "learning_rate": 3.255981416957027e-05,
      "loss": 0.0814,
      "step": 15020
    },
    {
      "epoch": 3.491289198606272,
      "grad_norm": 0.7948592901229858,
      "learning_rate": 3.254819976771196e-05,
      "loss": 0.0921,
      "step": 15030
    },
    {
      "epoch": 3.493612078977933,
      "grad_norm": 1.3913424015045166,
      "learning_rate": 3.2536585365853664e-05,
      "loss": 0.1144,
      "step": 15040
    },
    {
      "epoch": 3.4959349593495936,
      "grad_norm": 1.6009032726287842,
      "learning_rate": 3.252497096399535e-05,
      "loss": 0.1051,
      "step": 15050
    },
    {
      "epoch": 3.4982578397212545,
      "grad_norm": 0.9660388827323914,
      "learning_rate": 3.251335656213705e-05,
      "loss": 0.121,
      "step": 15060
    },
    {
      "epoch": 3.5005807200929153,
      "grad_norm": 1.3852735757827759,
      "learning_rate": 3.250174216027875e-05,
      "loss": 0.1735,
      "step": 15070
    },
    {
      "epoch": 3.502903600464576,
      "grad_norm": 1.1445834636688232,
      "learning_rate": 3.249012775842044e-05,
      "loss": 0.1271,
      "step": 15080
    },
    {
      "epoch": 3.505226480836237,
      "grad_norm": 1.0696672201156616,
      "learning_rate": 3.247851335656214e-05,
      "loss": 0.1475,
      "step": 15090
    },
    {
      "epoch": 3.507549361207898,
      "grad_norm": 0.8788369297981262,
      "learning_rate": 3.246689895470383e-05,
      "loss": 0.1257,
      "step": 15100
    },
    {
      "epoch": 3.5098722415795587,
      "grad_norm": 1.5351691246032715,
      "learning_rate": 3.245528455284553e-05,
      "loss": 0.074,
      "step": 15110
    },
    {
      "epoch": 3.5121951219512195,
      "grad_norm": 1.9489964246749878,
      "learning_rate": 3.244367015098723e-05,
      "loss": 0.2128,
      "step": 15120
    },
    {
      "epoch": 3.5145180023228804,
      "grad_norm": 0.9595280289649963,
      "learning_rate": 3.243205574912892e-05,
      "loss": 0.2039,
      "step": 15130
    },
    {
      "epoch": 3.516840882694541,
      "grad_norm": 1.3276017904281616,
      "learning_rate": 3.242044134727062e-05,
      "loss": 0.1171,
      "step": 15140
    },
    {
      "epoch": 3.519163763066202,
      "grad_norm": 0.911742091178894,
      "learning_rate": 3.240882694541231e-05,
      "loss": 0.1403,
      "step": 15150
    },
    {
      "epoch": 3.521486643437863,
      "grad_norm": 1.4690346717834473,
      "learning_rate": 3.239721254355401e-05,
      "loss": 0.1,
      "step": 15160
    },
    {
      "epoch": 3.5238095238095237,
      "grad_norm": 0.7626570463180542,
      "learning_rate": 3.238559814169571e-05,
      "loss": 0.0819,
      "step": 15170
    },
    {
      "epoch": 3.5261324041811846,
      "grad_norm": 1.1418403387069702,
      "learning_rate": 3.2373983739837396e-05,
      "loss": 0.1511,
      "step": 15180
    },
    {
      "epoch": 3.5284552845528454,
      "grad_norm": 1.7895617485046387,
      "learning_rate": 3.23623693379791e-05,
      "loss": 0.1473,
      "step": 15190
    },
    {
      "epoch": 3.5307781649245062,
      "grad_norm": 2.1043295860290527,
      "learning_rate": 3.235075493612079e-05,
      "loss": 0.1807,
      "step": 15200
    },
    {
      "epoch": 3.533101045296167,
      "grad_norm": 1.757285237312317,
      "learning_rate": 3.233914053426249e-05,
      "loss": 0.1798,
      "step": 15210
    },
    {
      "epoch": 3.5354239256678284,
      "grad_norm": 1.1681526899337769,
      "learning_rate": 3.232752613240418e-05,
      "loss": 0.1091,
      "step": 15220
    },
    {
      "epoch": 3.5377468060394888,
      "grad_norm": 1.2042406797409058,
      "learning_rate": 3.2315911730545876e-05,
      "loss": 0.086,
      "step": 15230
    },
    {
      "epoch": 3.54006968641115,
      "grad_norm": 0.8652443885803223,
      "learning_rate": 3.230429732868757e-05,
      "loss": 0.0994,
      "step": 15240
    },
    {
      "epoch": 3.5423925667828104,
      "grad_norm": 1.448628544807434,
      "learning_rate": 3.229268292682927e-05,
      "loss": 0.0733,
      "step": 15250
    },
    {
      "epoch": 3.5447154471544717,
      "grad_norm": 1.0016576051712036,
      "learning_rate": 3.228106852497097e-05,
      "loss": 0.0899,
      "step": 15260
    },
    {
      "epoch": 3.547038327526132,
      "grad_norm": 2.7046759128570557,
      "learning_rate": 3.226945412311266e-05,
      "loss": 0.1047,
      "step": 15270
    },
    {
      "epoch": 3.5493612078977934,
      "grad_norm": 1.8771579265594482,
      "learning_rate": 3.2257839721254356e-05,
      "loss": 0.0937,
      "step": 15280
    },
    {
      "epoch": 3.5516840882694543,
      "grad_norm": 0.6964879631996155,
      "learning_rate": 3.224622531939605e-05,
      "loss": 0.0587,
      "step": 15290
    },
    {
      "epoch": 3.554006968641115,
      "grad_norm": 0.8111975193023682,
      "learning_rate": 3.223461091753775e-05,
      "loss": 0.1268,
      "step": 15300
    },
    {
      "epoch": 3.556329849012776,
      "grad_norm": 1.5616313219070435,
      "learning_rate": 3.222299651567944e-05,
      "loss": 0.1253,
      "step": 15310
    },
    {
      "epoch": 3.5586527293844368,
      "grad_norm": 1.714555263519287,
      "learning_rate": 3.221138211382114e-05,
      "loss": 0.1466,
      "step": 15320
    },
    {
      "epoch": 3.5609756097560976,
      "grad_norm": 1.6997675895690918,
      "learning_rate": 3.219976771196284e-05,
      "loss": 0.1237,
      "step": 15330
    },
    {
      "epoch": 3.5632984901277585,
      "grad_norm": 0.8555999398231506,
      "learning_rate": 3.218815331010453e-05,
      "loss": 0.1658,
      "step": 15340
    },
    {
      "epoch": 3.5656213704994193,
      "grad_norm": 1.007615327835083,
      "learning_rate": 3.2176538908246226e-05,
      "loss": 0.1345,
      "step": 15350
    },
    {
      "epoch": 3.56794425087108,
      "grad_norm": 0.8650543689727783,
      "learning_rate": 3.216492450638792e-05,
      "loss": 0.1377,
      "step": 15360
    },
    {
      "epoch": 3.570267131242741,
      "grad_norm": 0.7918282747268677,
      "learning_rate": 3.2153310104529615e-05,
      "loss": 0.1762,
      "step": 15370
    },
    {
      "epoch": 3.572590011614402,
      "grad_norm": 0.7356062531471252,
      "learning_rate": 3.214169570267132e-05,
      "loss": 0.0564,
      "step": 15380
    },
    {
      "epoch": 3.5749128919860627,
      "grad_norm": 0.6226754784584045,
      "learning_rate": 3.213008130081301e-05,
      "loss": 0.1383,
      "step": 15390
    },
    {
      "epoch": 3.5772357723577235,
      "grad_norm": 2.4638099670410156,
      "learning_rate": 3.2118466898954706e-05,
      "loss": 0.1732,
      "step": 15400
    },
    {
      "epoch": 3.5795586527293843,
      "grad_norm": 0.7164345979690552,
      "learning_rate": 3.21068524970964e-05,
      "loss": 0.1649,
      "step": 15410
    },
    {
      "epoch": 3.581881533101045,
      "grad_norm": 1.1809358596801758,
      "learning_rate": 3.2095238095238095e-05,
      "loss": 0.0848,
      "step": 15420
    },
    {
      "epoch": 3.584204413472706,
      "grad_norm": 1.2691129446029663,
      "learning_rate": 3.20836236933798e-05,
      "loss": 0.1555,
      "step": 15430
    },
    {
      "epoch": 3.586527293844367,
      "grad_norm": 2.2056469917297363,
      "learning_rate": 3.2072009291521485e-05,
      "loss": 0.1341,
      "step": 15440
    },
    {
      "epoch": 3.588850174216028,
      "grad_norm": 0.9015213251113892,
      "learning_rate": 3.206039488966318e-05,
      "loss": 0.119,
      "step": 15450
    },
    {
      "epoch": 3.5911730545876885,
      "grad_norm": 1.5388340950012207,
      "learning_rate": 3.204878048780488e-05,
      "loss": 0.124,
      "step": 15460
    },
    {
      "epoch": 3.59349593495935,
      "grad_norm": 0.8198240995407104,
      "learning_rate": 3.2037166085946576e-05,
      "loss": 0.1317,
      "step": 15470
    },
    {
      "epoch": 3.59581881533101,
      "grad_norm": 0.5540494918823242,
      "learning_rate": 3.202555168408827e-05,
      "loss": 0.1511,
      "step": 15480
    },
    {
      "epoch": 3.5981416957026715,
      "grad_norm": 1.5958499908447266,
      "learning_rate": 3.2013937282229965e-05,
      "loss": 0.1103,
      "step": 15490
    },
    {
      "epoch": 3.600464576074332,
      "grad_norm": 0.7414441704750061,
      "learning_rate": 3.200232288037166e-05,
      "loss": 0.1224,
      "step": 15500
    },
    {
      "epoch": 3.602787456445993,
      "grad_norm": 0.7491534352302551,
      "learning_rate": 3.199070847851336e-05,
      "loss": 0.2225,
      "step": 15510
    },
    {
      "epoch": 3.605110336817654,
      "grad_norm": 0.6888790130615234,
      "learning_rate": 3.1979094076655056e-05,
      "loss": 0.0799,
      "step": 15520
    },
    {
      "epoch": 3.607433217189315,
      "grad_norm": 0.7306063771247864,
      "learning_rate": 3.196747967479675e-05,
      "loss": 0.1368,
      "step": 15530
    },
    {
      "epoch": 3.6097560975609757,
      "grad_norm": 1.0312825441360474,
      "learning_rate": 3.1955865272938445e-05,
      "loss": 0.1476,
      "step": 15540
    },
    {
      "epoch": 3.6120789779326365,
      "grad_norm": 0.728951096534729,
      "learning_rate": 3.194425087108014e-05,
      "loss": 0.2234,
      "step": 15550
    },
    {
      "epoch": 3.6144018583042974,
      "grad_norm": 1.4292281866073608,
      "learning_rate": 3.193263646922184e-05,
      "loss": 0.1072,
      "step": 15560
    },
    {
      "epoch": 3.6167247386759582,
      "grad_norm": 0.8726202845573425,
      "learning_rate": 3.192102206736353e-05,
      "loss": 0.1084,
      "step": 15570
    },
    {
      "epoch": 3.619047619047619,
      "grad_norm": 1.6541507244110107,
      "learning_rate": 3.1909407665505224e-05,
      "loss": 0.0927,
      "step": 15580
    },
    {
      "epoch": 3.62137049941928,
      "grad_norm": 1.0751813650131226,
      "learning_rate": 3.1897793263646925e-05,
      "loss": 0.122,
      "step": 15590
    },
    {
      "epoch": 3.6236933797909407,
      "grad_norm": 0.7116371989250183,
      "learning_rate": 3.188617886178862e-05,
      "loss": 0.0639,
      "step": 15600
    },
    {
      "epoch": 3.6260162601626016,
      "grad_norm": 0.9286142587661743,
      "learning_rate": 3.1874564459930315e-05,
      "loss": 0.1665,
      "step": 15610
    },
    {
      "epoch": 3.6283391405342624,
      "grad_norm": 0.5855417847633362,
      "learning_rate": 3.186295005807201e-05,
      "loss": 0.0665,
      "step": 15620
    },
    {
      "epoch": 3.6306620209059233,
      "grad_norm": 0.921146035194397,
      "learning_rate": 3.1851335656213704e-05,
      "loss": 0.141,
      "step": 15630
    },
    {
      "epoch": 3.632984901277584,
      "grad_norm": 0.8515958786010742,
      "learning_rate": 3.1839721254355405e-05,
      "loss": 0.1093,
      "step": 15640
    },
    {
      "epoch": 3.635307781649245,
      "grad_norm": 0.7186905741691589,
      "learning_rate": 3.18281068524971e-05,
      "loss": 0.1491,
      "step": 15650
    },
    {
      "epoch": 3.637630662020906,
      "grad_norm": 1.0543839931488037,
      "learning_rate": 3.1816492450638795e-05,
      "loss": 0.1321,
      "step": 15660
    },
    {
      "epoch": 3.6399535423925666,
      "grad_norm": 1.6043198108673096,
      "learning_rate": 3.180487804878049e-05,
      "loss": 0.155,
      "step": 15670
    },
    {
      "epoch": 3.642276422764228,
      "grad_norm": 0.8038051128387451,
      "learning_rate": 3.1793263646922184e-05,
      "loss": 0.1017,
      "step": 15680
    },
    {
      "epoch": 3.6445993031358883,
      "grad_norm": 1.8903766870498657,
      "learning_rate": 3.1781649245063886e-05,
      "loss": 0.0755,
      "step": 15690
    },
    {
      "epoch": 3.6469221835075496,
      "grad_norm": 0.9824750423431396,
      "learning_rate": 3.1770034843205573e-05,
      "loss": 0.1357,
      "step": 15700
    },
    {
      "epoch": 3.64924506387921,
      "grad_norm": 1.4936667680740356,
      "learning_rate": 3.175842044134727e-05,
      "loss": 0.1088,
      "step": 15710
    },
    {
      "epoch": 3.6515679442508713,
      "grad_norm": 1.1339595317840576,
      "learning_rate": 3.174680603948897e-05,
      "loss": 0.14,
      "step": 15720
    },
    {
      "epoch": 3.6538908246225317,
      "grad_norm": 0.6391090154647827,
      "learning_rate": 3.1735191637630664e-05,
      "loss": 0.1588,
      "step": 15730
    },
    {
      "epoch": 3.656213704994193,
      "grad_norm": 2.0468153953552246,
      "learning_rate": 3.172357723577236e-05,
      "loss": 0.1666,
      "step": 15740
    },
    {
      "epoch": 3.658536585365854,
      "grad_norm": 0.7103845477104187,
      "learning_rate": 3.1711962833914054e-05,
      "loss": 0.1188,
      "step": 15750
    },
    {
      "epoch": 3.6608594657375146,
      "grad_norm": 1.6372158527374268,
      "learning_rate": 3.170034843205575e-05,
      "loss": 0.1261,
      "step": 15760
    },
    {
      "epoch": 3.6631823461091755,
      "grad_norm": 1.53679358959198,
      "learning_rate": 3.168873403019745e-05,
      "loss": 0.1393,
      "step": 15770
    },
    {
      "epoch": 3.6655052264808363,
      "grad_norm": 0.7541472315788269,
      "learning_rate": 3.1677119628339144e-05,
      "loss": 0.0694,
      "step": 15780
    },
    {
      "epoch": 3.667828106852497,
      "grad_norm": 0.629774808883667,
      "learning_rate": 3.166550522648084e-05,
      "loss": 0.0814,
      "step": 15790
    },
    {
      "epoch": 3.670150987224158,
      "grad_norm": 0.9841885566711426,
      "learning_rate": 3.1653890824622534e-05,
      "loss": 0.0992,
      "step": 15800
    },
    {
      "epoch": 3.672473867595819,
      "grad_norm": 1.2550958395004272,
      "learning_rate": 3.164227642276423e-05,
      "loss": 0.1521,
      "step": 15810
    },
    {
      "epoch": 3.6747967479674797,
      "grad_norm": 1.5203771591186523,
      "learning_rate": 3.163066202090593e-05,
      "loss": 0.1465,
      "step": 15820
    },
    {
      "epoch": 3.6771196283391405,
      "grad_norm": 1.3455427885055542,
      "learning_rate": 3.161904761904762e-05,
      "loss": 0.0841,
      "step": 15830
    },
    {
      "epoch": 3.6794425087108014,
      "grad_norm": 0.8881608247756958,
      "learning_rate": 3.160743321718931e-05,
      "loss": 0.1634,
      "step": 15840
    },
    {
      "epoch": 3.681765389082462,
      "grad_norm": 0.9892719984054565,
      "learning_rate": 3.1595818815331014e-05,
      "loss": 0.0788,
      "step": 15850
    },
    {
      "epoch": 3.684088269454123,
      "grad_norm": 1.0771020650863647,
      "learning_rate": 3.158420441347271e-05,
      "loss": 0.1124,
      "step": 15860
    },
    {
      "epoch": 3.686411149825784,
      "grad_norm": 2.141399621963501,
      "learning_rate": 3.15725900116144e-05,
      "loss": 0.1035,
      "step": 15870
    },
    {
      "epoch": 3.6887340301974447,
      "grad_norm": 0.812985360622406,
      "learning_rate": 3.15609756097561e-05,
      "loss": 0.1921,
      "step": 15880
    },
    {
      "epoch": 3.6910569105691056,
      "grad_norm": 0.7875885963439941,
      "learning_rate": 3.154936120789779e-05,
      "loss": 0.0952,
      "step": 15890
    },
    {
      "epoch": 3.6933797909407664,
      "grad_norm": 0.8430755734443665,
      "learning_rate": 3.1537746806039494e-05,
      "loss": 0.1317,
      "step": 15900
    },
    {
      "epoch": 3.6957026713124272,
      "grad_norm": 0.7212096452713013,
      "learning_rate": 3.152613240418119e-05,
      "loss": 0.1245,
      "step": 15910
    },
    {
      "epoch": 3.698025551684088,
      "grad_norm": 1.6164637804031372,
      "learning_rate": 3.1514518002322877e-05,
      "loss": 0.101,
      "step": 15920
    },
    {
      "epoch": 3.7003484320557494,
      "grad_norm": 0.9747357964515686,
      "learning_rate": 3.150290360046458e-05,
      "loss": 0.1429,
      "step": 15930
    },
    {
      "epoch": 3.7026713124274098,
      "grad_norm": 0.9218156337738037,
      "learning_rate": 3.149128919860627e-05,
      "loss": 0.1989,
      "step": 15940
    },
    {
      "epoch": 3.704994192799071,
      "grad_norm": 0.7429215908050537,
      "learning_rate": 3.1479674796747974e-05,
      "loss": 0.0722,
      "step": 15950
    },
    {
      "epoch": 3.7073170731707314,
      "grad_norm": 1.6824183464050293,
      "learning_rate": 3.146806039488966e-05,
      "loss": 0.1035,
      "step": 15960
    },
    {
      "epoch": 3.7096399535423927,
      "grad_norm": 1.0602295398712158,
      "learning_rate": 3.145644599303136e-05,
      "loss": 0.1652,
      "step": 15970
    },
    {
      "epoch": 3.7119628339140536,
      "grad_norm": 1.8847662210464478,
      "learning_rate": 3.144483159117306e-05,
      "loss": 0.1872,
      "step": 15980
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 0.9208009243011475,
      "learning_rate": 3.143321718931475e-05,
      "loss": 0.1048,
      "step": 15990
    },
    {
      "epoch": 3.7166085946573753,
      "grad_norm": 2.0805835723876953,
      "learning_rate": 3.142160278745645e-05,
      "loss": 0.1199,
      "step": 16000
    },
    {
      "epoch": 3.718931475029036,
      "grad_norm": 1.5525778532028198,
      "learning_rate": 3.140998838559814e-05,
      "loss": 0.0726,
      "step": 16010
    },
    {
      "epoch": 3.721254355400697,
      "grad_norm": 0.7289105653762817,
      "learning_rate": 3.139837398373984e-05,
      "loss": 0.0606,
      "step": 16020
    },
    {
      "epoch": 3.7235772357723578,
      "grad_norm": 1.6184552907943726,
      "learning_rate": 3.138675958188154e-05,
      "loss": 0.1039,
      "step": 16030
    },
    {
      "epoch": 3.7259001161440186,
      "grad_norm": 1.6551669836044312,
      "learning_rate": 3.137514518002323e-05,
      "loss": 0.1436,
      "step": 16040
    },
    {
      "epoch": 3.7282229965156795,
      "grad_norm": 0.5901899337768555,
      "learning_rate": 3.136353077816492e-05,
      "loss": 0.2276,
      "step": 16050
    },
    {
      "epoch": 3.7305458768873403,
      "grad_norm": 1.344794511795044,
      "learning_rate": 3.135191637630662e-05,
      "loss": 0.1828,
      "step": 16060
    },
    {
      "epoch": 3.732868757259001,
      "grad_norm": 0.9741425514221191,
      "learning_rate": 3.134030197444832e-05,
      "loss": 0.1317,
      "step": 16070
    },
    {
      "epoch": 3.735191637630662,
      "grad_norm": 1.454814076423645,
      "learning_rate": 3.132868757259002e-05,
      "loss": 0.0962,
      "step": 16080
    },
    {
      "epoch": 3.737514518002323,
      "grad_norm": 0.8882877826690674,
      "learning_rate": 3.1317073170731706e-05,
      "loss": 0.1398,
      "step": 16090
    },
    {
      "epoch": 3.7398373983739837,
      "grad_norm": 0.8887385129928589,
      "learning_rate": 3.13054587688734e-05,
      "loss": 0.1026,
      "step": 16100
    },
    {
      "epoch": 3.7421602787456445,
      "grad_norm": 1.1153290271759033,
      "learning_rate": 3.12938443670151e-05,
      "loss": 0.1151,
      "step": 16110
    },
    {
      "epoch": 3.7444831591173053,
      "grad_norm": 1.0529638528823853,
      "learning_rate": 3.12822299651568e-05,
      "loss": 0.0804,
      "step": 16120
    },
    {
      "epoch": 3.746806039488966,
      "grad_norm": 0.45745715498924255,
      "learning_rate": 3.127061556329849e-05,
      "loss": 0.1464,
      "step": 16130
    },
    {
      "epoch": 3.749128919860627,
      "grad_norm": 1.225363850593567,
      "learning_rate": 3.1259001161440186e-05,
      "loss": 0.1178,
      "step": 16140
    },
    {
      "epoch": 3.751451800232288,
      "grad_norm": 0.6943643689155579,
      "learning_rate": 3.124738675958188e-05,
      "loss": 0.0926,
      "step": 16150
    },
    {
      "epoch": 3.753774680603949,
      "grad_norm": 0.5393968820571899,
      "learning_rate": 3.123577235772358e-05,
      "loss": 0.0743,
      "step": 16160
    },
    {
      "epoch": 3.7560975609756095,
      "grad_norm": 0.5560563802719116,
      "learning_rate": 3.122415795586528e-05,
      "loss": 0.1027,
      "step": 16170
    },
    {
      "epoch": 3.758420441347271,
      "grad_norm": 0.8805771470069885,
      "learning_rate": 3.1212543554006965e-05,
      "loss": 0.158,
      "step": 16180
    },
    {
      "epoch": 3.760743321718931,
      "grad_norm": 1.0243184566497803,
      "learning_rate": 3.1200929152148667e-05,
      "loss": 0.1092,
      "step": 16190
    },
    {
      "epoch": 3.7630662020905925,
      "grad_norm": 1.5803251266479492,
      "learning_rate": 3.118931475029036e-05,
      "loss": 0.0793,
      "step": 16200
    },
    {
      "epoch": 3.7653890824622533,
      "grad_norm": 1.1128675937652588,
      "learning_rate": 3.117770034843206e-05,
      "loss": 0.1489,
      "step": 16210
    },
    {
      "epoch": 3.767711962833914,
      "grad_norm": 1.2808138132095337,
      "learning_rate": 3.116608594657375e-05,
      "loss": 0.1223,
      "step": 16220
    },
    {
      "epoch": 3.770034843205575,
      "grad_norm": 1.223899006843567,
      "learning_rate": 3.1154471544715445e-05,
      "loss": 0.0925,
      "step": 16230
    },
    {
      "epoch": 3.772357723577236,
      "grad_norm": 0.9411333203315735,
      "learning_rate": 3.114285714285715e-05,
      "loss": 0.0694,
      "step": 16240
    },
    {
      "epoch": 3.7746806039488967,
      "grad_norm": 1.0597693920135498,
      "learning_rate": 3.113124274099884e-05,
      "loss": 0.1865,
      "step": 16250
    },
    {
      "epoch": 3.7770034843205575,
      "grad_norm": 1.455763816833496,
      "learning_rate": 3.1119628339140536e-05,
      "loss": 0.1697,
      "step": 16260
    },
    {
      "epoch": 3.7793263646922184,
      "grad_norm": 1.84059476852417,
      "learning_rate": 3.110801393728223e-05,
      "loss": 0.0855,
      "step": 16270
    },
    {
      "epoch": 3.7816492450638792,
      "grad_norm": 1.5912710428237915,
      "learning_rate": 3.1096399535423925e-05,
      "loss": 0.2781,
      "step": 16280
    },
    {
      "epoch": 3.78397212543554,
      "grad_norm": 1.3614412546157837,
      "learning_rate": 3.108478513356563e-05,
      "loss": 0.1866,
      "step": 16290
    },
    {
      "epoch": 3.786295005807201,
      "grad_norm": 1.627880573272705,
      "learning_rate": 3.107317073170732e-05,
      "loss": 0.2101,
      "step": 16300
    },
    {
      "epoch": 3.7886178861788617,
      "grad_norm": 1.2288423776626587,
      "learning_rate": 3.106155632984901e-05,
      "loss": 0.1509,
      "step": 16310
    },
    {
      "epoch": 3.7909407665505226,
      "grad_norm": 1.1446551084518433,
      "learning_rate": 3.104994192799071e-05,
      "loss": 0.0973,
      "step": 16320
    },
    {
      "epoch": 3.7932636469221834,
      "grad_norm": 1.145768404006958,
      "learning_rate": 3.1038327526132406e-05,
      "loss": 0.0705,
      "step": 16330
    },
    {
      "epoch": 3.7955865272938443,
      "grad_norm": 1.2938207387924194,
      "learning_rate": 3.102671312427411e-05,
      "loss": 0.1208,
      "step": 16340
    },
    {
      "epoch": 3.797909407665505,
      "grad_norm": 0.9447046518325806,
      "learning_rate": 3.1015098722415795e-05,
      "loss": 0.103,
      "step": 16350
    },
    {
      "epoch": 3.800232288037166,
      "grad_norm": 1.5131494998931885,
      "learning_rate": 3.100348432055749e-05,
      "loss": 0.1021,
      "step": 16360
    },
    {
      "epoch": 3.802555168408827,
      "grad_norm": 1.0187853574752808,
      "learning_rate": 3.099186991869919e-05,
      "loss": 0.132,
      "step": 16370
    },
    {
      "epoch": 3.8048780487804876,
      "grad_norm": 0.6490441560745239,
      "learning_rate": 3.0980255516840886e-05,
      "loss": 0.1191,
      "step": 16380
    },
    {
      "epoch": 3.807200929152149,
      "grad_norm": 1.767781376838684,
      "learning_rate": 3.096864111498258e-05,
      "loss": 0.1005,
      "step": 16390
    },
    {
      "epoch": 3.8095238095238093,
      "grad_norm": 1.782923936843872,
      "learning_rate": 3.0957026713124275e-05,
      "loss": 0.1241,
      "step": 16400
    },
    {
      "epoch": 3.8118466898954706,
      "grad_norm": 1.537554383277893,
      "learning_rate": 3.094541231126597e-05,
      "loss": 0.1129,
      "step": 16410
    },
    {
      "epoch": 3.814169570267131,
      "grad_norm": 1.2533169984817505,
      "learning_rate": 3.093379790940767e-05,
      "loss": 0.1452,
      "step": 16420
    },
    {
      "epoch": 3.8164924506387923,
      "grad_norm": 1.9001286029815674,
      "learning_rate": 3.0922183507549366e-05,
      "loss": 0.213,
      "step": 16430
    },
    {
      "epoch": 3.818815331010453,
      "grad_norm": 1.2286680936813354,
      "learning_rate": 3.0910569105691054e-05,
      "loss": 0.1305,
      "step": 16440
    },
    {
      "epoch": 3.821138211382114,
      "grad_norm": 1.8726205825805664,
      "learning_rate": 3.0898954703832755e-05,
      "loss": 0.1101,
      "step": 16450
    },
    {
      "epoch": 3.823461091753775,
      "grad_norm": 1.5280882120132446,
      "learning_rate": 3.088734030197445e-05,
      "loss": 0.1071,
      "step": 16460
    },
    {
      "epoch": 3.8257839721254356,
      "grad_norm": 1.533443808555603,
      "learning_rate": 3.087572590011615e-05,
      "loss": 0.112,
      "step": 16470
    },
    {
      "epoch": 3.8281068524970965,
      "grad_norm": 0.7381848692893982,
      "learning_rate": 3.086411149825784e-05,
      "loss": 0.0802,
      "step": 16480
    },
    {
      "epoch": 3.8304297328687573,
      "grad_norm": 2.4218814373016357,
      "learning_rate": 3.0852497096399534e-05,
      "loss": 0.0941,
      "step": 16490
    },
    {
      "epoch": 3.832752613240418,
      "grad_norm": 0.8117462992668152,
      "learning_rate": 3.0840882694541235e-05,
      "loss": 0.1224,
      "step": 16500
    },
    {
      "epoch": 3.835075493612079,
      "grad_norm": 1.1270493268966675,
      "learning_rate": 3.082926829268293e-05,
      "loss": 0.0906,
      "step": 16510
    },
    {
      "epoch": 3.83739837398374,
      "grad_norm": 0.7462289929389954,
      "learning_rate": 3.0817653890824625e-05,
      "loss": 0.0684,
      "step": 16520
    },
    {
      "epoch": 3.8397212543554007,
      "grad_norm": 0.8120157718658447,
      "learning_rate": 3.080603948896632e-05,
      "loss": 0.0926,
      "step": 16530
    },
    {
      "epoch": 3.8420441347270615,
      "grad_norm": 1.5306463241577148,
      "learning_rate": 3.0794425087108014e-05,
      "loss": 0.1092,
      "step": 16540
    },
    {
      "epoch": 3.8443670150987224,
      "grad_norm": 0.9521147608757019,
      "learning_rate": 3.0782810685249715e-05,
      "loss": 0.0886,
      "step": 16550
    },
    {
      "epoch": 3.846689895470383,
      "grad_norm": 0.6258928179740906,
      "learning_rate": 3.077119628339141e-05,
      "loss": 0.1533,
      "step": 16560
    },
    {
      "epoch": 3.849012775842044,
      "grad_norm": 1.8415007591247559,
      "learning_rate": 3.07595818815331e-05,
      "loss": 0.1461,
      "step": 16570
    },
    {
      "epoch": 3.851335656213705,
      "grad_norm": 1.0443062782287598,
      "learning_rate": 3.07479674796748e-05,
      "loss": 0.1207,
      "step": 16580
    },
    {
      "epoch": 3.8536585365853657,
      "grad_norm": 0.6896799206733704,
      "learning_rate": 3.0736353077816494e-05,
      "loss": 0.1326,
      "step": 16590
    },
    {
      "epoch": 3.8559814169570266,
      "grad_norm": 1.246741533279419,
      "learning_rate": 3.0724738675958196e-05,
      "loss": 0.2369,
      "step": 16600
    },
    {
      "epoch": 3.8583042973286874,
      "grad_norm": 2.2791523933410645,
      "learning_rate": 3.0713124274099883e-05,
      "loss": 0.1011,
      "step": 16610
    },
    {
      "epoch": 3.8606271777003487,
      "grad_norm": 1.006493330001831,
      "learning_rate": 3.070150987224158e-05,
      "loss": 0.1193,
      "step": 16620
    },
    {
      "epoch": 3.862950058072009,
      "grad_norm": 0.6327195763587952,
      "learning_rate": 3.068989547038328e-05,
      "loss": 0.2295,
      "step": 16630
    },
    {
      "epoch": 3.8652729384436704,
      "grad_norm": 1.271738886833191,
      "learning_rate": 3.0678281068524974e-05,
      "loss": 0.0811,
      "step": 16640
    },
    {
      "epoch": 3.8675958188153308,
      "grad_norm": 0.6939586997032166,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.049,
      "step": 16650
    },
    {
      "epoch": 3.869918699186992,
      "grad_norm": 2.1108133792877197,
      "learning_rate": 3.0655052264808364e-05,
      "loss": 0.142,
      "step": 16660
    },
    {
      "epoch": 3.872241579558653,
      "grad_norm": 1.4019060134887695,
      "learning_rate": 3.064343786295006e-05,
      "loss": 0.1299,
      "step": 16670
    },
    {
      "epoch": 3.8745644599303137,
      "grad_norm": 0.9248430728912354,
      "learning_rate": 3.063182346109176e-05,
      "loss": 0.0871,
      "step": 16680
    },
    {
      "epoch": 3.8768873403019746,
      "grad_norm": 1.6428323984146118,
      "learning_rate": 3.0620209059233454e-05,
      "loss": 0.1138,
      "step": 16690
    },
    {
      "epoch": 3.8792102206736354,
      "grad_norm": 1.4107714891433716,
      "learning_rate": 3.060859465737514e-05,
      "loss": 0.1368,
      "step": 16700
    },
    {
      "epoch": 3.8815331010452963,
      "grad_norm": 0.9153668880462646,
      "learning_rate": 3.0596980255516844e-05,
      "loss": 0.1389,
      "step": 16710
    },
    {
      "epoch": 3.883855981416957,
      "grad_norm": 1.035266399383545,
      "learning_rate": 3.058536585365854e-05,
      "loss": 0.1534,
      "step": 16720
    },
    {
      "epoch": 3.886178861788618,
      "grad_norm": 0.48983028531074524,
      "learning_rate": 3.057375145180023e-05,
      "loss": 0.1471,
      "step": 16730
    },
    {
      "epoch": 3.8885017421602788,
      "grad_norm": 0.7470447421073914,
      "learning_rate": 3.056213704994193e-05,
      "loss": 0.0584,
      "step": 16740
    },
    {
      "epoch": 3.8908246225319396,
      "grad_norm": 1.9662305116653442,
      "learning_rate": 3.055052264808362e-05,
      "loss": 0.1645,
      "step": 16750
    },
    {
      "epoch": 3.8931475029036005,
      "grad_norm": 1.6856364011764526,
      "learning_rate": 3.0538908246225324e-05,
      "loss": 0.1376,
      "step": 16760
    },
    {
      "epoch": 3.8954703832752613,
      "grad_norm": 0.619635820388794,
      "learning_rate": 3.052729384436702e-05,
      "loss": 0.1527,
      "step": 16770
    },
    {
      "epoch": 3.897793263646922,
      "grad_norm": 1.5109264850616455,
      "learning_rate": 3.051567944250871e-05,
      "loss": 0.1828,
      "step": 16780
    },
    {
      "epoch": 3.900116144018583,
      "grad_norm": 2.3628413677215576,
      "learning_rate": 3.0504065040650408e-05,
      "loss": 0.1125,
      "step": 16790
    },
    {
      "epoch": 3.902439024390244,
      "grad_norm": 0.7933562397956848,
      "learning_rate": 3.0492450638792103e-05,
      "loss": 0.0956,
      "step": 16800
    },
    {
      "epoch": 3.9047619047619047,
      "grad_norm": 1.553615927696228,
      "learning_rate": 3.04808362369338e-05,
      "loss": 0.1737,
      "step": 16810
    },
    {
      "epoch": 3.9070847851335655,
      "grad_norm": 2.2203609943389893,
      "learning_rate": 3.0469221835075495e-05,
      "loss": 0.1732,
      "step": 16820
    },
    {
      "epoch": 3.9094076655052263,
      "grad_norm": 1.8905678987503052,
      "learning_rate": 3.045760743321719e-05,
      "loss": 0.2208,
      "step": 16830
    },
    {
      "epoch": 3.911730545876887,
      "grad_norm": 1.0788843631744385,
      "learning_rate": 3.0445993031358888e-05,
      "loss": 0.146,
      "step": 16840
    },
    {
      "epoch": 3.9140534262485485,
      "grad_norm": 1.0730857849121094,
      "learning_rate": 3.0434378629500583e-05,
      "loss": 0.2053,
      "step": 16850
    },
    {
      "epoch": 3.916376306620209,
      "grad_norm": 0.6854931712150574,
      "learning_rate": 3.0422764227642274e-05,
      "loss": 0.1129,
      "step": 16860
    },
    {
      "epoch": 3.91869918699187,
      "grad_norm": 1.8645402193069458,
      "learning_rate": 3.0411149825783975e-05,
      "loss": 0.1238,
      "step": 16870
    },
    {
      "epoch": 3.9210220673635305,
      "grad_norm": 0.46678879857063293,
      "learning_rate": 3.0399535423925667e-05,
      "loss": 0.0826,
      "step": 16880
    },
    {
      "epoch": 3.923344947735192,
      "grad_norm": 1.1098203659057617,
      "learning_rate": 3.0387921022067368e-05,
      "loss": 0.1371,
      "step": 16890
    },
    {
      "epoch": 3.925667828106852,
      "grad_norm": 1.3841825723648071,
      "learning_rate": 3.037630662020906e-05,
      "loss": 0.0658,
      "step": 16900
    },
    {
      "epoch": 3.9279907084785135,
      "grad_norm": 1.3493735790252686,
      "learning_rate": 3.0364692218350754e-05,
      "loss": 0.1218,
      "step": 16910
    },
    {
      "epoch": 3.9303135888501743,
      "grad_norm": 2.285937786102295,
      "learning_rate": 3.0353077816492452e-05,
      "loss": 0.1384,
      "step": 16920
    },
    {
      "epoch": 3.932636469221835,
      "grad_norm": 0.302726149559021,
      "learning_rate": 3.0341463414634147e-05,
      "loss": 0.0873,
      "step": 16930
    },
    {
      "epoch": 3.934959349593496,
      "grad_norm": 1.3010045289993286,
      "learning_rate": 3.0329849012775845e-05,
      "loss": 0.0995,
      "step": 16940
    },
    {
      "epoch": 3.937282229965157,
      "grad_norm": 1.0168596506118774,
      "learning_rate": 3.031823461091754e-05,
      "loss": 0.1437,
      "step": 16950
    },
    {
      "epoch": 3.9396051103368177,
      "grad_norm": 0.6260225176811218,
      "learning_rate": 3.0306620209059234e-05,
      "loss": 0.1198,
      "step": 16960
    },
    {
      "epoch": 3.9419279907084785,
      "grad_norm": 1.8721470832824707,
      "learning_rate": 3.0295005807200932e-05,
      "loss": 0.075,
      "step": 16970
    },
    {
      "epoch": 3.9442508710801394,
      "grad_norm": 1.1275092363357544,
      "learning_rate": 3.0283391405342627e-05,
      "loss": 0.1356,
      "step": 16980
    },
    {
      "epoch": 3.9465737514518002,
      "grad_norm": 1.9709347486495972,
      "learning_rate": 3.027177700348432e-05,
      "loss": 0.109,
      "step": 16990
    },
    {
      "epoch": 3.948896631823461,
      "grad_norm": 1.1196149587631226,
      "learning_rate": 3.026016260162602e-05,
      "loss": 0.0651,
      "step": 17000
    },
    {
      "epoch": 3.951219512195122,
      "grad_norm": 0.46038883924484253,
      "learning_rate": 3.024854819976771e-05,
      "loss": 0.0969,
      "step": 17010
    },
    {
      "epoch": 3.9535423925667827,
      "grad_norm": 1.771375298500061,
      "learning_rate": 3.0236933797909412e-05,
      "loss": 0.1452,
      "step": 17020
    },
    {
      "epoch": 3.9558652729384436,
      "grad_norm": 0.9748064279556274,
      "learning_rate": 3.0225319396051104e-05,
      "loss": 0.1063,
      "step": 17030
    },
    {
      "epoch": 3.9581881533101044,
      "grad_norm": 0.8846360445022583,
      "learning_rate": 3.02137049941928e-05,
      "loss": 0.112,
      "step": 17040
    },
    {
      "epoch": 3.9605110336817653,
      "grad_norm": 0.6825388073921204,
      "learning_rate": 3.0202090592334497e-05,
      "loss": 0.0463,
      "step": 17050
    },
    {
      "epoch": 3.962833914053426,
      "grad_norm": 0.5268420577049255,
      "learning_rate": 3.019047619047619e-05,
      "loss": 0.1105,
      "step": 17060
    },
    {
      "epoch": 3.965156794425087,
      "grad_norm": 0.7850187420845032,
      "learning_rate": 3.017886178861789e-05,
      "loss": 0.0806,
      "step": 17070
    },
    {
      "epoch": 3.9674796747967482,
      "grad_norm": 0.7596428990364075,
      "learning_rate": 3.0167247386759584e-05,
      "loss": 0.0795,
      "step": 17080
    },
    {
      "epoch": 3.9698025551684086,
      "grad_norm": 1.7502813339233398,
      "learning_rate": 3.015563298490128e-05,
      "loss": 0.0793,
      "step": 17090
    },
    {
      "epoch": 3.97212543554007,
      "grad_norm": 0.873741865158081,
      "learning_rate": 3.0144018583042977e-05,
      "loss": 0.2164,
      "step": 17100
    },
    {
      "epoch": 3.9744483159117303,
      "grad_norm": 1.322313666343689,
      "learning_rate": 3.013240418118467e-05,
      "loss": 0.1185,
      "step": 17110
    },
    {
      "epoch": 3.9767711962833916,
      "grad_norm": 1.535083293914795,
      "learning_rate": 3.0120789779326363e-05,
      "loss": 0.0961,
      "step": 17120
    },
    {
      "epoch": 3.979094076655052,
      "grad_norm": 1.0144424438476562,
      "learning_rate": 3.0109175377468064e-05,
      "loss": 0.119,
      "step": 17130
    },
    {
      "epoch": 3.9814169570267133,
      "grad_norm": 1.6884046792984009,
      "learning_rate": 3.0097560975609755e-05,
      "loss": 0.1992,
      "step": 17140
    },
    {
      "epoch": 3.983739837398374,
      "grad_norm": 1.0007611513137817,
      "learning_rate": 3.0085946573751457e-05,
      "loss": 0.1911,
      "step": 17150
    },
    {
      "epoch": 3.986062717770035,
      "grad_norm": 1.3712983131408691,
      "learning_rate": 3.0074332171893148e-05,
      "loss": 0.1714,
      "step": 17160
    },
    {
      "epoch": 3.988385598141696,
      "grad_norm": 1.35879385471344,
      "learning_rate": 3.0062717770034843e-05,
      "loss": 0.1302,
      "step": 17170
    },
    {
      "epoch": 3.9907084785133566,
      "grad_norm": 1.504682183265686,
      "learning_rate": 3.005110336817654e-05,
      "loss": 0.0935,
      "step": 17180
    },
    {
      "epoch": 3.9930313588850175,
      "grad_norm": 1.36736261844635,
      "learning_rate": 3.0039488966318235e-05,
      "loss": 0.1399,
      "step": 17190
    },
    {
      "epoch": 3.9953542392566783,
      "grad_norm": 1.600614070892334,
      "learning_rate": 3.002903600464576e-05,
      "loss": 0.1393,
      "step": 17200
    },
    {
      "epoch": 3.997677119628339,
      "grad_norm": 0.754587709903717,
      "learning_rate": 3.001742160278746e-05,
      "loss": 0.0928,
      "step": 17210
    },
    {
      "epoch": 4.0,
      "grad_norm": 1.2011409997940063,
      "learning_rate": 3.0005807200929153e-05,
      "loss": 0.1869,
      "step": 17220
    },
    {
      "epoch": 4.002322880371661,
      "grad_norm": 0.6840096116065979,
      "learning_rate": 2.9994192799070848e-05,
      "loss": 0.0645,
      "step": 17230
    },
    {
      "epoch": 4.004645760743322,
      "grad_norm": 1.4625635147094727,
      "learning_rate": 2.9982578397212546e-05,
      "loss": 0.1305,
      "step": 17240
    },
    {
      "epoch": 4.006968641114983,
      "grad_norm": 1.9268620014190674,
      "learning_rate": 2.997096399535424e-05,
      "loss": 0.1263,
      "step": 17250
    },
    {
      "epoch": 4.009291521486643,
      "grad_norm": 0.8125237226486206,
      "learning_rate": 2.995934959349594e-05,
      "loss": 0.0731,
      "step": 17260
    },
    {
      "epoch": 4.011614401858305,
      "grad_norm": 1.5097589492797852,
      "learning_rate": 2.9947735191637634e-05,
      "loss": 0.1811,
      "step": 17270
    },
    {
      "epoch": 4.013937282229965,
      "grad_norm": 1.1328153610229492,
      "learning_rate": 2.9936120789779325e-05,
      "loss": 0.1916,
      "step": 17280
    },
    {
      "epoch": 4.016260162601626,
      "grad_norm": 0.752576470375061,
      "learning_rate": 2.9924506387921026e-05,
      "loss": 0.1813,
      "step": 17290
    },
    {
      "epoch": 4.018583042973287,
      "grad_norm": 2.596801996231079,
      "learning_rate": 2.9912891986062718e-05,
      "loss": 0.0975,
      "step": 17300
    },
    {
      "epoch": 4.020905923344948,
      "grad_norm": 1.2293860912322998,
      "learning_rate": 2.9901277584204412e-05,
      "loss": 0.0756,
      "step": 17310
    },
    {
      "epoch": 4.023228803716608,
      "grad_norm": 1.158288598060608,
      "learning_rate": 2.988966318234611e-05,
      "loss": 0.1224,
      "step": 17320
    },
    {
      "epoch": 4.02555168408827,
      "grad_norm": 0.9609270095825195,
      "learning_rate": 2.9878048780487805e-05,
      "loss": 0.1022,
      "step": 17330
    },
    {
      "epoch": 4.02787456445993,
      "grad_norm": 0.6139580607414246,
      "learning_rate": 2.9866434378629503e-05,
      "loss": 0.1102,
      "step": 17340
    },
    {
      "epoch": 4.030197444831591,
      "grad_norm": 1.0218870639801025,
      "learning_rate": 2.9854819976771198e-05,
      "loss": 0.1117,
      "step": 17350
    },
    {
      "epoch": 4.032520325203252,
      "grad_norm": 2.3250315189361572,
      "learning_rate": 2.9843205574912892e-05,
      "loss": 0.168,
      "step": 17360
    },
    {
      "epoch": 4.034843205574913,
      "grad_norm": 0.6949746012687683,
      "learning_rate": 2.983159117305459e-05,
      "loss": 0.1927,
      "step": 17370
    },
    {
      "epoch": 4.0371660859465734,
      "grad_norm": 2.0514986515045166,
      "learning_rate": 2.9819976771196285e-05,
      "loss": 0.0774,
      "step": 17380
    },
    {
      "epoch": 4.039488966318235,
      "grad_norm": 1.2056443691253662,
      "learning_rate": 2.9808362369337983e-05,
      "loss": 0.0726,
      "step": 17390
    },
    {
      "epoch": 4.041811846689895,
      "grad_norm": 0.6410815715789795,
      "learning_rate": 2.9796747967479678e-05,
      "loss": 0.1082,
      "step": 17400
    },
    {
      "epoch": 4.044134727061556,
      "grad_norm": 1.1000480651855469,
      "learning_rate": 2.978513356562137e-05,
      "loss": 0.1078,
      "step": 17410
    },
    {
      "epoch": 4.046457607433217,
      "grad_norm": 1.0380816459655762,
      "learning_rate": 2.977351916376307e-05,
      "loss": 0.1296,
      "step": 17420
    },
    {
      "epoch": 4.048780487804878,
      "grad_norm": 1.2194899320602417,
      "learning_rate": 2.9761904761904762e-05,
      "loss": 0.0912,
      "step": 17430
    },
    {
      "epoch": 4.0511033681765385,
      "grad_norm": 0.7705027461051941,
      "learning_rate": 2.9750290360046457e-05,
      "loss": 0.0986,
      "step": 17440
    },
    {
      "epoch": 4.0534262485482,
      "grad_norm": 1.2887563705444336,
      "learning_rate": 2.9738675958188155e-05,
      "loss": 0.1173,
      "step": 17450
    },
    {
      "epoch": 4.055749128919861,
      "grad_norm": 0.7737562656402588,
      "learning_rate": 2.972706155632985e-05,
      "loss": 0.1275,
      "step": 17460
    },
    {
      "epoch": 4.0580720092915215,
      "grad_norm": 1.3808032274246216,
      "learning_rate": 2.9715447154471547e-05,
      "loss": 0.1038,
      "step": 17470
    },
    {
      "epoch": 4.060394889663183,
      "grad_norm": 0.43546512722969055,
      "learning_rate": 2.9703832752613242e-05,
      "loss": 0.1369,
      "step": 17480
    },
    {
      "epoch": 4.062717770034843,
      "grad_norm": 1.1880664825439453,
      "learning_rate": 2.9692218350754937e-05,
      "loss": 0.0887,
      "step": 17490
    },
    {
      "epoch": 4.065040650406504,
      "grad_norm": 0.766652524471283,
      "learning_rate": 2.9680603948896635e-05,
      "loss": 0.1207,
      "step": 17500
    },
    {
      "epoch": 4.067363530778165,
      "grad_norm": 2.137913703918457,
      "learning_rate": 2.966898954703833e-05,
      "loss": 0.0968,
      "step": 17510
    },
    {
      "epoch": 4.069686411149826,
      "grad_norm": 1.5207545757293701,
      "learning_rate": 2.965737514518002e-05,
      "loss": 0.2185,
      "step": 17520
    },
    {
      "epoch": 4.0720092915214865,
      "grad_norm": 0.7564335465431213,
      "learning_rate": 2.9645760743321722e-05,
      "loss": 0.1544,
      "step": 17530
    },
    {
      "epoch": 4.074332171893148,
      "grad_norm": 0.6255452036857605,
      "learning_rate": 2.9634146341463413e-05,
      "loss": 0.1521,
      "step": 17540
    },
    {
      "epoch": 4.076655052264808,
      "grad_norm": 1.3513195514678955,
      "learning_rate": 2.9622531939605115e-05,
      "loss": 0.1362,
      "step": 17550
    },
    {
      "epoch": 4.0789779326364695,
      "grad_norm": 1.2416110038757324,
      "learning_rate": 2.9610917537746806e-05,
      "loss": 0.1138,
      "step": 17560
    },
    {
      "epoch": 4.08130081300813,
      "grad_norm": 1.5004043579101562,
      "learning_rate": 2.95993031358885e-05,
      "loss": 0.1369,
      "step": 17570
    },
    {
      "epoch": 4.083623693379791,
      "grad_norm": 0.8822301626205444,
      "learning_rate": 2.95876887340302e-05,
      "loss": 0.1563,
      "step": 17580
    },
    {
      "epoch": 4.0859465737514515,
      "grad_norm": 1.6428302526474,
      "learning_rate": 2.9576074332171894e-05,
      "loss": 0.1176,
      "step": 17590
    },
    {
      "epoch": 4.088269454123113,
      "grad_norm": 1.6321516036987305,
      "learning_rate": 2.956445993031359e-05,
      "loss": 0.0744,
      "step": 17600
    },
    {
      "epoch": 4.090592334494773,
      "grad_norm": 0.6862547397613525,
      "learning_rate": 2.9552845528455286e-05,
      "loss": 0.0859,
      "step": 17610
    },
    {
      "epoch": 4.0929152148664345,
      "grad_norm": 1.2414830923080444,
      "learning_rate": 2.954123112659698e-05,
      "loss": 0.0842,
      "step": 17620
    },
    {
      "epoch": 4.095238095238095,
      "grad_norm": 1.8955012559890747,
      "learning_rate": 2.952961672473868e-05,
      "loss": 0.0931,
      "step": 17630
    },
    {
      "epoch": 4.097560975609756,
      "grad_norm": 1.653304934501648,
      "learning_rate": 2.9518002322880374e-05,
      "loss": 0.1206,
      "step": 17640
    },
    {
      "epoch": 4.099883855981417,
      "grad_norm": 0.7985499501228333,
      "learning_rate": 2.9506387921022065e-05,
      "loss": 0.1018,
      "step": 17650
    },
    {
      "epoch": 4.102206736353078,
      "grad_norm": 0.5823372602462769,
      "learning_rate": 2.9494773519163766e-05,
      "loss": 0.1433,
      "step": 17660
    },
    {
      "epoch": 4.104529616724738,
      "grad_norm": 1.6118485927581787,
      "learning_rate": 2.9483159117305458e-05,
      "loss": 0.1107,
      "step": 17670
    },
    {
      "epoch": 4.1068524970963995,
      "grad_norm": 2.4839344024658203,
      "learning_rate": 2.947154471544716e-05,
      "loss": 0.1161,
      "step": 17680
    },
    {
      "epoch": 4.109175377468061,
      "grad_norm": 1.676695704460144,
      "learning_rate": 2.945993031358885e-05,
      "loss": 0.0992,
      "step": 17690
    },
    {
      "epoch": 4.111498257839721,
      "grad_norm": 1.5177888870239258,
      "learning_rate": 2.9448315911730545e-05,
      "loss": 0.186,
      "step": 17700
    },
    {
      "epoch": 4.1138211382113825,
      "grad_norm": 0.5903822183609009,
      "learning_rate": 2.9436701509872243e-05,
      "loss": 0.0952,
      "step": 17710
    },
    {
      "epoch": 4.116144018583043,
      "grad_norm": 2.076514720916748,
      "learning_rate": 2.9425087108013938e-05,
      "loss": 0.0982,
      "step": 17720
    },
    {
      "epoch": 4.118466898954704,
      "grad_norm": 0.9422370195388794,
      "learning_rate": 2.9413472706155636e-05,
      "loss": 0.108,
      "step": 17730
    },
    {
      "epoch": 4.120789779326365,
      "grad_norm": 1.4227170944213867,
      "learning_rate": 2.940185830429733e-05,
      "loss": 0.0903,
      "step": 17740
    },
    {
      "epoch": 4.123112659698026,
      "grad_norm": 1.827888011932373,
      "learning_rate": 2.9390243902439025e-05,
      "loss": 0.1431,
      "step": 17750
    },
    {
      "epoch": 4.125435540069686,
      "grad_norm": 1.1203290224075317,
      "learning_rate": 2.9378629500580723e-05,
      "loss": 0.0976,
      "step": 17760
    },
    {
      "epoch": 4.1277584204413476,
      "grad_norm": 1.4692292213439941,
      "learning_rate": 2.9367015098722418e-05,
      "loss": 0.1508,
      "step": 17770
    },
    {
      "epoch": 4.130081300813008,
      "grad_norm": 0.8239573836326599,
      "learning_rate": 2.935540069686411e-05,
      "loss": 0.0894,
      "step": 17780
    },
    {
      "epoch": 4.132404181184669,
      "grad_norm": 0.6839499473571777,
      "learning_rate": 2.934378629500581e-05,
      "loss": 0.0805,
      "step": 17790
    },
    {
      "epoch": 4.13472706155633,
      "grad_norm": 0.90787672996521,
      "learning_rate": 2.9332171893147502e-05,
      "loss": 0.1128,
      "step": 17800
    },
    {
      "epoch": 4.137049941927991,
      "grad_norm": 1.3516265153884888,
      "learning_rate": 2.9320557491289203e-05,
      "loss": 0.08,
      "step": 17810
    },
    {
      "epoch": 4.139372822299651,
      "grad_norm": 0.6851451396942139,
      "learning_rate": 2.9308943089430895e-05,
      "loss": 0.0818,
      "step": 17820
    },
    {
      "epoch": 4.141695702671313,
      "grad_norm": 1.0261073112487793,
      "learning_rate": 2.929732868757259e-05,
      "loss": 0.0792,
      "step": 17830
    },
    {
      "epoch": 4.144018583042973,
      "grad_norm": 2.1707980632781982,
      "learning_rate": 2.9285714285714288e-05,
      "loss": 0.1227,
      "step": 17840
    },
    {
      "epoch": 4.146341463414634,
      "grad_norm": 2.034705400466919,
      "learning_rate": 2.9274099883855982e-05,
      "loss": 0.1036,
      "step": 17850
    },
    {
      "epoch": 4.148664343786295,
      "grad_norm": 0.7737303376197815,
      "learning_rate": 2.926248548199768e-05,
      "loss": 0.1404,
      "step": 17860
    },
    {
      "epoch": 4.150987224157956,
      "grad_norm": 1.109311819076538,
      "learning_rate": 2.9250871080139375e-05,
      "loss": 0.0873,
      "step": 17870
    },
    {
      "epoch": 4.153310104529616,
      "grad_norm": 0.7791181206703186,
      "learning_rate": 2.923925667828107e-05,
      "loss": 0.0591,
      "step": 17880
    },
    {
      "epoch": 4.155632984901278,
      "grad_norm": 2.1204922199249268,
      "learning_rate": 2.9227642276422768e-05,
      "loss": 0.1455,
      "step": 17890
    },
    {
      "epoch": 4.157955865272938,
      "grad_norm": 1.1342164278030396,
      "learning_rate": 2.9216027874564462e-05,
      "loss": 0.1344,
      "step": 17900
    },
    {
      "epoch": 4.160278745644599,
      "grad_norm": 1.2073497772216797,
      "learning_rate": 2.9204413472706154e-05,
      "loss": 0.1784,
      "step": 17910
    },
    {
      "epoch": 4.16260162601626,
      "grad_norm": 0.9930095672607422,
      "learning_rate": 2.9192799070847855e-05,
      "loss": 0.094,
      "step": 17920
    },
    {
      "epoch": 4.164924506387921,
      "grad_norm": 0.9120137691497803,
      "learning_rate": 2.9181184668989546e-05,
      "loss": 0.1414,
      "step": 17930
    },
    {
      "epoch": 4.167247386759582,
      "grad_norm": 1.0209481716156006,
      "learning_rate": 2.9169570267131248e-05,
      "loss": 0.1755,
      "step": 17940
    },
    {
      "epoch": 4.169570267131243,
      "grad_norm": 1.2470468282699585,
      "learning_rate": 2.915795586527294e-05,
      "loss": 0.0855,
      "step": 17950
    },
    {
      "epoch": 4.171893147502904,
      "grad_norm": 0.8518865704536438,
      "learning_rate": 2.9146341463414634e-05,
      "loss": 0.1002,
      "step": 17960
    },
    {
      "epoch": 4.174216027874564,
      "grad_norm": 1.0569950342178345,
      "learning_rate": 2.9134727061556332e-05,
      "loss": 0.1484,
      "step": 17970
    },
    {
      "epoch": 4.176538908246226,
      "grad_norm": 1.1267896890640259,
      "learning_rate": 2.9123112659698026e-05,
      "loss": 0.1232,
      "step": 17980
    },
    {
      "epoch": 4.178861788617886,
      "grad_norm": 1.2497342824935913,
      "learning_rate": 2.911149825783972e-05,
      "loss": 0.1469,
      "step": 17990
    },
    {
      "epoch": 4.181184668989547,
      "grad_norm": 1.0849745273590088,
      "learning_rate": 2.909988385598142e-05,
      "loss": 0.0651,
      "step": 18000
    },
    {
      "epoch": 4.183507549361208,
      "grad_norm": 2.666835069656372,
      "learning_rate": 2.9088269454123114e-05,
      "loss": 0.1294,
      "step": 18010
    },
    {
      "epoch": 4.185830429732869,
      "grad_norm": 1.270633578300476,
      "learning_rate": 2.9076655052264812e-05,
      "loss": 0.0897,
      "step": 18020
    },
    {
      "epoch": 4.188153310104529,
      "grad_norm": 0.9067884087562561,
      "learning_rate": 2.9065040650406507e-05,
      "loss": 0.1965,
      "step": 18030
    },
    {
      "epoch": 4.190476190476191,
      "grad_norm": 1.244529366493225,
      "learning_rate": 2.9053426248548198e-05,
      "loss": 0.0955,
      "step": 18040
    },
    {
      "epoch": 4.192799070847851,
      "grad_norm": 1.3756011724472046,
      "learning_rate": 2.90418118466899e-05,
      "loss": 0.17,
      "step": 18050
    },
    {
      "epoch": 4.195121951219512,
      "grad_norm": 0.8427316546440125,
      "learning_rate": 2.903019744483159e-05,
      "loss": 0.0688,
      "step": 18060
    },
    {
      "epoch": 4.197444831591173,
      "grad_norm": 0.6424193978309631,
      "learning_rate": 2.9018583042973292e-05,
      "loss": 0.1489,
      "step": 18070
    },
    {
      "epoch": 4.199767711962834,
      "grad_norm": 0.8814071416854858,
      "learning_rate": 2.9006968641114983e-05,
      "loss": 0.128,
      "step": 18080
    },
    {
      "epoch": 4.2020905923344944,
      "grad_norm": 0.7321386933326721,
      "learning_rate": 2.8995354239256678e-05,
      "loss": 0.0769,
      "step": 18090
    },
    {
      "epoch": 4.204413472706156,
      "grad_norm": 1.0053434371948242,
      "learning_rate": 2.8983739837398376e-05,
      "loss": 0.2022,
      "step": 18100
    },
    {
      "epoch": 4.206736353077816,
      "grad_norm": 0.8689152002334595,
      "learning_rate": 2.897212543554007e-05,
      "loss": 0.0987,
      "step": 18110
    },
    {
      "epoch": 4.209059233449477,
      "grad_norm": 1.9610556364059448,
      "learning_rate": 2.8960511033681765e-05,
      "loss": 0.0806,
      "step": 18120
    },
    {
      "epoch": 4.211382113821138,
      "grad_norm": 2.6436569690704346,
      "learning_rate": 2.8948896631823464e-05,
      "loss": 0.0893,
      "step": 18130
    },
    {
      "epoch": 4.213704994192799,
      "grad_norm": 1.2860186100006104,
      "learning_rate": 2.8937282229965158e-05,
      "loss": 0.1875,
      "step": 18140
    },
    {
      "epoch": 4.21602787456446,
      "grad_norm": 1.3853999376296997,
      "learning_rate": 2.8925667828106856e-05,
      "loss": 0.0847,
      "step": 18150
    },
    {
      "epoch": 4.218350754936121,
      "grad_norm": 0.9791430830955505,
      "learning_rate": 2.891405342624855e-05,
      "loss": 0.1094,
      "step": 18160
    },
    {
      "epoch": 4.220673635307782,
      "grad_norm": 0.879338800907135,
      "learning_rate": 2.8902439024390242e-05,
      "loss": 0.0852,
      "step": 18170
    },
    {
      "epoch": 4.2229965156794425,
      "grad_norm": 1.3849823474884033,
      "learning_rate": 2.8890824622531944e-05,
      "loss": 0.1204,
      "step": 18180
    },
    {
      "epoch": 4.225319396051104,
      "grad_norm": 1.0094044208526611,
      "learning_rate": 2.8879210220673635e-05,
      "loss": 0.0635,
      "step": 18190
    },
    {
      "epoch": 4.227642276422764,
      "grad_norm": 1.814272403717041,
      "learning_rate": 2.8867595818815336e-05,
      "loss": 0.126,
      "step": 18200
    },
    {
      "epoch": 4.229965156794425,
      "grad_norm": 0.9982312321662903,
      "learning_rate": 2.8855981416957028e-05,
      "loss": 0.1988,
      "step": 18210
    },
    {
      "epoch": 4.232288037166086,
      "grad_norm": 0.6970949769020081,
      "learning_rate": 2.8844367015098722e-05,
      "loss": 0.0995,
      "step": 18220
    },
    {
      "epoch": 4.234610917537747,
      "grad_norm": 0.5129400491714478,
      "learning_rate": 2.883275261324042e-05,
      "loss": 0.0808,
      "step": 18230
    },
    {
      "epoch": 4.2369337979094075,
      "grad_norm": 0.7152204513549805,
      "learning_rate": 2.8821138211382115e-05,
      "loss": 0.1193,
      "step": 18240
    },
    {
      "epoch": 4.239256678281069,
      "grad_norm": 0.5701286792755127,
      "learning_rate": 2.880952380952381e-05,
      "loss": 0.1326,
      "step": 18250
    },
    {
      "epoch": 4.241579558652729,
      "grad_norm": 0.6648095846176147,
      "learning_rate": 2.8797909407665508e-05,
      "loss": 0.0785,
      "step": 18260
    },
    {
      "epoch": 4.2439024390243905,
      "grad_norm": 0.7009878754615784,
      "learning_rate": 2.8786295005807202e-05,
      "loss": 0.0872,
      "step": 18270
    },
    {
      "epoch": 4.246225319396051,
      "grad_norm": 0.4414304494857788,
      "learning_rate": 2.87746806039489e-05,
      "loss": 0.0493,
      "step": 18280
    },
    {
      "epoch": 4.248548199767712,
      "grad_norm": 0.6664336323738098,
      "learning_rate": 2.8763066202090595e-05,
      "loss": 0.1465,
      "step": 18290
    },
    {
      "epoch": 4.2508710801393725,
      "grad_norm": 0.6832633018493652,
      "learning_rate": 2.8751451800232286e-05,
      "loss": 0.104,
      "step": 18300
    },
    {
      "epoch": 4.253193960511034,
      "grad_norm": 1.5923678874969482,
      "learning_rate": 2.8739837398373988e-05,
      "loss": 0.1153,
      "step": 18310
    },
    {
      "epoch": 4.255516840882694,
      "grad_norm": 0.6954941749572754,
      "learning_rate": 2.872822299651568e-05,
      "loss": 0.0965,
      "step": 18320
    },
    {
      "epoch": 4.2578397212543555,
      "grad_norm": 0.7295331358909607,
      "learning_rate": 2.871660859465738e-05,
      "loss": 0.1413,
      "step": 18330
    },
    {
      "epoch": 4.260162601626016,
      "grad_norm": 1.2523744106292725,
      "learning_rate": 2.8704994192799072e-05,
      "loss": 0.1354,
      "step": 18340
    },
    {
      "epoch": 4.262485481997677,
      "grad_norm": 1.3366724252700806,
      "learning_rate": 2.8693379790940767e-05,
      "loss": 0.1353,
      "step": 18350
    },
    {
      "epoch": 4.264808362369338,
      "grad_norm": 1.0624395608901978,
      "learning_rate": 2.8681765389082465e-05,
      "loss": 0.1439,
      "step": 18360
    },
    {
      "epoch": 4.267131242740999,
      "grad_norm": 1.1064566373825073,
      "learning_rate": 2.867015098722416e-05,
      "loss": 0.0631,
      "step": 18370
    },
    {
      "epoch": 4.269454123112659,
      "grad_norm": 1.9619507789611816,
      "learning_rate": 2.8659698025551685e-05,
      "loss": 0.1441,
      "step": 18380
    },
    {
      "epoch": 4.2717770034843205,
      "grad_norm": 0.9967785477638245,
      "learning_rate": 2.8648083623693383e-05,
      "loss": 0.1525,
      "step": 18390
    },
    {
      "epoch": 4.274099883855982,
      "grad_norm": 2.2626900672912598,
      "learning_rate": 2.8636469221835077e-05,
      "loss": 0.1225,
      "step": 18400
    },
    {
      "epoch": 4.276422764227642,
      "grad_norm": 1.4764118194580078,
      "learning_rate": 2.8624854819976772e-05,
      "loss": 0.148,
      "step": 18410
    },
    {
      "epoch": 4.2787456445993035,
      "grad_norm": 0.8290586471557617,
      "learning_rate": 2.861324041811847e-05,
      "loss": 0.0854,
      "step": 18420
    },
    {
      "epoch": 4.281068524970964,
      "grad_norm": 0.8174644112586975,
      "learning_rate": 2.8601626016260165e-05,
      "loss": 0.1383,
      "step": 18430
    },
    {
      "epoch": 4.283391405342625,
      "grad_norm": 2.4697935581207275,
      "learning_rate": 2.8590011614401856e-05,
      "loss": 0.0924,
      "step": 18440
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.7452070713043213,
      "learning_rate": 2.8578397212543557e-05,
      "loss": 0.0882,
      "step": 18450
    },
    {
      "epoch": 4.288037166085947,
      "grad_norm": 2.3995933532714844,
      "learning_rate": 2.856678281068525e-05,
      "loss": 0.1281,
      "step": 18460
    },
    {
      "epoch": 4.290360046457607,
      "grad_norm": 2.026954174041748,
      "learning_rate": 2.855516840882695e-05,
      "loss": 0.1988,
      "step": 18470
    },
    {
      "epoch": 4.2926829268292686,
      "grad_norm": 0.8379915356636047,
      "learning_rate": 2.854355400696864e-05,
      "loss": 0.0906,
      "step": 18480
    },
    {
      "epoch": 4.295005807200929,
      "grad_norm": 0.8235366940498352,
      "learning_rate": 2.8531939605110336e-05,
      "loss": 0.0924,
      "step": 18490
    },
    {
      "epoch": 4.29732868757259,
      "grad_norm": 1.0949963331222534,
      "learning_rate": 2.8520325203252034e-05,
      "loss": 0.1701,
      "step": 18500
    },
    {
      "epoch": 4.299651567944251,
      "grad_norm": 0.45234671235084534,
      "learning_rate": 2.850871080139373e-05,
      "loss": 0.12,
      "step": 18510
    },
    {
      "epoch": 4.301974448315912,
      "grad_norm": 1.1241990327835083,
      "learning_rate": 2.8497096399535427e-05,
      "loss": 0.1376,
      "step": 18520
    },
    {
      "epoch": 4.304297328687572,
      "grad_norm": 0.8641175031661987,
      "learning_rate": 2.848548199767712e-05,
      "loss": 0.153,
      "step": 18530
    },
    {
      "epoch": 4.306620209059234,
      "grad_norm": 0.6014431715011597,
      "learning_rate": 2.8473867595818816e-05,
      "loss": 0.1357,
      "step": 18540
    },
    {
      "epoch": 4.308943089430894,
      "grad_norm": 0.7594326138496399,
      "learning_rate": 2.8462253193960514e-05,
      "loss": 0.0909,
      "step": 18550
    },
    {
      "epoch": 4.311265969802555,
      "grad_norm": 1.378519892692566,
      "learning_rate": 2.845063879210221e-05,
      "loss": 0.1485,
      "step": 18560
    },
    {
      "epoch": 4.313588850174216,
      "grad_norm": 0.5870124697685242,
      "learning_rate": 2.84390243902439e-05,
      "loss": 0.0846,
      "step": 18570
    },
    {
      "epoch": 4.315911730545877,
      "grad_norm": 1.052875280380249,
      "learning_rate": 2.8427409988385602e-05,
      "loss": 0.1405,
      "step": 18580
    },
    {
      "epoch": 4.318234610917537,
      "grad_norm": 0.7809872031211853,
      "learning_rate": 2.8415795586527293e-05,
      "loss": 0.0787,
      "step": 18590
    },
    {
      "epoch": 4.320557491289199,
      "grad_norm": 0.6988400816917419,
      "learning_rate": 2.8404181184668994e-05,
      "loss": 0.0554,
      "step": 18600
    },
    {
      "epoch": 4.32288037166086,
      "grad_norm": 1.2509043216705322,
      "learning_rate": 2.8392566782810686e-05,
      "loss": 0.1712,
      "step": 18610
    },
    {
      "epoch": 4.32520325203252,
      "grad_norm": 0.9314916729927063,
      "learning_rate": 2.838095238095238e-05,
      "loss": 0.1559,
      "step": 18620
    },
    {
      "epoch": 4.327526132404181,
      "grad_norm": 0.6313068866729736,
      "learning_rate": 2.836933797909408e-05,
      "loss": 0.1125,
      "step": 18630
    },
    {
      "epoch": 4.329849012775842,
      "grad_norm": 1.2804322242736816,
      "learning_rate": 2.8357723577235773e-05,
      "loss": 0.1117,
      "step": 18640
    },
    {
      "epoch": 4.332171893147503,
      "grad_norm": 0.7551136016845703,
      "learning_rate": 2.834610917537747e-05,
      "loss": 0.1246,
      "step": 18650
    },
    {
      "epoch": 4.334494773519164,
      "grad_norm": 0.6287546157836914,
      "learning_rate": 2.8334494773519166e-05,
      "loss": 0.0921,
      "step": 18660
    },
    {
      "epoch": 4.336817653890825,
      "grad_norm": 1.9469053745269775,
      "learning_rate": 2.832288037166086e-05,
      "loss": 0.1597,
      "step": 18670
    },
    {
      "epoch": 4.339140534262485,
      "grad_norm": 0.915131688117981,
      "learning_rate": 2.831126596980256e-05,
      "loss": 0.1679,
      "step": 18680
    },
    {
      "epoch": 4.341463414634147,
      "grad_norm": 0.47478142380714417,
      "learning_rate": 2.8299651567944253e-05,
      "loss": 0.1258,
      "step": 18690
    },
    {
      "epoch": 4.343786295005807,
      "grad_norm": 1.0918556451797485,
      "learning_rate": 2.8288037166085945e-05,
      "loss": 0.2102,
      "step": 18700
    },
    {
      "epoch": 4.346109175377468,
      "grad_norm": 1.4198065996170044,
      "learning_rate": 2.8276422764227646e-05,
      "loss": 0.1082,
      "step": 18710
    },
    {
      "epoch": 4.348432055749129,
      "grad_norm": 0.9787256717681885,
      "learning_rate": 2.8264808362369337e-05,
      "loss": 0.1534,
      "step": 18720
    },
    {
      "epoch": 4.35075493612079,
      "grad_norm": 1.1564027070999146,
      "learning_rate": 2.825319396051104e-05,
      "loss": 0.0817,
      "step": 18730
    },
    {
      "epoch": 4.35307781649245,
      "grad_norm": 0.911548912525177,
      "learning_rate": 2.824157955865273e-05,
      "loss": 0.1046,
      "step": 18740
    },
    {
      "epoch": 4.355400696864112,
      "grad_norm": 1.4148495197296143,
      "learning_rate": 2.8229965156794425e-05,
      "loss": 0.0731,
      "step": 18750
    },
    {
      "epoch": 4.357723577235772,
      "grad_norm": 0.4040108323097229,
      "learning_rate": 2.8218350754936123e-05,
      "loss": 0.1182,
      "step": 18760
    },
    {
      "epoch": 4.360046457607433,
      "grad_norm": 1.5362597703933716,
      "learning_rate": 2.8206736353077817e-05,
      "loss": 0.1196,
      "step": 18770
    },
    {
      "epoch": 4.362369337979094,
      "grad_norm": 1.155227541923523,
      "learning_rate": 2.8195121951219512e-05,
      "loss": 0.1276,
      "step": 18780
    },
    {
      "epoch": 4.364692218350755,
      "grad_norm": 0.7100505828857422,
      "learning_rate": 2.818350754936121e-05,
      "loss": 0.061,
      "step": 18790
    },
    {
      "epoch": 4.3670150987224154,
      "grad_norm": 1.5544086694717407,
      "learning_rate": 2.8171893147502905e-05,
      "loss": 0.0968,
      "step": 18800
    },
    {
      "epoch": 4.369337979094077,
      "grad_norm": 0.8822787404060364,
      "learning_rate": 2.8160278745644603e-05,
      "loss": 0.1145,
      "step": 18810
    },
    {
      "epoch": 4.371660859465737,
      "grad_norm": 0.7452330589294434,
      "learning_rate": 2.8148664343786298e-05,
      "loss": 0.1111,
      "step": 18820
    },
    {
      "epoch": 4.373983739837398,
      "grad_norm": 1.9340620040893555,
      "learning_rate": 2.813704994192799e-05,
      "loss": 0.1282,
      "step": 18830
    },
    {
      "epoch": 4.376306620209059,
      "grad_norm": 0.9846084713935852,
      "learning_rate": 2.812543554006969e-05,
      "loss": 0.1121,
      "step": 18840
    },
    {
      "epoch": 4.37862950058072,
      "grad_norm": 1.827585220336914,
      "learning_rate": 2.811382113821138e-05,
      "loss": 0.0896,
      "step": 18850
    },
    {
      "epoch": 4.380952380952381,
      "grad_norm": 0.724084198474884,
      "learning_rate": 2.8102206736353083e-05,
      "loss": 0.1027,
      "step": 18860
    },
    {
      "epoch": 4.383275261324042,
      "grad_norm": 0.6360085010528564,
      "learning_rate": 2.8090592334494774e-05,
      "loss": 0.0821,
      "step": 18870
    },
    {
      "epoch": 4.385598141695703,
      "grad_norm": 2.7187743186950684,
      "learning_rate": 2.807897793263647e-05,
      "loss": 0.1837,
      "step": 18880
    },
    {
      "epoch": 4.3879210220673635,
      "grad_norm": 1.0627310276031494,
      "learning_rate": 2.8067363530778167e-05,
      "loss": 0.0786,
      "step": 18890
    },
    {
      "epoch": 4.390243902439025,
      "grad_norm": 1.1339226961135864,
      "learning_rate": 2.8055749128919862e-05,
      "loss": 0.1379,
      "step": 18900
    },
    {
      "epoch": 4.392566782810685,
      "grad_norm": 0.7610214352607727,
      "learning_rate": 2.8044134727061556e-05,
      "loss": 0.1517,
      "step": 18910
    },
    {
      "epoch": 4.394889663182346,
      "grad_norm": 2.4225640296936035,
      "learning_rate": 2.8032520325203254e-05,
      "loss": 0.1048,
      "step": 18920
    },
    {
      "epoch": 4.397212543554007,
      "grad_norm": 1.4390099048614502,
      "learning_rate": 2.802090592334495e-05,
      "loss": 0.1924,
      "step": 18930
    },
    {
      "epoch": 4.399535423925668,
      "grad_norm": 1.3273351192474365,
      "learning_rate": 2.8009291521486647e-05,
      "loss": 0.1706,
      "step": 18940
    },
    {
      "epoch": 4.4018583042973285,
      "grad_norm": 2.656667947769165,
      "learning_rate": 2.7997677119628342e-05,
      "loss": 0.0745,
      "step": 18950
    },
    {
      "epoch": 4.40418118466899,
      "grad_norm": 0.7564099431037903,
      "learning_rate": 2.7986062717770033e-05,
      "loss": 0.2847,
      "step": 18960
    },
    {
      "epoch": 4.40650406504065,
      "grad_norm": 0.6470745801925659,
      "learning_rate": 2.7974448315911735e-05,
      "loss": 0.0764,
      "step": 18970
    },
    {
      "epoch": 4.4088269454123115,
      "grad_norm": 0.7905967235565186,
      "learning_rate": 2.7962833914053426e-05,
      "loss": 0.1247,
      "step": 18980
    },
    {
      "epoch": 4.411149825783972,
      "grad_norm": 0.9913405776023865,
      "learning_rate": 2.7951219512195127e-05,
      "loss": 0.0567,
      "step": 18990
    },
    {
      "epoch": 4.413472706155633,
      "grad_norm": 1.5419479608535767,
      "learning_rate": 2.793960511033682e-05,
      "loss": 0.1186,
      "step": 19000
    },
    {
      "epoch": 4.4157955865272935,
      "grad_norm": 0.868355393409729,
      "learning_rate": 2.7927990708478513e-05,
      "loss": 0.1224,
      "step": 19010
    },
    {
      "epoch": 4.418118466898955,
      "grad_norm": 1.020480751991272,
      "learning_rate": 2.791637630662021e-05,
      "loss": 0.1616,
      "step": 19020
    },
    {
      "epoch": 4.420441347270615,
      "grad_norm": 1.0902327299118042,
      "learning_rate": 2.7904761904761906e-05,
      "loss": 0.0715,
      "step": 19030
    },
    {
      "epoch": 4.4227642276422765,
      "grad_norm": 2.1856460571289062,
      "learning_rate": 2.78931475029036e-05,
      "loss": 0.1249,
      "step": 19040
    },
    {
      "epoch": 4.425087108013937,
      "grad_norm": 2.2303712368011475,
      "learning_rate": 2.78815331010453e-05,
      "loss": 0.1541,
      "step": 19050
    },
    {
      "epoch": 4.427409988385598,
      "grad_norm": 1.0091969966888428,
      "learning_rate": 2.7869918699186993e-05,
      "loss": 0.1135,
      "step": 19060
    },
    {
      "epoch": 4.4297328687572595,
      "grad_norm": 0.757573664188385,
      "learning_rate": 2.785830429732869e-05,
      "loss": 0.1126,
      "step": 19070
    },
    {
      "epoch": 4.43205574912892,
      "grad_norm": 0.9456603527069092,
      "learning_rate": 2.7846689895470386e-05,
      "loss": 0.1208,
      "step": 19080
    },
    {
      "epoch": 4.43437862950058,
      "grad_norm": 1.5111594200134277,
      "learning_rate": 2.7835075493612077e-05,
      "loss": 0.145,
      "step": 19090
    },
    {
      "epoch": 4.4367015098722415,
      "grad_norm": 1.1604582071304321,
      "learning_rate": 2.782346109175378e-05,
      "loss": 0.0714,
      "step": 19100
    },
    {
      "epoch": 4.439024390243903,
      "grad_norm": 1.305237054824829,
      "learning_rate": 2.781184668989547e-05,
      "loss": 0.0972,
      "step": 19110
    },
    {
      "epoch": 4.441347270615563,
      "grad_norm": 1.6922004222869873,
      "learning_rate": 2.780023228803717e-05,
      "loss": 0.1217,
      "step": 19120
    },
    {
      "epoch": 4.4436701509872245,
      "grad_norm": 0.8366593718528748,
      "learning_rate": 2.7788617886178863e-05,
      "loss": 0.1524,
      "step": 19130
    },
    {
      "epoch": 4.445993031358885,
      "grad_norm": 1.055409550666809,
      "learning_rate": 2.7777003484320558e-05,
      "loss": 0.1397,
      "step": 19140
    },
    {
      "epoch": 4.448315911730546,
      "grad_norm": 1.1603885889053345,
      "learning_rate": 2.7765389082462256e-05,
      "loss": 0.0923,
      "step": 19150
    },
    {
      "epoch": 4.450638792102207,
      "grad_norm": 1.0150479078292847,
      "learning_rate": 2.775377468060395e-05,
      "loss": 0.1007,
      "step": 19160
    },
    {
      "epoch": 4.452961672473868,
      "grad_norm": 1.5972334146499634,
      "learning_rate": 2.7742160278745645e-05,
      "loss": 0.0809,
      "step": 19170
    },
    {
      "epoch": 4.455284552845528,
      "grad_norm": 0.821060299873352,
      "learning_rate": 2.7730545876887343e-05,
      "loss": 0.1047,
      "step": 19180
    },
    {
      "epoch": 4.4576074332171896,
      "grad_norm": 1.6859525442123413,
      "learning_rate": 2.7718931475029038e-05,
      "loss": 0.1092,
      "step": 19190
    },
    {
      "epoch": 4.45993031358885,
      "grad_norm": 0.9136478900909424,
      "learning_rate": 2.7707317073170736e-05,
      "loss": 0.1229,
      "step": 19200
    },
    {
      "epoch": 4.462253193960511,
      "grad_norm": 0.7507486343383789,
      "learning_rate": 2.769570267131243e-05,
      "loss": 0.1248,
      "step": 19210
    },
    {
      "epoch": 4.464576074332172,
      "grad_norm": 2.103896141052246,
      "learning_rate": 2.7684088269454122e-05,
      "loss": 0.0767,
      "step": 19220
    },
    {
      "epoch": 4.466898954703833,
      "grad_norm": 1.0838245153427124,
      "learning_rate": 2.7672473867595823e-05,
      "loss": 0.1173,
      "step": 19230
    },
    {
      "epoch": 4.469221835075493,
      "grad_norm": 3.8832406997680664,
      "learning_rate": 2.7660859465737515e-05,
      "loss": 0.0994,
      "step": 19240
    },
    {
      "epoch": 4.471544715447155,
      "grad_norm": 1.9930158853530884,
      "learning_rate": 2.764924506387921e-05,
      "loss": 0.2496,
      "step": 19250
    },
    {
      "epoch": 4.473867595818815,
      "grad_norm": 0.47839370369911194,
      "learning_rate": 2.7637630662020907e-05,
      "loss": 0.0742,
      "step": 19260
    },
    {
      "epoch": 4.476190476190476,
      "grad_norm": 0.8754600286483765,
      "learning_rate": 2.7626016260162602e-05,
      "loss": 0.1294,
      "step": 19270
    },
    {
      "epoch": 4.478513356562137,
      "grad_norm": 1.477927565574646,
      "learning_rate": 2.76144018583043e-05,
      "loss": 0.089,
      "step": 19280
    },
    {
      "epoch": 4.480836236933798,
      "grad_norm": 1.0587838888168335,
      "learning_rate": 2.7602787456445995e-05,
      "loss": 0.17,
      "step": 19290
    },
    {
      "epoch": 4.483159117305458,
      "grad_norm": 0.6187019348144531,
      "learning_rate": 2.759117305458769e-05,
      "loss": 0.1251,
      "step": 19300
    },
    {
      "epoch": 4.48548199767712,
      "grad_norm": 2.4772331714630127,
      "learning_rate": 2.7579558652729387e-05,
      "loss": 0.0805,
      "step": 19310
    },
    {
      "epoch": 4.487804878048781,
      "grad_norm": 0.6083593368530273,
      "learning_rate": 2.7567944250871082e-05,
      "loss": 0.0663,
      "step": 19320
    },
    {
      "epoch": 4.490127758420441,
      "grad_norm": 0.9222428798675537,
      "learning_rate": 2.755632984901278e-05,
      "loss": 0.097,
      "step": 19330
    },
    {
      "epoch": 4.492450638792103,
      "grad_norm": 1.7228119373321533,
      "learning_rate": 2.7544715447154475e-05,
      "loss": 0.1533,
      "step": 19340
    },
    {
      "epoch": 4.494773519163763,
      "grad_norm": 1.5611597299575806,
      "learning_rate": 2.7533101045296166e-05,
      "loss": 0.0937,
      "step": 19350
    },
    {
      "epoch": 4.497096399535424,
      "grad_norm": 0.7071300745010376,
      "learning_rate": 2.7521486643437868e-05,
      "loss": 0.1359,
      "step": 19360
    },
    {
      "epoch": 4.499419279907085,
      "grad_norm": 1.0659459829330444,
      "learning_rate": 2.750987224157956e-05,
      "loss": 0.0787,
      "step": 19370
    },
    {
      "epoch": 4.501742160278746,
      "grad_norm": 0.6269421577453613,
      "learning_rate": 2.7498257839721253e-05,
      "loss": 0.1784,
      "step": 19380
    },
    {
      "epoch": 4.504065040650406,
      "grad_norm": 0.739120602607727,
      "learning_rate": 2.748664343786295e-05,
      "loss": 0.0964,
      "step": 19390
    },
    {
      "epoch": 4.506387921022068,
      "grad_norm": 1.3706083297729492,
      "learning_rate": 2.7475029036004646e-05,
      "loss": 0.1329,
      "step": 19400
    },
    {
      "epoch": 4.508710801393728,
      "grad_norm": 1.4224916696548462,
      "learning_rate": 2.7463414634146344e-05,
      "loss": 0.1699,
      "step": 19410
    },
    {
      "epoch": 4.511033681765389,
      "grad_norm": 1.410879135131836,
      "learning_rate": 2.745180023228804e-05,
      "loss": 0.1206,
      "step": 19420
    },
    {
      "epoch": 4.51335656213705,
      "grad_norm": 0.7727980017662048,
      "learning_rate": 2.7440185830429734e-05,
      "loss": 0.0707,
      "step": 19430
    },
    {
      "epoch": 4.515679442508711,
      "grad_norm": 0.6439163684844971,
      "learning_rate": 2.742857142857143e-05,
      "loss": 0.1027,
      "step": 19440
    },
    {
      "epoch": 4.518002322880371,
      "grad_norm": 3.6426186561584473,
      "learning_rate": 2.7416957026713126e-05,
      "loss": 0.1177,
      "step": 19450
    },
    {
      "epoch": 4.520325203252033,
      "grad_norm": 1.176737904548645,
      "learning_rate": 2.7405342624854824e-05,
      "loss": 0.2384,
      "step": 19460
    },
    {
      "epoch": 4.522648083623693,
      "grad_norm": 1.400922179222107,
      "learning_rate": 2.739372822299652e-05,
      "loss": 0.0871,
      "step": 19470
    },
    {
      "epoch": 4.524970963995354,
      "grad_norm": 1.3781497478485107,
      "learning_rate": 2.738211382113821e-05,
      "loss": 0.1238,
      "step": 19480
    },
    {
      "epoch": 4.527293844367015,
      "grad_norm": 1.6905022859573364,
      "learning_rate": 2.7370499419279912e-05,
      "loss": 0.1519,
      "step": 19490
    },
    {
      "epoch": 4.529616724738676,
      "grad_norm": 1.486525297164917,
      "learning_rate": 2.7358885017421603e-05,
      "loss": 0.1499,
      "step": 19500
    },
    {
      "epoch": 4.5319396051103364,
      "grad_norm": 0.6705301403999329,
      "learning_rate": 2.7347270615563298e-05,
      "loss": 0.1268,
      "step": 19510
    },
    {
      "epoch": 4.534262485481998,
      "grad_norm": 0.8855826258659363,
      "learning_rate": 2.7335656213704996e-05,
      "loss": 0.1439,
      "step": 19520
    },
    {
      "epoch": 4.536585365853659,
      "grad_norm": 0.8107122182846069,
      "learning_rate": 2.732404181184669e-05,
      "loss": 0.1254,
      "step": 19530
    },
    {
      "epoch": 4.538908246225319,
      "grad_norm": 1.262882947921753,
      "learning_rate": 2.731242740998839e-05,
      "loss": 0.1236,
      "step": 19540
    },
    {
      "epoch": 4.54123112659698,
      "grad_norm": 0.9359315633773804,
      "learning_rate": 2.7300813008130083e-05,
      "loss": 0.1884,
      "step": 19550
    },
    {
      "epoch": 4.543554006968641,
      "grad_norm": 1.5644491910934448,
      "learning_rate": 2.7289198606271778e-05,
      "loss": 0.0976,
      "step": 19560
    },
    {
      "epoch": 4.545876887340302,
      "grad_norm": 1.3171617984771729,
      "learning_rate": 2.7277584204413476e-05,
      "loss": 0.068,
      "step": 19570
    },
    {
      "epoch": 4.548199767711963,
      "grad_norm": 1.4576618671417236,
      "learning_rate": 2.726596980255517e-05,
      "loss": 0.0982,
      "step": 19580
    },
    {
      "epoch": 4.550522648083624,
      "grad_norm": 1.0773507356643677,
      "learning_rate": 2.7254355400696862e-05,
      "loss": 0.0702,
      "step": 19590
    },
    {
      "epoch": 4.5528455284552845,
      "grad_norm": 0.7210404276847839,
      "learning_rate": 2.7242740998838563e-05,
      "loss": 0.1229,
      "step": 19600
    },
    {
      "epoch": 4.555168408826946,
      "grad_norm": 2.0681726932525635,
      "learning_rate": 2.7231126596980255e-05,
      "loss": 0.1118,
      "step": 19610
    },
    {
      "epoch": 4.557491289198606,
      "grad_norm": 0.6576321721076965,
      "learning_rate": 2.7219512195121956e-05,
      "loss": 0.0831,
      "step": 19620
    },
    {
      "epoch": 4.559814169570267,
      "grad_norm": 0.9082244038581848,
      "learning_rate": 2.7207897793263647e-05,
      "loss": 0.1319,
      "step": 19630
    },
    {
      "epoch": 4.562137049941928,
      "grad_norm": 1.099510669708252,
      "learning_rate": 2.7196283391405342e-05,
      "loss": 0.155,
      "step": 19640
    },
    {
      "epoch": 4.564459930313589,
      "grad_norm": 1.2569117546081543,
      "learning_rate": 2.718466898954704e-05,
      "loss": 0.1155,
      "step": 19650
    },
    {
      "epoch": 4.5667828106852495,
      "grad_norm": 0.9848307967185974,
      "learning_rate": 2.7173054587688735e-05,
      "loss": 0.0749,
      "step": 19660
    },
    {
      "epoch": 4.569105691056911,
      "grad_norm": 1.183286190032959,
      "learning_rate": 2.7161440185830433e-05,
      "loss": 0.0982,
      "step": 19670
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 1.4784220457077026,
      "learning_rate": 2.7149825783972128e-05,
      "loss": 0.2249,
      "step": 19680
    },
    {
      "epoch": 4.5737514518002325,
      "grad_norm": 0.9258034825325012,
      "learning_rate": 2.7138211382113822e-05,
      "loss": 0.1092,
      "step": 19690
    },
    {
      "epoch": 4.576074332171893,
      "grad_norm": 1.2591770887374878,
      "learning_rate": 2.712659698025552e-05,
      "loss": 0.1198,
      "step": 19700
    },
    {
      "epoch": 4.578397212543554,
      "grad_norm": 1.8657302856445312,
      "learning_rate": 2.7114982578397215e-05,
      "loss": 0.2297,
      "step": 19710
    },
    {
      "epoch": 4.5807200929152145,
      "grad_norm": 2.776594877243042,
      "learning_rate": 2.7103368176538906e-05,
      "loss": 0.133,
      "step": 19720
    },
    {
      "epoch": 4.583042973286876,
      "grad_norm": 0.3345721662044525,
      "learning_rate": 2.7091753774680608e-05,
      "loss": 0.075,
      "step": 19730
    },
    {
      "epoch": 4.585365853658536,
      "grad_norm": 1.6177514791488647,
      "learning_rate": 2.70801393728223e-05,
      "loss": 0.134,
      "step": 19740
    },
    {
      "epoch": 4.5876887340301975,
      "grad_norm": 1.3045634031295776,
      "learning_rate": 2.7068524970964e-05,
      "loss": 0.1117,
      "step": 19750
    },
    {
      "epoch": 4.590011614401858,
      "grad_norm": 0.8571550250053406,
      "learning_rate": 2.7056910569105692e-05,
      "loss": 0.166,
      "step": 19760
    },
    {
      "epoch": 4.592334494773519,
      "grad_norm": 1.2516002655029297,
      "learning_rate": 2.7045296167247386e-05,
      "loss": 0.131,
      "step": 19770
    },
    {
      "epoch": 4.5946573751451805,
      "grad_norm": 1.769269585609436,
      "learning_rate": 2.7033681765389084e-05,
      "loss": 0.0875,
      "step": 19780
    },
    {
      "epoch": 4.596980255516841,
      "grad_norm": 0.6873233914375305,
      "learning_rate": 2.702206736353078e-05,
      "loss": 0.1086,
      "step": 19790
    },
    {
      "epoch": 4.599303135888501,
      "grad_norm": 1.7134002447128296,
      "learning_rate": 2.7010452961672477e-05,
      "loss": 0.1446,
      "step": 19800
    },
    {
      "epoch": 4.6016260162601625,
      "grad_norm": 0.9425045847892761,
      "learning_rate": 2.6998838559814172e-05,
      "loss": 0.0886,
      "step": 19810
    },
    {
      "epoch": 4.603948896631824,
      "grad_norm": 0.8505409955978394,
      "learning_rate": 2.6987224157955867e-05,
      "loss": 0.0641,
      "step": 19820
    },
    {
      "epoch": 4.606271777003484,
      "grad_norm": 1.1148024797439575,
      "learning_rate": 2.6975609756097565e-05,
      "loss": 0.1,
      "step": 19830
    },
    {
      "epoch": 4.6085946573751455,
      "grad_norm": 0.602372944355011,
      "learning_rate": 2.696399535423926e-05,
      "loss": 0.1008,
      "step": 19840
    },
    {
      "epoch": 4.610917537746806,
      "grad_norm": 1.777487874031067,
      "learning_rate": 2.695238095238095e-05,
      "loss": 0.106,
      "step": 19850
    },
    {
      "epoch": 4.613240418118467,
      "grad_norm": 1.4305607080459595,
      "learning_rate": 2.6940766550522652e-05,
      "loss": 0.0694,
      "step": 19860
    },
    {
      "epoch": 4.615563298490128,
      "grad_norm": 0.9022696614265442,
      "learning_rate": 2.6929152148664343e-05,
      "loss": 0.1395,
      "step": 19870
    },
    {
      "epoch": 4.617886178861789,
      "grad_norm": 0.8350735902786255,
      "learning_rate": 2.691753774680604e-05,
      "loss": 0.0956,
      "step": 19880
    },
    {
      "epoch": 4.620209059233449,
      "grad_norm": 2.435668706893921,
      "learning_rate": 2.6905923344947736e-05,
      "loss": 0.1481,
      "step": 19890
    },
    {
      "epoch": 4.6225319396051106,
      "grad_norm": 0.8079342842102051,
      "learning_rate": 2.689430894308943e-05,
      "loss": 0.0948,
      "step": 19900
    },
    {
      "epoch": 4.624854819976771,
      "grad_norm": 0.6908310055732727,
      "learning_rate": 2.688269454123113e-05,
      "loss": 0.118,
      "step": 19910
    },
    {
      "epoch": 4.627177700348432,
      "grad_norm": 0.5872422456741333,
      "learning_rate": 2.6871080139372823e-05,
      "loss": 0.1301,
      "step": 19920
    },
    {
      "epoch": 4.629500580720093,
      "grad_norm": 1.2687300443649292,
      "learning_rate": 2.685946573751452e-05,
      "loss": 0.0773,
      "step": 19930
    },
    {
      "epoch": 4.631823461091754,
      "grad_norm": 0.8966443538665771,
      "learning_rate": 2.6847851335656216e-05,
      "loss": 0.1099,
      "step": 19940
    },
    {
      "epoch": 4.634146341463414,
      "grad_norm": 1.2301809787750244,
      "learning_rate": 2.683623693379791e-05,
      "loss": 0.0827,
      "step": 19950
    },
    {
      "epoch": 4.636469221835076,
      "grad_norm": 0.9388501048088074,
      "learning_rate": 2.682462253193961e-05,
      "loss": 0.0622,
      "step": 19960
    },
    {
      "epoch": 4.638792102206736,
      "grad_norm": 0.8678284883499146,
      "learning_rate": 2.6813008130081304e-05,
      "loss": 0.0801,
      "step": 19970
    },
    {
      "epoch": 4.641114982578397,
      "grad_norm": 0.619634211063385,
      "learning_rate": 2.6801393728222995e-05,
      "loss": 0.1567,
      "step": 19980
    },
    {
      "epoch": 4.643437862950059,
      "grad_norm": 0.7683736681938171,
      "learning_rate": 2.6789779326364693e-05,
      "loss": 0.139,
      "step": 19990
    },
    {
      "epoch": 4.645760743321719,
      "grad_norm": 2.982053279876709,
      "learning_rate": 2.6778164924506388e-05,
      "loss": 0.118,
      "step": 20000
    },
    {
      "epoch": 4.648083623693379,
      "grad_norm": 1.3465543985366821,
      "learning_rate": 2.6766550522648086e-05,
      "loss": 0.1541,
      "step": 20010
    },
    {
      "epoch": 4.650406504065041,
      "grad_norm": 1.0687450170516968,
      "learning_rate": 2.675493612078978e-05,
      "loss": 0.0819,
      "step": 20020
    },
    {
      "epoch": 4.652729384436702,
      "grad_norm": 2.0110766887664795,
      "learning_rate": 2.6743321718931475e-05,
      "loss": 0.119,
      "step": 20030
    },
    {
      "epoch": 4.655052264808362,
      "grad_norm": 0.9318245649337769,
      "learning_rate": 2.6731707317073173e-05,
      "loss": 0.0823,
      "step": 20040
    },
    {
      "epoch": 4.657375145180024,
      "grad_norm": 1.6250636577606201,
      "learning_rate": 2.6720092915214868e-05,
      "loss": 0.0817,
      "step": 20050
    },
    {
      "epoch": 4.659698025551684,
      "grad_norm": 1.2344211339950562,
      "learning_rate": 2.6708478513356562e-05,
      "loss": 0.1349,
      "step": 20060
    },
    {
      "epoch": 4.662020905923345,
      "grad_norm": 1.2929946184158325,
      "learning_rate": 2.669686411149826e-05,
      "loss": 0.1289,
      "step": 20070
    },
    {
      "epoch": 4.664343786295006,
      "grad_norm": 1.151125192642212,
      "learning_rate": 2.6685249709639952e-05,
      "loss": 0.1387,
      "step": 20080
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 1.1092538833618164,
      "learning_rate": 2.6673635307781653e-05,
      "loss": 0.1278,
      "step": 20090
    },
    {
      "epoch": 4.668989547038327,
      "grad_norm": 0.34673887491226196,
      "learning_rate": 2.6662020905923344e-05,
      "loss": 0.1319,
      "step": 20100
    },
    {
      "epoch": 4.671312427409989,
      "grad_norm": 1.4722983837127686,
      "learning_rate": 2.665040650406504e-05,
      "loss": 0.1145,
      "step": 20110
    },
    {
      "epoch": 4.673635307781649,
      "grad_norm": 0.7699554562568665,
      "learning_rate": 2.6638792102206737e-05,
      "loss": 0.0733,
      "step": 20120
    },
    {
      "epoch": 4.67595818815331,
      "grad_norm": 1.375288724899292,
      "learning_rate": 2.6627177700348432e-05,
      "loss": 0.1045,
      "step": 20130
    },
    {
      "epoch": 4.678281068524971,
      "grad_norm": 0.8612656593322754,
      "learning_rate": 2.661556329849013e-05,
      "loss": 0.0594,
      "step": 20140
    },
    {
      "epoch": 4.680603948896632,
      "grad_norm": 1.5392341613769531,
      "learning_rate": 2.6603948896631825e-05,
      "loss": 0.0943,
      "step": 20150
    },
    {
      "epoch": 4.682926829268292,
      "grad_norm": 1.0198990106582642,
      "learning_rate": 2.659233449477352e-05,
      "loss": 0.057,
      "step": 20160
    },
    {
      "epoch": 4.685249709639954,
      "grad_norm": 2.303572416305542,
      "learning_rate": 2.6580720092915217e-05,
      "loss": 0.11,
      "step": 20170
    },
    {
      "epoch": 4.687572590011614,
      "grad_norm": 1.630902647972107,
      "learning_rate": 2.6569105691056912e-05,
      "loss": 0.1243,
      "step": 20180
    },
    {
      "epoch": 4.689895470383275,
      "grad_norm": 1.2935242652893066,
      "learning_rate": 2.6557491289198603e-05,
      "loss": 0.1199,
      "step": 20190
    },
    {
      "epoch": 4.692218350754936,
      "grad_norm": 1.8078579902648926,
      "learning_rate": 2.6545876887340305e-05,
      "loss": 0.185,
      "step": 20200
    },
    {
      "epoch": 4.694541231126597,
      "grad_norm": 0.9586426019668579,
      "learning_rate": 2.6534262485481996e-05,
      "loss": 0.0605,
      "step": 20210
    },
    {
      "epoch": 4.696864111498257,
      "grad_norm": 0.6279447674751282,
      "learning_rate": 2.6522648083623697e-05,
      "loss": 0.1726,
      "step": 20220
    },
    {
      "epoch": 4.699186991869919,
      "grad_norm": 0.8050382733345032,
      "learning_rate": 2.651103368176539e-05,
      "loss": 0.1217,
      "step": 20230
    },
    {
      "epoch": 4.70150987224158,
      "grad_norm": 0.9485641717910767,
      "learning_rate": 2.6499419279907083e-05,
      "loss": 0.1179,
      "step": 20240
    },
    {
      "epoch": 4.70383275261324,
      "grad_norm": 1.157566785812378,
      "learning_rate": 2.648780487804878e-05,
      "loss": 0.083,
      "step": 20250
    },
    {
      "epoch": 4.706155632984901,
      "grad_norm": 1.195604681968689,
      "learning_rate": 2.6476190476190476e-05,
      "loss": 0.1009,
      "step": 20260
    },
    {
      "epoch": 4.708478513356562,
      "grad_norm": 1.5602549314498901,
      "learning_rate": 2.6464576074332174e-05,
      "loss": 0.0763,
      "step": 20270
    },
    {
      "epoch": 4.710801393728223,
      "grad_norm": 0.884074330329895,
      "learning_rate": 2.645296167247387e-05,
      "loss": 0.1016,
      "step": 20280
    },
    {
      "epoch": 4.713124274099884,
      "grad_norm": 0.8765928149223328,
      "learning_rate": 2.6441347270615564e-05,
      "loss": 0.1256,
      "step": 20290
    },
    {
      "epoch": 4.715447154471545,
      "grad_norm": 0.39832255244255066,
      "learning_rate": 2.642973286875726e-05,
      "loss": 0.0715,
      "step": 20300
    },
    {
      "epoch": 4.7177700348432055,
      "grad_norm": 2.540525197982788,
      "learning_rate": 2.6418118466898956e-05,
      "loss": 0.1885,
      "step": 20310
    },
    {
      "epoch": 4.720092915214867,
      "grad_norm": 0.9581152200698853,
      "learning_rate": 2.6406504065040648e-05,
      "loss": 0.1229,
      "step": 20320
    },
    {
      "epoch": 4.722415795586527,
      "grad_norm": 1.3293436765670776,
      "learning_rate": 2.639488966318235e-05,
      "loss": 0.063,
      "step": 20330
    },
    {
      "epoch": 4.724738675958188,
      "grad_norm": 1.3047267198562622,
      "learning_rate": 2.638327526132404e-05,
      "loss": 0.0732,
      "step": 20340
    },
    {
      "epoch": 4.727061556329849,
      "grad_norm": 1.4292895793914795,
      "learning_rate": 2.6371660859465742e-05,
      "loss": 0.1254,
      "step": 20350
    },
    {
      "epoch": 4.72938443670151,
      "grad_norm": 0.8296884298324585,
      "learning_rate": 2.6360046457607433e-05,
      "loss": 0.1304,
      "step": 20360
    },
    {
      "epoch": 4.7317073170731705,
      "grad_norm": 1.9305700063705444,
      "learning_rate": 2.6348432055749128e-05,
      "loss": 0.107,
      "step": 20370
    },
    {
      "epoch": 4.734030197444832,
      "grad_norm": 1.4859145879745483,
      "learning_rate": 2.6336817653890826e-05,
      "loss": 0.1317,
      "step": 20380
    },
    {
      "epoch": 4.736353077816492,
      "grad_norm": 1.2767088413238525,
      "learning_rate": 2.632520325203252e-05,
      "loss": 0.088,
      "step": 20390
    },
    {
      "epoch": 4.7386759581881535,
      "grad_norm": 0.6531994938850403,
      "learning_rate": 2.631358885017422e-05,
      "loss": 0.0564,
      "step": 20400
    },
    {
      "epoch": 4.740998838559814,
      "grad_norm": 1.6768438816070557,
      "learning_rate": 2.6301974448315913e-05,
      "loss": 0.0786,
      "step": 20410
    },
    {
      "epoch": 4.743321718931475,
      "grad_norm": 0.61039137840271,
      "learning_rate": 2.6290360046457608e-05,
      "loss": 0.1106,
      "step": 20420
    },
    {
      "epoch": 4.7456445993031355,
      "grad_norm": 1.452541470527649,
      "learning_rate": 2.6278745644599306e-05,
      "loss": 0.0849,
      "step": 20430
    },
    {
      "epoch": 4.747967479674797,
      "grad_norm": 0.9041517376899719,
      "learning_rate": 2.6267131242741e-05,
      "loss": 0.1286,
      "step": 20440
    },
    {
      "epoch": 4.750290360046458,
      "grad_norm": 1.289804458618164,
      "learning_rate": 2.6255516840882692e-05,
      "loss": 0.11,
      "step": 20450
    },
    {
      "epoch": 4.7526132404181185,
      "grad_norm": 0.8325291872024536,
      "learning_rate": 2.6243902439024393e-05,
      "loss": 0.0886,
      "step": 20460
    },
    {
      "epoch": 4.754936120789779,
      "grad_norm": 0.8899287581443787,
      "learning_rate": 2.6232288037166085e-05,
      "loss": 0.1118,
      "step": 20470
    },
    {
      "epoch": 4.75725900116144,
      "grad_norm": 0.6552825570106506,
      "learning_rate": 2.6220673635307786e-05,
      "loss": 0.1403,
      "step": 20480
    },
    {
      "epoch": 4.7595818815331015,
      "grad_norm": 0.9339629411697388,
      "learning_rate": 2.6209059233449477e-05,
      "loss": 0.168,
      "step": 20490
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.8331664204597473,
      "learning_rate": 2.6197444831591172e-05,
      "loss": 0.2008,
      "step": 20500
    },
    {
      "epoch": 4.764227642276423,
      "grad_norm": 1.1038168668746948,
      "learning_rate": 2.618583042973287e-05,
      "loss": 0.1151,
      "step": 20510
    },
    {
      "epoch": 4.7665505226480835,
      "grad_norm": 0.5017403960227966,
      "learning_rate": 2.6174216027874565e-05,
      "loss": 0.0927,
      "step": 20520
    },
    {
      "epoch": 4.768873403019745,
      "grad_norm": 0.8725544810295105,
      "learning_rate": 2.616260162601626e-05,
      "loss": 0.1562,
      "step": 20530
    },
    {
      "epoch": 4.771196283391405,
      "grad_norm": 0.6909850835800171,
      "learning_rate": 2.6150987224157957e-05,
      "loss": 0.1407,
      "step": 20540
    },
    {
      "epoch": 4.7735191637630665,
      "grad_norm": 1.1229009628295898,
      "learning_rate": 2.6139372822299652e-05,
      "loss": 0.0943,
      "step": 20550
    },
    {
      "epoch": 4.775842044134727,
      "grad_norm": 0.8071512579917908,
      "learning_rate": 2.612775842044135e-05,
      "loss": 0.0721,
      "step": 20560
    },
    {
      "epoch": 4.778164924506388,
      "grad_norm": 0.8105112910270691,
      "learning_rate": 2.6116144018583045e-05,
      "loss": 0.13,
      "step": 20570
    },
    {
      "epoch": 4.780487804878049,
      "grad_norm": 1.0508829355239868,
      "learning_rate": 2.6104529616724736e-05,
      "loss": 0.0822,
      "step": 20580
    },
    {
      "epoch": 4.78281068524971,
      "grad_norm": 0.7085626125335693,
      "learning_rate": 2.6092915214866438e-05,
      "loss": 0.0704,
      "step": 20590
    },
    {
      "epoch": 4.78513356562137,
      "grad_norm": 1.5564087629318237,
      "learning_rate": 2.608130081300813e-05,
      "loss": 0.0965,
      "step": 20600
    },
    {
      "epoch": 4.7874564459930316,
      "grad_norm": 1.8702491521835327,
      "learning_rate": 2.606968641114983e-05,
      "loss": 0.1639,
      "step": 20610
    },
    {
      "epoch": 4.789779326364692,
      "grad_norm": 0.9835242033004761,
      "learning_rate": 2.605807200929152e-05,
      "loss": 0.0691,
      "step": 20620
    },
    {
      "epoch": 4.792102206736353,
      "grad_norm": 1.0287326574325562,
      "learning_rate": 2.6046457607433216e-05,
      "loss": 0.1612,
      "step": 20630
    },
    {
      "epoch": 4.794425087108014,
      "grad_norm": 0.8598089814186096,
      "learning_rate": 2.6034843205574914e-05,
      "loss": 0.0876,
      "step": 20640
    },
    {
      "epoch": 4.796747967479675,
      "grad_norm": 0.7469297051429749,
      "learning_rate": 2.602322880371661e-05,
      "loss": 0.089,
      "step": 20650
    },
    {
      "epoch": 4.799070847851335,
      "grad_norm": 1.1981348991394043,
      "learning_rate": 2.6011614401858304e-05,
      "loss": 0.0885,
      "step": 20660
    },
    {
      "epoch": 4.801393728222997,
      "grad_norm": 0.9182902574539185,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.1399,
      "step": 20670
    },
    {
      "epoch": 4.803716608594657,
      "grad_norm": 1.6570326089859009,
      "learning_rate": 2.5988385598141696e-05,
      "loss": 0.1699,
      "step": 20680
    },
    {
      "epoch": 4.806039488966318,
      "grad_norm": 1.2634334564208984,
      "learning_rate": 2.5976771196283395e-05,
      "loss": 0.0967,
      "step": 20690
    },
    {
      "epoch": 4.80836236933798,
      "grad_norm": 1.5911391973495483,
      "learning_rate": 2.596515679442509e-05,
      "loss": 0.1202,
      "step": 20700
    },
    {
      "epoch": 4.81068524970964,
      "grad_norm": 0.8094279170036316,
      "learning_rate": 2.595354239256678e-05,
      "loss": 0.1273,
      "step": 20710
    },
    {
      "epoch": 4.8130081300813,
      "grad_norm": 1.083282232284546,
      "learning_rate": 2.5941927990708482e-05,
      "loss": 0.1271,
      "step": 20720
    },
    {
      "epoch": 4.815331010452962,
      "grad_norm": 1.2098760604858398,
      "learning_rate": 2.5930313588850173e-05,
      "loss": 0.0918,
      "step": 20730
    },
    {
      "epoch": 4.817653890824623,
      "grad_norm": 2.268134355545044,
      "learning_rate": 2.5918699186991875e-05,
      "loss": 0.109,
      "step": 20740
    },
    {
      "epoch": 4.819976771196283,
      "grad_norm": 1.3658719062805176,
      "learning_rate": 2.5907084785133566e-05,
      "loss": 0.1162,
      "step": 20750
    },
    {
      "epoch": 4.822299651567945,
      "grad_norm": 0.7388885021209717,
      "learning_rate": 2.589547038327526e-05,
      "loss": 0.0806,
      "step": 20760
    },
    {
      "epoch": 4.824622531939605,
      "grad_norm": 0.8757048845291138,
      "learning_rate": 2.588385598141696e-05,
      "loss": 0.085,
      "step": 20770
    },
    {
      "epoch": 4.826945412311266,
      "grad_norm": 2.062079906463623,
      "learning_rate": 2.5872241579558653e-05,
      "loss": 0.0925,
      "step": 20780
    },
    {
      "epoch": 4.829268292682927,
      "grad_norm": 1.1603741645812988,
      "learning_rate": 2.5860627177700348e-05,
      "loss": 0.0887,
      "step": 20790
    },
    {
      "epoch": 4.831591173054588,
      "grad_norm": 0.5196788907051086,
      "learning_rate": 2.5849012775842046e-05,
      "loss": 0.133,
      "step": 20800
    },
    {
      "epoch": 4.833914053426248,
      "grad_norm": 0.8172529339790344,
      "learning_rate": 2.583739837398374e-05,
      "loss": 0.0872,
      "step": 20810
    },
    {
      "epoch": 4.83623693379791,
      "grad_norm": 0.9152637124061584,
      "learning_rate": 2.582578397212544e-05,
      "loss": 0.1266,
      "step": 20820
    },
    {
      "epoch": 4.83855981416957,
      "grad_norm": 0.5968148112297058,
      "learning_rate": 2.5814169570267133e-05,
      "loss": 0.1183,
      "step": 20830
    },
    {
      "epoch": 4.840882694541231,
      "grad_norm": 1.5555682182312012,
      "learning_rate": 2.5802555168408825e-05,
      "loss": 0.1365,
      "step": 20840
    },
    {
      "epoch": 4.843205574912892,
      "grad_norm": 1.2058305740356445,
      "learning_rate": 2.5790940766550526e-05,
      "loss": 0.1624,
      "step": 20850
    },
    {
      "epoch": 4.845528455284553,
      "grad_norm": 1.127392053604126,
      "learning_rate": 2.5779326364692218e-05,
      "loss": 0.0878,
      "step": 20860
    },
    {
      "epoch": 4.847851335656213,
      "grad_norm": 1.7623568773269653,
      "learning_rate": 2.5767711962833912e-05,
      "loss": 0.1376,
      "step": 20870
    },
    {
      "epoch": 4.850174216027875,
      "grad_norm": 0.8987124562263489,
      "learning_rate": 2.575609756097561e-05,
      "loss": 0.095,
      "step": 20880
    },
    {
      "epoch": 4.852497096399535,
      "grad_norm": 0.885104775428772,
      "learning_rate": 2.5744483159117305e-05,
      "loss": 0.115,
      "step": 20890
    },
    {
      "epoch": 4.854819976771196,
      "grad_norm": 1.1917774677276611,
      "learning_rate": 2.5732868757259003e-05,
      "loss": 0.0815,
      "step": 20900
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 0.9952247738838196,
      "learning_rate": 2.5721254355400698e-05,
      "loss": 0.0672,
      "step": 20910
    },
    {
      "epoch": 4.859465737514518,
      "grad_norm": 0.9520518779754639,
      "learning_rate": 2.5709639953542392e-05,
      "loss": 0.0561,
      "step": 20920
    },
    {
      "epoch": 4.861788617886178,
      "grad_norm": 1.6069222688674927,
      "learning_rate": 2.569802555168409e-05,
      "loss": 0.0762,
      "step": 20930
    },
    {
      "epoch": 4.86411149825784,
      "grad_norm": 0.7233182787895203,
      "learning_rate": 2.5686411149825785e-05,
      "loss": 0.0903,
      "step": 20940
    },
    {
      "epoch": 4.866434378629501,
      "grad_norm": 1.3675696849822998,
      "learning_rate": 2.5674796747967483e-05,
      "loss": 0.0901,
      "step": 20950
    },
    {
      "epoch": 4.868757259001161,
      "grad_norm": 1.3590346574783325,
      "learning_rate": 2.5663182346109178e-05,
      "loss": 0.101,
      "step": 20960
    },
    {
      "epoch": 4.871080139372822,
      "grad_norm": 0.7594432830810547,
      "learning_rate": 2.565156794425087e-05,
      "loss": 0.0919,
      "step": 20970
    },
    {
      "epoch": 4.873403019744483,
      "grad_norm": 0.7137840390205383,
      "learning_rate": 2.563995354239257e-05,
      "loss": 0.1808,
      "step": 20980
    },
    {
      "epoch": 4.875725900116144,
      "grad_norm": 1.2591222524642944,
      "learning_rate": 2.5628339140534262e-05,
      "loss": 0.0551,
      "step": 20990
    },
    {
      "epoch": 4.878048780487805,
      "grad_norm": 0.548770546913147,
      "learning_rate": 2.5616724738675956e-05,
      "loss": 0.059,
      "step": 21000
    },
    {
      "epoch": 4.880371660859466,
      "grad_norm": 0.6722803711891174,
      "learning_rate": 2.5605110336817655e-05,
      "loss": 0.1113,
      "step": 21010
    },
    {
      "epoch": 4.8826945412311265,
      "grad_norm": 0.7450704574584961,
      "learning_rate": 2.559349593495935e-05,
      "loss": 0.0894,
      "step": 21020
    },
    {
      "epoch": 4.885017421602788,
      "grad_norm": 1.1423171758651733,
      "learning_rate": 2.5581881533101047e-05,
      "loss": 0.1085,
      "step": 21030
    },
    {
      "epoch": 4.887340301974448,
      "grad_norm": 1.4607658386230469,
      "learning_rate": 2.5570267131242742e-05,
      "loss": 0.1403,
      "step": 21040
    },
    {
      "epoch": 4.889663182346109,
      "grad_norm": 0.9576693177223206,
      "learning_rate": 2.5558652729384437e-05,
      "loss": 0.0834,
      "step": 21050
    },
    {
      "epoch": 4.89198606271777,
      "grad_norm": 0.9737239480018616,
      "learning_rate": 2.5547038327526135e-05,
      "loss": 0.0902,
      "step": 21060
    },
    {
      "epoch": 4.894308943089431,
      "grad_norm": 0.9794791340827942,
      "learning_rate": 2.553542392566783e-05,
      "loss": 0.0805,
      "step": 21070
    },
    {
      "epoch": 4.8966318234610915,
      "grad_norm": 1.3057349920272827,
      "learning_rate": 2.5523809523809527e-05,
      "loss": 0.217,
      "step": 21080
    },
    {
      "epoch": 4.898954703832753,
      "grad_norm": 1.5039409399032593,
      "learning_rate": 2.5513356562137053e-05,
      "loss": 0.1215,
      "step": 21090
    },
    {
      "epoch": 4.901277584204413,
      "grad_norm": 1.0428799390792847,
      "learning_rate": 2.5501742160278747e-05,
      "loss": 0.1122,
      "step": 21100
    },
    {
      "epoch": 4.9036004645760745,
      "grad_norm": 0.7347567677497864,
      "learning_rate": 2.549012775842044e-05,
      "loss": 0.1093,
      "step": 21110
    },
    {
      "epoch": 4.905923344947735,
      "grad_norm": 0.7182110548019409,
      "learning_rate": 2.547851335656214e-05,
      "loss": 0.1151,
      "step": 21120
    },
    {
      "epoch": 4.908246225319396,
      "grad_norm": 0.8679829835891724,
      "learning_rate": 2.546689895470383e-05,
      "loss": 0.1224,
      "step": 21130
    },
    {
      "epoch": 4.9105691056910565,
      "grad_norm": 0.8596088290214539,
      "learning_rate": 2.5455284552845533e-05,
      "loss": 0.0897,
      "step": 21140
    },
    {
      "epoch": 4.912891986062718,
      "grad_norm": 0.9657111763954163,
      "learning_rate": 2.5443670150987224e-05,
      "loss": 0.0852,
      "step": 21150
    },
    {
      "epoch": 4.915214866434379,
      "grad_norm": 1.5213243961334229,
      "learning_rate": 2.543205574912892e-05,
      "loss": 0.1102,
      "step": 21160
    },
    {
      "epoch": 4.9175377468060395,
      "grad_norm": 0.655485212802887,
      "learning_rate": 2.5420441347270617e-05,
      "loss": 0.0674,
      "step": 21170
    },
    {
      "epoch": 4.9198606271777,
      "grad_norm": 0.6767230033874512,
      "learning_rate": 2.540882694541231e-05,
      "loss": 0.0623,
      "step": 21180
    },
    {
      "epoch": 4.922183507549361,
      "grad_norm": 1.2543978691101074,
      "learning_rate": 2.539721254355401e-05,
      "loss": 0.1224,
      "step": 21190
    },
    {
      "epoch": 4.9245063879210225,
      "grad_norm": 2.289188861846924,
      "learning_rate": 2.5385598141695704e-05,
      "loss": 0.0793,
      "step": 21200
    },
    {
      "epoch": 4.926829268292683,
      "grad_norm": 0.9279041886329651,
      "learning_rate": 2.53739837398374e-05,
      "loss": 0.0521,
      "step": 21210
    },
    {
      "epoch": 4.929152148664344,
      "grad_norm": 2.0366077423095703,
      "learning_rate": 2.5362369337979097e-05,
      "loss": 0.0863,
      "step": 21220
    },
    {
      "epoch": 4.9314750290360045,
      "grad_norm": 0.774531900882721,
      "learning_rate": 2.535075493612079e-05,
      "loss": 0.1202,
      "step": 21230
    },
    {
      "epoch": 4.933797909407666,
      "grad_norm": 1.0839656591415405,
      "learning_rate": 2.5339140534262483e-05,
      "loss": 0.082,
      "step": 21240
    },
    {
      "epoch": 4.936120789779326,
      "grad_norm": 0.812364935874939,
      "learning_rate": 2.5327526132404184e-05,
      "loss": 0.1843,
      "step": 21250
    },
    {
      "epoch": 4.9384436701509875,
      "grad_norm": 0.7196645140647888,
      "learning_rate": 2.5315911730545876e-05,
      "loss": 0.0654,
      "step": 21260
    },
    {
      "epoch": 4.940766550522648,
      "grad_norm": 0.7711412906646729,
      "learning_rate": 2.5304297328687577e-05,
      "loss": 0.0891,
      "step": 21270
    },
    {
      "epoch": 4.943089430894309,
      "grad_norm": 0.5376641750335693,
      "learning_rate": 2.529268292682927e-05,
      "loss": 0.1697,
      "step": 21280
    },
    {
      "epoch": 4.94541231126597,
      "grad_norm": 1.3367841243743896,
      "learning_rate": 2.5281068524970963e-05,
      "loss": 0.1105,
      "step": 21290
    },
    {
      "epoch": 4.947735191637631,
      "grad_norm": 0.7896045446395874,
      "learning_rate": 2.526945412311266e-05,
      "loss": 0.0597,
      "step": 21300
    },
    {
      "epoch": 4.950058072009291,
      "grad_norm": 0.3847544491291046,
      "learning_rate": 2.5257839721254356e-05,
      "loss": 0.1145,
      "step": 21310
    },
    {
      "epoch": 4.9523809523809526,
      "grad_norm": 0.6754127144813538,
      "learning_rate": 2.524622531939605e-05,
      "loss": 0.0709,
      "step": 21320
    },
    {
      "epoch": 4.954703832752613,
      "grad_norm": 2.326601505279541,
      "learning_rate": 2.523461091753775e-05,
      "loss": 0.1365,
      "step": 21330
    },
    {
      "epoch": 4.957026713124274,
      "grad_norm": 1.0734987258911133,
      "learning_rate": 2.5222996515679443e-05,
      "loss": 0.132,
      "step": 21340
    },
    {
      "epoch": 4.959349593495935,
      "grad_norm": 0.987733781337738,
      "learning_rate": 2.521138211382114e-05,
      "loss": 0.1117,
      "step": 21350
    },
    {
      "epoch": 4.961672473867596,
      "grad_norm": 2.2723286151885986,
      "learning_rate": 2.5199767711962836e-05,
      "loss": 0.0937,
      "step": 21360
    },
    {
      "epoch": 4.963995354239256,
      "grad_norm": 2.072448968887329,
      "learning_rate": 2.5188153310104527e-05,
      "loss": 0.1113,
      "step": 21370
    },
    {
      "epoch": 4.966318234610918,
      "grad_norm": 1.1538079977035522,
      "learning_rate": 2.517653890824623e-05,
      "loss": 0.1326,
      "step": 21380
    },
    {
      "epoch": 4.968641114982578,
      "grad_norm": 1.9875284433364868,
      "learning_rate": 2.516492450638792e-05,
      "loss": 0.0949,
      "step": 21390
    },
    {
      "epoch": 4.970963995354239,
      "grad_norm": 0.9101600050926208,
      "learning_rate": 2.515331010452962e-05,
      "loss": 0.1674,
      "step": 21400
    },
    {
      "epoch": 4.973286875725901,
      "grad_norm": 1.40692138671875,
      "learning_rate": 2.5141695702671313e-05,
      "loss": 0.1252,
      "step": 21410
    },
    {
      "epoch": 4.975609756097561,
      "grad_norm": 1.0412790775299072,
      "learning_rate": 2.5130081300813007e-05,
      "loss": 0.0807,
      "step": 21420
    },
    {
      "epoch": 4.977932636469221,
      "grad_norm": 0.4499592185020447,
      "learning_rate": 2.5118466898954705e-05,
      "loss": 0.1208,
      "step": 21430
    },
    {
      "epoch": 4.980255516840883,
      "grad_norm": 0.6868730783462524,
      "learning_rate": 2.51068524970964e-05,
      "loss": 0.081,
      "step": 21440
    },
    {
      "epoch": 4.982578397212544,
      "grad_norm": 0.9585484862327576,
      "learning_rate": 2.5095238095238095e-05,
      "loss": 0.0641,
      "step": 21450
    },
    {
      "epoch": 4.984901277584204,
      "grad_norm": 3.643249034881592,
      "learning_rate": 2.5083623693379793e-05,
      "loss": 0.1354,
      "step": 21460
    },
    {
      "epoch": 4.987224157955866,
      "grad_norm": 1.570793628692627,
      "learning_rate": 2.5072009291521487e-05,
      "loss": 0.132,
      "step": 21470
    },
    {
      "epoch": 4.989547038327526,
      "grad_norm": 1.1577504873275757,
      "learning_rate": 2.5060394889663186e-05,
      "loss": 0.089,
      "step": 21480
    },
    {
      "epoch": 4.991869918699187,
      "grad_norm": 0.544833242893219,
      "learning_rate": 2.504878048780488e-05,
      "loss": 0.1038,
      "step": 21490
    },
    {
      "epoch": 4.994192799070848,
      "grad_norm": 0.6723098754882812,
      "learning_rate": 2.503716608594657e-05,
      "loss": 0.094,
      "step": 21500
    },
    {
      "epoch": 4.996515679442509,
      "grad_norm": 0.5016133785247803,
      "learning_rate": 2.5025551684088273e-05,
      "loss": 0.1814,
      "step": 21510
    },
    {
      "epoch": 4.998838559814169,
      "grad_norm": 0.8882949352264404,
      "learning_rate": 2.5013937282229964e-05,
      "loss": 0.0924,
      "step": 21520
    },
    {
      "epoch": 5.001161440185831,
      "grad_norm": 1.576886534690857,
      "learning_rate": 2.5002322880371666e-05,
      "loss": 0.1051,
      "step": 21530
    },
    {
      "epoch": 5.003484320557491,
      "grad_norm": 1.3340448141098022,
      "learning_rate": 2.4990708478513357e-05,
      "loss": 0.0838,
      "step": 21540
    },
    {
      "epoch": 5.005807200929152,
      "grad_norm": 2.0086517333984375,
      "learning_rate": 2.4979094076655055e-05,
      "loss": 0.1428,
      "step": 21550
    },
    {
      "epoch": 5.008130081300813,
      "grad_norm": 0.8091673254966736,
      "learning_rate": 2.496747967479675e-05,
      "loss": 0.1033,
      "step": 21560
    },
    {
      "epoch": 5.010452961672474,
      "grad_norm": 0.8925691246986389,
      "learning_rate": 2.4955865272938444e-05,
      "loss": 0.1874,
      "step": 21570
    },
    {
      "epoch": 5.012775842044134,
      "grad_norm": 1.1193424463272095,
      "learning_rate": 2.4944250871080142e-05,
      "loss": 0.0865,
      "step": 21580
    },
    {
      "epoch": 5.015098722415796,
      "grad_norm": 0.8728314638137817,
      "learning_rate": 2.4932636469221837e-05,
      "loss": 0.0721,
      "step": 21590
    },
    {
      "epoch": 5.017421602787456,
      "grad_norm": 0.6136313676834106,
      "learning_rate": 2.4921022067363532e-05,
      "loss": 0.0998,
      "step": 21600
    },
    {
      "epoch": 5.019744483159117,
      "grad_norm": 1.1674998998641968,
      "learning_rate": 2.4909407665505226e-05,
      "loss": 0.0991,
      "step": 21610
    },
    {
      "epoch": 5.022067363530778,
      "grad_norm": 0.6992813348770142,
      "learning_rate": 2.4897793263646924e-05,
      "loss": 0.1271,
      "step": 21620
    },
    {
      "epoch": 5.024390243902439,
      "grad_norm": 1.4653042554855347,
      "learning_rate": 2.488617886178862e-05,
      "loss": 0.101,
      "step": 21630
    },
    {
      "epoch": 5.026713124274099,
      "grad_norm": 0.4251461327075958,
      "learning_rate": 2.4874564459930314e-05,
      "loss": 0.1934,
      "step": 21640
    },
    {
      "epoch": 5.029036004645761,
      "grad_norm": 0.6355381608009338,
      "learning_rate": 2.486295005807201e-05,
      "loss": 0.0632,
      "step": 21650
    },
    {
      "epoch": 5.031358885017422,
      "grad_norm": 1.0718894004821777,
      "learning_rate": 2.4851335656213707e-05,
      "loss": 0.1505,
      "step": 21660
    },
    {
      "epoch": 5.033681765389082,
      "grad_norm": 1.2891905307769775,
      "learning_rate": 2.48397212543554e-05,
      "loss": 0.1424,
      "step": 21670
    },
    {
      "epoch": 5.036004645760744,
      "grad_norm": 1.1420602798461914,
      "learning_rate": 2.48281068524971e-05,
      "loss": 0.0673,
      "step": 21680
    },
    {
      "epoch": 5.038327526132404,
      "grad_norm": 1.1798919439315796,
      "learning_rate": 2.4816492450638794e-05,
      "loss": 0.1183,
      "step": 21690
    },
    {
      "epoch": 5.040650406504065,
      "grad_norm": 0.7919555306434631,
      "learning_rate": 2.480487804878049e-05,
      "loss": 0.1098,
      "step": 21700
    },
    {
      "epoch": 5.042973286875726,
      "grad_norm": 0.7456465363502502,
      "learning_rate": 2.4793263646922187e-05,
      "loss": 0.0787,
      "step": 21710
    },
    {
      "epoch": 5.045296167247387,
      "grad_norm": 1.41655695438385,
      "learning_rate": 2.478164924506388e-05,
      "loss": 0.0881,
      "step": 21720
    },
    {
      "epoch": 5.0476190476190474,
      "grad_norm": 1.9914183616638184,
      "learning_rate": 2.4770034843205576e-05,
      "loss": 0.0684,
      "step": 21730
    },
    {
      "epoch": 5.049941927990709,
      "grad_norm": 2.1617987155914307,
      "learning_rate": 2.475842044134727e-05,
      "loss": 0.0676,
      "step": 21740
    },
    {
      "epoch": 5.052264808362369,
      "grad_norm": 1.2187691926956177,
      "learning_rate": 2.474680603948897e-05,
      "loss": 0.1127,
      "step": 21750
    },
    {
      "epoch": 5.05458768873403,
      "grad_norm": 1.365592122077942,
      "learning_rate": 2.4735191637630663e-05,
      "loss": 0.1193,
      "step": 21760
    },
    {
      "epoch": 5.056910569105691,
      "grad_norm": 2.9049384593963623,
      "learning_rate": 2.4723577235772358e-05,
      "loss": 0.1783,
      "step": 21770
    },
    {
      "epoch": 5.059233449477352,
      "grad_norm": 1.3388965129852295,
      "learning_rate": 2.4711962833914053e-05,
      "loss": 0.1392,
      "step": 21780
    },
    {
      "epoch": 5.0615563298490125,
      "grad_norm": 0.6270961761474609,
      "learning_rate": 2.470034843205575e-05,
      "loss": 0.1187,
      "step": 21790
    },
    {
      "epoch": 5.063879210220674,
      "grad_norm": 1.4669878482818604,
      "learning_rate": 2.4688734030197446e-05,
      "loss": 0.0601,
      "step": 21800
    },
    {
      "epoch": 5.066202090592334,
      "grad_norm": 1.3118317127227783,
      "learning_rate": 2.467711962833914e-05,
      "loss": 0.1357,
      "step": 21810
    },
    {
      "epoch": 5.0685249709639955,
      "grad_norm": 0.9986028075218201,
      "learning_rate": 2.4665505226480838e-05,
      "loss": 0.1049,
      "step": 21820
    },
    {
      "epoch": 5.070847851335656,
      "grad_norm": 1.3445881605148315,
      "learning_rate": 2.4653890824622533e-05,
      "loss": 0.0843,
      "step": 21830
    },
    {
      "epoch": 5.073170731707317,
      "grad_norm": 0.8542513847351074,
      "learning_rate": 2.464227642276423e-05,
      "loss": 0.1749,
      "step": 21840
    },
    {
      "epoch": 5.0754936120789775,
      "grad_norm": 1.5083396434783936,
      "learning_rate": 2.4630662020905926e-05,
      "loss": 0.0948,
      "step": 21850
    },
    {
      "epoch": 5.077816492450639,
      "grad_norm": 1.3666530847549438,
      "learning_rate": 2.461904761904762e-05,
      "loss": 0.0821,
      "step": 21860
    },
    {
      "epoch": 5.080139372822299,
      "grad_norm": 0.7002381086349487,
      "learning_rate": 2.4607433217189315e-05,
      "loss": 0.113,
      "step": 21870
    },
    {
      "epoch": 5.0824622531939605,
      "grad_norm": 0.8977706432342529,
      "learning_rate": 2.4595818815331013e-05,
      "loss": 0.0898,
      "step": 21880
    },
    {
      "epoch": 5.084785133565622,
      "grad_norm": 0.49906808137893677,
      "learning_rate": 2.4584204413472708e-05,
      "loss": 0.0894,
      "step": 21890
    },
    {
      "epoch": 5.087108013937282,
      "grad_norm": 0.8522841930389404,
      "learning_rate": 2.4572590011614402e-05,
      "loss": 0.0956,
      "step": 21900
    },
    {
      "epoch": 5.0894308943089435,
      "grad_norm": 0.4689616858959198,
      "learning_rate": 2.4560975609756097e-05,
      "loss": 0.0888,
      "step": 21910
    },
    {
      "epoch": 5.091753774680604,
      "grad_norm": 1.442218542098999,
      "learning_rate": 2.4549361207897795e-05,
      "loss": 0.1388,
      "step": 21920
    },
    {
      "epoch": 5.094076655052265,
      "grad_norm": 1.4596190452575684,
      "learning_rate": 2.453774680603949e-05,
      "loss": 0.0794,
      "step": 21930
    },
    {
      "epoch": 5.0963995354239255,
      "grad_norm": 1.0733877420425415,
      "learning_rate": 2.4526132404181185e-05,
      "loss": 0.1123,
      "step": 21940
    },
    {
      "epoch": 5.098722415795587,
      "grad_norm": 0.7832968235015869,
      "learning_rate": 2.4514518002322883e-05,
      "loss": 0.1159,
      "step": 21950
    },
    {
      "epoch": 5.101045296167247,
      "grad_norm": 0.7532843351364136,
      "learning_rate": 2.4502903600464577e-05,
      "loss": 0.0952,
      "step": 21960
    },
    {
      "epoch": 5.1033681765389085,
      "grad_norm": 0.6155373454093933,
      "learning_rate": 2.4491289198606275e-05,
      "loss": 0.0828,
      "step": 21970
    },
    {
      "epoch": 5.105691056910569,
      "grad_norm": 1.280465841293335,
      "learning_rate": 2.4479674796747967e-05,
      "loss": 0.1335,
      "step": 21980
    },
    {
      "epoch": 5.10801393728223,
      "grad_norm": 0.774336040019989,
      "learning_rate": 2.4468060394889665e-05,
      "loss": 0.0781,
      "step": 21990
    },
    {
      "epoch": 5.110336817653891,
      "grad_norm": 1.5703498125076294,
      "learning_rate": 2.445644599303136e-05,
      "loss": 0.1614,
      "step": 22000
    },
    {
      "epoch": 5.112659698025552,
      "grad_norm": 0.6015801429748535,
      "learning_rate": 2.4444831591173057e-05,
      "loss": 0.137,
      "step": 22010
    },
    {
      "epoch": 5.114982578397212,
      "grad_norm": 1.1206741333007812,
      "learning_rate": 2.4433217189314752e-05,
      "loss": 0.0939,
      "step": 22020
    },
    {
      "epoch": 5.1173054587688735,
      "grad_norm": 0.6495128273963928,
      "learning_rate": 2.4421602787456447e-05,
      "loss": 0.0816,
      "step": 22030
    },
    {
      "epoch": 5.119628339140534,
      "grad_norm": 1.3899716138839722,
      "learning_rate": 2.440998838559814e-05,
      "loss": 0.1073,
      "step": 22040
    },
    {
      "epoch": 5.121951219512195,
      "grad_norm": 1.0762118101119995,
      "learning_rate": 2.439837398373984e-05,
      "loss": 0.0541,
      "step": 22050
    },
    {
      "epoch": 5.124274099883856,
      "grad_norm": 0.7132664322853088,
      "learning_rate": 2.4386759581881534e-05,
      "loss": 0.0878,
      "step": 22060
    },
    {
      "epoch": 5.126596980255517,
      "grad_norm": 0.5893462896347046,
      "learning_rate": 2.437514518002323e-05,
      "loss": 0.0895,
      "step": 22070
    },
    {
      "epoch": 5.128919860627177,
      "grad_norm": 0.6650323867797852,
      "learning_rate": 2.4363530778164927e-05,
      "loss": 0.0814,
      "step": 22080
    },
    {
      "epoch": 5.131242740998839,
      "grad_norm": 0.840640664100647,
      "learning_rate": 2.435191637630662e-05,
      "loss": 0.0735,
      "step": 22090
    },
    {
      "epoch": 5.133565621370499,
      "grad_norm": 2.0082883834838867,
      "learning_rate": 2.434030197444832e-05,
      "loss": 0.1904,
      "step": 22100
    },
    {
      "epoch": 5.13588850174216,
      "grad_norm": 1.6830466985702515,
      "learning_rate": 2.432868757259001e-05,
      "loss": 0.1051,
      "step": 22110
    },
    {
      "epoch": 5.138211382113822,
      "grad_norm": 0.8584688305854797,
      "learning_rate": 2.431707317073171e-05,
      "loss": 0.0903,
      "step": 22120
    },
    {
      "epoch": 5.140534262485482,
      "grad_norm": 0.7992199063301086,
      "learning_rate": 2.4305458768873404e-05,
      "loss": 0.0946,
      "step": 22130
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 1.7395727634429932,
      "learning_rate": 2.42938443670151e-05,
      "loss": 0.1358,
      "step": 22140
    },
    {
      "epoch": 5.145180023228804,
      "grad_norm": 0.613335371017456,
      "learning_rate": 2.4282229965156796e-05,
      "loss": 0.1967,
      "step": 22150
    },
    {
      "epoch": 5.147502903600465,
      "grad_norm": 0.7356163859367371,
      "learning_rate": 2.427061556329849e-05,
      "loss": 0.1176,
      "step": 22160
    },
    {
      "epoch": 5.149825783972125,
      "grad_norm": 0.5692791938781738,
      "learning_rate": 2.4259001161440186e-05,
      "loss": 0.0668,
      "step": 22170
    },
    {
      "epoch": 5.152148664343787,
      "grad_norm": 1.7381662130355835,
      "learning_rate": 2.4247386759581884e-05,
      "loss": 0.135,
      "step": 22180
    },
    {
      "epoch": 5.154471544715447,
      "grad_norm": 2.8351361751556396,
      "learning_rate": 2.423577235772358e-05,
      "loss": 0.1466,
      "step": 22190
    },
    {
      "epoch": 5.156794425087108,
      "grad_norm": 0.41724535822868347,
      "learning_rate": 2.4224157955865273e-05,
      "loss": 0.044,
      "step": 22200
    },
    {
      "epoch": 5.159117305458769,
      "grad_norm": 0.6012667417526245,
      "learning_rate": 2.421254355400697e-05,
      "loss": 0.0866,
      "step": 22210
    },
    {
      "epoch": 5.16144018583043,
      "grad_norm": 0.9025844931602478,
      "learning_rate": 2.4200929152148666e-05,
      "loss": 0.1451,
      "step": 22220
    },
    {
      "epoch": 5.16376306620209,
      "grad_norm": 1.7443757057189941,
      "learning_rate": 2.4189314750290364e-05,
      "loss": 0.0765,
      "step": 22230
    },
    {
      "epoch": 5.166085946573752,
      "grad_norm": 0.989628255367279,
      "learning_rate": 2.4177700348432055e-05,
      "loss": 0.1252,
      "step": 22240
    },
    {
      "epoch": 5.168408826945412,
      "grad_norm": 1.326282024383545,
      "learning_rate": 2.4166085946573753e-05,
      "loss": 0.1449,
      "step": 22250
    },
    {
      "epoch": 5.170731707317073,
      "grad_norm": 1.5703155994415283,
      "learning_rate": 2.4154471544715448e-05,
      "loss": 0.1274,
      "step": 22260
    },
    {
      "epoch": 5.173054587688734,
      "grad_norm": 1.499556541442871,
      "learning_rate": 2.4142857142857146e-05,
      "loss": 0.1371,
      "step": 22270
    },
    {
      "epoch": 5.175377468060395,
      "grad_norm": 0.6621859669685364,
      "learning_rate": 2.4131242740998837e-05,
      "loss": 0.0979,
      "step": 22280
    },
    {
      "epoch": 5.177700348432055,
      "grad_norm": 1.557762861251831,
      "learning_rate": 2.4119628339140535e-05,
      "loss": 0.0954,
      "step": 22290
    },
    {
      "epoch": 5.180023228803717,
      "grad_norm": 0.5768098831176758,
      "learning_rate": 2.410801393728223e-05,
      "loss": 0.0676,
      "step": 22300
    },
    {
      "epoch": 5.182346109175377,
      "grad_norm": 1.9247170686721802,
      "learning_rate": 2.4096399535423928e-05,
      "loss": 0.094,
      "step": 22310
    },
    {
      "epoch": 5.184668989547038,
      "grad_norm": 0.6322547197341919,
      "learning_rate": 2.4084785133565623e-05,
      "loss": 0.1246,
      "step": 22320
    },
    {
      "epoch": 5.186991869918699,
      "grad_norm": 0.7682469487190247,
      "learning_rate": 2.4073170731707317e-05,
      "loss": 0.0945,
      "step": 22330
    },
    {
      "epoch": 5.18931475029036,
      "grad_norm": 0.8857995271682739,
      "learning_rate": 2.4061556329849012e-05,
      "loss": 0.1091,
      "step": 22340
    },
    {
      "epoch": 5.191637630662021,
      "grad_norm": 1.8953921794891357,
      "learning_rate": 2.404994192799071e-05,
      "loss": 0.1366,
      "step": 22350
    },
    {
      "epoch": 5.193960511033682,
      "grad_norm": 1.2034330368041992,
      "learning_rate": 2.4038327526132405e-05,
      "loss": 0.0746,
      "step": 22360
    },
    {
      "epoch": 5.196283391405343,
      "grad_norm": 1.207972526550293,
      "learning_rate": 2.40267131242741e-05,
      "loss": 0.0945,
      "step": 22370
    },
    {
      "epoch": 5.198606271777003,
      "grad_norm": 0.9633174538612366,
      "learning_rate": 2.4015098722415798e-05,
      "loss": 0.0792,
      "step": 22380
    },
    {
      "epoch": 5.200929152148665,
      "grad_norm": 1.5379908084869385,
      "learning_rate": 2.4003484320557492e-05,
      "loss": 0.122,
      "step": 22390
    },
    {
      "epoch": 5.203252032520325,
      "grad_norm": 1.128988265991211,
      "learning_rate": 2.399186991869919e-05,
      "loss": 0.0672,
      "step": 22400
    },
    {
      "epoch": 5.205574912891986,
      "grad_norm": 0.9107802510261536,
      "learning_rate": 2.398025551684088e-05,
      "loss": 0.0934,
      "step": 22410
    },
    {
      "epoch": 5.207897793263647,
      "grad_norm": 0.9037995934486389,
      "learning_rate": 2.396864111498258e-05,
      "loss": 0.091,
      "step": 22420
    },
    {
      "epoch": 5.210220673635308,
      "grad_norm": 1.226660132408142,
      "learning_rate": 2.3957026713124274e-05,
      "loss": 0.0585,
      "step": 22430
    },
    {
      "epoch": 5.2125435540069684,
      "grad_norm": 0.9481496810913086,
      "learning_rate": 2.3945412311265972e-05,
      "loss": 0.0775,
      "step": 22440
    },
    {
      "epoch": 5.21486643437863,
      "grad_norm": 0.8790283203125,
      "learning_rate": 2.3933797909407664e-05,
      "loss": 0.0967,
      "step": 22450
    },
    {
      "epoch": 5.21718931475029,
      "grad_norm": 0.9300369024276733,
      "learning_rate": 2.392218350754936e-05,
      "loss": 0.0744,
      "step": 22460
    },
    {
      "epoch": 5.219512195121951,
      "grad_norm": 0.5130672454833984,
      "learning_rate": 2.3910569105691056e-05,
      "loss": 0.1259,
      "step": 22470
    },
    {
      "epoch": 5.221835075493612,
      "grad_norm": 0.9708788990974426,
      "learning_rate": 2.3898954703832754e-05,
      "loss": 0.0848,
      "step": 22480
    },
    {
      "epoch": 5.224157955865273,
      "grad_norm": 1.1086902618408203,
      "learning_rate": 2.388734030197445e-05,
      "loss": 0.1058,
      "step": 22490
    },
    {
      "epoch": 5.2264808362369335,
      "grad_norm": 1.5753649473190308,
      "learning_rate": 2.3875725900116144e-05,
      "loss": 0.109,
      "step": 22500
    },
    {
      "epoch": 5.228803716608595,
      "grad_norm": 1.3740217685699463,
      "learning_rate": 2.3864111498257842e-05,
      "loss": 0.1075,
      "step": 22510
    },
    {
      "epoch": 5.231126596980255,
      "grad_norm": 0.7635475397109985,
      "learning_rate": 2.3852497096399537e-05,
      "loss": 0.1077,
      "step": 22520
    },
    {
      "epoch": 5.2334494773519165,
      "grad_norm": 1.532690405845642,
      "learning_rate": 2.3840882694541235e-05,
      "loss": 0.1101,
      "step": 22530
    },
    {
      "epoch": 5.235772357723577,
      "grad_norm": 1.0470545291900635,
      "learning_rate": 2.3829268292682926e-05,
      "loss": 0.0984,
      "step": 22540
    },
    {
      "epoch": 5.238095238095238,
      "grad_norm": 1.172903060913086,
      "learning_rate": 2.3817653890824624e-05,
      "loss": 0.0943,
      "step": 22550
    },
    {
      "epoch": 5.2404181184668985,
      "grad_norm": 0.674433708190918,
      "learning_rate": 2.380603948896632e-05,
      "loss": 0.1443,
      "step": 22560
    },
    {
      "epoch": 5.24274099883856,
      "grad_norm": 1.2382839918136597,
      "learning_rate": 2.3794425087108017e-05,
      "loss": 0.1687,
      "step": 22570
    },
    {
      "epoch": 5.245063879210221,
      "grad_norm": 0.5694950819015503,
      "learning_rate": 2.3782810685249708e-05,
      "loss": 0.0823,
      "step": 22580
    },
    {
      "epoch": 5.2473867595818815,
      "grad_norm": 0.6775637865066528,
      "learning_rate": 2.3771196283391406e-05,
      "loss": 0.0917,
      "step": 22590
    },
    {
      "epoch": 5.249709639953543,
      "grad_norm": 1.6093018054962158,
      "learning_rate": 2.37595818815331e-05,
      "loss": 0.0665,
      "step": 22600
    },
    {
      "epoch": 5.252032520325203,
      "grad_norm": 0.3876361846923828,
      "learning_rate": 2.37479674796748e-05,
      "loss": 0.1544,
      "step": 22610
    },
    {
      "epoch": 5.2543554006968645,
      "grad_norm": 0.8170632123947144,
      "learning_rate": 2.3736353077816493e-05,
      "loss": 0.0561,
      "step": 22620
    },
    {
      "epoch": 5.256678281068525,
      "grad_norm": 1.252197504043579,
      "learning_rate": 2.3724738675958188e-05,
      "loss": 0.1035,
      "step": 22630
    },
    {
      "epoch": 5.259001161440186,
      "grad_norm": 1.175849437713623,
      "learning_rate": 2.3713124274099886e-05,
      "loss": 0.155,
      "step": 22640
    },
    {
      "epoch": 5.2613240418118465,
      "grad_norm": 0.4859625995159149,
      "learning_rate": 2.370150987224158e-05,
      "loss": 0.0825,
      "step": 22650
    },
    {
      "epoch": 5.263646922183508,
      "grad_norm": 0.9679370522499084,
      "learning_rate": 2.368989547038328e-05,
      "loss": 0.137,
      "step": 22660
    },
    {
      "epoch": 5.265969802555168,
      "grad_norm": 0.5589539408683777,
      "learning_rate": 2.367828106852497e-05,
      "loss": 0.1483,
      "step": 22670
    },
    {
      "epoch": 5.2682926829268295,
      "grad_norm": 0.8941692113876343,
      "learning_rate": 2.3666666666666668e-05,
      "loss": 0.0767,
      "step": 22680
    },
    {
      "epoch": 5.27061556329849,
      "grad_norm": 1.7551069259643555,
      "learning_rate": 2.3655052264808363e-05,
      "loss": 0.1274,
      "step": 22690
    },
    {
      "epoch": 5.272938443670151,
      "grad_norm": 1.7317173480987549,
      "learning_rate": 2.364343786295006e-05,
      "loss": 0.1493,
      "step": 22700
    },
    {
      "epoch": 5.275261324041812,
      "grad_norm": 1.2145076990127563,
      "learning_rate": 2.3631823461091752e-05,
      "loss": 0.107,
      "step": 22710
    },
    {
      "epoch": 5.277584204413473,
      "grad_norm": 0.7761227488517761,
      "learning_rate": 2.362020905923345e-05,
      "loss": 0.0822,
      "step": 22720
    },
    {
      "epoch": 5.279907084785133,
      "grad_norm": 1.2607355117797852,
      "learning_rate": 2.3608594657375145e-05,
      "loss": 0.1243,
      "step": 22730
    },
    {
      "epoch": 5.2822299651567945,
      "grad_norm": 0.6492434144020081,
      "learning_rate": 2.3596980255516843e-05,
      "loss": 0.0806,
      "step": 22740
    },
    {
      "epoch": 5.284552845528455,
      "grad_norm": 1.3410784006118774,
      "learning_rate": 2.3585365853658538e-05,
      "loss": 0.1092,
      "step": 22750
    },
    {
      "epoch": 5.286875725900116,
      "grad_norm": 0.6455101370811462,
      "learning_rate": 2.3573751451800232e-05,
      "loss": 0.1321,
      "step": 22760
    },
    {
      "epoch": 5.289198606271777,
      "grad_norm": 0.9179855585098267,
      "learning_rate": 2.356213704994193e-05,
      "loss": 0.1288,
      "step": 22770
    },
    {
      "epoch": 5.291521486643438,
      "grad_norm": 1.3476078510284424,
      "learning_rate": 2.3550522648083625e-05,
      "loss": 0.1053,
      "step": 22780
    },
    {
      "epoch": 5.293844367015098,
      "grad_norm": 1.6923586130142212,
      "learning_rate": 2.3538908246225323e-05,
      "loss": 0.1484,
      "step": 22790
    },
    {
      "epoch": 5.29616724738676,
      "grad_norm": 1.7739717960357666,
      "learning_rate": 2.3527293844367014e-05,
      "loss": 0.1011,
      "step": 22800
    },
    {
      "epoch": 5.29849012775842,
      "grad_norm": 1.1295607089996338,
      "learning_rate": 2.3515679442508713e-05,
      "loss": 0.2476,
      "step": 22810
    },
    {
      "epoch": 5.300813008130081,
      "grad_norm": 1.3806301355361938,
      "learning_rate": 2.3504065040650407e-05,
      "loss": 0.0597,
      "step": 22820
    },
    {
      "epoch": 5.303135888501743,
      "grad_norm": 1.0636165142059326,
      "learning_rate": 2.3492450638792105e-05,
      "loss": 0.1239,
      "step": 22830
    },
    {
      "epoch": 5.305458768873403,
      "grad_norm": 1.7108515501022339,
      "learning_rate": 2.3480836236933797e-05,
      "loss": 0.1253,
      "step": 22840
    },
    {
      "epoch": 5.307781649245064,
      "grad_norm": 1.2365515232086182,
      "learning_rate": 2.3469221835075495e-05,
      "loss": 0.1301,
      "step": 22850
    },
    {
      "epoch": 5.310104529616725,
      "grad_norm": 1.9346431493759155,
      "learning_rate": 2.345760743321719e-05,
      "loss": 0.1514,
      "step": 22860
    },
    {
      "epoch": 5.312427409988386,
      "grad_norm": 0.6185523271560669,
      "learning_rate": 2.3445993031358887e-05,
      "loss": 0.1095,
      "step": 22870
    },
    {
      "epoch": 5.314750290360046,
      "grad_norm": 1.568894624710083,
      "learning_rate": 2.3434378629500582e-05,
      "loss": 0.1084,
      "step": 22880
    },
    {
      "epoch": 5.317073170731708,
      "grad_norm": 0.8184084892272949,
      "learning_rate": 2.3422764227642277e-05,
      "loss": 0.0877,
      "step": 22890
    },
    {
      "epoch": 5.319396051103368,
      "grad_norm": 1.7906900644302368,
      "learning_rate": 2.3411149825783975e-05,
      "loss": 0.0867,
      "step": 22900
    },
    {
      "epoch": 5.321718931475029,
      "grad_norm": 1.4188988208770752,
      "learning_rate": 2.339953542392567e-05,
      "loss": 0.1209,
      "step": 22910
    },
    {
      "epoch": 5.32404181184669,
      "grad_norm": 2.3731918334960938,
      "learning_rate": 2.3387921022067364e-05,
      "loss": 0.145,
      "step": 22920
    },
    {
      "epoch": 5.326364692218351,
      "grad_norm": 0.4715999364852905,
      "learning_rate": 2.337630662020906e-05,
      "loss": 0.1228,
      "step": 22930
    },
    {
      "epoch": 5.328687572590011,
      "grad_norm": 1.5331668853759766,
      "learning_rate": 2.3364692218350757e-05,
      "loss": 0.0819,
      "step": 22940
    },
    {
      "epoch": 5.331010452961673,
      "grad_norm": 0.8615135550498962,
      "learning_rate": 2.335307781649245e-05,
      "loss": 0.0804,
      "step": 22950
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 1.019344687461853,
      "learning_rate": 2.334146341463415e-05,
      "loss": 0.1408,
      "step": 22960
    },
    {
      "epoch": 5.335656213704994,
      "grad_norm": 0.5144045948982239,
      "learning_rate": 2.332984901277584e-05,
      "loss": 0.0578,
      "step": 22970
    },
    {
      "epoch": 5.337979094076655,
      "grad_norm": 1.0721505880355835,
      "learning_rate": 2.331823461091754e-05,
      "loss": 0.066,
      "step": 22980
    },
    {
      "epoch": 5.340301974448316,
      "grad_norm": 1.6813191175460815,
      "learning_rate": 2.3306620209059234e-05,
      "loss": 0.0927,
      "step": 22990
    },
    {
      "epoch": 5.342624854819976,
      "grad_norm": 0.7326821088790894,
      "learning_rate": 2.329500580720093e-05,
      "loss": 0.2424,
      "step": 23000
    },
    {
      "epoch": 5.344947735191638,
      "grad_norm": 1.3977642059326172,
      "learning_rate": 2.3283391405342626e-05,
      "loss": 0.1567,
      "step": 23010
    },
    {
      "epoch": 5.347270615563298,
      "grad_norm": 0.5997092723846436,
      "learning_rate": 2.327177700348432e-05,
      "loss": 0.0782,
      "step": 23020
    },
    {
      "epoch": 5.349593495934959,
      "grad_norm": 1.0049066543579102,
      "learning_rate": 2.326016260162602e-05,
      "loss": 0.1141,
      "step": 23030
    },
    {
      "epoch": 5.351916376306621,
      "grad_norm": 1.0181540250778198,
      "learning_rate": 2.3248548199767714e-05,
      "loss": 0.1052,
      "step": 23040
    },
    {
      "epoch": 5.354239256678281,
      "grad_norm": 1.133226752281189,
      "learning_rate": 2.323693379790941e-05,
      "loss": 0.0785,
      "step": 23050
    },
    {
      "epoch": 5.356562137049942,
      "grad_norm": 2.8275372982025146,
      "learning_rate": 2.3225319396051103e-05,
      "loss": 0.1362,
      "step": 23060
    },
    {
      "epoch": 5.358885017421603,
      "grad_norm": 0.797888457775116,
      "learning_rate": 2.32137049941928e-05,
      "loss": 0.0808,
      "step": 23070
    },
    {
      "epoch": 5.361207897793264,
      "grad_norm": 1.7613341808319092,
      "learning_rate": 2.3202090592334496e-05,
      "loss": 0.1262,
      "step": 23080
    },
    {
      "epoch": 5.363530778164924,
      "grad_norm": 1.8338868618011475,
      "learning_rate": 2.319047619047619e-05,
      "loss": 0.0842,
      "step": 23090
    },
    {
      "epoch": 5.365853658536586,
      "grad_norm": 0.7171204686164856,
      "learning_rate": 2.3178861788617885e-05,
      "loss": 0.081,
      "step": 23100
    },
    {
      "epoch": 5.368176538908246,
      "grad_norm": 1.812086820602417,
      "learning_rate": 2.3167247386759583e-05,
      "loss": 0.1807,
      "step": 23110
    },
    {
      "epoch": 5.370499419279907,
      "grad_norm": 0.7200877070426941,
      "learning_rate": 2.3155632984901278e-05,
      "loss": 0.1224,
      "step": 23120
    },
    {
      "epoch": 5.372822299651568,
      "grad_norm": 2.138211488723755,
      "learning_rate": 2.3144018583042976e-05,
      "loss": 0.1782,
      "step": 23130
    },
    {
      "epoch": 5.375145180023229,
      "grad_norm": 0.9402278065681458,
      "learning_rate": 2.313240418118467e-05,
      "loss": 0.0901,
      "step": 23140
    },
    {
      "epoch": 5.3774680603948894,
      "grad_norm": 0.2429688572883606,
      "learning_rate": 2.3120789779326365e-05,
      "loss": 0.0528,
      "step": 23150
    },
    {
      "epoch": 5.379790940766551,
      "grad_norm": 0.9414408206939697,
      "learning_rate": 2.3109175377468063e-05,
      "loss": 0.1045,
      "step": 23160
    },
    {
      "epoch": 5.382113821138211,
      "grad_norm": 0.8395843505859375,
      "learning_rate": 2.3097560975609758e-05,
      "loss": 0.1094,
      "step": 23170
    },
    {
      "epoch": 5.384436701509872,
      "grad_norm": 1.3725707530975342,
      "learning_rate": 2.3085946573751453e-05,
      "loss": 0.0716,
      "step": 23180
    },
    {
      "epoch": 5.386759581881533,
      "grad_norm": 0.5773571729660034,
      "learning_rate": 2.3074332171893147e-05,
      "loss": 0.0941,
      "step": 23190
    },
    {
      "epoch": 5.389082462253194,
      "grad_norm": 1.0609790086746216,
      "learning_rate": 2.3062717770034845e-05,
      "loss": 0.0443,
      "step": 23200
    },
    {
      "epoch": 5.3914053426248545,
      "grad_norm": 1.123731255531311,
      "learning_rate": 2.305110336817654e-05,
      "loss": 0.1137,
      "step": 23210
    },
    {
      "epoch": 5.393728222996516,
      "grad_norm": 0.8696795105934143,
      "learning_rate": 2.3039488966318235e-05,
      "loss": 0.0677,
      "step": 23220
    },
    {
      "epoch": 5.396051103368176,
      "grad_norm": 1.1674344539642334,
      "learning_rate": 2.302787456445993e-05,
      "loss": 0.1162,
      "step": 23230
    },
    {
      "epoch": 5.3983739837398375,
      "grad_norm": 0.8622443079948425,
      "learning_rate": 2.3016260162601627e-05,
      "loss": 0.137,
      "step": 23240
    },
    {
      "epoch": 5.400696864111498,
      "grad_norm": 0.42993584275245667,
      "learning_rate": 2.3004645760743322e-05,
      "loss": 0.0524,
      "step": 23250
    },
    {
      "epoch": 5.403019744483159,
      "grad_norm": 1.1136072874069214,
      "learning_rate": 2.2993031358885017e-05,
      "loss": 0.0617,
      "step": 23260
    },
    {
      "epoch": 5.4053426248548195,
      "grad_norm": 1.0303306579589844,
      "learning_rate": 2.2981416957026715e-05,
      "loss": 0.0772,
      "step": 23270
    },
    {
      "epoch": 5.407665505226481,
      "grad_norm": 1.2229945659637451,
      "learning_rate": 2.296980255516841e-05,
      "loss": 0.1575,
      "step": 23280
    },
    {
      "epoch": 5.409988385598142,
      "grad_norm": 1.4615398645401,
      "learning_rate": 2.2958188153310108e-05,
      "loss": 0.0918,
      "step": 23290
    },
    {
      "epoch": 5.4123112659698025,
      "grad_norm": 1.6275628805160522,
      "learning_rate": 2.2946573751451802e-05,
      "loss": 0.1057,
      "step": 23300
    },
    {
      "epoch": 5.414634146341464,
      "grad_norm": 0.9333149194717407,
      "learning_rate": 2.2934959349593497e-05,
      "loss": 0.0703,
      "step": 23310
    },
    {
      "epoch": 5.416957026713124,
      "grad_norm": 1.1356004476547241,
      "learning_rate": 2.292334494773519e-05,
      "loss": 0.1138,
      "step": 23320
    },
    {
      "epoch": 5.4192799070847855,
      "grad_norm": 1.0196114778518677,
      "learning_rate": 2.291173054587689e-05,
      "loss": 0.1875,
      "step": 23330
    },
    {
      "epoch": 5.421602787456446,
      "grad_norm": 2.510437488555908,
      "learning_rate": 2.2900116144018584e-05,
      "loss": 0.1574,
      "step": 23340
    },
    {
      "epoch": 5.423925667828107,
      "grad_norm": 0.7148934006690979,
      "learning_rate": 2.288850174216028e-05,
      "loss": 0.171,
      "step": 23350
    },
    {
      "epoch": 5.4262485481997675,
      "grad_norm": 0.9505302906036377,
      "learning_rate": 2.2876887340301974e-05,
      "loss": 0.1441,
      "step": 23360
    },
    {
      "epoch": 5.428571428571429,
      "grad_norm": 1.4216609001159668,
      "learning_rate": 2.2865272938443672e-05,
      "loss": 0.0845,
      "step": 23370
    },
    {
      "epoch": 5.430894308943089,
      "grad_norm": 1.4345020055770874,
      "learning_rate": 2.2853658536585366e-05,
      "loss": 0.0699,
      "step": 23380
    },
    {
      "epoch": 5.4332171893147505,
      "grad_norm": 0.6318432688713074,
      "learning_rate": 2.284204413472706e-05,
      "loss": 0.1654,
      "step": 23390
    },
    {
      "epoch": 5.435540069686411,
      "grad_norm": 1.1409554481506348,
      "learning_rate": 2.283042973286876e-05,
      "loss": 0.1454,
      "step": 23400
    },
    {
      "epoch": 5.437862950058072,
      "grad_norm": 0.5960067510604858,
      "learning_rate": 2.2818815331010454e-05,
      "loss": 0.0961,
      "step": 23410
    },
    {
      "epoch": 5.440185830429733,
      "grad_norm": 1.6432130336761475,
      "learning_rate": 2.2807200929152152e-05,
      "loss": 0.1029,
      "step": 23420
    },
    {
      "epoch": 5.442508710801394,
      "grad_norm": 2.0054502487182617,
      "learning_rate": 2.2795586527293847e-05,
      "loss": 0.0968,
      "step": 23430
    },
    {
      "epoch": 5.444831591173054,
      "grad_norm": 0.5569542646408081,
      "learning_rate": 2.278397212543554e-05,
      "loss": 0.0994,
      "step": 23440
    },
    {
      "epoch": 5.4471544715447155,
      "grad_norm": 0.9075456857681274,
      "learning_rate": 2.2772357723577236e-05,
      "loss": 0.1039,
      "step": 23450
    },
    {
      "epoch": 5.449477351916376,
      "grad_norm": 1.8584671020507812,
      "learning_rate": 2.2760743321718934e-05,
      "loss": 0.1632,
      "step": 23460
    },
    {
      "epoch": 5.451800232288037,
      "grad_norm": 1.158534049987793,
      "learning_rate": 2.274912891986063e-05,
      "loss": 0.1378,
      "step": 23470
    },
    {
      "epoch": 5.454123112659698,
      "grad_norm": 0.7141720056533813,
      "learning_rate": 2.2737514518002323e-05,
      "loss": 0.1172,
      "step": 23480
    },
    {
      "epoch": 5.456445993031359,
      "grad_norm": 1.7017031908035278,
      "learning_rate": 2.2725900116144018e-05,
      "loss": 0.0946,
      "step": 23490
    },
    {
      "epoch": 5.45876887340302,
      "grad_norm": 0.5869030952453613,
      "learning_rate": 2.2714285714285716e-05,
      "loss": 0.0684,
      "step": 23500
    },
    {
      "epoch": 5.461091753774681,
      "grad_norm": 1.5707849264144897,
      "learning_rate": 2.270267131242741e-05,
      "loss": 0.0846,
      "step": 23510
    },
    {
      "epoch": 5.463414634146342,
      "grad_norm": 1.5086723566055298,
      "learning_rate": 2.2691056910569105e-05,
      "loss": 0.1163,
      "step": 23520
    },
    {
      "epoch": 5.465737514518002,
      "grad_norm": 1.2506080865859985,
      "learning_rate": 2.2679442508710803e-05,
      "loss": 0.1011,
      "step": 23530
    },
    {
      "epoch": 5.4680603948896636,
      "grad_norm": 0.5916597843170166,
      "learning_rate": 2.2667828106852498e-05,
      "loss": 0.085,
      "step": 23540
    },
    {
      "epoch": 5.470383275261324,
      "grad_norm": 0.7263088226318359,
      "learning_rate": 2.2656213704994196e-05,
      "loss": 0.0857,
      "step": 23550
    },
    {
      "epoch": 5.472706155632985,
      "grad_norm": 0.8332114815711975,
      "learning_rate": 2.2644599303135887e-05,
      "loss": 0.1735,
      "step": 23560
    },
    {
      "epoch": 5.475029036004646,
      "grad_norm": 1.3391785621643066,
      "learning_rate": 2.2632984901277586e-05,
      "loss": 0.0685,
      "step": 23570
    },
    {
      "epoch": 5.477351916376307,
      "grad_norm": 0.5004461407661438,
      "learning_rate": 2.262137049941928e-05,
      "loss": 0.0825,
      "step": 23580
    },
    {
      "epoch": 5.479674796747967,
      "grad_norm": 1.4367274045944214,
      "learning_rate": 2.2609756097560978e-05,
      "loss": 0.1034,
      "step": 23590
    },
    {
      "epoch": 5.481997677119629,
      "grad_norm": 0.8401578664779663,
      "learning_rate": 2.2598141695702673e-05,
      "loss": 0.1056,
      "step": 23600
    },
    {
      "epoch": 5.484320557491289,
      "grad_norm": 0.8957230448722839,
      "learning_rate": 2.2586527293844368e-05,
      "loss": 0.0739,
      "step": 23610
    },
    {
      "epoch": 5.48664343786295,
      "grad_norm": 2.316441535949707,
      "learning_rate": 2.2574912891986062e-05,
      "loss": 0.1423,
      "step": 23620
    },
    {
      "epoch": 5.488966318234611,
      "grad_norm": 1.5511726140975952,
      "learning_rate": 2.256329849012776e-05,
      "loss": 0.1409,
      "step": 23630
    },
    {
      "epoch": 5.491289198606272,
      "grad_norm": 0.7474156022071838,
      "learning_rate": 2.2551684088269455e-05,
      "loss": 0.128,
      "step": 23640
    },
    {
      "epoch": 5.493612078977932,
      "grad_norm": 0.9324373006820679,
      "learning_rate": 2.254006968641115e-05,
      "loss": 0.1328,
      "step": 23650
    },
    {
      "epoch": 5.495934959349594,
      "grad_norm": 0.9557362198829651,
      "learning_rate": 2.2528455284552848e-05,
      "loss": 0.1215,
      "step": 23660
    },
    {
      "epoch": 5.498257839721254,
      "grad_norm": 0.4113621711730957,
      "learning_rate": 2.2516840882694542e-05,
      "loss": 0.1852,
      "step": 23670
    },
    {
      "epoch": 5.500580720092915,
      "grad_norm": 1.1024491786956787,
      "learning_rate": 2.250522648083624e-05,
      "loss": 0.1714,
      "step": 23680
    },
    {
      "epoch": 5.502903600464576,
      "grad_norm": 0.6408935189247131,
      "learning_rate": 2.2493612078977932e-05,
      "loss": 0.1029,
      "step": 23690
    },
    {
      "epoch": 5.505226480836237,
      "grad_norm": 0.7139142751693726,
      "learning_rate": 2.248315911730546e-05,
      "loss": 0.147,
      "step": 23700
    },
    {
      "epoch": 5.507549361207898,
      "grad_norm": 2.8139090538024902,
      "learning_rate": 2.2471544715447155e-05,
      "loss": 0.0934,
      "step": 23710
    },
    {
      "epoch": 5.509872241579559,
      "grad_norm": 0.509032130241394,
      "learning_rate": 2.245993031358885e-05,
      "loss": 0.0781,
      "step": 23720
    },
    {
      "epoch": 5.512195121951219,
      "grad_norm": 1.0524789094924927,
      "learning_rate": 2.2448315911730548e-05,
      "loss": 0.114,
      "step": 23730
    },
    {
      "epoch": 5.51451800232288,
      "grad_norm": 1.707558274269104,
      "learning_rate": 2.2436701509872242e-05,
      "loss": 0.0742,
      "step": 23740
    },
    {
      "epoch": 5.516840882694542,
      "grad_norm": 2.133655071258545,
      "learning_rate": 2.242508710801394e-05,
      "loss": 0.1013,
      "step": 23750
    },
    {
      "epoch": 5.519163763066202,
      "grad_norm": 2.0685672760009766,
      "learning_rate": 2.2413472706155632e-05,
      "loss": 0.0864,
      "step": 23760
    },
    {
      "epoch": 5.521486643437863,
      "grad_norm": 0.7679846286773682,
      "learning_rate": 2.240185830429733e-05,
      "loss": 0.1352,
      "step": 23770
    },
    {
      "epoch": 5.523809523809524,
      "grad_norm": 1.478810429573059,
      "learning_rate": 2.2390243902439025e-05,
      "loss": 0.1177,
      "step": 23780
    },
    {
      "epoch": 5.526132404181185,
      "grad_norm": 0.7766596674919128,
      "learning_rate": 2.2378629500580723e-05,
      "loss": 0.1344,
      "step": 23790
    },
    {
      "epoch": 5.528455284552845,
      "grad_norm": 0.9813650846481323,
      "learning_rate": 2.2367015098722417e-05,
      "loss": 0.1188,
      "step": 23800
    },
    {
      "epoch": 5.530778164924507,
      "grad_norm": 1.885781168937683,
      "learning_rate": 2.2355400696864112e-05,
      "loss": 0.1281,
      "step": 23810
    },
    {
      "epoch": 5.533101045296167,
      "grad_norm": 0.6205664277076721,
      "learning_rate": 2.234378629500581e-05,
      "loss": 0.0885,
      "step": 23820
    },
    {
      "epoch": 5.535423925667828,
      "grad_norm": 0.7371816635131836,
      "learning_rate": 2.2332171893147505e-05,
      "loss": 0.1374,
      "step": 23830
    },
    {
      "epoch": 5.537746806039489,
      "grad_norm": 1.1298881769180298,
      "learning_rate": 2.23205574912892e-05,
      "loss": 0.087,
      "step": 23840
    },
    {
      "epoch": 5.54006968641115,
      "grad_norm": 0.530474841594696,
      "learning_rate": 2.2308943089430894e-05,
      "loss": 0.0849,
      "step": 23850
    },
    {
      "epoch": 5.5423925667828104,
      "grad_norm": 0.6845204830169678,
      "learning_rate": 2.2297328687572592e-05,
      "loss": 0.0935,
      "step": 23860
    },
    {
      "epoch": 5.544715447154472,
      "grad_norm": 0.25186407566070557,
      "learning_rate": 2.2285714285714287e-05,
      "loss": 0.0711,
      "step": 23870
    },
    {
      "epoch": 5.547038327526132,
      "grad_norm": 1.0108927488327026,
      "learning_rate": 2.227409988385598e-05,
      "loss": 0.1072,
      "step": 23880
    },
    {
      "epoch": 5.549361207897793,
      "grad_norm": 0.8824175000190735,
      "learning_rate": 2.2262485481997676e-05,
      "loss": 0.0932,
      "step": 23890
    },
    {
      "epoch": 5.551684088269454,
      "grad_norm": 1.0478479862213135,
      "learning_rate": 2.2250871080139374e-05,
      "loss": 0.0655,
      "step": 23900
    },
    {
      "epoch": 5.554006968641115,
      "grad_norm": 0.9476052522659302,
      "learning_rate": 2.223925667828107e-05,
      "loss": 0.0837,
      "step": 23910
    },
    {
      "epoch": 5.5563298490127755,
      "grad_norm": 0.47300177812576294,
      "learning_rate": 2.2227642276422767e-05,
      "loss": 0.0664,
      "step": 23920
    },
    {
      "epoch": 5.558652729384437,
      "grad_norm": 0.6201064586639404,
      "learning_rate": 2.221602787456446e-05,
      "loss": 0.122,
      "step": 23930
    },
    {
      "epoch": 5.560975609756097,
      "grad_norm": 1.1613136529922485,
      "learning_rate": 2.2204413472706156e-05,
      "loss": 0.1098,
      "step": 23940
    },
    {
      "epoch": 5.5632984901277585,
      "grad_norm": 0.7345206141471863,
      "learning_rate": 2.2192799070847854e-05,
      "loss": 0.0726,
      "step": 23950
    },
    {
      "epoch": 5.56562137049942,
      "grad_norm": 1.9662137031555176,
      "learning_rate": 2.218118466898955e-05,
      "loss": 0.1184,
      "step": 23960
    },
    {
      "epoch": 5.56794425087108,
      "grad_norm": 1.2591418027877808,
      "learning_rate": 2.2169570267131244e-05,
      "loss": 0.1407,
      "step": 23970
    },
    {
      "epoch": 5.5702671312427405,
      "grad_norm": 1.424119234085083,
      "learning_rate": 2.215795586527294e-05,
      "loss": 0.0552,
      "step": 23980
    },
    {
      "epoch": 5.572590011614402,
      "grad_norm": 1.5244698524475098,
      "learning_rate": 2.2146341463414636e-05,
      "loss": 0.0598,
      "step": 23990
    },
    {
      "epoch": 5.574912891986063,
      "grad_norm": 1.1109002828598022,
      "learning_rate": 2.213472706155633e-05,
      "loss": 0.1332,
      "step": 24000
    },
    {
      "epoch": 5.5772357723577235,
      "grad_norm": 1.0498765707015991,
      "learning_rate": 2.2123112659698026e-05,
      "loss": 0.0901,
      "step": 24010
    },
    {
      "epoch": 5.579558652729385,
      "grad_norm": 0.8893993496894836,
      "learning_rate": 2.211149825783972e-05,
      "loss": 0.0555,
      "step": 24020
    },
    {
      "epoch": 5.581881533101045,
      "grad_norm": 0.6225247979164124,
      "learning_rate": 2.209988385598142e-05,
      "loss": 0.1346,
      "step": 24030
    },
    {
      "epoch": 5.5842044134727065,
      "grad_norm": 2.546799898147583,
      "learning_rate": 2.2088269454123113e-05,
      "loss": 0.1073,
      "step": 24040
    },
    {
      "epoch": 5.586527293844367,
      "grad_norm": 0.7958237528800964,
      "learning_rate": 2.207665505226481e-05,
      "loss": 0.1059,
      "step": 24050
    },
    {
      "epoch": 5.588850174216028,
      "grad_norm": 1.1947987079620361,
      "learning_rate": 2.2065040650406506e-05,
      "loss": 0.0691,
      "step": 24060
    },
    {
      "epoch": 5.5911730545876885,
      "grad_norm": 0.9225527048110962,
      "learning_rate": 2.20534262485482e-05,
      "loss": 0.0601,
      "step": 24070
    },
    {
      "epoch": 5.59349593495935,
      "grad_norm": 1.183940052986145,
      "learning_rate": 2.20418118466899e-05,
      "loss": 0.0976,
      "step": 24080
    },
    {
      "epoch": 5.59581881533101,
      "grad_norm": 1.9668009281158447,
      "learning_rate": 2.2030197444831593e-05,
      "loss": 0.0826,
      "step": 24090
    },
    {
      "epoch": 5.5981416957026715,
      "grad_norm": 0.6932756900787354,
      "learning_rate": 2.2018583042973288e-05,
      "loss": 0.0778,
      "step": 24100
    },
    {
      "epoch": 5.600464576074332,
      "grad_norm": 1.0094492435455322,
      "learning_rate": 2.2006968641114983e-05,
      "loss": 0.0832,
      "step": 24110
    },
    {
      "epoch": 5.602787456445993,
      "grad_norm": 0.9312772154808044,
      "learning_rate": 2.199535423925668e-05,
      "loss": 0.1029,
      "step": 24120
    },
    {
      "epoch": 5.605110336817654,
      "grad_norm": 0.7132519483566284,
      "learning_rate": 2.1983739837398375e-05,
      "loss": 0.1148,
      "step": 24130
    },
    {
      "epoch": 5.607433217189315,
      "grad_norm": 0.46334680914878845,
      "learning_rate": 2.197212543554007e-05,
      "loss": 0.0981,
      "step": 24140
    },
    {
      "epoch": 5.609756097560975,
      "grad_norm": 1.1764122247695923,
      "learning_rate": 2.1960511033681765e-05,
      "loss": 0.0768,
      "step": 24150
    },
    {
      "epoch": 5.6120789779326365,
      "grad_norm": 0.9387330412864685,
      "learning_rate": 2.1948896631823463e-05,
      "loss": 0.0786,
      "step": 24160
    },
    {
      "epoch": 5.614401858304297,
      "grad_norm": 1.5195521116256714,
      "learning_rate": 2.1937282229965157e-05,
      "loss": 0.1021,
      "step": 24170
    },
    {
      "epoch": 5.616724738675958,
      "grad_norm": 1.657166838645935,
      "learning_rate": 2.1925667828106852e-05,
      "loss": 0.1303,
      "step": 24180
    },
    {
      "epoch": 5.619047619047619,
      "grad_norm": 1.4852948188781738,
      "learning_rate": 2.191405342624855e-05,
      "loss": 0.1082,
      "step": 24190
    },
    {
      "epoch": 5.62137049941928,
      "grad_norm": 0.9423817992210388,
      "learning_rate": 2.1902439024390245e-05,
      "loss": 0.1462,
      "step": 24200
    },
    {
      "epoch": 5.623693379790941,
      "grad_norm": 1.965226173400879,
      "learning_rate": 2.1890824622531943e-05,
      "loss": 0.202,
      "step": 24210
    },
    {
      "epoch": 5.626016260162602,
      "grad_norm": 1.531722903251648,
      "learning_rate": 2.1879210220673638e-05,
      "loss": 0.08,
      "step": 24220
    },
    {
      "epoch": 5.628339140534262,
      "grad_norm": 0.9507977962493896,
      "learning_rate": 2.1867595818815332e-05,
      "loss": 0.1347,
      "step": 24230
    },
    {
      "epoch": 5.630662020905923,
      "grad_norm": 1.2458657026290894,
      "learning_rate": 2.1855981416957027e-05,
      "loss": 0.0847,
      "step": 24240
    },
    {
      "epoch": 5.6329849012775846,
      "grad_norm": 1.2304620742797852,
      "learning_rate": 2.1844367015098725e-05,
      "loss": 0.0913,
      "step": 24250
    },
    {
      "epoch": 5.635307781649245,
      "grad_norm": 0.6796102523803711,
      "learning_rate": 2.183275261324042e-05,
      "loss": 0.1036,
      "step": 24260
    },
    {
      "epoch": 5.637630662020906,
      "grad_norm": 1.4583799839019775,
      "learning_rate": 2.1821138211382114e-05,
      "loss": 0.0865,
      "step": 24270
    },
    {
      "epoch": 5.639953542392567,
      "grad_norm": 1.061719536781311,
      "learning_rate": 2.180952380952381e-05,
      "loss": 0.0771,
      "step": 24280
    },
    {
      "epoch": 5.642276422764228,
      "grad_norm": 0.3594873547554016,
      "learning_rate": 2.1797909407665507e-05,
      "loss": 0.0885,
      "step": 24290
    },
    {
      "epoch": 5.644599303135888,
      "grad_norm": 1.31403386592865,
      "learning_rate": 2.1786295005807202e-05,
      "loss": 0.1188,
      "step": 24300
    },
    {
      "epoch": 5.64692218350755,
      "grad_norm": 1.1957919597625732,
      "learning_rate": 2.1774680603948896e-05,
      "loss": 0.1197,
      "step": 24310
    },
    {
      "epoch": 5.64924506387921,
      "grad_norm": 1.239503264427185,
      "learning_rate": 2.1763066202090594e-05,
      "loss": 0.1279,
      "step": 24320
    },
    {
      "epoch": 5.651567944250871,
      "grad_norm": 1.2225927114486694,
      "learning_rate": 2.175145180023229e-05,
      "loss": 0.1349,
      "step": 24330
    },
    {
      "epoch": 5.653890824622532,
      "grad_norm": 1.0080468654632568,
      "learning_rate": 2.1739837398373987e-05,
      "loss": 0.1029,
      "step": 24340
    },
    {
      "epoch": 5.656213704994193,
      "grad_norm": 1.1427239179611206,
      "learning_rate": 2.172822299651568e-05,
      "loss": 0.0795,
      "step": 24350
    },
    {
      "epoch": 5.658536585365853,
      "grad_norm": 0.9920050501823425,
      "learning_rate": 2.1716608594657377e-05,
      "loss": 0.1561,
      "step": 24360
    },
    {
      "epoch": 5.660859465737515,
      "grad_norm": 0.5651798844337463,
      "learning_rate": 2.170499419279907e-05,
      "loss": 0.1093,
      "step": 24370
    },
    {
      "epoch": 5.663182346109175,
      "grad_norm": 2.226165533065796,
      "learning_rate": 2.169337979094077e-05,
      "loss": 0.0784,
      "step": 24380
    },
    {
      "epoch": 5.665505226480836,
      "grad_norm": 1.3301351070404053,
      "learning_rate": 2.1681765389082464e-05,
      "loss": 0.115,
      "step": 24390
    },
    {
      "epoch": 5.667828106852497,
      "grad_norm": 1.5497984886169434,
      "learning_rate": 2.167015098722416e-05,
      "loss": 0.1229,
      "step": 24400
    },
    {
      "epoch": 5.670150987224158,
      "grad_norm": 0.8448376655578613,
      "learning_rate": 2.1658536585365853e-05,
      "loss": 0.116,
      "step": 24410
    },
    {
      "epoch": 5.672473867595819,
      "grad_norm": 2.5009799003601074,
      "learning_rate": 2.164692218350755e-05,
      "loss": 0.1319,
      "step": 24420
    },
    {
      "epoch": 5.67479674796748,
      "grad_norm": 0.6862456202507019,
      "learning_rate": 2.1635307781649246e-05,
      "loss": 0.1486,
      "step": 24430
    },
    {
      "epoch": 5.67711962833914,
      "grad_norm": 0.7699275016784668,
      "learning_rate": 2.162369337979094e-05,
      "loss": 0.0685,
      "step": 24440
    },
    {
      "epoch": 5.679442508710801,
      "grad_norm": 1.160209059715271,
      "learning_rate": 2.161207897793264e-05,
      "loss": 0.0791,
      "step": 24450
    },
    {
      "epoch": 5.681765389082463,
      "grad_norm": 0.5700573921203613,
      "learning_rate": 2.1600464576074333e-05,
      "loss": 0.0959,
      "step": 24460
    },
    {
      "epoch": 5.684088269454123,
      "grad_norm": 0.857672393321991,
      "learning_rate": 2.158885017421603e-05,
      "loss": 0.1177,
      "step": 24470
    },
    {
      "epoch": 5.686411149825784,
      "grad_norm": 1.1078438758850098,
      "learning_rate": 2.1577235772357723e-05,
      "loss": 0.211,
      "step": 24480
    },
    {
      "epoch": 5.688734030197445,
      "grad_norm": 1.2552757263183594,
      "learning_rate": 2.156562137049942e-05,
      "loss": 0.1286,
      "step": 24490
    },
    {
      "epoch": 5.691056910569106,
      "grad_norm": 0.3952229619026184,
      "learning_rate": 2.1554006968641116e-05,
      "loss": 0.0963,
      "step": 24500
    },
    {
      "epoch": 5.693379790940766,
      "grad_norm": 0.8632999062538147,
      "learning_rate": 2.1542392566782814e-05,
      "loss": 0.0907,
      "step": 24510
    },
    {
      "epoch": 5.695702671312428,
      "grad_norm": 0.7572169899940491,
      "learning_rate": 2.1530778164924505e-05,
      "loss": 0.1344,
      "step": 24520
    },
    {
      "epoch": 5.698025551684088,
      "grad_norm": 0.7251092195510864,
      "learning_rate": 2.1519163763066203e-05,
      "loss": 0.2135,
      "step": 24530
    },
    {
      "epoch": 5.700348432055749,
      "grad_norm": 0.729682445526123,
      "learning_rate": 2.1507549361207898e-05,
      "loss": 0.056,
      "step": 24540
    },
    {
      "epoch": 5.70267131242741,
      "grad_norm": 1.3983486890792847,
      "learning_rate": 2.1495934959349596e-05,
      "loss": 0.1994,
      "step": 24550
    },
    {
      "epoch": 5.704994192799071,
      "grad_norm": 1.2301082611083984,
      "learning_rate": 2.148432055749129e-05,
      "loss": 0.0996,
      "step": 24560
    },
    {
      "epoch": 5.7073170731707314,
      "grad_norm": 1.287999153137207,
      "learning_rate": 2.1472706155632985e-05,
      "loss": 0.0833,
      "step": 24570
    },
    {
      "epoch": 5.709639953542393,
      "grad_norm": 0.8444987535476685,
      "learning_rate": 2.1461091753774683e-05,
      "loss": 0.1132,
      "step": 24580
    },
    {
      "epoch": 5.711962833914053,
      "grad_norm": 1.4830559492111206,
      "learning_rate": 2.1449477351916378e-05,
      "loss": 0.0553,
      "step": 24590
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.9378765821456909,
      "learning_rate": 2.1437862950058076e-05,
      "loss": 0.1169,
      "step": 24600
    },
    {
      "epoch": 5.716608594657375,
      "grad_norm": 1.3968453407287598,
      "learning_rate": 2.1426248548199767e-05,
      "loss": 0.0923,
      "step": 24610
    },
    {
      "epoch": 5.718931475029036,
      "grad_norm": 1.4214062690734863,
      "learning_rate": 2.1414634146341465e-05,
      "loss": 0.1499,
      "step": 24620
    },
    {
      "epoch": 5.7212543554006965,
      "grad_norm": 0.7533465027809143,
      "learning_rate": 2.140301974448316e-05,
      "loss": 0.0403,
      "step": 24630
    },
    {
      "epoch": 5.723577235772358,
      "grad_norm": 1.3816806077957153,
      "learning_rate": 2.1391405342624858e-05,
      "loss": 0.0771,
      "step": 24640
    },
    {
      "epoch": 5.725900116144018,
      "grad_norm": 1.239909052848816,
      "learning_rate": 2.137979094076655e-05,
      "loss": 0.0837,
      "step": 24650
    },
    {
      "epoch": 5.7282229965156795,
      "grad_norm": 0.7216540575027466,
      "learning_rate": 2.1368176538908247e-05,
      "loss": 0.0607,
      "step": 24660
    },
    {
      "epoch": 5.730545876887341,
      "grad_norm": 0.8098255395889282,
      "learning_rate": 2.1356562137049942e-05,
      "loss": 0.065,
      "step": 24670
    },
    {
      "epoch": 5.732868757259001,
      "grad_norm": 2.4522244930267334,
      "learning_rate": 2.134494773519164e-05,
      "loss": 0.1369,
      "step": 24680
    },
    {
      "epoch": 5.7351916376306615,
      "grad_norm": 0.7425429224967957,
      "learning_rate": 2.1333333333333335e-05,
      "loss": 0.1019,
      "step": 24690
    },
    {
      "epoch": 5.737514518002323,
      "grad_norm": 1.6997146606445312,
      "learning_rate": 2.132171893147503e-05,
      "loss": 0.1201,
      "step": 24700
    },
    {
      "epoch": 5.739837398373984,
      "grad_norm": 0.534846842288971,
      "learning_rate": 2.1310104529616724e-05,
      "loss": 0.1199,
      "step": 24710
    },
    {
      "epoch": 5.7421602787456445,
      "grad_norm": 1.423282265663147,
      "learning_rate": 2.1298490127758422e-05,
      "loss": 0.1859,
      "step": 24720
    },
    {
      "epoch": 5.744483159117306,
      "grad_norm": 1.2158865928649902,
      "learning_rate": 2.1286875725900117e-05,
      "loss": 0.1382,
      "step": 24730
    },
    {
      "epoch": 5.746806039488966,
      "grad_norm": 1.0948399305343628,
      "learning_rate": 2.127526132404181e-05,
      "loss": 0.0587,
      "step": 24740
    },
    {
      "epoch": 5.7491289198606275,
      "grad_norm": 0.6128302216529846,
      "learning_rate": 2.126364692218351e-05,
      "loss": 0.1101,
      "step": 24750
    },
    {
      "epoch": 5.751451800232288,
      "grad_norm": 1.615402340888977,
      "learning_rate": 2.1252032520325204e-05,
      "loss": 0.1024,
      "step": 24760
    },
    {
      "epoch": 5.753774680603949,
      "grad_norm": 0.7311407327651978,
      "learning_rate": 2.1240418118466902e-05,
      "loss": 0.0874,
      "step": 24770
    },
    {
      "epoch": 5.7560975609756095,
      "grad_norm": 1.1509408950805664,
      "learning_rate": 2.1228803716608593e-05,
      "loss": 0.0507,
      "step": 24780
    },
    {
      "epoch": 5.758420441347271,
      "grad_norm": 1.3945170640945435,
      "learning_rate": 2.121718931475029e-05,
      "loss": 0.0693,
      "step": 24790
    },
    {
      "epoch": 5.760743321718931,
      "grad_norm": 1.2763153314590454,
      "learning_rate": 2.1205574912891986e-05,
      "loss": 0.1011,
      "step": 24800
    },
    {
      "epoch": 5.7630662020905925,
      "grad_norm": 0.8600662350654602,
      "learning_rate": 2.1193960511033684e-05,
      "loss": 0.0777,
      "step": 24810
    },
    {
      "epoch": 5.765389082462253,
      "grad_norm": 1.1074497699737549,
      "learning_rate": 2.1182346109175376e-05,
      "loss": 0.0857,
      "step": 24820
    },
    {
      "epoch": 5.767711962833914,
      "grad_norm": 0.6735003590583801,
      "learning_rate": 2.1170731707317074e-05,
      "loss": 0.0992,
      "step": 24830
    },
    {
      "epoch": 5.770034843205575,
      "grad_norm": 0.6979719996452332,
      "learning_rate": 2.1159117305458768e-05,
      "loss": 0.1305,
      "step": 24840
    },
    {
      "epoch": 5.772357723577236,
      "grad_norm": 1.188878059387207,
      "learning_rate": 2.1147502903600466e-05,
      "loss": 0.0696,
      "step": 24850
    },
    {
      "epoch": 5.774680603948896,
      "grad_norm": 0.840545654296875,
      "learning_rate": 2.113588850174216e-05,
      "loss": 0.1015,
      "step": 24860
    },
    {
      "epoch": 5.7770034843205575,
      "grad_norm": 0.5795429944992065,
      "learning_rate": 2.1124274099883856e-05,
      "loss": 0.0689,
      "step": 24870
    },
    {
      "epoch": 5.779326364692219,
      "grad_norm": 1.3268259763717651,
      "learning_rate": 2.1112659698025554e-05,
      "loss": 0.1527,
      "step": 24880
    },
    {
      "epoch": 5.781649245063879,
      "grad_norm": 1.638347864151001,
      "learning_rate": 2.110104529616725e-05,
      "loss": 0.1264,
      "step": 24890
    },
    {
      "epoch": 5.78397212543554,
      "grad_norm": 0.7624351978302002,
      "learning_rate": 2.1089430894308946e-05,
      "loss": 0.0685,
      "step": 24900
    },
    {
      "epoch": 5.786295005807201,
      "grad_norm": 1.2089173793792725,
      "learning_rate": 2.1077816492450638e-05,
      "loss": 0.0927,
      "step": 24910
    },
    {
      "epoch": 5.788617886178862,
      "grad_norm": 1.3347524404525757,
      "learning_rate": 2.1066202090592336e-05,
      "loss": 0.1588,
      "step": 24920
    },
    {
      "epoch": 5.790940766550523,
      "grad_norm": 1.964661955833435,
      "learning_rate": 2.105458768873403e-05,
      "loss": 0.1125,
      "step": 24930
    },
    {
      "epoch": 5.793263646922184,
      "grad_norm": 0.5662861466407776,
      "learning_rate": 2.104297328687573e-05,
      "loss": 0.0639,
      "step": 24940
    },
    {
      "epoch": 5.795586527293844,
      "grad_norm": 0.5607930421829224,
      "learning_rate": 2.103135888501742e-05,
      "loss": 0.122,
      "step": 24950
    },
    {
      "epoch": 5.7979094076655056,
      "grad_norm": 0.5122814774513245,
      "learning_rate": 2.1019744483159118e-05,
      "loss": 0.1497,
      "step": 24960
    },
    {
      "epoch": 5.800232288037166,
      "grad_norm": 1.0416507720947266,
      "learning_rate": 2.1008130081300813e-05,
      "loss": 0.0885,
      "step": 24970
    },
    {
      "epoch": 5.802555168408827,
      "grad_norm": 0.9512141346931458,
      "learning_rate": 2.099651567944251e-05,
      "loss": 0.1753,
      "step": 24980
    },
    {
      "epoch": 5.804878048780488,
      "grad_norm": 1.7055402994155884,
      "learning_rate": 2.0984901277584205e-05,
      "loss": 0.1372,
      "step": 24990
    },
    {
      "epoch": 5.807200929152149,
      "grad_norm": 0.9408290386199951,
      "learning_rate": 2.09732868757259e-05,
      "loss": 0.0948,
      "step": 25000
    },
    {
      "epoch": 5.809523809523809,
      "grad_norm": 1.4479140043258667,
      "learning_rate": 2.0961672473867598e-05,
      "loss": 0.1062,
      "step": 25010
    },
    {
      "epoch": 5.811846689895471,
      "grad_norm": 1.095805287361145,
      "learning_rate": 2.0950058072009293e-05,
      "loss": 0.1287,
      "step": 25020
    },
    {
      "epoch": 5.814169570267131,
      "grad_norm": 0.45056432485580444,
      "learning_rate": 2.093844367015099e-05,
      "loss": 0.1179,
      "step": 25030
    },
    {
      "epoch": 5.816492450638792,
      "grad_norm": 0.6648095846176147,
      "learning_rate": 2.0926829268292682e-05,
      "loss": 0.0779,
      "step": 25040
    },
    {
      "epoch": 5.818815331010453,
      "grad_norm": 0.595525860786438,
      "learning_rate": 2.091521486643438e-05,
      "loss": 0.1428,
      "step": 25050
    },
    {
      "epoch": 5.821138211382114,
      "grad_norm": 0.7285268902778625,
      "learning_rate": 2.0903600464576075e-05,
      "loss": 0.0595,
      "step": 25060
    },
    {
      "epoch": 5.823461091753774,
      "grad_norm": 0.8394020795822144,
      "learning_rate": 2.0891986062717773e-05,
      "loss": 0.1307,
      "step": 25070
    },
    {
      "epoch": 5.825783972125436,
      "grad_norm": 2.415328025817871,
      "learning_rate": 2.0880371660859464e-05,
      "loss": 0.1128,
      "step": 25080
    },
    {
      "epoch": 5.828106852497096,
      "grad_norm": 1.0312254428863525,
      "learning_rate": 2.0868757259001162e-05,
      "loss": 0.0672,
      "step": 25090
    },
    {
      "epoch": 5.830429732868757,
      "grad_norm": 0.9287647604942322,
      "learning_rate": 2.0857142857142857e-05,
      "loss": 0.0726,
      "step": 25100
    },
    {
      "epoch": 5.832752613240418,
      "grad_norm": 1.2998161315917969,
      "learning_rate": 2.0845528455284555e-05,
      "loss": 0.0638,
      "step": 25110
    },
    {
      "epoch": 5.835075493612079,
      "grad_norm": 1.136582612991333,
      "learning_rate": 2.083391405342625e-05,
      "loss": 0.1328,
      "step": 25120
    },
    {
      "epoch": 5.83739837398374,
      "grad_norm": 0.9876629114151001,
      "learning_rate": 2.0822299651567944e-05,
      "loss": 0.0796,
      "step": 25130
    },
    {
      "epoch": 5.839721254355401,
      "grad_norm": 2.2746200561523438,
      "learning_rate": 2.0810685249709642e-05,
      "loss": 0.1321,
      "step": 25140
    },
    {
      "epoch": 5.842044134727061,
      "grad_norm": 1.5997167825698853,
      "learning_rate": 2.0799070847851337e-05,
      "loss": 0.0845,
      "step": 25150
    },
    {
      "epoch": 5.844367015098722,
      "grad_norm": 1.0484225749969482,
      "learning_rate": 2.078745644599303e-05,
      "loss": 0.1028,
      "step": 25160
    },
    {
      "epoch": 5.846689895470384,
      "grad_norm": 0.6589535474777222,
      "learning_rate": 2.0775842044134726e-05,
      "loss": 0.1343,
      "step": 25170
    },
    {
      "epoch": 5.849012775842044,
      "grad_norm": 0.9028995037078857,
      "learning_rate": 2.0764227642276424e-05,
      "loss": 0.0598,
      "step": 25180
    },
    {
      "epoch": 5.851335656213705,
      "grad_norm": 0.9738557934761047,
      "learning_rate": 2.075261324041812e-05,
      "loss": 0.0806,
      "step": 25190
    },
    {
      "epoch": 5.853658536585366,
      "grad_norm": 3.142312526702881,
      "learning_rate": 2.0740998838559817e-05,
      "loss": 0.1784,
      "step": 25200
    },
    {
      "epoch": 5.855981416957027,
      "grad_norm": 0.9865138530731201,
      "learning_rate": 2.072938443670151e-05,
      "loss": 0.1028,
      "step": 25210
    },
    {
      "epoch": 5.858304297328687,
      "grad_norm": 1.402360439300537,
      "learning_rate": 2.0717770034843206e-05,
      "loss": 0.0866,
      "step": 25220
    },
    {
      "epoch": 5.860627177700349,
      "grad_norm": 1.0597553253173828,
      "learning_rate": 2.07061556329849e-05,
      "loss": 0.1033,
      "step": 25230
    },
    {
      "epoch": 5.862950058072009,
      "grad_norm": 2.58636736869812,
      "learning_rate": 2.06945412311266e-05,
      "loss": 0.1499,
      "step": 25240
    },
    {
      "epoch": 5.86527293844367,
      "grad_norm": 1.1987196207046509,
      "learning_rate": 2.0682926829268294e-05,
      "loss": 0.1177,
      "step": 25250
    },
    {
      "epoch": 5.867595818815331,
      "grad_norm": 0.5567889213562012,
      "learning_rate": 2.067131242740999e-05,
      "loss": 0.0646,
      "step": 25260
    },
    {
      "epoch": 5.869918699186992,
      "grad_norm": 0.5522286891937256,
      "learning_rate": 2.0659698025551687e-05,
      "loss": 0.0842,
      "step": 25270
    },
    {
      "epoch": 5.8722415795586524,
      "grad_norm": 0.511430561542511,
      "learning_rate": 2.064808362369338e-05,
      "loss": 0.1552,
      "step": 25280
    },
    {
      "epoch": 5.874564459930314,
      "grad_norm": 1.1798065900802612,
      "learning_rate": 2.0636469221835076e-05,
      "loss": 0.1637,
      "step": 25290
    },
    {
      "epoch": 5.876887340301974,
      "grad_norm": 0.5690488815307617,
      "learning_rate": 2.062485481997677e-05,
      "loss": 0.0486,
      "step": 25300
    },
    {
      "epoch": 5.879210220673635,
      "grad_norm": 0.5742089748382568,
      "learning_rate": 2.061324041811847e-05,
      "loss": 0.1562,
      "step": 25310
    },
    {
      "epoch": 5.881533101045296,
      "grad_norm": 0.6397975087165833,
      "learning_rate": 2.0601626016260163e-05,
      "loss": 0.0834,
      "step": 25320
    },
    {
      "epoch": 5.883855981416957,
      "grad_norm": 1.5610798597335815,
      "learning_rate": 2.059001161440186e-05,
      "loss": 0.1534,
      "step": 25330
    },
    {
      "epoch": 5.886178861788618,
      "grad_norm": 1.1715573072433472,
      "learning_rate": 2.0578397212543553e-05,
      "loss": 0.0686,
      "step": 25340
    },
    {
      "epoch": 5.888501742160279,
      "grad_norm": 1.1760069131851196,
      "learning_rate": 2.056678281068525e-05,
      "loss": 0.0844,
      "step": 25350
    },
    {
      "epoch": 5.890824622531939,
      "grad_norm": 0.7459306120872498,
      "learning_rate": 2.0555168408826945e-05,
      "loss": 0.0923,
      "step": 25360
    },
    {
      "epoch": 5.8931475029036005,
      "grad_norm": 0.9019935131072998,
      "learning_rate": 2.0543554006968644e-05,
      "loss": 0.0915,
      "step": 25370
    },
    {
      "epoch": 5.895470383275262,
      "grad_norm": 1.7509074211120605,
      "learning_rate": 2.0531939605110338e-05,
      "loss": 0.1306,
      "step": 25380
    },
    {
      "epoch": 5.897793263646922,
      "grad_norm": 2.675025463104248,
      "learning_rate": 2.0520325203252033e-05,
      "loss": 0.0741,
      "step": 25390
    },
    {
      "epoch": 5.900116144018583,
      "grad_norm": 1.3043878078460693,
      "learning_rate": 2.050871080139373e-05,
      "loss": 0.1283,
      "step": 25400
    },
    {
      "epoch": 5.902439024390244,
      "grad_norm": 1.1442151069641113,
      "learning_rate": 2.0497096399535426e-05,
      "loss": 0.1123,
      "step": 25410
    },
    {
      "epoch": 5.904761904761905,
      "grad_norm": 1.3175551891326904,
      "learning_rate": 2.048548199767712e-05,
      "loss": 0.0652,
      "step": 25420
    },
    {
      "epoch": 5.9070847851335655,
      "grad_norm": 0.6016945838928223,
      "learning_rate": 2.0473867595818815e-05,
      "loss": 0.0993,
      "step": 25430
    },
    {
      "epoch": 5.909407665505227,
      "grad_norm": 1.632714867591858,
      "learning_rate": 2.0462253193960513e-05,
      "loss": 0.1617,
      "step": 25440
    },
    {
      "epoch": 5.911730545876887,
      "grad_norm": 0.9624786972999573,
      "learning_rate": 2.0450638792102208e-05,
      "loss": 0.0765,
      "step": 25450
    },
    {
      "epoch": 5.9140534262485485,
      "grad_norm": 1.5810211896896362,
      "learning_rate": 2.0439024390243902e-05,
      "loss": 0.1245,
      "step": 25460
    },
    {
      "epoch": 5.916376306620209,
      "grad_norm": 0.7600568532943726,
      "learning_rate": 2.0427409988385597e-05,
      "loss": 0.131,
      "step": 25470
    },
    {
      "epoch": 5.91869918699187,
      "grad_norm": 0.7624545097351074,
      "learning_rate": 2.0415795586527295e-05,
      "loss": 0.1016,
      "step": 25480
    },
    {
      "epoch": 5.9210220673635305,
      "grad_norm": 0.8548696041107178,
      "learning_rate": 2.040418118466899e-05,
      "loss": 0.0502,
      "step": 25490
    },
    {
      "epoch": 5.923344947735192,
      "grad_norm": 0.9048792123794556,
      "learning_rate": 2.0392566782810688e-05,
      "loss": 0.1538,
      "step": 25500
    },
    {
      "epoch": 5.925667828106852,
      "grad_norm": 1.2723379135131836,
      "learning_rate": 2.0380952380952382e-05,
      "loss": 0.0556,
      "step": 25510
    },
    {
      "epoch": 5.9279907084785135,
      "grad_norm": 0.9434512257575989,
      "learning_rate": 2.0369337979094077e-05,
      "loss": 0.1229,
      "step": 25520
    },
    {
      "epoch": 5.930313588850174,
      "grad_norm": 0.9237868785858154,
      "learning_rate": 2.0357723577235775e-05,
      "loss": 0.0844,
      "step": 25530
    },
    {
      "epoch": 5.932636469221835,
      "grad_norm": 0.5131212472915649,
      "learning_rate": 2.034610917537747e-05,
      "loss": 0.0621,
      "step": 25540
    },
    {
      "epoch": 5.934959349593496,
      "grad_norm": 1.2428430318832397,
      "learning_rate": 2.0334494773519165e-05,
      "loss": 0.0873,
      "step": 25550
    },
    {
      "epoch": 5.937282229965157,
      "grad_norm": 1.941308617591858,
      "learning_rate": 2.032288037166086e-05,
      "loss": 0.063,
      "step": 25560
    },
    {
      "epoch": 5.939605110336817,
      "grad_norm": 0.537202775478363,
      "learning_rate": 2.0311265969802557e-05,
      "loss": 0.0722,
      "step": 25570
    },
    {
      "epoch": 5.9419279907084785,
      "grad_norm": 0.8507993817329407,
      "learning_rate": 2.0299651567944252e-05,
      "loss": 0.0946,
      "step": 25580
    },
    {
      "epoch": 5.94425087108014,
      "grad_norm": 1.4669749736785889,
      "learning_rate": 2.0288037166085947e-05,
      "loss": 0.0913,
      "step": 25590
    },
    {
      "epoch": 5.9465737514518,
      "grad_norm": 0.4617915749549866,
      "learning_rate": 2.027642276422764e-05,
      "loss": 0.134,
      "step": 25600
    },
    {
      "epoch": 5.948896631823461,
      "grad_norm": 0.7168968319892883,
      "learning_rate": 2.026480836236934e-05,
      "loss": 0.0929,
      "step": 25610
    },
    {
      "epoch": 5.951219512195122,
      "grad_norm": 1.5852223634719849,
      "learning_rate": 2.0253193960511034e-05,
      "loss": 0.0805,
      "step": 25620
    },
    {
      "epoch": 5.953542392566783,
      "grad_norm": 1.2682256698608398,
      "learning_rate": 2.024157955865273e-05,
      "loss": 0.1251,
      "step": 25630
    },
    {
      "epoch": 5.955865272938444,
      "grad_norm": 1.236566185951233,
      "learning_rate": 2.0229965156794427e-05,
      "loss": 0.0894,
      "step": 25640
    },
    {
      "epoch": 5.958188153310105,
      "grad_norm": 1.0064492225646973,
      "learning_rate": 2.021835075493612e-05,
      "loss": 0.1146,
      "step": 25650
    },
    {
      "epoch": 5.960511033681765,
      "grad_norm": 0.8799839019775391,
      "learning_rate": 2.020673635307782e-05,
      "loss": 0.1076,
      "step": 25660
    },
    {
      "epoch": 5.9628339140534266,
      "grad_norm": 1.4846256971359253,
      "learning_rate": 2.0195121951219514e-05,
      "loss": 0.1741,
      "step": 25670
    },
    {
      "epoch": 5.965156794425087,
      "grad_norm": 1.2528266906738281,
      "learning_rate": 2.018350754936121e-05,
      "loss": 0.0532,
      "step": 25680
    },
    {
      "epoch": 5.967479674796748,
      "grad_norm": 0.659967839717865,
      "learning_rate": 2.0171893147502904e-05,
      "loss": 0.0728,
      "step": 25690
    },
    {
      "epoch": 5.969802555168409,
      "grad_norm": 0.6227300763130188,
      "learning_rate": 2.01602787456446e-05,
      "loss": 0.1079,
      "step": 25700
    },
    {
      "epoch": 5.97212543554007,
      "grad_norm": 1.7290600538253784,
      "learning_rate": 2.0148664343786296e-05,
      "loss": 0.148,
      "step": 25710
    },
    {
      "epoch": 5.97444831591173,
      "grad_norm": 1.319374680519104,
      "learning_rate": 2.013704994192799e-05,
      "loss": 0.088,
      "step": 25720
    },
    {
      "epoch": 5.976771196283392,
      "grad_norm": 0.7109538316726685,
      "learning_rate": 2.0125435540069686e-05,
      "loss": 0.0892,
      "step": 25730
    },
    {
      "epoch": 5.979094076655052,
      "grad_norm": 0.4554305076599121,
      "learning_rate": 2.0113821138211384e-05,
      "loss": 0.0799,
      "step": 25740
    },
    {
      "epoch": 5.981416957026713,
      "grad_norm": 0.8397374153137207,
      "learning_rate": 2.010220673635308e-05,
      "loss": 0.0589,
      "step": 25750
    },
    {
      "epoch": 5.983739837398374,
      "grad_norm": 1.4200856685638428,
      "learning_rate": 2.0090592334494773e-05,
      "loss": 0.122,
      "step": 25760
    },
    {
      "epoch": 5.986062717770035,
      "grad_norm": 1.536703109741211,
      "learning_rate": 2.007897793263647e-05,
      "loss": 0.1015,
      "step": 25770
    },
    {
      "epoch": 5.988385598141695,
      "grad_norm": 0.769950270652771,
      "learning_rate": 2.0067363530778166e-05,
      "loss": 0.1702,
      "step": 25780
    },
    {
      "epoch": 5.990708478513357,
      "grad_norm": 0.6732111573219299,
      "learning_rate": 2.0055749128919864e-05,
      "loss": 0.1055,
      "step": 25790
    },
    {
      "epoch": 5.993031358885017,
      "grad_norm": 1.0002349615097046,
      "learning_rate": 2.0044134727061555e-05,
      "loss": 0.0665,
      "step": 25800
    },
    {
      "epoch": 5.995354239256678,
      "grad_norm": 0.5473568439483643,
      "learning_rate": 2.0032520325203253e-05,
      "loss": 0.0894,
      "step": 25810
    },
    {
      "epoch": 5.997677119628339,
      "grad_norm": 2.081458330154419,
      "learning_rate": 2.0020905923344948e-05,
      "loss": 0.095,
      "step": 25820
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.4968843460083008,
      "learning_rate": 2.0009291521486646e-05,
      "loss": 0.1425,
      "step": 25830
    },
    {
      "epoch": 6.002322880371661,
      "grad_norm": 0.8561180233955383,
      "learning_rate": 1.999767711962834e-05,
      "loss": 0.0973,
      "step": 25840
    },
    {
      "epoch": 6.004645760743322,
      "grad_norm": 2.1419856548309326,
      "learning_rate": 1.9986062717770035e-05,
      "loss": 0.0597,
      "step": 25850
    },
    {
      "epoch": 6.006968641114983,
      "grad_norm": 1.763565182685852,
      "learning_rate": 1.997444831591173e-05,
      "loss": 0.0987,
      "step": 25860
    },
    {
      "epoch": 6.009291521486643,
      "grad_norm": 1.127639889717102,
      "learning_rate": 1.9962833914053428e-05,
      "loss": 0.0485,
      "step": 25870
    },
    {
      "epoch": 6.011614401858305,
      "grad_norm": 1.667734980583191,
      "learning_rate": 1.9951219512195123e-05,
      "loss": 0.1543,
      "step": 25880
    },
    {
      "epoch": 6.013937282229965,
      "grad_norm": 0.9465692639350891,
      "learning_rate": 1.9939605110336817e-05,
      "loss": 0.093,
      "step": 25890
    },
    {
      "epoch": 6.016260162601626,
      "grad_norm": 0.7468287348747253,
      "learning_rate": 1.9927990708478515e-05,
      "loss": 0.1402,
      "step": 25900
    },
    {
      "epoch": 6.018583042973287,
      "grad_norm": 2.3136069774627686,
      "learning_rate": 1.991637630662021e-05,
      "loss": 0.1741,
      "step": 25910
    },
    {
      "epoch": 6.020905923344948,
      "grad_norm": 1.1534318923950195,
      "learning_rate": 1.9904761904761908e-05,
      "loss": 0.1228,
      "step": 25920
    },
    {
      "epoch": 6.023228803716608,
      "grad_norm": 1.25944983959198,
      "learning_rate": 1.98931475029036e-05,
      "loss": 0.0777,
      "step": 25930
    },
    {
      "epoch": 6.02555168408827,
      "grad_norm": 0.6528646945953369,
      "learning_rate": 1.9881533101045297e-05,
      "loss": 0.1301,
      "step": 25940
    },
    {
      "epoch": 6.02787456445993,
      "grad_norm": 1.4823864698410034,
      "learning_rate": 1.9869918699186992e-05,
      "loss": 0.097,
      "step": 25950
    },
    {
      "epoch": 6.030197444831591,
      "grad_norm": 1.4934910535812378,
      "learning_rate": 1.985830429732869e-05,
      "loss": 0.1219,
      "step": 25960
    },
    {
      "epoch": 6.032520325203252,
      "grad_norm": 1.765878677368164,
      "learning_rate": 1.9846689895470385e-05,
      "loss": 0.0751,
      "step": 25970
    },
    {
      "epoch": 6.034843205574913,
      "grad_norm": 1.2736589908599854,
      "learning_rate": 1.983507549361208e-05,
      "loss": 0.0631,
      "step": 25980
    },
    {
      "epoch": 6.0371660859465734,
      "grad_norm": 1.03805410861969,
      "learning_rate": 1.9823461091753774e-05,
      "loss": 0.0466,
      "step": 25990
    },
    {
      "epoch": 6.039488966318235,
      "grad_norm": 0.8022184371948242,
      "learning_rate": 1.9811846689895472e-05,
      "loss": 0.1013,
      "step": 26000
    },
    {
      "epoch": 6.041811846689895,
      "grad_norm": 1.8710864782333374,
      "learning_rate": 1.9800232288037167e-05,
      "loss": 0.1551,
      "step": 26010
    },
    {
      "epoch": 6.044134727061556,
      "grad_norm": 0.9228224158287048,
      "learning_rate": 1.978861788617886e-05,
      "loss": 0.0782,
      "step": 26020
    },
    {
      "epoch": 6.046457607433217,
      "grad_norm": 1.5152156352996826,
      "learning_rate": 1.977700348432056e-05,
      "loss": 0.0618,
      "step": 26030
    },
    {
      "epoch": 6.048780487804878,
      "grad_norm": 0.6661224365234375,
      "learning_rate": 1.9765389082462254e-05,
      "loss": 0.0917,
      "step": 26040
    },
    {
      "epoch": 6.0511033681765385,
      "grad_norm": 1.0841628313064575,
      "learning_rate": 1.9753774680603952e-05,
      "loss": 0.1162,
      "step": 26050
    },
    {
      "epoch": 6.0534262485482,
      "grad_norm": 0.9445303678512573,
      "learning_rate": 1.9742160278745644e-05,
      "loss": 0.0609,
      "step": 26060
    },
    {
      "epoch": 6.055749128919861,
      "grad_norm": 0.6829453110694885,
      "learning_rate": 1.9730545876887342e-05,
      "loss": 0.0959,
      "step": 26070
    },
    {
      "epoch": 6.0580720092915215,
      "grad_norm": 0.990074872970581,
      "learning_rate": 1.9718931475029036e-05,
      "loss": 0.1157,
      "step": 26080
    },
    {
      "epoch": 6.060394889663183,
      "grad_norm": 1.050088882446289,
      "learning_rate": 1.9707317073170734e-05,
      "loss": 0.061,
      "step": 26090
    },
    {
      "epoch": 6.062717770034843,
      "grad_norm": 1.0095791816711426,
      "learning_rate": 1.9695702671312426e-05,
      "loss": 0.0613,
      "step": 26100
    },
    {
      "epoch": 6.065040650406504,
      "grad_norm": 2.145911931991577,
      "learning_rate": 1.9684088269454124e-05,
      "loss": 0.0791,
      "step": 26110
    },
    {
      "epoch": 6.067363530778165,
      "grad_norm": 0.7219806909561157,
      "learning_rate": 1.967247386759582e-05,
      "loss": 0.1058,
      "step": 26120
    },
    {
      "epoch": 6.069686411149826,
      "grad_norm": 0.6416128277778625,
      "learning_rate": 1.9660859465737517e-05,
      "loss": 0.1077,
      "step": 26130
    },
    {
      "epoch": 6.0720092915214865,
      "grad_norm": 0.8822039365768433,
      "learning_rate": 1.964924506387921e-05,
      "loss": 0.0834,
      "step": 26140
    },
    {
      "epoch": 6.074332171893148,
      "grad_norm": 1.6552667617797852,
      "learning_rate": 1.9637630662020906e-05,
      "loss": 0.1365,
      "step": 26150
    },
    {
      "epoch": 6.076655052264808,
      "grad_norm": 0.6644387245178223,
      "learning_rate": 1.9626016260162604e-05,
      "loss": 0.068,
      "step": 26160
    },
    {
      "epoch": 6.0789779326364695,
      "grad_norm": 0.6274144053459167,
      "learning_rate": 1.96144018583043e-05,
      "loss": 0.1806,
      "step": 26170
    },
    {
      "epoch": 6.08130081300813,
      "grad_norm": 0.7037593722343445,
      "learning_rate": 1.9602787456445997e-05,
      "loss": 0.1803,
      "step": 26180
    },
    {
      "epoch": 6.083623693379791,
      "grad_norm": 0.3940947651863098,
      "learning_rate": 1.9591173054587688e-05,
      "loss": 0.0817,
      "step": 26190
    },
    {
      "epoch": 6.0859465737514515,
      "grad_norm": 0.6175056099891663,
      "learning_rate": 1.9579558652729386e-05,
      "loss": 0.1174,
      "step": 26200
    },
    {
      "epoch": 6.088269454123113,
      "grad_norm": 1.482783555984497,
      "learning_rate": 1.956794425087108e-05,
      "loss": 0.1949,
      "step": 26210
    },
    {
      "epoch": 6.090592334494773,
      "grad_norm": 1.3945719003677368,
      "learning_rate": 1.955632984901278e-05,
      "loss": 0.1188,
      "step": 26220
    },
    {
      "epoch": 6.0929152148664345,
      "grad_norm": 1.3308273553848267,
      "learning_rate": 1.954471544715447e-05,
      "loss": 0.1224,
      "step": 26230
    },
    {
      "epoch": 6.095238095238095,
      "grad_norm": 0.9411181807518005,
      "learning_rate": 1.9533101045296168e-05,
      "loss": 0.096,
      "step": 26240
    },
    {
      "epoch": 6.097560975609756,
      "grad_norm": 0.8269926309585571,
      "learning_rate": 1.9521486643437863e-05,
      "loss": 0.0827,
      "step": 26250
    },
    {
      "epoch": 6.099883855981417,
      "grad_norm": 0.95993971824646,
      "learning_rate": 1.950987224157956e-05,
      "loss": 0.076,
      "step": 26260
    },
    {
      "epoch": 6.102206736353078,
      "grad_norm": 1.081730842590332,
      "learning_rate": 1.9498257839721256e-05,
      "loss": 0.1456,
      "step": 26270
    },
    {
      "epoch": 6.104529616724738,
      "grad_norm": 0.7050412893295288,
      "learning_rate": 1.948664343786295e-05,
      "loss": 0.0943,
      "step": 26280
    },
    {
      "epoch": 6.1068524970963995,
      "grad_norm": 1.0496572256088257,
      "learning_rate": 1.9475029036004648e-05,
      "loss": 0.0738,
      "step": 26290
    },
    {
      "epoch": 6.109175377468061,
      "grad_norm": 2.155144691467285,
      "learning_rate": 1.9463414634146343e-05,
      "loss": 0.1889,
      "step": 26300
    },
    {
      "epoch": 6.111498257839721,
      "grad_norm": 0.8017553687095642,
      "learning_rate": 1.945180023228804e-05,
      "loss": 0.0768,
      "step": 26310
    },
    {
      "epoch": 6.1138211382113825,
      "grad_norm": 0.6011546850204468,
      "learning_rate": 1.9440185830429732e-05,
      "loss": 0.1218,
      "step": 26320
    },
    {
      "epoch": 6.116144018583043,
      "grad_norm": 0.5725927352905273,
      "learning_rate": 1.942857142857143e-05,
      "loss": 0.1116,
      "step": 26330
    },
    {
      "epoch": 6.118466898954704,
      "grad_norm": 0.8080370426177979,
      "learning_rate": 1.9416957026713125e-05,
      "loss": 0.0957,
      "step": 26340
    },
    {
      "epoch": 6.120789779326365,
      "grad_norm": 1.961391806602478,
      "learning_rate": 1.9405342624854823e-05,
      "loss": 0.0824,
      "step": 26350
    },
    {
      "epoch": 6.123112659698026,
      "grad_norm": 0.8006208539009094,
      "learning_rate": 1.9393728222996514e-05,
      "loss": 0.0592,
      "step": 26360
    },
    {
      "epoch": 6.125435540069686,
      "grad_norm": 1.829412817955017,
      "learning_rate": 1.9382113821138212e-05,
      "loss": 0.0845,
      "step": 26370
    },
    {
      "epoch": 6.1277584204413476,
      "grad_norm": 1.0959140062332153,
      "learning_rate": 1.9370499419279907e-05,
      "loss": 0.0637,
      "step": 26380
    },
    {
      "epoch": 6.130081300813008,
      "grad_norm": 0.7017579078674316,
      "learning_rate": 1.9358885017421605e-05,
      "loss": 0.077,
      "step": 26390
    },
    {
      "epoch": 6.132404181184669,
      "grad_norm": 1.1250073909759521,
      "learning_rate": 1.93472706155633e-05,
      "loss": 0.1331,
      "step": 26400
    },
    {
      "epoch": 6.13472706155633,
      "grad_norm": 1.8370579481124878,
      "learning_rate": 1.9335656213704995e-05,
      "loss": 0.1903,
      "step": 26410
    },
    {
      "epoch": 6.137049941927991,
      "grad_norm": 1.0101206302642822,
      "learning_rate": 1.9324041811846693e-05,
      "loss": 0.0674,
      "step": 26420
    },
    {
      "epoch": 6.139372822299651,
      "grad_norm": 1.0183137655258179,
      "learning_rate": 1.9312427409988387e-05,
      "loss": 0.0804,
      "step": 26430
    },
    {
      "epoch": 6.141695702671313,
      "grad_norm": 1.189778447151184,
      "learning_rate": 1.9300813008130082e-05,
      "loss": 0.1148,
      "step": 26440
    },
    {
      "epoch": 6.144018583042973,
      "grad_norm": 0.7978243231773376,
      "learning_rate": 1.9289198606271777e-05,
      "loss": 0.1005,
      "step": 26450
    },
    {
      "epoch": 6.146341463414634,
      "grad_norm": 1.7047092914581299,
      "learning_rate": 1.9277584204413475e-05,
      "loss": 0.0692,
      "step": 26460
    },
    {
      "epoch": 6.148664343786295,
      "grad_norm": 1.0183237791061401,
      "learning_rate": 1.926596980255517e-05,
      "loss": 0.0768,
      "step": 26470
    },
    {
      "epoch": 6.150987224157956,
      "grad_norm": 1.0803812742233276,
      "learning_rate": 1.9254355400696867e-05,
      "loss": 0.138,
      "step": 26480
    },
    {
      "epoch": 6.153310104529616,
      "grad_norm": 0.6246448755264282,
      "learning_rate": 1.924274099883856e-05,
      "loss": 0.1532,
      "step": 26490
    },
    {
      "epoch": 6.155632984901278,
      "grad_norm": 0.7731600999832153,
      "learning_rate": 1.9231126596980257e-05,
      "loss": 0.1403,
      "step": 26500
    },
    {
      "epoch": 6.157955865272938,
      "grad_norm": 0.6522690653800964,
      "learning_rate": 1.921951219512195e-05,
      "loss": 0.077,
      "step": 26510
    },
    {
      "epoch": 6.160278745644599,
      "grad_norm": 1.1593142747879028,
      "learning_rate": 1.920789779326365e-05,
      "loss": 0.1089,
      "step": 26520
    },
    {
      "epoch": 6.16260162601626,
      "grad_norm": 0.8559406399726868,
      "learning_rate": 1.9196283391405344e-05,
      "loss": 0.2055,
      "step": 26530
    },
    {
      "epoch": 6.164924506387921,
      "grad_norm": 1.0228382349014282,
      "learning_rate": 1.918466898954704e-05,
      "loss": 0.0973,
      "step": 26540
    },
    {
      "epoch": 6.167247386759582,
      "grad_norm": 1.3345119953155518,
      "learning_rate": 1.9173054587688737e-05,
      "loss": 0.1266,
      "step": 26550
    },
    {
      "epoch": 6.169570267131243,
      "grad_norm": 0.9769662618637085,
      "learning_rate": 1.916144018583043e-05,
      "loss": 0.1063,
      "step": 26560
    },
    {
      "epoch": 6.171893147502904,
      "grad_norm": 0.900865375995636,
      "learning_rate": 1.9149825783972126e-05,
      "loss": 0.0932,
      "step": 26570
    },
    {
      "epoch": 6.174216027874564,
      "grad_norm": 0.7528730630874634,
      "learning_rate": 1.913821138211382e-05,
      "loss": 0.0816,
      "step": 26580
    },
    {
      "epoch": 6.176538908246226,
      "grad_norm": 0.6018865704536438,
      "learning_rate": 1.912659698025552e-05,
      "loss": 0.0607,
      "step": 26590
    },
    {
      "epoch": 6.178861788617886,
      "grad_norm": 0.8293842673301697,
      "learning_rate": 1.9114982578397214e-05,
      "loss": 0.1321,
      "step": 26600
    },
    {
      "epoch": 6.181184668989547,
      "grad_norm": 1.2571494579315186,
      "learning_rate": 1.910336817653891e-05,
      "loss": 0.059,
      "step": 26610
    },
    {
      "epoch": 6.183507549361208,
      "grad_norm": 0.7994457483291626,
      "learning_rate": 1.9091753774680603e-05,
      "loss": 0.1166,
      "step": 26620
    },
    {
      "epoch": 6.185830429732869,
      "grad_norm": 0.6643321514129639,
      "learning_rate": 1.90801393728223e-05,
      "loss": 0.1084,
      "step": 26630
    },
    {
      "epoch": 6.188153310104529,
      "grad_norm": 0.6044542193412781,
      "learning_rate": 1.9068524970963996e-05,
      "loss": 0.0618,
      "step": 26640
    },
    {
      "epoch": 6.190476190476191,
      "grad_norm": 0.8497362732887268,
      "learning_rate": 1.9056910569105694e-05,
      "loss": 0.1107,
      "step": 26650
    },
    {
      "epoch": 6.192799070847851,
      "grad_norm": 0.9057004451751709,
      "learning_rate": 1.904529616724739e-05,
      "loss": 0.1057,
      "step": 26660
    },
    {
      "epoch": 6.195121951219512,
      "grad_norm": 1.4153921604156494,
      "learning_rate": 1.9033681765389083e-05,
      "loss": 0.1192,
      "step": 26670
    },
    {
      "epoch": 6.197444831591173,
      "grad_norm": 0.7243029475212097,
      "learning_rate": 1.9022067363530778e-05,
      "loss": 0.0784,
      "step": 26680
    },
    {
      "epoch": 6.199767711962834,
      "grad_norm": 0.6462778449058533,
      "learning_rate": 1.9010452961672476e-05,
      "loss": 0.0583,
      "step": 26690
    },
    {
      "epoch": 6.2020905923344944,
      "grad_norm": 0.5390481352806091,
      "learning_rate": 1.899883855981417e-05,
      "loss": 0.0734,
      "step": 26700
    },
    {
      "epoch": 6.204413472706156,
      "grad_norm": 0.42612430453300476,
      "learning_rate": 1.8987224157955865e-05,
      "loss": 0.0473,
      "step": 26710
    },
    {
      "epoch": 6.206736353077816,
      "grad_norm": 0.9517831802368164,
      "learning_rate": 1.8975609756097563e-05,
      "loss": 0.0559,
      "step": 26720
    },
    {
      "epoch": 6.209059233449477,
      "grad_norm": 1.9444353580474854,
      "learning_rate": 1.8963995354239258e-05,
      "loss": 0.0989,
      "step": 26730
    },
    {
      "epoch": 6.211382113821138,
      "grad_norm": 0.5757384896278381,
      "learning_rate": 1.8952380952380953e-05,
      "loss": 0.0623,
      "step": 26740
    },
    {
      "epoch": 6.213704994192799,
      "grad_norm": 0.8832074999809265,
      "learning_rate": 1.8940766550522647e-05,
      "loss": 0.1796,
      "step": 26750
    },
    {
      "epoch": 6.21602787456446,
      "grad_norm": 0.9143968820571899,
      "learning_rate": 1.8929152148664345e-05,
      "loss": 0.0653,
      "step": 26760
    },
    {
      "epoch": 6.218350754936121,
      "grad_norm": 1.1638551950454712,
      "learning_rate": 1.891753774680604e-05,
      "loss": 0.0647,
      "step": 26770
    },
    {
      "epoch": 6.220673635307782,
      "grad_norm": 1.5260568857192993,
      "learning_rate": 1.8905923344947738e-05,
      "loss": 0.1088,
      "step": 26780
    },
    {
      "epoch": 6.2229965156794425,
      "grad_norm": 0.8402174115180969,
      "learning_rate": 1.889430894308943e-05,
      "loss": 0.0608,
      "step": 26790
    },
    {
      "epoch": 6.225319396051104,
      "grad_norm": 1.4016512632369995,
      "learning_rate": 1.8882694541231127e-05,
      "loss": 0.0638,
      "step": 26800
    },
    {
      "epoch": 6.227642276422764,
      "grad_norm": 0.9663873314857483,
      "learning_rate": 1.8871080139372822e-05,
      "loss": 0.101,
      "step": 26810
    },
    {
      "epoch": 6.229965156794425,
      "grad_norm": 0.6906113028526306,
      "learning_rate": 1.885946573751452e-05,
      "loss": 0.1263,
      "step": 26820
    },
    {
      "epoch": 6.232288037166086,
      "grad_norm": 0.7901166081428528,
      "learning_rate": 1.8847851335656215e-05,
      "loss": 0.0617,
      "step": 26830
    },
    {
      "epoch": 6.234610917537747,
      "grad_norm": 1.4474269151687622,
      "learning_rate": 1.883623693379791e-05,
      "loss": 0.127,
      "step": 26840
    },
    {
      "epoch": 6.2369337979094075,
      "grad_norm": 1.6316475868225098,
      "learning_rate": 1.8824622531939608e-05,
      "loss": 0.0582,
      "step": 26850
    },
    {
      "epoch": 6.239256678281069,
      "grad_norm": 0.9432533383369446,
      "learning_rate": 1.8813008130081302e-05,
      "loss": 0.0944,
      "step": 26860
    },
    {
      "epoch": 6.241579558652729,
      "grad_norm": 0.8446142077445984,
      "learning_rate": 1.8801393728222997e-05,
      "loss": 0.1093,
      "step": 26870
    },
    {
      "epoch": 6.2439024390243905,
      "grad_norm": 0.5376495122909546,
      "learning_rate": 1.878977932636469e-05,
      "loss": 0.1133,
      "step": 26880
    },
    {
      "epoch": 6.246225319396051,
      "grad_norm": 2.0390756130218506,
      "learning_rate": 1.877816492450639e-05,
      "loss": 0.1221,
      "step": 26890
    },
    {
      "epoch": 6.248548199767712,
      "grad_norm": 2.4821066856384277,
      "learning_rate": 1.8766550522648084e-05,
      "loss": 0.1016,
      "step": 26900
    },
    {
      "epoch": 6.2508710801393725,
      "grad_norm": 1.1802407503128052,
      "learning_rate": 1.875493612078978e-05,
      "loss": 0.159,
      "step": 26910
    },
    {
      "epoch": 6.253193960511034,
      "grad_norm": 1.854440450668335,
      "learning_rate": 1.8743321718931474e-05,
      "loss": 0.1051,
      "step": 26920
    },
    {
      "epoch": 6.255516840882694,
      "grad_norm": 1.0208731889724731,
      "learning_rate": 1.8731707317073172e-05,
      "loss": 0.079,
      "step": 26930
    },
    {
      "epoch": 6.2578397212543555,
      "grad_norm": 1.5804376602172852,
      "learning_rate": 1.8720092915214866e-05,
      "loss": 0.123,
      "step": 26940
    },
    {
      "epoch": 6.260162601626016,
      "grad_norm": 1.6215046644210815,
      "learning_rate": 1.8708478513356564e-05,
      "loss": 0.088,
      "step": 26950
    },
    {
      "epoch": 6.262485481997677,
      "grad_norm": 2.0348758697509766,
      "learning_rate": 1.869686411149826e-05,
      "loss": 0.1517,
      "step": 26960
    },
    {
      "epoch": 6.264808362369338,
      "grad_norm": 0.7639193534851074,
      "learning_rate": 1.8685249709639954e-05,
      "loss": 0.1281,
      "step": 26970
    },
    {
      "epoch": 6.267131242740999,
      "grad_norm": 2.177691698074341,
      "learning_rate": 1.8673635307781652e-05,
      "loss": 0.1347,
      "step": 26980
    },
    {
      "epoch": 6.269454123112659,
      "grad_norm": 2.156602144241333,
      "learning_rate": 1.8662020905923347e-05,
      "loss": 0.1218,
      "step": 26990
    },
    {
      "epoch": 6.2717770034843205,
      "grad_norm": 2.1516051292419434,
      "learning_rate": 1.865040650406504e-05,
      "loss": 0.0872,
      "step": 27000
    },
    {
      "epoch": 6.274099883855982,
      "grad_norm": 1.2301852703094482,
      "learning_rate": 1.8638792102206736e-05,
      "loss": 0.0726,
      "step": 27010
    },
    {
      "epoch": 6.276422764227642,
      "grad_norm": 1.0333677530288696,
      "learning_rate": 1.8627177700348434e-05,
      "loss": 0.0703,
      "step": 27020
    },
    {
      "epoch": 6.2787456445993035,
      "grad_norm": 0.5544479489326477,
      "learning_rate": 1.861556329849013e-05,
      "loss": 0.0781,
      "step": 27030
    },
    {
      "epoch": 6.281068524970964,
      "grad_norm": 0.6241856813430786,
      "learning_rate": 1.8603948896631823e-05,
      "loss": 0.121,
      "step": 27040
    },
    {
      "epoch": 6.283391405342625,
      "grad_norm": 1.598788857460022,
      "learning_rate": 1.8592334494773518e-05,
      "loss": 0.116,
      "step": 27050
    },
    {
      "epoch": 6.285714285714286,
      "grad_norm": 0.6013979911804199,
      "learning_rate": 1.8580720092915216e-05,
      "loss": 0.0508,
      "step": 27060
    },
    {
      "epoch": 6.288037166085947,
      "grad_norm": 1.3313064575195312,
      "learning_rate": 1.856910569105691e-05,
      "loss": 0.0852,
      "step": 27070
    },
    {
      "epoch": 6.290360046457607,
      "grad_norm": 1.8347326517105103,
      "learning_rate": 1.8557491289198605e-05,
      "loss": 0.0838,
      "step": 27080
    },
    {
      "epoch": 6.2926829268292686,
      "grad_norm": 0.8653251528739929,
      "learning_rate": 1.8545876887340303e-05,
      "loss": 0.0784,
      "step": 27090
    },
    {
      "epoch": 6.295005807200929,
      "grad_norm": 1.147658109664917,
      "learning_rate": 1.8534262485481998e-05,
      "loss": 0.1228,
      "step": 27100
    },
    {
      "epoch": 6.29732868757259,
      "grad_norm": 1.4162144660949707,
      "learning_rate": 1.8522648083623696e-05,
      "loss": 0.0753,
      "step": 27110
    },
    {
      "epoch": 6.299651567944251,
      "grad_norm": 1.6063576936721802,
      "learning_rate": 1.851103368176539e-05,
      "loss": 0.095,
      "step": 27120
    },
    {
      "epoch": 6.301974448315912,
      "grad_norm": 1.1343765258789062,
      "learning_rate": 1.8499419279907085e-05,
      "loss": 0.0925,
      "step": 27130
    },
    {
      "epoch": 6.304297328687572,
      "grad_norm": 0.7338639497756958,
      "learning_rate": 1.848780487804878e-05,
      "loss": 0.1368,
      "step": 27140
    },
    {
      "epoch": 6.306620209059234,
      "grad_norm": 1.467194676399231,
      "learning_rate": 1.8476190476190478e-05,
      "loss": 0.1817,
      "step": 27150
    },
    {
      "epoch": 6.308943089430894,
      "grad_norm": 0.9275803565979004,
      "learning_rate": 1.8464576074332173e-05,
      "loss": 0.2027,
      "step": 27160
    },
    {
      "epoch": 6.311265969802555,
      "grad_norm": 0.643440306186676,
      "learning_rate": 1.8452961672473868e-05,
      "loss": 0.0635,
      "step": 27170
    },
    {
      "epoch": 6.313588850174216,
      "grad_norm": 2.095761299133301,
      "learning_rate": 1.8441347270615562e-05,
      "loss": 0.098,
      "step": 27180
    },
    {
      "epoch": 6.315911730545877,
      "grad_norm": 0.6911689043045044,
      "learning_rate": 1.842973286875726e-05,
      "loss": 0.0669,
      "step": 27190
    },
    {
      "epoch": 6.318234610917537,
      "grad_norm": 1.5250853300094604,
      "learning_rate": 1.8418118466898955e-05,
      "loss": 0.1171,
      "step": 27200
    },
    {
      "epoch": 6.320557491289199,
      "grad_norm": 1.04585862159729,
      "learning_rate": 1.840650406504065e-05,
      "loss": 0.0552,
      "step": 27210
    },
    {
      "epoch": 6.32288037166086,
      "grad_norm": 1.5009621381759644,
      "learning_rate": 1.8394889663182348e-05,
      "loss": 0.1869,
      "step": 27220
    },
    {
      "epoch": 6.32520325203252,
      "grad_norm": 2.3737235069274902,
      "learning_rate": 1.8383275261324042e-05,
      "loss": 0.1381,
      "step": 27230
    },
    {
      "epoch": 6.327526132404181,
      "grad_norm": 0.793394923210144,
      "learning_rate": 1.837166085946574e-05,
      "loss": 0.1468,
      "step": 27240
    },
    {
      "epoch": 6.329849012775842,
      "grad_norm": 0.9923667907714844,
      "learning_rate": 1.8360046457607435e-05,
      "loss": 0.0934,
      "step": 27250
    },
    {
      "epoch": 6.332171893147503,
      "grad_norm": 0.532028317451477,
      "learning_rate": 1.834843205574913e-05,
      "loss": 0.1048,
      "step": 27260
    },
    {
      "epoch": 6.334494773519164,
      "grad_norm": 1.9312469959259033,
      "learning_rate": 1.8336817653890824e-05,
      "loss": 0.1658,
      "step": 27270
    },
    {
      "epoch": 6.336817653890825,
      "grad_norm": 0.7668059468269348,
      "learning_rate": 1.8325203252032523e-05,
      "loss": 0.0743,
      "step": 27280
    },
    {
      "epoch": 6.339140534262485,
      "grad_norm": 0.8133193254470825,
      "learning_rate": 1.8313588850174217e-05,
      "loss": 0.0704,
      "step": 27290
    },
    {
      "epoch": 6.341463414634147,
      "grad_norm": 1.9777858257293701,
      "learning_rate": 1.8301974448315912e-05,
      "loss": 0.1141,
      "step": 27300
    },
    {
      "epoch": 6.343786295005807,
      "grad_norm": 0.8558816313743591,
      "learning_rate": 1.8290360046457607e-05,
      "loss": 0.0528,
      "step": 27310
    },
    {
      "epoch": 6.346109175377468,
      "grad_norm": 1.968699336051941,
      "learning_rate": 1.8278745644599305e-05,
      "loss": 0.0682,
      "step": 27320
    },
    {
      "epoch": 6.348432055749129,
      "grad_norm": 0.47460994124412537,
      "learning_rate": 1.8267131242741e-05,
      "loss": 0.1233,
      "step": 27330
    },
    {
      "epoch": 6.35075493612079,
      "grad_norm": 0.8085838556289673,
      "learning_rate": 1.8255516840882694e-05,
      "loss": 0.1145,
      "step": 27340
    },
    {
      "epoch": 6.35307781649245,
      "grad_norm": 1.770243763923645,
      "learning_rate": 1.8243902439024392e-05,
      "loss": 0.1147,
      "step": 27350
    },
    {
      "epoch": 6.355400696864112,
      "grad_norm": 0.6471672058105469,
      "learning_rate": 1.8232288037166087e-05,
      "loss": 0.1092,
      "step": 27360
    },
    {
      "epoch": 6.357723577235772,
      "grad_norm": 0.6229289770126343,
      "learning_rate": 1.8220673635307785e-05,
      "loss": 0.1148,
      "step": 27370
    },
    {
      "epoch": 6.360046457607433,
      "grad_norm": 0.4019857943058014,
      "learning_rate": 1.8209059233449476e-05,
      "loss": 0.0993,
      "step": 27380
    },
    {
      "epoch": 6.362369337979094,
      "grad_norm": 1.2952771186828613,
      "learning_rate": 1.8197444831591174e-05,
      "loss": 0.0851,
      "step": 27390
    },
    {
      "epoch": 6.364692218350755,
      "grad_norm": 1.4338797330856323,
      "learning_rate": 1.818583042973287e-05,
      "loss": 0.1305,
      "step": 27400
    },
    {
      "epoch": 6.3670150987224154,
      "grad_norm": 0.9770882725715637,
      "learning_rate": 1.8174216027874567e-05,
      "loss": 0.1051,
      "step": 27410
    },
    {
      "epoch": 6.369337979094077,
      "grad_norm": 1.0440540313720703,
      "learning_rate": 1.816260162601626e-05,
      "loss": 0.0943,
      "step": 27420
    },
    {
      "epoch": 6.371660859465737,
      "grad_norm": 0.8952916264533997,
      "learning_rate": 1.8150987224157956e-05,
      "loss": 0.1257,
      "step": 27430
    },
    {
      "epoch": 6.373983739837398,
      "grad_norm": 1.2010570764541626,
      "learning_rate": 1.813937282229965e-05,
      "loss": 0.0779,
      "step": 27440
    },
    {
      "epoch": 6.376306620209059,
      "grad_norm": 0.588783323764801,
      "learning_rate": 1.812775842044135e-05,
      "loss": 0.1052,
      "step": 27450
    },
    {
      "epoch": 6.37862950058072,
      "grad_norm": 0.5846302509307861,
      "learning_rate": 1.8116144018583044e-05,
      "loss": 0.1302,
      "step": 27460
    },
    {
      "epoch": 6.380952380952381,
      "grad_norm": 1.8905200958251953,
      "learning_rate": 1.8104529616724738e-05,
      "loss": 0.177,
      "step": 27470
    },
    {
      "epoch": 6.383275261324042,
      "grad_norm": 1.33086359500885,
      "learning_rate": 1.8092915214866436e-05,
      "loss": 0.1535,
      "step": 27480
    },
    {
      "epoch": 6.385598141695703,
      "grad_norm": 1.720957636833191,
      "learning_rate": 1.808130081300813e-05,
      "loss": 0.0626,
      "step": 27490
    },
    {
      "epoch": 6.3879210220673635,
      "grad_norm": 0.9361575841903687,
      "learning_rate": 1.806968641114983e-05,
      "loss": 0.0609,
      "step": 27500
    },
    {
      "epoch": 6.390243902439025,
      "grad_norm": 0.8060604333877563,
      "learning_rate": 1.805807200929152e-05,
      "loss": 0.106,
      "step": 27510
    },
    {
      "epoch": 6.392566782810685,
      "grad_norm": 0.7979074120521545,
      "learning_rate": 1.804645760743322e-05,
      "loss": 0.0829,
      "step": 27520
    },
    {
      "epoch": 6.394889663182346,
      "grad_norm": 0.9709426164627075,
      "learning_rate": 1.8034843205574913e-05,
      "loss": 0.0652,
      "step": 27530
    },
    {
      "epoch": 6.397212543554007,
      "grad_norm": 0.7925291061401367,
      "learning_rate": 1.802322880371661e-05,
      "loss": 0.0876,
      "step": 27540
    },
    {
      "epoch": 6.399535423925668,
      "grad_norm": 0.9615451693534851,
      "learning_rate": 1.8011614401858302e-05,
      "loss": 0.0634,
      "step": 27550
    },
    {
      "epoch": 6.4018583042973285,
      "grad_norm": 0.30714914202690125,
      "learning_rate": 1.8e-05,
      "loss": 0.0819,
      "step": 27560
    },
    {
      "epoch": 6.40418118466899,
      "grad_norm": 1.1913654804229736,
      "learning_rate": 1.7988385598141695e-05,
      "loss": 0.137,
      "step": 27570
    },
    {
      "epoch": 6.40650406504065,
      "grad_norm": 1.1120394468307495,
      "learning_rate": 1.7976771196283393e-05,
      "loss": 0.1859,
      "step": 27580
    },
    {
      "epoch": 6.4088269454123115,
      "grad_norm": 1.704699158668518,
      "learning_rate": 1.7965156794425088e-05,
      "loss": 0.1528,
      "step": 27590
    },
    {
      "epoch": 6.411149825783972,
      "grad_norm": 0.5208938121795654,
      "learning_rate": 1.7953542392566783e-05,
      "loss": 0.072,
      "step": 27600
    },
    {
      "epoch": 6.413472706155633,
      "grad_norm": 0.8171856999397278,
      "learning_rate": 1.794192799070848e-05,
      "loss": 0.1476,
      "step": 27610
    },
    {
      "epoch": 6.4157955865272935,
      "grad_norm": 1.1201560497283936,
      "learning_rate": 1.7930313588850175e-05,
      "loss": 0.1366,
      "step": 27620
    },
    {
      "epoch": 6.418118466898955,
      "grad_norm": 0.5616335868835449,
      "learning_rate": 1.7918699186991873e-05,
      "loss": 0.1536,
      "step": 27630
    },
    {
      "epoch": 6.420441347270615,
      "grad_norm": 0.6350063681602478,
      "learning_rate": 1.7907084785133565e-05,
      "loss": 0.0612,
      "step": 27640
    },
    {
      "epoch": 6.4227642276422765,
      "grad_norm": 0.6491429209709167,
      "learning_rate": 1.7895470383275263e-05,
      "loss": 0.1225,
      "step": 27650
    },
    {
      "epoch": 6.425087108013937,
      "grad_norm": 1.239943265914917,
      "learning_rate": 1.7883855981416957e-05,
      "loss": 0.1876,
      "step": 27660
    },
    {
      "epoch": 6.427409988385598,
      "grad_norm": 1.1664730310440063,
      "learning_rate": 1.7872241579558655e-05,
      "loss": 0.091,
      "step": 27670
    },
    {
      "epoch": 6.4297328687572595,
      "grad_norm": 0.5830839276313782,
      "learning_rate": 1.7860627177700347e-05,
      "loss": 0.0701,
      "step": 27680
    },
    {
      "epoch": 6.43205574912892,
      "grad_norm": 1.9425886869430542,
      "learning_rate": 1.7849012775842045e-05,
      "loss": 0.1018,
      "step": 27690
    },
    {
      "epoch": 6.43437862950058,
      "grad_norm": 0.8709381222724915,
      "learning_rate": 1.783739837398374e-05,
      "loss": 0.1053,
      "step": 27700
    },
    {
      "epoch": 6.4367015098722415,
      "grad_norm": 0.8003895282745361,
      "learning_rate": 1.7825783972125437e-05,
      "loss": 0.0567,
      "step": 27710
    },
    {
      "epoch": 6.439024390243903,
      "grad_norm": 1.0776748657226562,
      "learning_rate": 1.7814169570267132e-05,
      "loss": 0.0741,
      "step": 27720
    },
    {
      "epoch": 6.441347270615563,
      "grad_norm": 0.5099652409553528,
      "learning_rate": 1.7802555168408827e-05,
      "loss": 0.133,
      "step": 27730
    },
    {
      "epoch": 6.4436701509872245,
      "grad_norm": 0.7168829441070557,
      "learning_rate": 1.7790940766550525e-05,
      "loss": 0.0793,
      "step": 27740
    },
    {
      "epoch": 6.445993031358885,
      "grad_norm": 1.258821725845337,
      "learning_rate": 1.778048780487805e-05,
      "loss": 0.134,
      "step": 27750
    },
    {
      "epoch": 6.448315911730546,
      "grad_norm": 0.8580007553100586,
      "learning_rate": 1.7768873403019745e-05,
      "loss": 0.076,
      "step": 27760
    },
    {
      "epoch": 6.450638792102207,
      "grad_norm": 1.1399592161178589,
      "learning_rate": 1.7757259001161443e-05,
      "loss": 0.1386,
      "step": 27770
    },
    {
      "epoch": 6.452961672473868,
      "grad_norm": 0.4954669773578644,
      "learning_rate": 1.7745644599303138e-05,
      "loss": 0.0828,
      "step": 27780
    },
    {
      "epoch": 6.455284552845528,
      "grad_norm": 1.3772401809692383,
      "learning_rate": 1.7734030197444832e-05,
      "loss": 0.1572,
      "step": 27790
    },
    {
      "epoch": 6.4576074332171896,
      "grad_norm": 0.6114517450332642,
      "learning_rate": 1.7722415795586527e-05,
      "loss": 0.1043,
      "step": 27800
    },
    {
      "epoch": 6.45993031358885,
      "grad_norm": 1.1096482276916504,
      "learning_rate": 1.7710801393728225e-05,
      "loss": 0.0811,
      "step": 27810
    },
    {
      "epoch": 6.462253193960511,
      "grad_norm": 0.8304911255836487,
      "learning_rate": 1.769918699186992e-05,
      "loss": 0.1182,
      "step": 27820
    },
    {
      "epoch": 6.464576074332172,
      "grad_norm": 1.1183191537857056,
      "learning_rate": 1.7687572590011614e-05,
      "loss": 0.1193,
      "step": 27830
    },
    {
      "epoch": 6.466898954703833,
      "grad_norm": 0.6450631618499756,
      "learning_rate": 1.767595818815331e-05,
      "loss": 0.1142,
      "step": 27840
    },
    {
      "epoch": 6.469221835075493,
      "grad_norm": 0.7801210284233093,
      "learning_rate": 1.7664343786295007e-05,
      "loss": 0.0788,
      "step": 27850
    },
    {
      "epoch": 6.471544715447155,
      "grad_norm": 0.9366098642349243,
      "learning_rate": 1.76527293844367e-05,
      "loss": 0.142,
      "step": 27860
    },
    {
      "epoch": 6.473867595818815,
      "grad_norm": 0.9759901762008667,
      "learning_rate": 1.7641114982578396e-05,
      "loss": 0.0924,
      "step": 27870
    },
    {
      "epoch": 6.476190476190476,
      "grad_norm": 1.310835361480713,
      "learning_rate": 1.7629500580720094e-05,
      "loss": 0.0702,
      "step": 27880
    },
    {
      "epoch": 6.478513356562137,
      "grad_norm": 1.6644577980041504,
      "learning_rate": 1.761788617886179e-05,
      "loss": 0.1056,
      "step": 27890
    },
    {
      "epoch": 6.480836236933798,
      "grad_norm": 0.41750773787498474,
      "learning_rate": 1.7606271777003487e-05,
      "loss": 0.1044,
      "step": 27900
    },
    {
      "epoch": 6.483159117305458,
      "grad_norm": 1.0908920764923096,
      "learning_rate": 1.7594657375145182e-05,
      "loss": 0.0877,
      "step": 27910
    },
    {
      "epoch": 6.48548199767712,
      "grad_norm": 0.6029305458068848,
      "learning_rate": 1.7583042973286876e-05,
      "loss": 0.0673,
      "step": 27920
    },
    {
      "epoch": 6.487804878048781,
      "grad_norm": 1.4023221731185913,
      "learning_rate": 1.757142857142857e-05,
      "loss": 0.1596,
      "step": 27930
    },
    {
      "epoch": 6.490127758420441,
      "grad_norm": 0.720522940158844,
      "learning_rate": 1.755981416957027e-05,
      "loss": 0.1146,
      "step": 27940
    },
    {
      "epoch": 6.492450638792103,
      "grad_norm": 1.0939645767211914,
      "learning_rate": 1.7548199767711964e-05,
      "loss": 0.1792,
      "step": 27950
    },
    {
      "epoch": 6.494773519163763,
      "grad_norm": 0.7292031049728394,
      "learning_rate": 1.753658536585366e-05,
      "loss": 0.123,
      "step": 27960
    },
    {
      "epoch": 6.497096399535424,
      "grad_norm": 1.6295344829559326,
      "learning_rate": 1.7524970963995353e-05,
      "loss": 0.1088,
      "step": 27970
    },
    {
      "epoch": 6.499419279907085,
      "grad_norm": 0.7763103246688843,
      "learning_rate": 1.751335656213705e-05,
      "loss": 0.0834,
      "step": 27980
    },
    {
      "epoch": 6.501742160278746,
      "grad_norm": 0.8090567588806152,
      "learning_rate": 1.7501742160278746e-05,
      "loss": 0.0683,
      "step": 27990
    },
    {
      "epoch": 6.504065040650406,
      "grad_norm": 1.8279281854629517,
      "learning_rate": 1.749012775842044e-05,
      "loss": 0.0901,
      "step": 28000
    },
    {
      "epoch": 6.506387921022068,
      "grad_norm": 0.45675891637802124,
      "learning_rate": 1.747851335656214e-05,
      "loss": 0.0728,
      "step": 28010
    },
    {
      "epoch": 6.508710801393728,
      "grad_norm": 0.8000705242156982,
      "learning_rate": 1.7466898954703833e-05,
      "loss": 0.0693,
      "step": 28020
    },
    {
      "epoch": 6.511033681765389,
      "grad_norm": 0.9899770021438599,
      "learning_rate": 1.745528455284553e-05,
      "loss": 0.0563,
      "step": 28030
    },
    {
      "epoch": 6.51335656213705,
      "grad_norm": 1.8868037462234497,
      "learning_rate": 1.7443670150987226e-05,
      "loss": 0.1233,
      "step": 28040
    },
    {
      "epoch": 6.515679442508711,
      "grad_norm": 0.5790603160858154,
      "learning_rate": 1.743205574912892e-05,
      "loss": 0.0862,
      "step": 28050
    },
    {
      "epoch": 6.518002322880371,
      "grad_norm": 1.1449453830718994,
      "learning_rate": 1.7420441347270615e-05,
      "loss": 0.0699,
      "step": 28060
    },
    {
      "epoch": 6.520325203252033,
      "grad_norm": 0.8203283548355103,
      "learning_rate": 1.7408826945412314e-05,
      "loss": 0.087,
      "step": 28070
    },
    {
      "epoch": 6.522648083623693,
      "grad_norm": 0.989672064781189,
      "learning_rate": 1.7397212543554008e-05,
      "loss": 0.069,
      "step": 28080
    },
    {
      "epoch": 6.524970963995354,
      "grad_norm": 0.6822438836097717,
      "learning_rate": 1.7385598141695703e-05,
      "loss": 0.1162,
      "step": 28090
    },
    {
      "epoch": 6.527293844367015,
      "grad_norm": 1.9751205444335938,
      "learning_rate": 1.7373983739837398e-05,
      "loss": 0.1331,
      "step": 28100
    },
    {
      "epoch": 6.529616724738676,
      "grad_norm": 1.5675075054168701,
      "learning_rate": 1.7362369337979096e-05,
      "loss": 0.0909,
      "step": 28110
    },
    {
      "epoch": 6.5319396051103364,
      "grad_norm": 0.805803656578064,
      "learning_rate": 1.735075493612079e-05,
      "loss": 0.1093,
      "step": 28120
    },
    {
      "epoch": 6.534262485481998,
      "grad_norm": 0.3884044587612152,
      "learning_rate": 1.7339140534262485e-05,
      "loss": 0.0686,
      "step": 28130
    },
    {
      "epoch": 6.536585365853659,
      "grad_norm": 0.5223722457885742,
      "learning_rate": 1.7327526132404183e-05,
      "loss": 0.1184,
      "step": 28140
    },
    {
      "epoch": 6.538908246225319,
      "grad_norm": 1.3213435411453247,
      "learning_rate": 1.7315911730545878e-05,
      "loss": 0.0713,
      "step": 28150
    },
    {
      "epoch": 6.54123112659698,
      "grad_norm": 1.1243395805358887,
      "learning_rate": 1.7304297328687576e-05,
      "loss": 0.0717,
      "step": 28160
    },
    {
      "epoch": 6.543554006968641,
      "grad_norm": 0.7281919121742249,
      "learning_rate": 1.7292682926829267e-05,
      "loss": 0.09,
      "step": 28170
    },
    {
      "epoch": 6.545876887340302,
      "grad_norm": 1.5644137859344482,
      "learning_rate": 1.7281068524970965e-05,
      "loss": 0.1854,
      "step": 28180
    },
    {
      "epoch": 6.548199767711963,
      "grad_norm": 0.4798654019832611,
      "learning_rate": 1.726945412311266e-05,
      "loss": 0.075,
      "step": 28190
    },
    {
      "epoch": 6.550522648083624,
      "grad_norm": 0.6774526238441467,
      "learning_rate": 1.7257839721254358e-05,
      "loss": 0.0745,
      "step": 28200
    },
    {
      "epoch": 6.5528455284552845,
      "grad_norm": 1.6479237079620361,
      "learning_rate": 1.7246225319396052e-05,
      "loss": 0.0998,
      "step": 28210
    },
    {
      "epoch": 6.555168408826946,
      "grad_norm": 0.4905979633331299,
      "learning_rate": 1.7234610917537747e-05,
      "loss": 0.0925,
      "step": 28220
    },
    {
      "epoch": 6.557491289198606,
      "grad_norm": 1.9599186182022095,
      "learning_rate": 1.7222996515679442e-05,
      "loss": 0.1007,
      "step": 28230
    },
    {
      "epoch": 6.559814169570267,
      "grad_norm": 0.8894602060317993,
      "learning_rate": 1.721138211382114e-05,
      "loss": 0.0788,
      "step": 28240
    },
    {
      "epoch": 6.562137049941928,
      "grad_norm": 0.48425957560539246,
      "learning_rate": 1.7199767711962835e-05,
      "loss": 0.0739,
      "step": 28250
    },
    {
      "epoch": 6.564459930313589,
      "grad_norm": 1.8591207265853882,
      "learning_rate": 1.718815331010453e-05,
      "loss": 0.0858,
      "step": 28260
    },
    {
      "epoch": 6.5667828106852495,
      "grad_norm": 1.4651540517807007,
      "learning_rate": 1.7176538908246227e-05,
      "loss": 0.138,
      "step": 28270
    },
    {
      "epoch": 6.569105691056911,
      "grad_norm": 0.5153853297233582,
      "learning_rate": 1.7164924506387922e-05,
      "loss": 0.0724,
      "step": 28280
    },
    {
      "epoch": 6.571428571428571,
      "grad_norm": 0.9970291256904602,
      "learning_rate": 1.715331010452962e-05,
      "loss": 0.0453,
      "step": 28290
    },
    {
      "epoch": 6.5737514518002325,
      "grad_norm": 1.3411184549331665,
      "learning_rate": 1.714169570267131e-05,
      "loss": 0.1051,
      "step": 28300
    },
    {
      "epoch": 6.576074332171893,
      "grad_norm": 0.5884813666343689,
      "learning_rate": 1.713008130081301e-05,
      "loss": 0.2174,
      "step": 28310
    },
    {
      "epoch": 6.578397212543554,
      "grad_norm": 0.6930195093154907,
      "learning_rate": 1.7118466898954704e-05,
      "loss": 0.1116,
      "step": 28320
    },
    {
      "epoch": 6.5807200929152145,
      "grad_norm": 0.9651780128479004,
      "learning_rate": 1.7106852497096402e-05,
      "loss": 0.0833,
      "step": 28330
    },
    {
      "epoch": 6.583042973286876,
      "grad_norm": 1.4667288064956665,
      "learning_rate": 1.7095238095238093e-05,
      "loss": 0.0623,
      "step": 28340
    },
    {
      "epoch": 6.585365853658536,
      "grad_norm": 0.9657343626022339,
      "learning_rate": 1.708362369337979e-05,
      "loss": 0.0677,
      "step": 28350
    },
    {
      "epoch": 6.5876887340301975,
      "grad_norm": 2.2983899116516113,
      "learning_rate": 1.7072009291521486e-05,
      "loss": 0.13,
      "step": 28360
    },
    {
      "epoch": 6.590011614401858,
      "grad_norm": 1.0673120021820068,
      "learning_rate": 1.7060394889663184e-05,
      "loss": 0.0714,
      "step": 28370
    },
    {
      "epoch": 6.592334494773519,
      "grad_norm": 1.0388667583465576,
      "learning_rate": 1.704878048780488e-05,
      "loss": 0.1477,
      "step": 28380
    },
    {
      "epoch": 6.5946573751451805,
      "grad_norm": 1.9066338539123535,
      "learning_rate": 1.7037166085946574e-05,
      "loss": 0.1332,
      "step": 28390
    },
    {
      "epoch": 6.596980255516841,
      "grad_norm": 1.3284385204315186,
      "learning_rate": 1.702555168408827e-05,
      "loss": 0.1325,
      "step": 28400
    },
    {
      "epoch": 6.599303135888501,
      "grad_norm": 1.381211519241333,
      "learning_rate": 1.7013937282229966e-05,
      "loss": 0.1144,
      "step": 28410
    },
    {
      "epoch": 6.6016260162601625,
      "grad_norm": 0.8019425272941589,
      "learning_rate": 1.7002322880371664e-05,
      "loss": 0.0591,
      "step": 28420
    },
    {
      "epoch": 6.603948896631824,
      "grad_norm": 2.1885619163513184,
      "learning_rate": 1.6990708478513356e-05,
      "loss": 0.0718,
      "step": 28430
    },
    {
      "epoch": 6.606271777003484,
      "grad_norm": 1.6252366304397583,
      "learning_rate": 1.6979094076655054e-05,
      "loss": 0.1012,
      "step": 28440
    },
    {
      "epoch": 6.6085946573751455,
      "grad_norm": 0.9265850782394409,
      "learning_rate": 1.696747967479675e-05,
      "loss": 0.1292,
      "step": 28450
    },
    {
      "epoch": 6.610917537746806,
      "grad_norm": 1.301247477531433,
      "learning_rate": 1.6955865272938446e-05,
      "loss": 0.121,
      "step": 28460
    },
    {
      "epoch": 6.613240418118467,
      "grad_norm": 1.2952489852905273,
      "learning_rate": 1.6944250871080138e-05,
      "loss": 0.0618,
      "step": 28470
    },
    {
      "epoch": 6.615563298490128,
      "grad_norm": 0.6662976741790771,
      "learning_rate": 1.6932636469221836e-05,
      "loss": 0.0527,
      "step": 28480
    },
    {
      "epoch": 6.617886178861789,
      "grad_norm": 0.9092268943786621,
      "learning_rate": 1.692102206736353e-05,
      "loss": 0.0512,
      "step": 28490
    },
    {
      "epoch": 6.620209059233449,
      "grad_norm": 0.6471624970436096,
      "learning_rate": 1.690940766550523e-05,
      "loss": 0.0596,
      "step": 28500
    },
    {
      "epoch": 6.6225319396051106,
      "grad_norm": 0.7030521631240845,
      "learning_rate": 1.6897793263646923e-05,
      "loss": 0.045,
      "step": 28510
    },
    {
      "epoch": 6.624854819976771,
      "grad_norm": 1.4148874282836914,
      "learning_rate": 1.6886178861788618e-05,
      "loss": 0.0805,
      "step": 28520
    },
    {
      "epoch": 6.627177700348432,
      "grad_norm": 0.41680917143821716,
      "learning_rate": 1.6874564459930316e-05,
      "loss": 0.1288,
      "step": 28530
    },
    {
      "epoch": 6.629500580720093,
      "grad_norm": 1.6126158237457275,
      "learning_rate": 1.686295005807201e-05,
      "loss": 0.062,
      "step": 28540
    },
    {
      "epoch": 6.631823461091754,
      "grad_norm": 0.6250780820846558,
      "learning_rate": 1.685133565621371e-05,
      "loss": 0.1354,
      "step": 28550
    },
    {
      "epoch": 6.634146341463414,
      "grad_norm": 0.6147691011428833,
      "learning_rate": 1.68397212543554e-05,
      "loss": 0.1558,
      "step": 28560
    },
    {
      "epoch": 6.636469221835076,
      "grad_norm": 0.8182944655418396,
      "learning_rate": 1.6828106852497098e-05,
      "loss": 0.0891,
      "step": 28570
    },
    {
      "epoch": 6.638792102206736,
      "grad_norm": 1.0007951259613037,
      "learning_rate": 1.6816492450638793e-05,
      "loss": 0.0757,
      "step": 28580
    },
    {
      "epoch": 6.641114982578397,
      "grad_norm": 1.7542399168014526,
      "learning_rate": 1.680487804878049e-05,
      "loss": 0.13,
      "step": 28590
    },
    {
      "epoch": 6.643437862950059,
      "grad_norm": 1.4986947774887085,
      "learning_rate": 1.6793263646922182e-05,
      "loss": 0.09,
      "step": 28600
    },
    {
      "epoch": 6.645760743321719,
      "grad_norm": 0.860914409160614,
      "learning_rate": 1.678164924506388e-05,
      "loss": 0.1012,
      "step": 28610
    },
    {
      "epoch": 6.648083623693379,
      "grad_norm": 0.958486795425415,
      "learning_rate": 1.6770034843205575e-05,
      "loss": 0.0961,
      "step": 28620
    },
    {
      "epoch": 6.650406504065041,
      "grad_norm": 0.8015612363815308,
      "learning_rate": 1.6758420441347273e-05,
      "loss": 0.0969,
      "step": 28630
    },
    {
      "epoch": 6.652729384436702,
      "grad_norm": 2.337282657623291,
      "learning_rate": 1.6746806039488967e-05,
      "loss": 0.0725,
      "step": 28640
    },
    {
      "epoch": 6.655052264808362,
      "grad_norm": 2.8017895221710205,
      "learning_rate": 1.6735191637630662e-05,
      "loss": 0.1599,
      "step": 28650
    },
    {
      "epoch": 6.657375145180024,
      "grad_norm": 0.9499742388725281,
      "learning_rate": 1.672357723577236e-05,
      "loss": 0.0616,
      "step": 28660
    },
    {
      "epoch": 6.659698025551684,
      "grad_norm": 0.9847758412361145,
      "learning_rate": 1.6711962833914055e-05,
      "loss": 0.0717,
      "step": 28670
    },
    {
      "epoch": 6.662020905923345,
      "grad_norm": 1.7768077850341797,
      "learning_rate": 1.6700348432055753e-05,
      "loss": 0.0882,
      "step": 28680
    },
    {
      "epoch": 6.664343786295006,
      "grad_norm": 0.9510189890861511,
      "learning_rate": 1.6688734030197444e-05,
      "loss": 0.0535,
      "step": 28690
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 1.614968180656433,
      "learning_rate": 1.6677119628339142e-05,
      "loss": 0.0786,
      "step": 28700
    },
    {
      "epoch": 6.668989547038327,
      "grad_norm": 0.6734774112701416,
      "learning_rate": 1.6665505226480837e-05,
      "loss": 0.094,
      "step": 28710
    },
    {
      "epoch": 6.671312427409989,
      "grad_norm": 0.549623429775238,
      "learning_rate": 1.6653890824622535e-05,
      "loss": 0.0761,
      "step": 28720
    },
    {
      "epoch": 6.673635307781649,
      "grad_norm": 1.5065865516662598,
      "learning_rate": 1.6642276422764226e-05,
      "loss": 0.0982,
      "step": 28730
    },
    {
      "epoch": 6.67595818815331,
      "grad_norm": 0.3224119246006012,
      "learning_rate": 1.6630662020905924e-05,
      "loss": 0.0559,
      "step": 28740
    },
    {
      "epoch": 6.678281068524971,
      "grad_norm": 0.9695566892623901,
      "learning_rate": 1.661904761904762e-05,
      "loss": 0.0945,
      "step": 28750
    },
    {
      "epoch": 6.680603948896632,
      "grad_norm": 0.7558640241622925,
      "learning_rate": 1.6607433217189317e-05,
      "loss": 0.0642,
      "step": 28760
    },
    {
      "epoch": 6.682926829268292,
      "grad_norm": 0.8948376774787903,
      "learning_rate": 1.6595818815331012e-05,
      "loss": 0.0603,
      "step": 28770
    },
    {
      "epoch": 6.685249709639954,
      "grad_norm": 0.40422552824020386,
      "learning_rate": 1.6584204413472706e-05,
      "loss": 0.0807,
      "step": 28780
    },
    {
      "epoch": 6.687572590011614,
      "grad_norm": 1.9182085990905762,
      "learning_rate": 1.6572590011614404e-05,
      "loss": 0.1226,
      "step": 28790
    },
    {
      "epoch": 6.689895470383275,
      "grad_norm": 1.9700934886932373,
      "learning_rate": 1.65609756097561e-05,
      "loss": 0.0718,
      "step": 28800
    },
    {
      "epoch": 6.692218350754936,
      "grad_norm": 0.6986120343208313,
      "learning_rate": 1.6549361207897794e-05,
      "loss": 0.0636,
      "step": 28810
    },
    {
      "epoch": 6.694541231126597,
      "grad_norm": 0.9423624277114868,
      "learning_rate": 1.653774680603949e-05,
      "loss": 0.07,
      "step": 28820
    },
    {
      "epoch": 6.696864111498257,
      "grad_norm": 0.4481584131717682,
      "learning_rate": 1.6526132404181187e-05,
      "loss": 0.0748,
      "step": 28830
    },
    {
      "epoch": 6.699186991869919,
      "grad_norm": 0.7436028122901917,
      "learning_rate": 1.651451800232288e-05,
      "loss": 0.114,
      "step": 28840
    },
    {
      "epoch": 6.70150987224158,
      "grad_norm": 0.9008365869522095,
      "learning_rate": 1.650290360046458e-05,
      "loss": 0.0908,
      "step": 28850
    },
    {
      "epoch": 6.70383275261324,
      "grad_norm": 0.7997660636901855,
      "learning_rate": 1.649128919860627e-05,
      "loss": 0.0938,
      "step": 28860
    },
    {
      "epoch": 6.706155632984901,
      "grad_norm": 1.6858489513397217,
      "learning_rate": 1.647967479674797e-05,
      "loss": 0.059,
      "step": 28870
    },
    {
      "epoch": 6.708478513356562,
      "grad_norm": 1.0670952796936035,
      "learning_rate": 1.6468060394889663e-05,
      "loss": 0.0718,
      "step": 28880
    },
    {
      "epoch": 6.710801393728223,
      "grad_norm": 0.8737947344779968,
      "learning_rate": 1.645644599303136e-05,
      "loss": 0.1519,
      "step": 28890
    },
    {
      "epoch": 6.713124274099884,
      "grad_norm": 1.1992712020874023,
      "learning_rate": 1.6444831591173056e-05,
      "loss": 0.172,
      "step": 28900
    },
    {
      "epoch": 6.715447154471545,
      "grad_norm": 0.6708945035934448,
      "learning_rate": 1.643321718931475e-05,
      "loss": 0.0989,
      "step": 28910
    },
    {
      "epoch": 6.7177700348432055,
      "grad_norm": 1.0313102006912231,
      "learning_rate": 1.642160278745645e-05,
      "loss": 0.0929,
      "step": 28920
    },
    {
      "epoch": 6.720092915214867,
      "grad_norm": 1.1776095628738403,
      "learning_rate": 1.6409988385598143e-05,
      "loss": 0.1055,
      "step": 28930
    },
    {
      "epoch": 6.722415795586527,
      "grad_norm": 1.366169810295105,
      "learning_rate": 1.6398373983739838e-05,
      "loss": 0.1021,
      "step": 28940
    },
    {
      "epoch": 6.724738675958188,
      "grad_norm": 2.007697343826294,
      "learning_rate": 1.6386759581881533e-05,
      "loss": 0.1359,
      "step": 28950
    },
    {
      "epoch": 6.727061556329849,
      "grad_norm": 1.1091810464859009,
      "learning_rate": 1.637514518002323e-05,
      "loss": 0.148,
      "step": 28960
    },
    {
      "epoch": 6.72938443670151,
      "grad_norm": 1.1856870651245117,
      "learning_rate": 1.6363530778164926e-05,
      "loss": 0.1589,
      "step": 28970
    },
    {
      "epoch": 6.7317073170731705,
      "grad_norm": 1.098128080368042,
      "learning_rate": 1.635191637630662e-05,
      "loss": 0.0903,
      "step": 28980
    },
    {
      "epoch": 6.734030197444832,
      "grad_norm": 1.684638500213623,
      "learning_rate": 1.6340301974448315e-05,
      "loss": 0.0982,
      "step": 28990
    },
    {
      "epoch": 6.736353077816492,
      "grad_norm": 1.8234862089157104,
      "learning_rate": 1.6328687572590013e-05,
      "loss": 0.1118,
      "step": 29000
    },
    {
      "epoch": 6.7386759581881535,
      "grad_norm": 1.3714724779129028,
      "learning_rate": 1.6317073170731708e-05,
      "loss": 0.0992,
      "step": 29010
    },
    {
      "epoch": 6.740998838559814,
      "grad_norm": 1.7623833417892456,
      "learning_rate": 1.6305458768873406e-05,
      "loss": 0.1426,
      "step": 29020
    },
    {
      "epoch": 6.743321718931475,
      "grad_norm": 1.159321665763855,
      "learning_rate": 1.6293844367015097e-05,
      "loss": 0.1245,
      "step": 29030
    },
    {
      "epoch": 6.7456445993031355,
      "grad_norm": 1.3791635036468506,
      "learning_rate": 1.6282229965156795e-05,
      "loss": 0.1902,
      "step": 29040
    },
    {
      "epoch": 6.747967479674797,
      "grad_norm": 1.096175193786621,
      "learning_rate": 1.627061556329849e-05,
      "loss": 0.095,
      "step": 29050
    },
    {
      "epoch": 6.750290360046458,
      "grad_norm": 0.5982422232627869,
      "learning_rate": 1.6259001161440188e-05,
      "loss": 0.1025,
      "step": 29060
    },
    {
      "epoch": 6.7526132404181185,
      "grad_norm": 2.063070058822632,
      "learning_rate": 1.6247386759581882e-05,
      "loss": 0.0829,
      "step": 29070
    },
    {
      "epoch": 6.754936120789779,
      "grad_norm": 1.2154840230941772,
      "learning_rate": 1.6235772357723577e-05,
      "loss": 0.172,
      "step": 29080
    },
    {
      "epoch": 6.75725900116144,
      "grad_norm": 1.6958098411560059,
      "learning_rate": 1.6224157955865275e-05,
      "loss": 0.1165,
      "step": 29090
    },
    {
      "epoch": 6.7595818815331015,
      "grad_norm": 1.761898159980774,
      "learning_rate": 1.621254355400697e-05,
      "loss": 0.0746,
      "step": 29100
    },
    {
      "epoch": 6.761904761904762,
      "grad_norm": 1.0145227909088135,
      "learning_rate": 1.6200929152148664e-05,
      "loss": 0.0596,
      "step": 29110
    },
    {
      "epoch": 6.764227642276423,
      "grad_norm": 1.1113852262496948,
      "learning_rate": 1.618931475029036e-05,
      "loss": 0.0996,
      "step": 29120
    },
    {
      "epoch": 6.7665505226480835,
      "grad_norm": 1.2304885387420654,
      "learning_rate": 1.6177700348432057e-05,
      "loss": 0.1167,
      "step": 29130
    },
    {
      "epoch": 6.768873403019745,
      "grad_norm": 1.4483877420425415,
      "learning_rate": 1.6166085946573752e-05,
      "loss": 0.1119,
      "step": 29140
    },
    {
      "epoch": 6.771196283391405,
      "grad_norm": 0.806132972240448,
      "learning_rate": 1.6154471544715447e-05,
      "loss": 0.0561,
      "step": 29150
    },
    {
      "epoch": 6.7735191637630665,
      "grad_norm": 0.6964094638824463,
      "learning_rate": 1.6144018583042975e-05,
      "loss": 0.1041,
      "step": 29160
    },
    {
      "epoch": 6.775842044134727,
      "grad_norm": 1.4380375146865845,
      "learning_rate": 1.613240418118467e-05,
      "loss": 0.1177,
      "step": 29170
    },
    {
      "epoch": 6.778164924506388,
      "grad_norm": 1.204199194908142,
      "learning_rate": 1.6120789779326365e-05,
      "loss": 0.0794,
      "step": 29180
    },
    {
      "epoch": 6.780487804878049,
      "grad_norm": 1.4030848741531372,
      "learning_rate": 1.6109175377468063e-05,
      "loss": 0.0996,
      "step": 29190
    },
    {
      "epoch": 6.78281068524971,
      "grad_norm": 1.1479600667953491,
      "learning_rate": 1.6097560975609757e-05,
      "loss": 0.0582,
      "step": 29200
    },
    {
      "epoch": 6.78513356562137,
      "grad_norm": 0.9837328791618347,
      "learning_rate": 1.6085946573751455e-05,
      "loss": 0.1501,
      "step": 29210
    },
    {
      "epoch": 6.7874564459930316,
      "grad_norm": 0.8482933044433594,
      "learning_rate": 1.6074332171893147e-05,
      "loss": 0.0991,
      "step": 29220
    },
    {
      "epoch": 6.789779326364692,
      "grad_norm": 1.003232717514038,
      "learning_rate": 1.6062717770034845e-05,
      "loss": 0.0575,
      "step": 29230
    },
    {
      "epoch": 6.792102206736353,
      "grad_norm": 0.44285884499549866,
      "learning_rate": 1.605110336817654e-05,
      "loss": 0.0799,
      "step": 29240
    },
    {
      "epoch": 6.794425087108014,
      "grad_norm": 0.9681513905525208,
      "learning_rate": 1.6039488966318237e-05,
      "loss": 0.1144,
      "step": 29250
    },
    {
      "epoch": 6.796747967479675,
      "grad_norm": 0.6424900889396667,
      "learning_rate": 1.602787456445993e-05,
      "loss": 0.1031,
      "step": 29260
    },
    {
      "epoch": 6.799070847851335,
      "grad_norm": 3.1566226482391357,
      "learning_rate": 1.6016260162601627e-05,
      "loss": 0.0956,
      "step": 29270
    },
    {
      "epoch": 6.801393728222997,
      "grad_norm": 0.9478086829185486,
      "learning_rate": 1.600464576074332e-05,
      "loss": 0.0843,
      "step": 29280
    },
    {
      "epoch": 6.803716608594657,
      "grad_norm": 1.0180972814559937,
      "learning_rate": 1.599303135888502e-05,
      "loss": 0.1127,
      "step": 29290
    },
    {
      "epoch": 6.806039488966318,
      "grad_norm": 0.8021866083145142,
      "learning_rate": 1.5981416957026714e-05,
      "loss": 0.1305,
      "step": 29300
    },
    {
      "epoch": 6.80836236933798,
      "grad_norm": 0.8537439703941345,
      "learning_rate": 1.596980255516841e-05,
      "loss": 0.0691,
      "step": 29310
    },
    {
      "epoch": 6.81068524970964,
      "grad_norm": 1.0678315162658691,
      "learning_rate": 1.5958188153310107e-05,
      "loss": 0.1887,
      "step": 29320
    },
    {
      "epoch": 6.8130081300813,
      "grad_norm": 0.4964446723461151,
      "learning_rate": 1.59465737514518e-05,
      "loss": 0.0681,
      "step": 29330
    },
    {
      "epoch": 6.815331010452962,
      "grad_norm": 0.5054320096969604,
      "learning_rate": 1.5934959349593496e-05,
      "loss": 0.1594,
      "step": 29340
    },
    {
      "epoch": 6.817653890824623,
      "grad_norm": 1.3684558868408203,
      "learning_rate": 1.592334494773519e-05,
      "loss": 0.1121,
      "step": 29350
    },
    {
      "epoch": 6.819976771196283,
      "grad_norm": 0.6647258996963501,
      "learning_rate": 1.591173054587689e-05,
      "loss": 0.114,
      "step": 29360
    },
    {
      "epoch": 6.822299651567945,
      "grad_norm": 0.6039438843727112,
      "learning_rate": 1.5900116144018584e-05,
      "loss": 0.1113,
      "step": 29370
    },
    {
      "epoch": 6.824622531939605,
      "grad_norm": 0.6311150789260864,
      "learning_rate": 1.588850174216028e-05,
      "loss": 0.0834,
      "step": 29380
    },
    {
      "epoch": 6.826945412311266,
      "grad_norm": 0.5629043579101562,
      "learning_rate": 1.5876887340301973e-05,
      "loss": 0.1098,
      "step": 29390
    },
    {
      "epoch": 6.829268292682927,
      "grad_norm": 1.670512318611145,
      "learning_rate": 1.586527293844367e-05,
      "loss": 0.0839,
      "step": 29400
    },
    {
      "epoch": 6.831591173054588,
      "grad_norm": 1.748538851737976,
      "learning_rate": 1.5853658536585366e-05,
      "loss": 0.1409,
      "step": 29410
    },
    {
      "epoch": 6.833914053426248,
      "grad_norm": 1.2561322450637817,
      "learning_rate": 1.5842044134727064e-05,
      "loss": 0.0889,
      "step": 29420
    },
    {
      "epoch": 6.83623693379791,
      "grad_norm": 0.5769997835159302,
      "learning_rate": 1.583042973286876e-05,
      "loss": 0.0766,
      "step": 29430
    },
    {
      "epoch": 6.83855981416957,
      "grad_norm": 1.0650261640548706,
      "learning_rate": 1.5818815331010453e-05,
      "loss": 0.1089,
      "step": 29440
    },
    {
      "epoch": 6.840882694541231,
      "grad_norm": 2.0973050594329834,
      "learning_rate": 1.5807200929152148e-05,
      "loss": 0.116,
      "step": 29450
    },
    {
      "epoch": 6.843205574912892,
      "grad_norm": 2.945425510406494,
      "learning_rate": 1.5795586527293846e-05,
      "loss": 0.1018,
      "step": 29460
    },
    {
      "epoch": 6.845528455284553,
      "grad_norm": 1.1801433563232422,
      "learning_rate": 1.578397212543554e-05,
      "loss": 0.1209,
      "step": 29470
    },
    {
      "epoch": 6.847851335656213,
      "grad_norm": 0.6114833950996399,
      "learning_rate": 1.5772357723577235e-05,
      "loss": 0.1454,
      "step": 29480
    },
    {
      "epoch": 6.850174216027875,
      "grad_norm": 0.6191774010658264,
      "learning_rate": 1.5760743321718933e-05,
      "loss": 0.0882,
      "step": 29490
    },
    {
      "epoch": 6.852497096399535,
      "grad_norm": 1.9736392498016357,
      "learning_rate": 1.5749128919860628e-05,
      "loss": 0.0709,
      "step": 29500
    },
    {
      "epoch": 6.854819976771196,
      "grad_norm": 0.9833799004554749,
      "learning_rate": 1.5737514518002326e-05,
      "loss": 0.0776,
      "step": 29510
    },
    {
      "epoch": 6.857142857142857,
      "grad_norm": 1.241788625717163,
      "learning_rate": 1.5725900116144017e-05,
      "loss": 0.0603,
      "step": 29520
    },
    {
      "epoch": 6.859465737514518,
      "grad_norm": 1.1314451694488525,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 0.0835,
      "step": 29530
    },
    {
      "epoch": 6.861788617886178,
      "grad_norm": 0.8482456803321838,
      "learning_rate": 1.570267131242741e-05,
      "loss": 0.1326,
      "step": 29540
    },
    {
      "epoch": 6.86411149825784,
      "grad_norm": 0.4383556544780731,
      "learning_rate": 1.5691056910569108e-05,
      "loss": 0.0711,
      "step": 29550
    },
    {
      "epoch": 6.866434378629501,
      "grad_norm": 0.7995901703834534,
      "learning_rate": 1.56794425087108e-05,
      "loss": 0.0615,
      "step": 29560
    },
    {
      "epoch": 6.868757259001161,
      "grad_norm": 0.7940117716789246,
      "learning_rate": 1.5667828106852497e-05,
      "loss": 0.1149,
      "step": 29570
    },
    {
      "epoch": 6.871080139372822,
      "grad_norm": 0.774494469165802,
      "learning_rate": 1.5656213704994192e-05,
      "loss": 0.1675,
      "step": 29580
    },
    {
      "epoch": 6.873403019744483,
      "grad_norm": 0.9355556964874268,
      "learning_rate": 1.564459930313589e-05,
      "loss": 0.0735,
      "step": 29590
    },
    {
      "epoch": 6.875725900116144,
      "grad_norm": 1.5389856100082397,
      "learning_rate": 1.5632984901277585e-05,
      "loss": 0.0695,
      "step": 29600
    },
    {
      "epoch": 6.878048780487805,
      "grad_norm": 2.440182685852051,
      "learning_rate": 1.562137049941928e-05,
      "loss": 0.0738,
      "step": 29610
    },
    {
      "epoch": 6.880371660859466,
      "grad_norm": 1.1226407289505005,
      "learning_rate": 1.5609756097560978e-05,
      "loss": 0.0748,
      "step": 29620
    },
    {
      "epoch": 6.8826945412311265,
      "grad_norm": 1.395182728767395,
      "learning_rate": 1.5598141695702672e-05,
      "loss": 0.0887,
      "step": 29630
    },
    {
      "epoch": 6.885017421602788,
      "grad_norm": 1.2417923212051392,
      "learning_rate": 1.558652729384437e-05,
      "loss": 0.089,
      "step": 29640
    },
    {
      "epoch": 6.887340301974448,
      "grad_norm": 0.8562360405921936,
      "learning_rate": 1.557491289198606e-05,
      "loss": 0.0548,
      "step": 29650
    },
    {
      "epoch": 6.889663182346109,
      "grad_norm": 2.6704680919647217,
      "learning_rate": 1.556329849012776e-05,
      "loss": 0.1003,
      "step": 29660
    },
    {
      "epoch": 6.89198606271777,
      "grad_norm": 1.0879693031311035,
      "learning_rate": 1.5551684088269454e-05,
      "loss": 0.1159,
      "step": 29670
    },
    {
      "epoch": 6.894308943089431,
      "grad_norm": 0.4668663740158081,
      "learning_rate": 1.5540069686411152e-05,
      "loss": 0.0519,
      "step": 29680
    },
    {
      "epoch": 6.8966318234610915,
      "grad_norm": 2.961000680923462,
      "learning_rate": 1.5528455284552844e-05,
      "loss": 0.1142,
      "step": 29690
    },
    {
      "epoch": 6.898954703832753,
      "grad_norm": 1.0649465322494507,
      "learning_rate": 1.5516840882694542e-05,
      "loss": 0.0615,
      "step": 29700
    },
    {
      "epoch": 6.901277584204413,
      "grad_norm": 0.6465598344802856,
      "learning_rate": 1.5505226480836236e-05,
      "loss": 0.2043,
      "step": 29710
    },
    {
      "epoch": 6.9036004645760745,
      "grad_norm": 0.6149016618728638,
      "learning_rate": 1.5493612078977934e-05,
      "loss": 0.069,
      "step": 29720
    },
    {
      "epoch": 6.905923344947735,
      "grad_norm": 0.8078248500823975,
      "learning_rate": 1.548199767711963e-05,
      "loss": 0.0893,
      "step": 29730
    },
    {
      "epoch": 6.908246225319396,
      "grad_norm": 0.5849329829216003,
      "learning_rate": 1.5470383275261324e-05,
      "loss": 0.1316,
      "step": 29740
    },
    {
      "epoch": 6.9105691056910565,
      "grad_norm": 1.578431248664856,
      "learning_rate": 1.5458768873403022e-05,
      "loss": 0.0872,
      "step": 29750
    },
    {
      "epoch": 6.912891986062718,
      "grad_norm": 0.8277018070220947,
      "learning_rate": 1.5447154471544717e-05,
      "loss": 0.1333,
      "step": 29760
    },
    {
      "epoch": 6.915214866434379,
      "grad_norm": 0.8077883124351501,
      "learning_rate": 1.543554006968641e-05,
      "loss": 0.0993,
      "step": 29770
    },
    {
      "epoch": 6.9175377468060395,
      "grad_norm": 0.8027629852294922,
      "learning_rate": 1.5423925667828106e-05,
      "loss": 0.0832,
      "step": 29780
    },
    {
      "epoch": 6.9198606271777,
      "grad_norm": 1.010620355606079,
      "learning_rate": 1.5412311265969804e-05,
      "loss": 0.1305,
      "step": 29790
    },
    {
      "epoch": 6.922183507549361,
      "grad_norm": 0.7079020738601685,
      "learning_rate": 1.54006968641115e-05,
      "loss": 0.1254,
      "step": 29800
    },
    {
      "epoch": 6.9245063879210225,
      "grad_norm": 0.7604066729545593,
      "learning_rate": 1.5389082462253197e-05,
      "loss": 0.1179,
      "step": 29810
    },
    {
      "epoch": 6.926829268292683,
      "grad_norm": 1.2804076671600342,
      "learning_rate": 1.5377468060394888e-05,
      "loss": 0.1855,
      "step": 29820
    },
    {
      "epoch": 6.929152148664344,
      "grad_norm": 0.8162029981613159,
      "learning_rate": 1.5365853658536586e-05,
      "loss": 0.1516,
      "step": 29830
    },
    {
      "epoch": 6.9314750290360045,
      "grad_norm": 0.9105286002159119,
      "learning_rate": 1.535423925667828e-05,
      "loss": 0.0597,
      "step": 29840
    },
    {
      "epoch": 6.933797909407666,
      "grad_norm": 1.6759655475616455,
      "learning_rate": 1.534262485481998e-05,
      "loss": 0.1413,
      "step": 29850
    },
    {
      "epoch": 6.936120789779326,
      "grad_norm": 0.9755899906158447,
      "learning_rate": 1.5331010452961673e-05,
      "loss": 0.0591,
      "step": 29860
    },
    {
      "epoch": 6.9384436701509875,
      "grad_norm": 1.1133317947387695,
      "learning_rate": 1.5319396051103368e-05,
      "loss": 0.0898,
      "step": 29870
    },
    {
      "epoch": 6.940766550522648,
      "grad_norm": 0.8816404342651367,
      "learning_rate": 1.5307781649245066e-05,
      "loss": 0.0728,
      "step": 29880
    },
    {
      "epoch": 6.943089430894309,
      "grad_norm": 0.8835412859916687,
      "learning_rate": 1.529616724738676e-05,
      "loss": 0.0748,
      "step": 29890
    },
    {
      "epoch": 6.94541231126597,
      "grad_norm": 0.8044472336769104,
      "learning_rate": 1.5284552845528455e-05,
      "loss": 0.0779,
      "step": 29900
    },
    {
      "epoch": 6.947735191637631,
      "grad_norm": 0.5596801042556763,
      "learning_rate": 1.527293844367015e-05,
      "loss": 0.0646,
      "step": 29910
    },
    {
      "epoch": 6.950058072009291,
      "grad_norm": 1.8519750833511353,
      "learning_rate": 1.5261324041811848e-05,
      "loss": 0.1109,
      "step": 29920
    },
    {
      "epoch": 6.9523809523809526,
      "grad_norm": 1.131274938583374,
      "learning_rate": 1.5249709639953545e-05,
      "loss": 0.1132,
      "step": 29930
    },
    {
      "epoch": 6.954703832752613,
      "grad_norm": 2.183340549468994,
      "learning_rate": 1.5238095238095241e-05,
      "loss": 0.067,
      "step": 29940
    },
    {
      "epoch": 6.957026713124274,
      "grad_norm": 0.652448832988739,
      "learning_rate": 1.5226480836236934e-05,
      "loss": 0.097,
      "step": 29950
    },
    {
      "epoch": 6.959349593495935,
      "grad_norm": 1.5188413858413696,
      "learning_rate": 1.521486643437863e-05,
      "loss": 0.1251,
      "step": 29960
    },
    {
      "epoch": 6.961672473867596,
      "grad_norm": 0.596754252910614,
      "learning_rate": 1.5203252032520327e-05,
      "loss": 0.0674,
      "step": 29970
    },
    {
      "epoch": 6.963995354239256,
      "grad_norm": 0.7858325839042664,
      "learning_rate": 1.5191637630662023e-05,
      "loss": 0.0828,
      "step": 29980
    },
    {
      "epoch": 6.966318234610918,
      "grad_norm": 0.8090938329696655,
      "learning_rate": 1.5180023228803716e-05,
      "loss": 0.1022,
      "step": 29990
    },
    {
      "epoch": 6.968641114982578,
      "grad_norm": 0.6120917797088623,
      "learning_rate": 1.5168408826945412e-05,
      "loss": 0.0799,
      "step": 30000
    },
    {
      "epoch": 6.970963995354239,
      "grad_norm": 0.8301916718482971,
      "learning_rate": 1.5156794425087109e-05,
      "loss": 0.0749,
      "step": 30010
    },
    {
      "epoch": 6.973286875725901,
      "grad_norm": 1.138863444328308,
      "learning_rate": 1.5145180023228805e-05,
      "loss": 0.063,
      "step": 30020
    },
    {
      "epoch": 6.975609756097561,
      "grad_norm": 1.2170790433883667,
      "learning_rate": 1.51335656213705e-05,
      "loss": 0.0629,
      "step": 30030
    },
    {
      "epoch": 6.977932636469221,
      "grad_norm": 0.8904536366462708,
      "learning_rate": 1.5121951219512196e-05,
      "loss": 0.0853,
      "step": 30040
    },
    {
      "epoch": 6.980255516840883,
      "grad_norm": 1.0941087007522583,
      "learning_rate": 1.5110336817653893e-05,
      "loss": 0.1287,
      "step": 30050
    },
    {
      "epoch": 6.982578397212544,
      "grad_norm": 0.5664225816726685,
      "learning_rate": 1.5098722415795589e-05,
      "loss": 0.0517,
      "step": 30060
    },
    {
      "epoch": 6.984901277584204,
      "grad_norm": 0.6260632276535034,
      "learning_rate": 1.5087108013937282e-05,
      "loss": 0.0734,
      "step": 30070
    },
    {
      "epoch": 6.987224157955866,
      "grad_norm": 1.171055555343628,
      "learning_rate": 1.5075493612078978e-05,
      "loss": 0.118,
      "step": 30080
    },
    {
      "epoch": 6.989547038327526,
      "grad_norm": 0.8433924913406372,
      "learning_rate": 1.5063879210220675e-05,
      "loss": 0.1024,
      "step": 30090
    },
    {
      "epoch": 6.991869918699187,
      "grad_norm": 1.2175318002700806,
      "learning_rate": 1.5052264808362371e-05,
      "loss": 0.1114,
      "step": 30100
    },
    {
      "epoch": 6.994192799070848,
      "grad_norm": 1.2979778051376343,
      "learning_rate": 1.5040650406504067e-05,
      "loss": 0.126,
      "step": 30110
    },
    {
      "epoch": 6.996515679442509,
      "grad_norm": 1.1181433200836182,
      "learning_rate": 1.502903600464576e-05,
      "loss": 0.0809,
      "step": 30120
    },
    {
      "epoch": 6.998838559814169,
      "grad_norm": 1.4753822088241577,
      "learning_rate": 1.5017421602787457e-05,
      "loss": 0.0927,
      "step": 30130
    },
    {
      "epoch": 7.001161440185831,
      "grad_norm": 0.8750068545341492,
      "learning_rate": 1.5005807200929153e-05,
      "loss": 0.0819,
      "step": 30140
    },
    {
      "epoch": 7.003484320557491,
      "grad_norm": 0.4159495234489441,
      "learning_rate": 1.499419279907085e-05,
      "loss": 0.1335,
      "step": 30150
    },
    {
      "epoch": 7.005807200929152,
      "grad_norm": 0.9298532605171204,
      "learning_rate": 1.4982578397212544e-05,
      "loss": 0.0567,
      "step": 30160
    },
    {
      "epoch": 7.008130081300813,
      "grad_norm": 1.0511078834533691,
      "learning_rate": 1.497096399535424e-05,
      "loss": 0.0445,
      "step": 30170
    },
    {
      "epoch": 7.010452961672474,
      "grad_norm": 0.6781174540519714,
      "learning_rate": 1.4959349593495937e-05,
      "loss": 0.1024,
      "step": 30180
    },
    {
      "epoch": 7.012775842044134,
      "grad_norm": 0.516889750957489,
      "learning_rate": 1.4947735191637633e-05,
      "loss": 0.0551,
      "step": 30190
    },
    {
      "epoch": 7.015098722415796,
      "grad_norm": 0.7008427381515503,
      "learning_rate": 1.4936120789779326e-05,
      "loss": 0.0537,
      "step": 30200
    },
    {
      "epoch": 7.017421602787456,
      "grad_norm": 0.9501447081565857,
      "learning_rate": 1.4924506387921023e-05,
      "loss": 0.1009,
      "step": 30210
    },
    {
      "epoch": 7.019744483159117,
      "grad_norm": 0.7501242160797119,
      "learning_rate": 1.4912891986062719e-05,
      "loss": 0.1492,
      "step": 30220
    },
    {
      "epoch": 7.022067363530778,
      "grad_norm": 1.6569682359695435,
      "learning_rate": 1.4901277584204415e-05,
      "loss": 0.1168,
      "step": 30230
    },
    {
      "epoch": 7.024390243902439,
      "grad_norm": 0.5262107253074646,
      "learning_rate": 1.4889663182346108e-05,
      "loss": 0.1141,
      "step": 30240
    },
    {
      "epoch": 7.026713124274099,
      "grad_norm": 1.3133972883224487,
      "learning_rate": 1.4878048780487805e-05,
      "loss": 0.0691,
      "step": 30250
    },
    {
      "epoch": 7.029036004645761,
      "grad_norm": 0.8615346550941467,
      "learning_rate": 1.4866434378629501e-05,
      "loss": 0.0622,
      "step": 30260
    },
    {
      "epoch": 7.031358885017422,
      "grad_norm": 0.5185337662696838,
      "learning_rate": 1.4854819976771197e-05,
      "loss": 0.1229,
      "step": 30270
    },
    {
      "epoch": 7.033681765389082,
      "grad_norm": 1.2710503339767456,
      "learning_rate": 1.4843205574912894e-05,
      "loss": 0.1041,
      "step": 30280
    },
    {
      "epoch": 7.036004645760744,
      "grad_norm": 0.6623684763908386,
      "learning_rate": 1.4831591173054588e-05,
      "loss": 0.0881,
      "step": 30290
    },
    {
      "epoch": 7.038327526132404,
      "grad_norm": 1.8286060094833374,
      "learning_rate": 1.4819976771196285e-05,
      "loss": 0.1075,
      "step": 30300
    },
    {
      "epoch": 7.040650406504065,
      "grad_norm": 1.2628498077392578,
      "learning_rate": 1.4808362369337981e-05,
      "loss": 0.1087,
      "step": 30310
    },
    {
      "epoch": 7.042973286875726,
      "grad_norm": 0.393963485956192,
      "learning_rate": 1.4796747967479676e-05,
      "loss": 0.0897,
      "step": 30320
    },
    {
      "epoch": 7.045296167247387,
      "grad_norm": 0.5795602202415466,
      "learning_rate": 1.478513356562137e-05,
      "loss": 0.078,
      "step": 30330
    },
    {
      "epoch": 7.0476190476190474,
      "grad_norm": 1.1406112909317017,
      "learning_rate": 1.4773519163763067e-05,
      "loss": 0.0597,
      "step": 30340
    },
    {
      "epoch": 7.049941927990709,
      "grad_norm": 1.5331815481185913,
      "learning_rate": 1.4761904761904763e-05,
      "loss": 0.1218,
      "step": 30350
    },
    {
      "epoch": 7.052264808362369,
      "grad_norm": 1.4227782487869263,
      "learning_rate": 1.475029036004646e-05,
      "loss": 0.0719,
      "step": 30360
    },
    {
      "epoch": 7.05458768873403,
      "grad_norm": 0.8884581327438354,
      "learning_rate": 1.4738675958188153e-05,
      "loss": 0.0802,
      "step": 30370
    },
    {
      "epoch": 7.056910569105691,
      "grad_norm": 1.2126942873001099,
      "learning_rate": 1.4727061556329849e-05,
      "loss": 0.0469,
      "step": 30380
    },
    {
      "epoch": 7.059233449477352,
      "grad_norm": 1.2287392616271973,
      "learning_rate": 1.4715447154471545e-05,
      "loss": 0.0904,
      "step": 30390
    },
    {
      "epoch": 7.0615563298490125,
      "grad_norm": 0.5306399464607239,
      "learning_rate": 1.4703832752613242e-05,
      "loss": 0.1083,
      "step": 30400
    },
    {
      "epoch": 7.063879210220674,
      "grad_norm": 0.9006412029266357,
      "learning_rate": 1.4692218350754936e-05,
      "loss": 0.13,
      "step": 30410
    },
    {
      "epoch": 7.066202090592334,
      "grad_norm": 1.8055248260498047,
      "learning_rate": 1.4680603948896631e-05,
      "loss": 0.0811,
      "step": 30420
    },
    {
      "epoch": 7.0685249709639955,
      "grad_norm": 0.5632877349853516,
      "learning_rate": 1.4668989547038327e-05,
      "loss": 0.0598,
      "step": 30430
    },
    {
      "epoch": 7.070847851335656,
      "grad_norm": 1.3028708696365356,
      "learning_rate": 1.4657375145180024e-05,
      "loss": 0.1927,
      "step": 30440
    },
    {
      "epoch": 7.073170731707317,
      "grad_norm": 0.5175743699073792,
      "learning_rate": 1.464576074332172e-05,
      "loss": 0.0421,
      "step": 30450
    },
    {
      "epoch": 7.0754936120789775,
      "grad_norm": 0.6455179452896118,
      "learning_rate": 1.4634146341463415e-05,
      "loss": 0.0677,
      "step": 30460
    },
    {
      "epoch": 7.077816492450639,
      "grad_norm": 0.5442857146263123,
      "learning_rate": 1.4622531939605111e-05,
      "loss": 0.0842,
      "step": 30470
    },
    {
      "epoch": 7.080139372822299,
      "grad_norm": 0.9998065233230591,
      "learning_rate": 1.4610917537746807e-05,
      "loss": 0.1229,
      "step": 30480
    },
    {
      "epoch": 7.0824622531939605,
      "grad_norm": 1.6667662858963013,
      "learning_rate": 1.4599303135888504e-05,
      "loss": 0.1181,
      "step": 30490
    },
    {
      "epoch": 7.084785133565622,
      "grad_norm": 1.1211596727371216,
      "learning_rate": 1.4587688734030197e-05,
      "loss": 0.093,
      "step": 30500
    },
    {
      "epoch": 7.087108013937282,
      "grad_norm": 1.119430661201477,
      "learning_rate": 1.4576074332171893e-05,
      "loss": 0.0928,
      "step": 30510
    },
    {
      "epoch": 7.0894308943089435,
      "grad_norm": 1.6497957706451416,
      "learning_rate": 1.456445993031359e-05,
      "loss": 0.1485,
      "step": 30520
    },
    {
      "epoch": 7.091753774680604,
      "grad_norm": 0.6440919637680054,
      "learning_rate": 1.4552845528455286e-05,
      "loss": 0.1219,
      "step": 30530
    },
    {
      "epoch": 7.094076655052265,
      "grad_norm": 2.009016990661621,
      "learning_rate": 1.4541231126596979e-05,
      "loss": 0.1291,
      "step": 30540
    },
    {
      "epoch": 7.0963995354239255,
      "grad_norm": 1.2091403007507324,
      "learning_rate": 1.4529616724738675e-05,
      "loss": 0.082,
      "step": 30550
    },
    {
      "epoch": 7.098722415795587,
      "grad_norm": 1.2082583904266357,
      "learning_rate": 1.4518002322880372e-05,
      "loss": 0.1252,
      "step": 30560
    },
    {
      "epoch": 7.101045296167247,
      "grad_norm": 1.1746535301208496,
      "learning_rate": 1.4506387921022068e-05,
      "loss": 0.085,
      "step": 30570
    },
    {
      "epoch": 7.1033681765389085,
      "grad_norm": 0.9675176739692688,
      "learning_rate": 1.4494773519163764e-05,
      "loss": 0.0908,
      "step": 30580
    },
    {
      "epoch": 7.105691056910569,
      "grad_norm": 1.4139903783798218,
      "learning_rate": 1.4483159117305459e-05,
      "loss": 0.1067,
      "step": 30590
    },
    {
      "epoch": 7.10801393728223,
      "grad_norm": 1.4564366340637207,
      "learning_rate": 1.4471544715447155e-05,
      "loss": 0.0648,
      "step": 30600
    },
    {
      "epoch": 7.110336817653891,
      "grad_norm": 0.7626078724861145,
      "learning_rate": 1.4459930313588852e-05,
      "loss": 0.0571,
      "step": 30610
    },
    {
      "epoch": 7.112659698025552,
      "grad_norm": 0.709572970867157,
      "learning_rate": 1.4448315911730548e-05,
      "loss": 0.0914,
      "step": 30620
    },
    {
      "epoch": 7.114982578397212,
      "grad_norm": 1.5682035684585571,
      "learning_rate": 1.4436701509872241e-05,
      "loss": 0.0786,
      "step": 30630
    },
    {
      "epoch": 7.1173054587688735,
      "grad_norm": 1.1773149967193604,
      "learning_rate": 1.4425087108013938e-05,
      "loss": 0.1784,
      "step": 30640
    },
    {
      "epoch": 7.119628339140534,
      "grad_norm": 1.1142014265060425,
      "learning_rate": 1.4413472706155634e-05,
      "loss": 0.1195,
      "step": 30650
    },
    {
      "epoch": 7.121951219512195,
      "grad_norm": 3.700761318206787,
      "learning_rate": 1.440185830429733e-05,
      "loss": 0.1316,
      "step": 30660
    },
    {
      "epoch": 7.124274099883856,
      "grad_norm": 0.619213879108429,
      "learning_rate": 1.4390243902439023e-05,
      "loss": 0.0779,
      "step": 30670
    },
    {
      "epoch": 7.126596980255517,
      "grad_norm": 0.5815696120262146,
      "learning_rate": 1.437862950058072e-05,
      "loss": 0.069,
      "step": 30680
    },
    {
      "epoch": 7.128919860627177,
      "grad_norm": 0.5360443592071533,
      "learning_rate": 1.4367015098722416e-05,
      "loss": 0.136,
      "step": 30690
    },
    {
      "epoch": 7.131242740998839,
      "grad_norm": 0.8372400403022766,
      "learning_rate": 1.4355400696864112e-05,
      "loss": 0.1851,
      "step": 30700
    },
    {
      "epoch": 7.133565621370499,
      "grad_norm": 0.5255122184753418,
      "learning_rate": 1.4343786295005807e-05,
      "loss": 0.1056,
      "step": 30710
    },
    {
      "epoch": 7.13588850174216,
      "grad_norm": 0.5274136066436768,
      "learning_rate": 1.4332171893147503e-05,
      "loss": 0.1417,
      "step": 30720
    },
    {
      "epoch": 7.138211382113822,
      "grad_norm": 0.6869871020317078,
      "learning_rate": 1.43205574912892e-05,
      "loss": 0.1805,
      "step": 30730
    },
    {
      "epoch": 7.140534262485482,
      "grad_norm": 2.1128222942352295,
      "learning_rate": 1.4308943089430896e-05,
      "loss": 0.2017,
      "step": 30740
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.5681616067886353,
      "learning_rate": 1.4297328687572592e-05,
      "loss": 0.1349,
      "step": 30750
    },
    {
      "epoch": 7.145180023228804,
      "grad_norm": 1.0662480592727661,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 0.1344,
      "step": 30760
    },
    {
      "epoch": 7.147502903600465,
      "grad_norm": 1.4681564569473267,
      "learning_rate": 1.4274099883855982e-05,
      "loss": 0.0817,
      "step": 30770
    },
    {
      "epoch": 7.149825783972125,
      "grad_norm": 1.1909099817276,
      "learning_rate": 1.4262485481997678e-05,
      "loss": 0.1646,
      "step": 30780
    },
    {
      "epoch": 7.152148664343787,
      "grad_norm": 1.573541283607483,
      "learning_rate": 1.4250871080139375e-05,
      "loss": 0.0873,
      "step": 30790
    },
    {
      "epoch": 7.154471544715447,
      "grad_norm": 1.8921127319335938,
      "learning_rate": 1.4239256678281068e-05,
      "loss": 0.1246,
      "step": 30800
    },
    {
      "epoch": 7.156794425087108,
      "grad_norm": 0.9523683786392212,
      "learning_rate": 1.4227642276422764e-05,
      "loss": 0.067,
      "step": 30810
    },
    {
      "epoch": 7.159117305458769,
      "grad_norm": 0.2029445320367813,
      "learning_rate": 1.421602787456446e-05,
      "loss": 0.1305,
      "step": 30820
    },
    {
      "epoch": 7.16144018583043,
      "grad_norm": 0.9058372378349304,
      "learning_rate": 1.4204413472706157e-05,
      "loss": 0.0982,
      "step": 30830
    },
    {
      "epoch": 7.16376306620209,
      "grad_norm": 1.1213916540145874,
      "learning_rate": 1.4192799070847851e-05,
      "loss": 0.1642,
      "step": 30840
    },
    {
      "epoch": 7.166085946573752,
      "grad_norm": 1.2137829065322876,
      "learning_rate": 1.4181184668989548e-05,
      "loss": 0.0754,
      "step": 30850
    },
    {
      "epoch": 7.168408826945412,
      "grad_norm": 1.9668697118759155,
      "learning_rate": 1.4169570267131244e-05,
      "loss": 0.1023,
      "step": 30860
    },
    {
      "epoch": 7.170731707317073,
      "grad_norm": 1.8280751705169678,
      "learning_rate": 1.415795586527294e-05,
      "loss": 0.1293,
      "step": 30870
    },
    {
      "epoch": 7.173054587688734,
      "grad_norm": 0.4945562779903412,
      "learning_rate": 1.4146341463414633e-05,
      "loss": 0.0541,
      "step": 30880
    },
    {
      "epoch": 7.175377468060395,
      "grad_norm": 1.673618197441101,
      "learning_rate": 1.413472706155633e-05,
      "loss": 0.1086,
      "step": 30890
    },
    {
      "epoch": 7.177700348432055,
      "grad_norm": 1.4713802337646484,
      "learning_rate": 1.4123112659698026e-05,
      "loss": 0.0819,
      "step": 30900
    },
    {
      "epoch": 7.180023228803717,
      "grad_norm": 0.8996543884277344,
      "learning_rate": 1.4111498257839722e-05,
      "loss": 0.1596,
      "step": 30910
    },
    {
      "epoch": 7.182346109175377,
      "grad_norm": 0.5641137957572937,
      "learning_rate": 1.4099883855981419e-05,
      "loss": 0.0512,
      "step": 30920
    },
    {
      "epoch": 7.184668989547038,
      "grad_norm": 1.0571017265319824,
      "learning_rate": 1.4088269454123112e-05,
      "loss": 0.1043,
      "step": 30930
    },
    {
      "epoch": 7.186991869918699,
      "grad_norm": 0.8747300505638123,
      "learning_rate": 1.4076655052264808e-05,
      "loss": 0.0782,
      "step": 30940
    },
    {
      "epoch": 7.18931475029036,
      "grad_norm": 1.9115859270095825,
      "learning_rate": 1.4065040650406505e-05,
      "loss": 0.145,
      "step": 30950
    },
    {
      "epoch": 7.191637630662021,
      "grad_norm": 0.6371139287948608,
      "learning_rate": 1.4053426248548201e-05,
      "loss": 0.1259,
      "step": 30960
    },
    {
      "epoch": 7.193960511033682,
      "grad_norm": 2.62453556060791,
      "learning_rate": 1.4041811846689896e-05,
      "loss": 0.08,
      "step": 30970
    },
    {
      "epoch": 7.196283391405343,
      "grad_norm": 1.348242998123169,
      "learning_rate": 1.4030197444831592e-05,
      "loss": 0.1129,
      "step": 30980
    },
    {
      "epoch": 7.198606271777003,
      "grad_norm": 0.573981523513794,
      "learning_rate": 1.4018583042973288e-05,
      "loss": 0.0724,
      "step": 30990
    },
    {
      "epoch": 7.200929152148665,
      "grad_norm": 0.7941030859947205,
      "learning_rate": 1.4006968641114985e-05,
      "loss": 0.1372,
      "step": 31000
    },
    {
      "epoch": 7.203252032520325,
      "grad_norm": 0.7986841797828674,
      "learning_rate": 1.3995354239256678e-05,
      "loss": 0.1093,
      "step": 31010
    },
    {
      "epoch": 7.205574912891986,
      "grad_norm": 0.8088981509208679,
      "learning_rate": 1.3983739837398374e-05,
      "loss": 0.0419,
      "step": 31020
    },
    {
      "epoch": 7.207897793263647,
      "grad_norm": 0.8860113620758057,
      "learning_rate": 1.397212543554007e-05,
      "loss": 0.0919,
      "step": 31030
    },
    {
      "epoch": 7.210220673635308,
      "grad_norm": 0.9161966443061829,
      "learning_rate": 1.3960511033681767e-05,
      "loss": 0.0906,
      "step": 31040
    },
    {
      "epoch": 7.2125435540069684,
      "grad_norm": 1.6331589221954346,
      "learning_rate": 1.394889663182346e-05,
      "loss": 0.105,
      "step": 31050
    },
    {
      "epoch": 7.21486643437863,
      "grad_norm": 1.1755294799804688,
      "learning_rate": 1.3937282229965156e-05,
      "loss": 0.0651,
      "step": 31060
    },
    {
      "epoch": 7.21718931475029,
      "grad_norm": 1.164049506187439,
      "learning_rate": 1.3925667828106852e-05,
      "loss": 0.2046,
      "step": 31070
    },
    {
      "epoch": 7.219512195121951,
      "grad_norm": 0.6552197933197021,
      "learning_rate": 1.3914053426248549e-05,
      "loss": 0.0998,
      "step": 31080
    },
    {
      "epoch": 7.221835075493612,
      "grad_norm": 1.1862006187438965,
      "learning_rate": 1.3902439024390245e-05,
      "loss": 0.1123,
      "step": 31090
    },
    {
      "epoch": 7.224157955865273,
      "grad_norm": 0.4608975350856781,
      "learning_rate": 1.389082462253194e-05,
      "loss": 0.0725,
      "step": 31100
    },
    {
      "epoch": 7.2264808362369335,
      "grad_norm": 1.107511043548584,
      "learning_rate": 1.3879210220673636e-05,
      "loss": 0.0806,
      "step": 31110
    },
    {
      "epoch": 7.228803716608595,
      "grad_norm": 1.3786894083023071,
      "learning_rate": 1.3867595818815333e-05,
      "loss": 0.0794,
      "step": 31120
    },
    {
      "epoch": 7.231126596980255,
      "grad_norm": 1.5237843990325928,
      "learning_rate": 1.3855981416957029e-05,
      "loss": 0.1311,
      "step": 31130
    },
    {
      "epoch": 7.2334494773519165,
      "grad_norm": 1.8970383405685425,
      "learning_rate": 1.3844367015098722e-05,
      "loss": 0.1004,
      "step": 31140
    },
    {
      "epoch": 7.235772357723577,
      "grad_norm": 0.5297223329544067,
      "learning_rate": 1.3832752613240418e-05,
      "loss": 0.0754,
      "step": 31150
    },
    {
      "epoch": 7.238095238095238,
      "grad_norm": 0.5034083127975464,
      "learning_rate": 1.3821138211382115e-05,
      "loss": 0.0568,
      "step": 31160
    },
    {
      "epoch": 7.2404181184668985,
      "grad_norm": 0.45765718817710876,
      "learning_rate": 1.3809523809523811e-05,
      "loss": 0.053,
      "step": 31170
    },
    {
      "epoch": 7.24274099883856,
      "grad_norm": 1.263594388961792,
      "learning_rate": 1.3797909407665504e-05,
      "loss": 0.0798,
      "step": 31180
    },
    {
      "epoch": 7.245063879210221,
      "grad_norm": 2.369145631790161,
      "learning_rate": 1.37862950058072e-05,
      "loss": 0.1731,
      "step": 31190
    },
    {
      "epoch": 7.2473867595818815,
      "grad_norm": 1.7189666032791138,
      "learning_rate": 1.3774680603948897e-05,
      "loss": 0.0874,
      "step": 31200
    },
    {
      "epoch": 7.249709639953543,
      "grad_norm": 1.1486244201660156,
      "learning_rate": 1.3763066202090593e-05,
      "loss": 0.0667,
      "step": 31210
    },
    {
      "epoch": 7.252032520325203,
      "grad_norm": 1.1247541904449463,
      "learning_rate": 1.375145180023229e-05,
      "loss": 0.12,
      "step": 31220
    },
    {
      "epoch": 7.2543554006968645,
      "grad_norm": 1.1169688701629639,
      "learning_rate": 1.3739837398373984e-05,
      "loss": 0.0976,
      "step": 31230
    },
    {
      "epoch": 7.256678281068525,
      "grad_norm": 1.2450685501098633,
      "learning_rate": 1.372822299651568e-05,
      "loss": 0.0864,
      "step": 31240
    },
    {
      "epoch": 7.259001161440186,
      "grad_norm": 0.5878171920776367,
      "learning_rate": 1.3716608594657377e-05,
      "loss": 0.1125,
      "step": 31250
    },
    {
      "epoch": 7.2613240418118465,
      "grad_norm": 0.7390848398208618,
      "learning_rate": 1.3704994192799073e-05,
      "loss": 0.1138,
      "step": 31260
    },
    {
      "epoch": 7.263646922183508,
      "grad_norm": 1.6504968404769897,
      "learning_rate": 1.3693379790940766e-05,
      "loss": 0.1281,
      "step": 31270
    },
    {
      "epoch": 7.265969802555168,
      "grad_norm": 2.155712366104126,
      "learning_rate": 1.3681765389082463e-05,
      "loss": 0.1061,
      "step": 31280
    },
    {
      "epoch": 7.2682926829268295,
      "grad_norm": 0.8834415078163147,
      "learning_rate": 1.3670150987224159e-05,
      "loss": 0.0882,
      "step": 31290
    },
    {
      "epoch": 7.27061556329849,
      "grad_norm": 0.8146810531616211,
      "learning_rate": 1.3658536585365855e-05,
      "loss": 0.1579,
      "step": 31300
    },
    {
      "epoch": 7.272938443670151,
      "grad_norm": 1.8405699729919434,
      "learning_rate": 1.3646922183507548e-05,
      "loss": 0.0843,
      "step": 31310
    },
    {
      "epoch": 7.275261324041812,
      "grad_norm": 0.7001573443412781,
      "learning_rate": 1.3635307781649245e-05,
      "loss": 0.0744,
      "step": 31320
    },
    {
      "epoch": 7.277584204413473,
      "grad_norm": 0.49756553769111633,
      "learning_rate": 1.3623693379790941e-05,
      "loss": 0.0818,
      "step": 31330
    },
    {
      "epoch": 7.279907084785133,
      "grad_norm": 0.7206594347953796,
      "learning_rate": 1.3612078977932637e-05,
      "loss": 0.0682,
      "step": 31340
    },
    {
      "epoch": 7.2822299651567945,
      "grad_norm": 0.8485581874847412,
      "learning_rate": 1.3600464576074332e-05,
      "loss": 0.1645,
      "step": 31350
    },
    {
      "epoch": 7.284552845528455,
      "grad_norm": 1.1458098888397217,
      "learning_rate": 1.3588850174216028e-05,
      "loss": 0.087,
      "step": 31360
    },
    {
      "epoch": 7.286875725900116,
      "grad_norm": 1.4512178897857666,
      "learning_rate": 1.3577235772357725e-05,
      "loss": 0.1442,
      "step": 31370
    },
    {
      "epoch": 7.289198606271777,
      "grad_norm": 0.4418330490589142,
      "learning_rate": 1.3565621370499421e-05,
      "loss": 0.082,
      "step": 31380
    },
    {
      "epoch": 7.291521486643438,
      "grad_norm": 0.5867016911506653,
      "learning_rate": 1.3554006968641118e-05,
      "loss": 0.0738,
      "step": 31390
    },
    {
      "epoch": 7.293844367015098,
      "grad_norm": 1.230589747428894,
      "learning_rate": 1.354239256678281e-05,
      "loss": 0.0831,
      "step": 31400
    },
    {
      "epoch": 7.29616724738676,
      "grad_norm": 1.263002634048462,
      "learning_rate": 1.3530778164924507e-05,
      "loss": 0.147,
      "step": 31410
    },
    {
      "epoch": 7.29849012775842,
      "grad_norm": 0.5265045166015625,
      "learning_rate": 1.3519163763066203e-05,
      "loss": 0.1026,
      "step": 31420
    },
    {
      "epoch": 7.300813008130081,
      "grad_norm": 1.1353412866592407,
      "learning_rate": 1.35075493612079e-05,
      "loss": 0.0675,
      "step": 31430
    },
    {
      "epoch": 7.303135888501743,
      "grad_norm": 0.7824721932411194,
      "learning_rate": 1.3495934959349593e-05,
      "loss": 0.1194,
      "step": 31440
    },
    {
      "epoch": 7.305458768873403,
      "grad_norm": 1.9185243844985962,
      "learning_rate": 1.3484320557491289e-05,
      "loss": 0.108,
      "step": 31450
    },
    {
      "epoch": 7.307781649245064,
      "grad_norm": 0.6392083764076233,
      "learning_rate": 1.3472706155632985e-05,
      "loss": 0.1769,
      "step": 31460
    },
    {
      "epoch": 7.310104529616725,
      "grad_norm": 1.421956181526184,
      "learning_rate": 1.3461091753774682e-05,
      "loss": 0.202,
      "step": 31470
    },
    {
      "epoch": 7.312427409988386,
      "grad_norm": 1.0485272407531738,
      "learning_rate": 1.3449477351916376e-05,
      "loss": 0.1061,
      "step": 31480
    },
    {
      "epoch": 7.314750290360046,
      "grad_norm": 0.9947533011436462,
      "learning_rate": 1.3437862950058073e-05,
      "loss": 0.0974,
      "step": 31490
    },
    {
      "epoch": 7.317073170731708,
      "grad_norm": 0.9701306819915771,
      "learning_rate": 1.3426248548199769e-05,
      "loss": 0.0551,
      "step": 31500
    },
    {
      "epoch": 7.319396051103368,
      "grad_norm": 1.0882948637008667,
      "learning_rate": 1.3414634146341466e-05,
      "loss": 0.1163,
      "step": 31510
    },
    {
      "epoch": 7.321718931475029,
      "grad_norm": 0.7387390732765198,
      "learning_rate": 1.3403019744483158e-05,
      "loss": 0.1481,
      "step": 31520
    },
    {
      "epoch": 7.32404181184669,
      "grad_norm": 0.5159112811088562,
      "learning_rate": 1.3391405342624855e-05,
      "loss": 0.0554,
      "step": 31530
    },
    {
      "epoch": 7.326364692218351,
      "grad_norm": 0.5199028253555298,
      "learning_rate": 1.3379790940766551e-05,
      "loss": 0.104,
      "step": 31540
    },
    {
      "epoch": 7.328687572590011,
      "grad_norm": 1.5114916563034058,
      "learning_rate": 1.3368176538908248e-05,
      "loss": 0.0585,
      "step": 31550
    },
    {
      "epoch": 7.331010452961673,
      "grad_norm": 0.9528478980064392,
      "learning_rate": 1.3356562137049944e-05,
      "loss": 0.1016,
      "step": 31560
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 1.3319472074508667,
      "learning_rate": 1.3344947735191637e-05,
      "loss": 0.0638,
      "step": 31570
    },
    {
      "epoch": 7.335656213704994,
      "grad_norm": 1.3690557479858398,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 0.1098,
      "step": 31580
    },
    {
      "epoch": 7.337979094076655,
      "grad_norm": 0.9539927244186401,
      "learning_rate": 1.332171893147503e-05,
      "loss": 0.0611,
      "step": 31590
    },
    {
      "epoch": 7.340301974448316,
      "grad_norm": 0.8189842104911804,
      "learning_rate": 1.3310104529616726e-05,
      "loss": 0.0572,
      "step": 31600
    },
    {
      "epoch": 7.342624854819976,
      "grad_norm": 1.3104082345962524,
      "learning_rate": 1.329849012775842e-05,
      "loss": 0.081,
      "step": 31610
    },
    {
      "epoch": 7.344947735191638,
      "grad_norm": 1.253440499305725,
      "learning_rate": 1.3286875725900117e-05,
      "loss": 0.112,
      "step": 31620
    },
    {
      "epoch": 7.347270615563298,
      "grad_norm": 1.0995863676071167,
      "learning_rate": 1.3275261324041813e-05,
      "loss": 0.0784,
      "step": 31630
    },
    {
      "epoch": 7.349593495934959,
      "grad_norm": 1.163096308708191,
      "learning_rate": 1.326364692218351e-05,
      "loss": 0.082,
      "step": 31640
    },
    {
      "epoch": 7.351916376306621,
      "grad_norm": 1.752839207649231,
      "learning_rate": 1.3252032520325203e-05,
      "loss": 0.0773,
      "step": 31650
    },
    {
      "epoch": 7.354239256678281,
      "grad_norm": 1.9324339628219604,
      "learning_rate": 1.3240418118466899e-05,
      "loss": 0.1441,
      "step": 31660
    },
    {
      "epoch": 7.356562137049942,
      "grad_norm": 0.4890773594379425,
      "learning_rate": 1.3228803716608596e-05,
      "loss": 0.0726,
      "step": 31670
    },
    {
      "epoch": 7.358885017421603,
      "grad_norm": 0.8327709436416626,
      "learning_rate": 1.3217189314750292e-05,
      "loss": 0.1121,
      "step": 31680
    },
    {
      "epoch": 7.361207897793264,
      "grad_norm": 1.553455114364624,
      "learning_rate": 1.3205574912891985e-05,
      "loss": 0.115,
      "step": 31690
    },
    {
      "epoch": 7.363530778164924,
      "grad_norm": 0.6488370895385742,
      "learning_rate": 1.3193960511033681e-05,
      "loss": 0.0789,
      "step": 31700
    },
    {
      "epoch": 7.365853658536586,
      "grad_norm": 0.6749415397644043,
      "learning_rate": 1.3182346109175378e-05,
      "loss": 0.105,
      "step": 31710
    },
    {
      "epoch": 7.368176538908246,
      "grad_norm": 0.7556484937667847,
      "learning_rate": 1.3170731707317074e-05,
      "loss": 0.1313,
      "step": 31720
    },
    {
      "epoch": 7.370499419279907,
      "grad_norm": 0.4927179515361786,
      "learning_rate": 1.315911730545877e-05,
      "loss": 0.093,
      "step": 31730
    },
    {
      "epoch": 7.372822299651568,
      "grad_norm": 1.1712543964385986,
      "learning_rate": 1.3147502903600465e-05,
      "loss": 0.0643,
      "step": 31740
    },
    {
      "epoch": 7.375145180023229,
      "grad_norm": 0.802570104598999,
      "learning_rate": 1.3135888501742161e-05,
      "loss": 0.0854,
      "step": 31750
    },
    {
      "epoch": 7.3774680603948894,
      "grad_norm": 1.810659408569336,
      "learning_rate": 1.3124274099883858e-05,
      "loss": 0.1516,
      "step": 31760
    },
    {
      "epoch": 7.379790940766551,
      "grad_norm": 0.7471108436584473,
      "learning_rate": 1.3112659698025554e-05,
      "loss": 0.107,
      "step": 31770
    },
    {
      "epoch": 7.382113821138211,
      "grad_norm": 0.5474599003791809,
      "learning_rate": 1.3101045296167247e-05,
      "loss": 0.057,
      "step": 31780
    },
    {
      "epoch": 7.384436701509872,
      "grad_norm": 0.6473895907402039,
      "learning_rate": 1.3089430894308943e-05,
      "loss": 0.0803,
      "step": 31790
    },
    {
      "epoch": 7.386759581881533,
      "grad_norm": 0.8484333753585815,
      "learning_rate": 1.307781649245064e-05,
      "loss": 0.0774,
      "step": 31800
    },
    {
      "epoch": 7.389082462253194,
      "grad_norm": 0.8295731544494629,
      "learning_rate": 1.3066202090592336e-05,
      "loss": 0.0822,
      "step": 31810
    },
    {
      "epoch": 7.3914053426248545,
      "grad_norm": 1.021747350692749,
      "learning_rate": 1.305458768873403e-05,
      "loss": 0.1603,
      "step": 31820
    },
    {
      "epoch": 7.393728222996516,
      "grad_norm": 1.7974404096603394,
      "learning_rate": 1.3042973286875726e-05,
      "loss": 0.0998,
      "step": 31830
    },
    {
      "epoch": 7.396051103368176,
      "grad_norm": 1.8484774827957153,
      "learning_rate": 1.3031358885017422e-05,
      "loss": 0.079,
      "step": 31840
    },
    {
      "epoch": 7.3983739837398375,
      "grad_norm": 0.5719610452651978,
      "learning_rate": 1.3019744483159118e-05,
      "loss": 0.0724,
      "step": 31850
    },
    {
      "epoch": 7.400696864111498,
      "grad_norm": 0.8414950966835022,
      "learning_rate": 1.3008130081300815e-05,
      "loss": 0.0683,
      "step": 31860
    },
    {
      "epoch": 7.403019744483159,
      "grad_norm": 1.2745712995529175,
      "learning_rate": 1.299651567944251e-05,
      "loss": 0.0713,
      "step": 31870
    },
    {
      "epoch": 7.4053426248548195,
      "grad_norm": 1.4098409414291382,
      "learning_rate": 1.2984901277584206e-05,
      "loss": 0.0624,
      "step": 31880
    },
    {
      "epoch": 7.407665505226481,
      "grad_norm": 0.8096746206283569,
      "learning_rate": 1.2973286875725902e-05,
      "loss": 0.0749,
      "step": 31890
    },
    {
      "epoch": 7.409988385598142,
      "grad_norm": 2.312729835510254,
      "learning_rate": 1.2961672473867598e-05,
      "loss": 0.0916,
      "step": 31900
    },
    {
      "epoch": 7.4123112659698025,
      "grad_norm": 0.6618332862854004,
      "learning_rate": 1.2950058072009291e-05,
      "loss": 0.1197,
      "step": 31910
    },
    {
      "epoch": 7.414634146341464,
      "grad_norm": 1.089705467224121,
      "learning_rate": 1.2938443670150988e-05,
      "loss": 0.1036,
      "step": 31920
    },
    {
      "epoch": 7.416957026713124,
      "grad_norm": 1.169280767440796,
      "learning_rate": 1.2926829268292684e-05,
      "loss": 0.0608,
      "step": 31930
    },
    {
      "epoch": 7.4192799070847855,
      "grad_norm": 1.221264123916626,
      "learning_rate": 1.291521486643438e-05,
      "loss": 0.0725,
      "step": 31940
    },
    {
      "epoch": 7.421602787456446,
      "grad_norm": 1.1434128284454346,
      "learning_rate": 1.2903600464576073e-05,
      "loss": 0.0683,
      "step": 31950
    },
    {
      "epoch": 7.423925667828107,
      "grad_norm": 1.0037078857421875,
      "learning_rate": 1.289198606271777e-05,
      "loss": 0.0839,
      "step": 31960
    },
    {
      "epoch": 7.4262485481997675,
      "grad_norm": 1.1586812734603882,
      "learning_rate": 1.2880371660859466e-05,
      "loss": 0.1638,
      "step": 31970
    },
    {
      "epoch": 7.428571428571429,
      "grad_norm": 0.34469887614250183,
      "learning_rate": 1.2868757259001163e-05,
      "loss": 0.0489,
      "step": 31980
    },
    {
      "epoch": 7.430894308943089,
      "grad_norm": 1.0673030614852905,
      "learning_rate": 1.2857142857142857e-05,
      "loss": 0.0674,
      "step": 31990
    },
    {
      "epoch": 7.4332171893147505,
      "grad_norm": 0.47408443689346313,
      "learning_rate": 1.2845528455284554e-05,
      "loss": 0.066,
      "step": 32000
    },
    {
      "epoch": 7.435540069686411,
      "grad_norm": 0.8472319841384888,
      "learning_rate": 1.283391405342625e-05,
      "loss": 0.1662,
      "step": 32010
    },
    {
      "epoch": 7.437862950058072,
      "grad_norm": 0.7334656715393066,
      "learning_rate": 1.2822299651567946e-05,
      "loss": 0.1043,
      "step": 32020
    },
    {
      "epoch": 7.440185830429733,
      "grad_norm": 1.3313528299331665,
      "learning_rate": 1.2810685249709643e-05,
      "loss": 0.1101,
      "step": 32030
    },
    {
      "epoch": 7.442508710801394,
      "grad_norm": 0.7366640567779541,
      "learning_rate": 1.2799070847851336e-05,
      "loss": 0.0749,
      "step": 32040
    },
    {
      "epoch": 7.444831591173054,
      "grad_norm": 0.4060930609703064,
      "learning_rate": 1.2787456445993032e-05,
      "loss": 0.062,
      "step": 32050
    },
    {
      "epoch": 7.4471544715447155,
      "grad_norm": 0.7435984015464783,
      "learning_rate": 1.2775842044134728e-05,
      "loss": 0.1278,
      "step": 32060
    },
    {
      "epoch": 7.449477351916376,
      "grad_norm": 1.098745346069336,
      "learning_rate": 1.2764227642276425e-05,
      "loss": 0.1089,
      "step": 32070
    },
    {
      "epoch": 7.451800232288037,
      "grad_norm": 0.4801282584667206,
      "learning_rate": 1.2752613240418118e-05,
      "loss": 0.114,
      "step": 32080
    },
    {
      "epoch": 7.454123112659698,
      "grad_norm": 0.7458446025848389,
      "learning_rate": 1.2740998838559814e-05,
      "loss": 0.1368,
      "step": 32090
    },
    {
      "epoch": 7.456445993031359,
      "grad_norm": 1.9666078090667725,
      "learning_rate": 1.272938443670151e-05,
      "loss": 0.1213,
      "step": 32100
    },
    {
      "epoch": 7.45876887340302,
      "grad_norm": 0.7414019107818604,
      "learning_rate": 1.2717770034843207e-05,
      "loss": 0.1137,
      "step": 32110
    },
    {
      "epoch": 7.461091753774681,
      "grad_norm": 0.7814260721206665,
      "learning_rate": 1.2706155632984902e-05,
      "loss": 0.0998,
      "step": 32120
    },
    {
      "epoch": 7.463414634146342,
      "grad_norm": 1.6093213558197021,
      "learning_rate": 1.2694541231126598e-05,
      "loss": 0.0763,
      "step": 32130
    },
    {
      "epoch": 7.465737514518002,
      "grad_norm": 0.5344580411911011,
      "learning_rate": 1.2682926829268294e-05,
      "loss": 0.0918,
      "step": 32140
    },
    {
      "epoch": 7.4680603948896636,
      "grad_norm": 2.222352981567383,
      "learning_rate": 1.267131242740999e-05,
      "loss": 0.1439,
      "step": 32150
    },
    {
      "epoch": 7.470383275261324,
      "grad_norm": 0.7775672674179077,
      "learning_rate": 1.2659698025551684e-05,
      "loss": 0.0933,
      "step": 32160
    },
    {
      "epoch": 7.472706155632985,
      "grad_norm": 1.310132622718811,
      "learning_rate": 1.264808362369338e-05,
      "loss": 0.0607,
      "step": 32170
    },
    {
      "epoch": 7.475029036004646,
      "grad_norm": 1.531591773033142,
      "learning_rate": 1.2636469221835076e-05,
      "loss": 0.0928,
      "step": 32180
    },
    {
      "epoch": 7.477351916376307,
      "grad_norm": 0.44007328152656555,
      "learning_rate": 1.2624854819976773e-05,
      "loss": 0.1148,
      "step": 32190
    },
    {
      "epoch": 7.479674796747967,
      "grad_norm": 0.4930141270160675,
      "learning_rate": 1.2613240418118469e-05,
      "loss": 0.1255,
      "step": 32200
    },
    {
      "epoch": 7.481997677119629,
      "grad_norm": 0.732580304145813,
      "learning_rate": 1.2601626016260162e-05,
      "loss": 0.0924,
      "step": 32210
    },
    {
      "epoch": 7.484320557491289,
      "grad_norm": 0.5337758660316467,
      "learning_rate": 1.2590011614401858e-05,
      "loss": 0.0801,
      "step": 32220
    },
    {
      "epoch": 7.48664343786295,
      "grad_norm": 2.1229817867279053,
      "learning_rate": 1.2578397212543555e-05,
      "loss": 0.056,
      "step": 32230
    },
    {
      "epoch": 7.488966318234611,
      "grad_norm": 1.036670446395874,
      "learning_rate": 1.2566782810685251e-05,
      "loss": 0.0824,
      "step": 32240
    },
    {
      "epoch": 7.491289198606272,
      "grad_norm": 0.9767666459083557,
      "learning_rate": 1.2555168408826946e-05,
      "loss": 0.0825,
      "step": 32250
    },
    {
      "epoch": 7.493612078977932,
      "grad_norm": 0.9940322637557983,
      "learning_rate": 1.2543554006968642e-05,
      "loss": 0.0603,
      "step": 32260
    },
    {
      "epoch": 7.495934959349594,
      "grad_norm": 1.7008146047592163,
      "learning_rate": 1.2531939605110339e-05,
      "loss": 0.1139,
      "step": 32270
    },
    {
      "epoch": 7.498257839721254,
      "grad_norm": 1.2192153930664062,
      "learning_rate": 1.2520325203252033e-05,
      "loss": 0.0687,
      "step": 32280
    },
    {
      "epoch": 7.500580720092915,
      "grad_norm": 1.431543231010437,
      "learning_rate": 1.2508710801393728e-05,
      "loss": 0.0953,
      "step": 32290
    },
    {
      "epoch": 7.502903600464576,
      "grad_norm": 0.67209792137146,
      "learning_rate": 1.2497096399535424e-05,
      "loss": 0.1782,
      "step": 32300
    },
    {
      "epoch": 7.505226480836237,
      "grad_norm": 0.9015307426452637,
      "learning_rate": 1.248548199767712e-05,
      "loss": 0.0774,
      "step": 32310
    },
    {
      "epoch": 7.507549361207898,
      "grad_norm": 1.2050193548202515,
      "learning_rate": 1.2473867595818815e-05,
      "loss": 0.0755,
      "step": 32320
    },
    {
      "epoch": 7.509872241579559,
      "grad_norm": 0.5301044583320618,
      "learning_rate": 1.2462253193960512e-05,
      "loss": 0.074,
      "step": 32330
    },
    {
      "epoch": 7.512195121951219,
      "grad_norm": 1.1985243558883667,
      "learning_rate": 1.2450638792102208e-05,
      "loss": 0.1649,
      "step": 32340
    },
    {
      "epoch": 7.51451800232288,
      "grad_norm": 0.915808379650116,
      "learning_rate": 1.2439024390243903e-05,
      "loss": 0.0869,
      "step": 32350
    },
    {
      "epoch": 7.516840882694542,
      "grad_norm": 1.036227822303772,
      "learning_rate": 1.2427409988385599e-05,
      "loss": 0.0871,
      "step": 32360
    },
    {
      "epoch": 7.519163763066202,
      "grad_norm": 1.5667009353637695,
      "learning_rate": 1.2415795586527294e-05,
      "loss": 0.0938,
      "step": 32370
    },
    {
      "epoch": 7.521486643437863,
      "grad_norm": 0.46375808119773865,
      "learning_rate": 1.240418118466899e-05,
      "loss": 0.0732,
      "step": 32380
    },
    {
      "epoch": 7.523809523809524,
      "grad_norm": 2.115889310836792,
      "learning_rate": 1.2392566782810685e-05,
      "loss": 0.0934,
      "step": 32390
    },
    {
      "epoch": 7.526132404181185,
      "grad_norm": 0.5873473882675171,
      "learning_rate": 1.2380952380952381e-05,
      "loss": 0.0843,
      "step": 32400
    },
    {
      "epoch": 7.528455284552845,
      "grad_norm": 1.0533126592636108,
      "learning_rate": 1.2369337979094078e-05,
      "loss": 0.0686,
      "step": 32410
    },
    {
      "epoch": 7.530778164924507,
      "grad_norm": 1.3312445878982544,
      "learning_rate": 1.2357723577235774e-05,
      "loss": 0.1228,
      "step": 32420
    },
    {
      "epoch": 7.533101045296167,
      "grad_norm": 0.7360378503799438,
      "learning_rate": 1.2346109175377469e-05,
      "loss": 0.1148,
      "step": 32430
    },
    {
      "epoch": 7.535423925667828,
      "grad_norm": 0.7411292195320129,
      "learning_rate": 1.2334494773519165e-05,
      "loss": 0.1198,
      "step": 32440
    },
    {
      "epoch": 7.537746806039489,
      "grad_norm": 1.4860283136367798,
      "learning_rate": 1.232288037166086e-05,
      "loss": 0.0762,
      "step": 32450
    },
    {
      "epoch": 7.54006968641115,
      "grad_norm": 1.452465295791626,
      "learning_rate": 1.2311265969802556e-05,
      "loss": 0.062,
      "step": 32460
    },
    {
      "epoch": 7.5423925667828104,
      "grad_norm": 0.5364589095115662,
      "learning_rate": 1.229965156794425e-05,
      "loss": 0.0421,
      "step": 32470
    },
    {
      "epoch": 7.544715447154472,
      "grad_norm": 3.083509683609009,
      "learning_rate": 1.2288037166085947e-05,
      "loss": 0.1167,
      "step": 32480
    },
    {
      "epoch": 7.547038327526132,
      "grad_norm": 0.43363648653030396,
      "learning_rate": 1.2276422764227642e-05,
      "loss": 0.0654,
      "step": 32490
    },
    {
      "epoch": 7.549361207897793,
      "grad_norm": 1.181373953819275,
      "learning_rate": 1.2264808362369338e-05,
      "loss": 0.0902,
      "step": 32500
    },
    {
      "epoch": 7.551684088269454,
      "grad_norm": 1.624956488609314,
      "learning_rate": 1.2253193960511034e-05,
      "loss": 0.0844,
      "step": 32510
    },
    {
      "epoch": 7.554006968641115,
      "grad_norm": 1.3983403444290161,
      "learning_rate": 1.2241579558652729e-05,
      "loss": 0.1021,
      "step": 32520
    },
    {
      "epoch": 7.5563298490127755,
      "grad_norm": 0.6886258721351624,
      "learning_rate": 1.2229965156794425e-05,
      "loss": 0.0732,
      "step": 32530
    },
    {
      "epoch": 7.558652729384437,
      "grad_norm": 1.7846035957336426,
      "learning_rate": 1.2218350754936122e-05,
      "loss": 0.0706,
      "step": 32540
    },
    {
      "epoch": 7.560975609756097,
      "grad_norm": 2.517185688018799,
      "learning_rate": 1.2206736353077818e-05,
      "loss": 0.1208,
      "step": 32550
    },
    {
      "epoch": 7.5632984901277585,
      "grad_norm": 0.600266695022583,
      "learning_rate": 1.2195121951219513e-05,
      "loss": 0.0768,
      "step": 32560
    },
    {
      "epoch": 7.56562137049942,
      "grad_norm": 1.5194810628890991,
      "learning_rate": 1.218350754936121e-05,
      "loss": 0.0778,
      "step": 32570
    },
    {
      "epoch": 7.56794425087108,
      "grad_norm": 1.599268913269043,
      "learning_rate": 1.2171893147502904e-05,
      "loss": 0.1149,
      "step": 32580
    },
    {
      "epoch": 7.5702671312427405,
      "grad_norm": 0.9086008071899414,
      "learning_rate": 1.21602787456446e-05,
      "loss": 0.0626,
      "step": 32590
    },
    {
      "epoch": 7.572590011614402,
      "grad_norm": 1.207763671875,
      "learning_rate": 1.2148664343786295e-05,
      "loss": 0.1267,
      "step": 32600
    },
    {
      "epoch": 7.574912891986063,
      "grad_norm": 1.560498595237732,
      "learning_rate": 1.2137049941927991e-05,
      "loss": 0.1066,
      "step": 32610
    },
    {
      "epoch": 7.5772357723577235,
      "grad_norm": 0.593425989151001,
      "learning_rate": 1.2125435540069686e-05,
      "loss": 0.0615,
      "step": 32620
    },
    {
      "epoch": 7.579558652729385,
      "grad_norm": 1.5814377069473267,
      "learning_rate": 1.2113821138211382e-05,
      "loss": 0.0765,
      "step": 32630
    },
    {
      "epoch": 7.581881533101045,
      "grad_norm": 1.136030912399292,
      "learning_rate": 1.2102206736353077e-05,
      "loss": 0.1432,
      "step": 32640
    },
    {
      "epoch": 7.5842044134727065,
      "grad_norm": 1.248552680015564,
      "learning_rate": 1.2090592334494773e-05,
      "loss": 0.0921,
      "step": 32650
    },
    {
      "epoch": 7.586527293844367,
      "grad_norm": 0.6115347146987915,
      "learning_rate": 1.207897793263647e-05,
      "loss": 0.1449,
      "step": 32660
    },
    {
      "epoch": 7.588850174216028,
      "grad_norm": 0.9520465731620789,
      "learning_rate": 1.2067363530778166e-05,
      "loss": 0.0733,
      "step": 32670
    },
    {
      "epoch": 7.5911730545876885,
      "grad_norm": 1.4893617630004883,
      "learning_rate": 1.2055749128919862e-05,
      "loss": 0.0598,
      "step": 32680
    },
    {
      "epoch": 7.59349593495935,
      "grad_norm": 0.7205705046653748,
      "learning_rate": 1.2044134727061557e-05,
      "loss": 0.1232,
      "step": 32690
    },
    {
      "epoch": 7.59581881533101,
      "grad_norm": 1.2976396083831787,
      "learning_rate": 1.2032520325203254e-05,
      "loss": 0.0818,
      "step": 32700
    },
    {
      "epoch": 7.5981416957026715,
      "grad_norm": 0.6406897306442261,
      "learning_rate": 1.2020905923344948e-05,
      "loss": 0.0739,
      "step": 32710
    },
    {
      "epoch": 7.600464576074332,
      "grad_norm": 1.76459801197052,
      "learning_rate": 1.2009291521486645e-05,
      "loss": 0.0572,
      "step": 32720
    },
    {
      "epoch": 7.602787456445993,
      "grad_norm": 0.6771091222763062,
      "learning_rate": 1.199767711962834e-05,
      "loss": 0.0958,
      "step": 32730
    },
    {
      "epoch": 7.605110336817654,
      "grad_norm": 0.5512902140617371,
      "learning_rate": 1.1986062717770036e-05,
      "loss": 0.1856,
      "step": 32740
    },
    {
      "epoch": 7.607433217189315,
      "grad_norm": 1.2013578414916992,
      "learning_rate": 1.197444831591173e-05,
      "loss": 0.1345,
      "step": 32750
    },
    {
      "epoch": 7.609756097560975,
      "grad_norm": 1.9061336517333984,
      "learning_rate": 1.1962833914053427e-05,
      "loss": 0.0868,
      "step": 32760
    },
    {
      "epoch": 7.6120789779326365,
      "grad_norm": 0.9058836698532104,
      "learning_rate": 1.1951219512195121e-05,
      "loss": 0.0858,
      "step": 32770
    },
    {
      "epoch": 7.614401858304297,
      "grad_norm": 1.6307923793792725,
      "learning_rate": 1.1939605110336818e-05,
      "loss": 0.099,
      "step": 32780
    },
    {
      "epoch": 7.616724738675958,
      "grad_norm": 1.2447288036346436,
      "learning_rate": 1.1927990708478514e-05,
      "loss": 0.0724,
      "step": 32790
    },
    {
      "epoch": 7.619047619047619,
      "grad_norm": 0.46646785736083984,
      "learning_rate": 1.191637630662021e-05,
      "loss": 0.0837,
      "step": 32800
    },
    {
      "epoch": 7.62137049941928,
      "grad_norm": 0.683530330657959,
      "learning_rate": 1.1904761904761905e-05,
      "loss": 0.0581,
      "step": 32810
    },
    {
      "epoch": 7.623693379790941,
      "grad_norm": 0.5073151588439941,
      "learning_rate": 1.1893147502903601e-05,
      "loss": 0.1355,
      "step": 32820
    },
    {
      "epoch": 7.626016260162602,
      "grad_norm": 1.646658182144165,
      "learning_rate": 1.1881533101045298e-05,
      "loss": 0.0825,
      "step": 32830
    },
    {
      "epoch": 7.628339140534262,
      "grad_norm": 0.8340690732002258,
      "learning_rate": 1.1869918699186992e-05,
      "loss": 0.0742,
      "step": 32840
    },
    {
      "epoch": 7.630662020905923,
      "grad_norm": 1.1398916244506836,
      "learning_rate": 1.1858304297328689e-05,
      "loss": 0.0904,
      "step": 32850
    },
    {
      "epoch": 7.6329849012775846,
      "grad_norm": 0.9481476545333862,
      "learning_rate": 1.1846689895470384e-05,
      "loss": 0.1266,
      "step": 32860
    },
    {
      "epoch": 7.635307781649245,
      "grad_norm": 0.928726851940155,
      "learning_rate": 1.183507549361208e-05,
      "loss": 0.0434,
      "step": 32870
    },
    {
      "epoch": 7.637630662020906,
      "grad_norm": 0.9372141361236572,
      "learning_rate": 1.1823461091753775e-05,
      "loss": 0.0593,
      "step": 32880
    },
    {
      "epoch": 7.639953542392567,
      "grad_norm": 0.9988816976547241,
      "learning_rate": 1.1811846689895471e-05,
      "loss": 0.0975,
      "step": 32890
    },
    {
      "epoch": 7.642276422764228,
      "grad_norm": 0.9453629851341248,
      "learning_rate": 1.1800232288037166e-05,
      "loss": 0.0584,
      "step": 32900
    },
    {
      "epoch": 7.644599303135888,
      "grad_norm": 0.6643006801605225,
      "learning_rate": 1.1788617886178862e-05,
      "loss": 0.0685,
      "step": 32910
    },
    {
      "epoch": 7.64692218350755,
      "grad_norm": 1.4734116792678833,
      "learning_rate": 1.1777003484320558e-05,
      "loss": 0.0803,
      "step": 32920
    },
    {
      "epoch": 7.64924506387921,
      "grad_norm": 0.7132713794708252,
      "learning_rate": 1.1765389082462255e-05,
      "loss": 0.0895,
      "step": 32930
    },
    {
      "epoch": 7.651567944250871,
      "grad_norm": 1.0351245403289795,
      "learning_rate": 1.175377468060395e-05,
      "loss": 0.0596,
      "step": 32940
    },
    {
      "epoch": 7.653890824622532,
      "grad_norm": 0.5597333908081055,
      "learning_rate": 1.1742160278745646e-05,
      "loss": 0.159,
      "step": 32950
    },
    {
      "epoch": 7.656213704994193,
      "grad_norm": 0.6526288390159607,
      "learning_rate": 1.173054587688734e-05,
      "loss": 0.0729,
      "step": 32960
    },
    {
      "epoch": 7.658536585365853,
      "grad_norm": 0.6429320573806763,
      "learning_rate": 1.1718931475029037e-05,
      "loss": 0.1603,
      "step": 32970
    },
    {
      "epoch": 7.660859465737515,
      "grad_norm": 1.1209900379180908,
      "learning_rate": 1.1707317073170733e-05,
      "loss": 0.0474,
      "step": 32980
    },
    {
      "epoch": 7.663182346109175,
      "grad_norm": 0.4075876772403717,
      "learning_rate": 1.1695702671312428e-05,
      "loss": 0.0884,
      "step": 32990
    },
    {
      "epoch": 7.665505226480836,
      "grad_norm": 0.6409286260604858,
      "learning_rate": 1.1684088269454124e-05,
      "loss": 0.0621,
      "step": 33000
    },
    {
      "epoch": 7.667828106852497,
      "grad_norm": 2.0412416458129883,
      "learning_rate": 1.1672473867595819e-05,
      "loss": 0.1208,
      "step": 33010
    },
    {
      "epoch": 7.670150987224158,
      "grad_norm": 1.6332828998565674,
      "learning_rate": 1.1660859465737515e-05,
      "loss": 0.11,
      "step": 33020
    },
    {
      "epoch": 7.672473867595819,
      "grad_norm": 1.5177369117736816,
      "learning_rate": 1.164924506387921e-05,
      "loss": 0.1278,
      "step": 33030
    },
    {
      "epoch": 7.67479674796748,
      "grad_norm": 1.0925794839859009,
      "learning_rate": 1.1637630662020906e-05,
      "loss": 0.0963,
      "step": 33040
    },
    {
      "epoch": 7.67711962833914,
      "grad_norm": 0.5379491448402405,
      "learning_rate": 1.1626016260162603e-05,
      "loss": 0.0919,
      "step": 33050
    },
    {
      "epoch": 7.679442508710801,
      "grad_norm": 1.318259358406067,
      "learning_rate": 1.1614401858304299e-05,
      "loss": 0.1381,
      "step": 33060
    },
    {
      "epoch": 7.681765389082463,
      "grad_norm": 1.8400980234146118,
      "learning_rate": 1.1602787456445994e-05,
      "loss": 0.0998,
      "step": 33070
    },
    {
      "epoch": 7.684088269454123,
      "grad_norm": 1.155536413192749,
      "learning_rate": 1.159117305458769e-05,
      "loss": 0.0969,
      "step": 33080
    },
    {
      "epoch": 7.686411149825784,
      "grad_norm": 0.8967574238777161,
      "learning_rate": 1.1579558652729385e-05,
      "loss": 0.1448,
      "step": 33090
    },
    {
      "epoch": 7.688734030197445,
      "grad_norm": 0.6803807020187378,
      "learning_rate": 1.1567944250871081e-05,
      "loss": 0.0904,
      "step": 33100
    },
    {
      "epoch": 7.691056910569106,
      "grad_norm": 0.5646417140960693,
      "learning_rate": 1.1556329849012776e-05,
      "loss": 0.0516,
      "step": 33110
    },
    {
      "epoch": 7.693379790940766,
      "grad_norm": 1.9351887702941895,
      "learning_rate": 1.1544715447154472e-05,
      "loss": 0.1211,
      "step": 33120
    },
    {
      "epoch": 7.695702671312428,
      "grad_norm": 0.7496004700660706,
      "learning_rate": 1.1533101045296167e-05,
      "loss": 0.1164,
      "step": 33130
    },
    {
      "epoch": 7.698025551684088,
      "grad_norm": 1.2192726135253906,
      "learning_rate": 1.1521486643437863e-05,
      "loss": 0.055,
      "step": 33140
    },
    {
      "epoch": 7.700348432055749,
      "grad_norm": 0.7312366962432861,
      "learning_rate": 1.150987224157956e-05,
      "loss": 0.0748,
      "step": 33150
    },
    {
      "epoch": 7.70267131242741,
      "grad_norm": 1.389936089515686,
      "learning_rate": 1.1499419279907085e-05,
      "loss": 0.0791,
      "step": 33160
    },
    {
      "epoch": 7.704994192799071,
      "grad_norm": 1.3540126085281372,
      "learning_rate": 1.1487804878048781e-05,
      "loss": 0.0793,
      "step": 33170
    },
    {
      "epoch": 7.7073170731707314,
      "grad_norm": 0.6359928846359253,
      "learning_rate": 1.1476190476190476e-05,
      "loss": 0.0514,
      "step": 33180
    },
    {
      "epoch": 7.709639953542393,
      "grad_norm": 0.8760623931884766,
      "learning_rate": 1.1464576074332172e-05,
      "loss": 0.061,
      "step": 33190
    },
    {
      "epoch": 7.711962833914053,
      "grad_norm": 1.3915046453475952,
      "learning_rate": 1.1452961672473869e-05,
      "loss": 0.0881,
      "step": 33200
    },
    {
      "epoch": 7.714285714285714,
      "grad_norm": 1.1131112575531006,
      "learning_rate": 1.1441347270615565e-05,
      "loss": 0.083,
      "step": 33210
    },
    {
      "epoch": 7.716608594657375,
      "grad_norm": 1.0419530868530273,
      "learning_rate": 1.142973286875726e-05,
      "loss": 0.0648,
      "step": 33220
    },
    {
      "epoch": 7.718931475029036,
      "grad_norm": 0.7192408442497253,
      "learning_rate": 1.1418118466898956e-05,
      "loss": 0.0568,
      "step": 33230
    },
    {
      "epoch": 7.7212543554006965,
      "grad_norm": 1.8442223072052002,
      "learning_rate": 1.140650406504065e-05,
      "loss": 0.0765,
      "step": 33240
    },
    {
      "epoch": 7.723577235772358,
      "grad_norm": 0.5751249194145203,
      "learning_rate": 1.1394889663182347e-05,
      "loss": 0.1091,
      "step": 33250
    },
    {
      "epoch": 7.725900116144018,
      "grad_norm": 0.38548654317855835,
      "learning_rate": 1.1383275261324042e-05,
      "loss": 0.0439,
      "step": 33260
    },
    {
      "epoch": 7.7282229965156795,
      "grad_norm": 0.4540730118751526,
      "learning_rate": 1.1371660859465738e-05,
      "loss": 0.0853,
      "step": 33270
    },
    {
      "epoch": 7.730545876887341,
      "grad_norm": 0.5877076387405396,
      "learning_rate": 1.1360046457607433e-05,
      "loss": 0.0925,
      "step": 33280
    },
    {
      "epoch": 7.732868757259001,
      "grad_norm": 0.7761415839195251,
      "learning_rate": 1.1348432055749129e-05,
      "loss": 0.1254,
      "step": 33290
    },
    {
      "epoch": 7.7351916376306615,
      "grad_norm": 1.3044618368148804,
      "learning_rate": 1.1336817653890825e-05,
      "loss": 0.0738,
      "step": 33300
    },
    {
      "epoch": 7.737514518002323,
      "grad_norm": 0.9580381512641907,
      "learning_rate": 1.132520325203252e-05,
      "loss": 0.0468,
      "step": 33310
    },
    {
      "epoch": 7.739837398373984,
      "grad_norm": 0.4046688973903656,
      "learning_rate": 1.1313588850174216e-05,
      "loss": 0.0705,
      "step": 33320
    },
    {
      "epoch": 7.7421602787456445,
      "grad_norm": 0.49610525369644165,
      "learning_rate": 1.1301974448315913e-05,
      "loss": 0.1324,
      "step": 33330
    },
    {
      "epoch": 7.744483159117306,
      "grad_norm": 0.49222540855407715,
      "learning_rate": 1.129036004645761e-05,
      "loss": 0.1026,
      "step": 33340
    },
    {
      "epoch": 7.746806039488966,
      "grad_norm": 0.7080544233322144,
      "learning_rate": 1.1278745644599304e-05,
      "loss": 0.0857,
      "step": 33350
    },
    {
      "epoch": 7.7491289198606275,
      "grad_norm": 1.39857017993927,
      "learning_rate": 1.1267131242741e-05,
      "loss": 0.0873,
      "step": 33360
    },
    {
      "epoch": 7.751451800232288,
      "grad_norm": 2.6024911403656006,
      "learning_rate": 1.1255516840882695e-05,
      "loss": 0.144,
      "step": 33370
    },
    {
      "epoch": 7.753774680603949,
      "grad_norm": 1.0357110500335693,
      "learning_rate": 1.1243902439024391e-05,
      "loss": 0.0752,
      "step": 33380
    },
    {
      "epoch": 7.7560975609756095,
      "grad_norm": 0.6996185779571533,
      "learning_rate": 1.1232288037166086e-05,
      "loss": 0.1534,
      "step": 33390
    },
    {
      "epoch": 7.758420441347271,
      "grad_norm": 0.6735306978225708,
      "learning_rate": 1.1220673635307782e-05,
      "loss": 0.0682,
      "step": 33400
    },
    {
      "epoch": 7.760743321718931,
      "grad_norm": 2.0700907707214355,
      "learning_rate": 1.1209059233449477e-05,
      "loss": 0.1895,
      "step": 33410
    },
    {
      "epoch": 7.7630662020905925,
      "grad_norm": 0.960152804851532,
      "learning_rate": 1.1197444831591173e-05,
      "loss": 0.0465,
      "step": 33420
    },
    {
      "epoch": 7.765389082462253,
      "grad_norm": 1.0755136013031006,
      "learning_rate": 1.1185830429732868e-05,
      "loss": 0.1433,
      "step": 33430
    },
    {
      "epoch": 7.767711962833914,
      "grad_norm": 0.9998600482940674,
      "learning_rate": 1.1174216027874564e-05,
      "loss": 0.1103,
      "step": 33440
    },
    {
      "epoch": 7.770034843205575,
      "grad_norm": 1.8996278047561646,
      "learning_rate": 1.116260162601626e-05,
      "loss": 0.0867,
      "step": 33450
    },
    {
      "epoch": 7.772357723577236,
      "grad_norm": 1.992963194847107,
      "learning_rate": 1.1150987224157957e-05,
      "loss": 0.1041,
      "step": 33460
    },
    {
      "epoch": 7.774680603948896,
      "grad_norm": 1.0921716690063477,
      "learning_rate": 1.1139372822299653e-05,
      "loss": 0.0944,
      "step": 33470
    },
    {
      "epoch": 7.7770034843205575,
      "grad_norm": 0.8364015817642212,
      "learning_rate": 1.1127758420441348e-05,
      "loss": 0.1298,
      "step": 33480
    },
    {
      "epoch": 7.779326364692219,
      "grad_norm": 0.6310818195343018,
      "learning_rate": 1.1116144018583045e-05,
      "loss": 0.0643,
      "step": 33490
    },
    {
      "epoch": 7.781649245063879,
      "grad_norm": 1.9357267618179321,
      "learning_rate": 1.110452961672474e-05,
      "loss": 0.082,
      "step": 33500
    },
    {
      "epoch": 7.78397212543554,
      "grad_norm": 0.6446905732154846,
      "learning_rate": 1.1092915214866436e-05,
      "loss": 0.083,
      "step": 33510
    },
    {
      "epoch": 7.786295005807201,
      "grad_norm": 0.9465785026550293,
      "learning_rate": 1.108130081300813e-05,
      "loss": 0.0585,
      "step": 33520
    },
    {
      "epoch": 7.788617886178862,
      "grad_norm": 0.3713235855102539,
      "learning_rate": 1.1069686411149827e-05,
      "loss": 0.0878,
      "step": 33530
    },
    {
      "epoch": 7.790940766550523,
      "grad_norm": 0.8402149081230164,
      "learning_rate": 1.1058072009291521e-05,
      "loss": 0.0752,
      "step": 33540
    },
    {
      "epoch": 7.793263646922184,
      "grad_norm": 1.1637632846832275,
      "learning_rate": 1.1046457607433218e-05,
      "loss": 0.0927,
      "step": 33550
    },
    {
      "epoch": 7.795586527293844,
      "grad_norm": 2.107750415802002,
      "learning_rate": 1.1034843205574912e-05,
      "loss": 0.124,
      "step": 33560
    },
    {
      "epoch": 7.7979094076655056,
      "grad_norm": 0.5771145224571228,
      "learning_rate": 1.1023228803716609e-05,
      "loss": 0.1197,
      "step": 33570
    },
    {
      "epoch": 7.800232288037166,
      "grad_norm": 1.0024296045303345,
      "learning_rate": 1.1011614401858305e-05,
      "loss": 0.0899,
      "step": 33580
    },
    {
      "epoch": 7.802555168408827,
      "grad_norm": 0.7192823886871338,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.048,
      "step": 33590
    },
    {
      "epoch": 7.804878048780488,
      "grad_norm": 0.8938480019569397,
      "learning_rate": 1.0988385598141696e-05,
      "loss": 0.0848,
      "step": 33600
    },
    {
      "epoch": 7.807200929152149,
      "grad_norm": 0.41723960638046265,
      "learning_rate": 1.0976771196283392e-05,
      "loss": 0.0991,
      "step": 33610
    },
    {
      "epoch": 7.809523809523809,
      "grad_norm": 1.005425214767456,
      "learning_rate": 1.0965156794425089e-05,
      "loss": 0.1076,
      "step": 33620
    },
    {
      "epoch": 7.811846689895471,
      "grad_norm": 0.7854104042053223,
      "learning_rate": 1.0953542392566783e-05,
      "loss": 0.0599,
      "step": 33630
    },
    {
      "epoch": 7.814169570267131,
      "grad_norm": 0.5347076654434204,
      "learning_rate": 1.094192799070848e-05,
      "loss": 0.0597,
      "step": 33640
    },
    {
      "epoch": 7.816492450638792,
      "grad_norm": 2.3931620121002197,
      "learning_rate": 1.0930313588850175e-05,
      "loss": 0.0866,
      "step": 33650
    },
    {
      "epoch": 7.818815331010453,
      "grad_norm": 0.7489344477653503,
      "learning_rate": 1.0918699186991871e-05,
      "loss": 0.0459,
      "step": 33660
    },
    {
      "epoch": 7.821138211382114,
      "grad_norm": 1.4085031747817993,
      "learning_rate": 1.0907084785133566e-05,
      "loss": 0.1149,
      "step": 33670
    },
    {
      "epoch": 7.823461091753774,
      "grad_norm": 1.7908742427825928,
      "learning_rate": 1.0895470383275262e-05,
      "loss": 0.0586,
      "step": 33680
    },
    {
      "epoch": 7.825783972125436,
      "grad_norm": 1.0611807107925415,
      "learning_rate": 1.0883855981416957e-05,
      "loss": 0.0614,
      "step": 33690
    },
    {
      "epoch": 7.828106852497096,
      "grad_norm": 0.5074034929275513,
      "learning_rate": 1.0872241579558653e-05,
      "loss": 0.1279,
      "step": 33700
    },
    {
      "epoch": 7.830429732868757,
      "grad_norm": 0.7073265314102173,
      "learning_rate": 1.0860627177700348e-05,
      "loss": 0.0793,
      "step": 33710
    },
    {
      "epoch": 7.832752613240418,
      "grad_norm": 0.7272695302963257,
      "learning_rate": 1.0849012775842044e-05,
      "loss": 0.1077,
      "step": 33720
    },
    {
      "epoch": 7.835075493612079,
      "grad_norm": 1.495282769203186,
      "learning_rate": 1.083739837398374e-05,
      "loss": 0.1001,
      "step": 33730
    },
    {
      "epoch": 7.83739837398374,
      "grad_norm": 2.225712776184082,
      "learning_rate": 1.0825783972125437e-05,
      "loss": 0.0731,
      "step": 33740
    },
    {
      "epoch": 7.839721254355401,
      "grad_norm": 0.8106988668441772,
      "learning_rate": 1.0814169570267131e-05,
      "loss": 0.0785,
      "step": 33750
    },
    {
      "epoch": 7.842044134727061,
      "grad_norm": 0.896587610244751,
      "learning_rate": 1.0802555168408828e-05,
      "loss": 0.099,
      "step": 33760
    },
    {
      "epoch": 7.844367015098722,
      "grad_norm": 1.029646873474121,
      "learning_rate": 1.0790940766550524e-05,
      "loss": 0.0688,
      "step": 33770
    },
    {
      "epoch": 7.846689895470384,
      "grad_norm": 1.2611565589904785,
      "learning_rate": 1.0779326364692219e-05,
      "loss": 0.1036,
      "step": 33780
    },
    {
      "epoch": 7.849012775842044,
      "grad_norm": 0.6452378630638123,
      "learning_rate": 1.0767711962833915e-05,
      "loss": 0.1104,
      "step": 33790
    },
    {
      "epoch": 7.851335656213705,
      "grad_norm": 0.8889533877372742,
      "learning_rate": 1.075609756097561e-05,
      "loss": 0.1395,
      "step": 33800
    },
    {
      "epoch": 7.853658536585366,
      "grad_norm": 0.8542301654815674,
      "learning_rate": 1.0744483159117306e-05,
      "loss": 0.0879,
      "step": 33810
    },
    {
      "epoch": 7.855981416957027,
      "grad_norm": 1.1570831537246704,
      "learning_rate": 1.0732868757259001e-05,
      "loss": 0.1149,
      "step": 33820
    },
    {
      "epoch": 7.858304297328687,
      "grad_norm": 1.2479283809661865,
      "learning_rate": 1.0721254355400697e-05,
      "loss": 0.1038,
      "step": 33830
    },
    {
      "epoch": 7.860627177700349,
      "grad_norm": 0.8849998712539673,
      "learning_rate": 1.0709639953542392e-05,
      "loss": 0.1103,
      "step": 33840
    },
    {
      "epoch": 7.862950058072009,
      "grad_norm": 1.456836223602295,
      "learning_rate": 1.0698025551684088e-05,
      "loss": 0.0959,
      "step": 33850
    },
    {
      "epoch": 7.86527293844367,
      "grad_norm": 0.4445600211620331,
      "learning_rate": 1.0686411149825785e-05,
      "loss": 0.0903,
      "step": 33860
    },
    {
      "epoch": 7.867595818815331,
      "grad_norm": 0.6548351645469666,
      "learning_rate": 1.0674796747967481e-05,
      "loss": 0.0934,
      "step": 33870
    },
    {
      "epoch": 7.869918699186992,
      "grad_norm": 1.3360463380813599,
      "learning_rate": 1.0663182346109176e-05,
      "loss": 0.1138,
      "step": 33880
    },
    {
      "epoch": 7.8722415795586524,
      "grad_norm": 1.270598292350769,
      "learning_rate": 1.0651567944250872e-05,
      "loss": 0.0981,
      "step": 33890
    },
    {
      "epoch": 7.874564459930314,
      "grad_norm": 0.5079574584960938,
      "learning_rate": 1.0639953542392567e-05,
      "loss": 0.1793,
      "step": 33900
    },
    {
      "epoch": 7.876887340301974,
      "grad_norm": 0.7339562177658081,
      "learning_rate": 1.0628339140534263e-05,
      "loss": 0.0469,
      "step": 33910
    },
    {
      "epoch": 7.879210220673635,
      "grad_norm": 2.111117124557495,
      "learning_rate": 1.0616724738675958e-05,
      "loss": 0.1748,
      "step": 33920
    },
    {
      "epoch": 7.881533101045296,
      "grad_norm": 0.6964555382728577,
      "learning_rate": 1.0605110336817654e-05,
      "loss": 0.0634,
      "step": 33930
    },
    {
      "epoch": 7.883855981416957,
      "grad_norm": 1.0888750553131104,
      "learning_rate": 1.059349593495935e-05,
      "loss": 0.0842,
      "step": 33940
    },
    {
      "epoch": 7.886178861788618,
      "grad_norm": 0.91214919090271,
      "learning_rate": 1.0581881533101045e-05,
      "loss": 0.0603,
      "step": 33950
    },
    {
      "epoch": 7.888501742160279,
      "grad_norm": 0.4945651888847351,
      "learning_rate": 1.0570267131242742e-05,
      "loss": 0.0412,
      "step": 33960
    },
    {
      "epoch": 7.890824622531939,
      "grad_norm": 0.6451038718223572,
      "learning_rate": 1.0558652729384436e-05,
      "loss": 0.0905,
      "step": 33970
    },
    {
      "epoch": 7.8931475029036005,
      "grad_norm": 1.1029337644577026,
      "learning_rate": 1.0547038327526133e-05,
      "loss": 0.0798,
      "step": 33980
    },
    {
      "epoch": 7.895470383275262,
      "grad_norm": 1.1262943744659424,
      "learning_rate": 1.0535423925667829e-05,
      "loss": 0.0931,
      "step": 33990
    },
    {
      "epoch": 7.897793263646922,
      "grad_norm": 0.7925201058387756,
      "learning_rate": 1.0523809523809525e-05,
      "loss": 0.138,
      "step": 34000
    },
    {
      "epoch": 7.900116144018583,
      "grad_norm": 0.9060694575309753,
      "learning_rate": 1.051219512195122e-05,
      "loss": 0.1047,
      "step": 34010
    },
    {
      "epoch": 7.902439024390244,
      "grad_norm": 1.1817893981933594,
      "learning_rate": 1.0500580720092916e-05,
      "loss": 0.0597,
      "step": 34020
    },
    {
      "epoch": 7.904761904761905,
      "grad_norm": 0.6479343175888062,
      "learning_rate": 1.0488966318234611e-05,
      "loss": 0.0633,
      "step": 34030
    },
    {
      "epoch": 7.9070847851335655,
      "grad_norm": 0.7803111672401428,
      "learning_rate": 1.0477351916376307e-05,
      "loss": 0.0488,
      "step": 34040
    },
    {
      "epoch": 7.909407665505227,
      "grad_norm": 0.8005140423774719,
      "learning_rate": 1.0465737514518002e-05,
      "loss": 0.1271,
      "step": 34050
    },
    {
      "epoch": 7.911730545876887,
      "grad_norm": 0.850200891494751,
      "learning_rate": 1.0454123112659698e-05,
      "loss": 0.0541,
      "step": 34060
    },
    {
      "epoch": 7.9140534262485485,
      "grad_norm": 0.6842530369758606,
      "learning_rate": 1.0442508710801393e-05,
      "loss": 0.1148,
      "step": 34070
    },
    {
      "epoch": 7.916376306620209,
      "grad_norm": 0.9738394021987915,
      "learning_rate": 1.043089430894309e-05,
      "loss": 0.1025,
      "step": 34080
    },
    {
      "epoch": 7.91869918699187,
      "grad_norm": 0.8003536462783813,
      "learning_rate": 1.0419279907084786e-05,
      "loss": 0.1111,
      "step": 34090
    },
    {
      "epoch": 7.9210220673635305,
      "grad_norm": 0.7524575591087341,
      "learning_rate": 1.040766550522648e-05,
      "loss": 0.0882,
      "step": 34100
    },
    {
      "epoch": 7.923344947735192,
      "grad_norm": 1.1859197616577148,
      "learning_rate": 1.0396051103368177e-05,
      "loss": 0.0775,
      "step": 34110
    },
    {
      "epoch": 7.925667828106852,
      "grad_norm": 0.8948341012001038,
      "learning_rate": 1.0384436701509873e-05,
      "loss": 0.0976,
      "step": 34120
    },
    {
      "epoch": 7.9279907084785135,
      "grad_norm": 0.9287025928497314,
      "learning_rate": 1.037282229965157e-05,
      "loss": 0.1339,
      "step": 34130
    },
    {
      "epoch": 7.930313588850174,
      "grad_norm": 0.6801466345787048,
      "learning_rate": 1.0361207897793264e-05,
      "loss": 0.0819,
      "step": 34140
    },
    {
      "epoch": 7.932636469221835,
      "grad_norm": 0.987058699131012,
      "learning_rate": 1.034959349593496e-05,
      "loss": 0.0631,
      "step": 34150
    },
    {
      "epoch": 7.934959349593496,
      "grad_norm": 0.4440617561340332,
      "learning_rate": 1.0337979094076655e-05,
      "loss": 0.1766,
      "step": 34160
    },
    {
      "epoch": 7.937282229965157,
      "grad_norm": 0.2722034454345703,
      "learning_rate": 1.0326364692218352e-05,
      "loss": 0.0774,
      "step": 34170
    },
    {
      "epoch": 7.939605110336817,
      "grad_norm": 1.1237752437591553,
      "learning_rate": 1.0314750290360046e-05,
      "loss": 0.0765,
      "step": 34180
    },
    {
      "epoch": 7.9419279907084785,
      "grad_norm": 1.3153644800186157,
      "learning_rate": 1.0303135888501743e-05,
      "loss": 0.086,
      "step": 34190
    },
    {
      "epoch": 7.94425087108014,
      "grad_norm": 0.9410622119903564,
      "learning_rate": 1.0291521486643437e-05,
      "loss": 0.0723,
      "step": 34200
    },
    {
      "epoch": 7.9465737514518,
      "grad_norm": 0.7834191918373108,
      "learning_rate": 1.0279907084785134e-05,
      "loss": 0.0786,
      "step": 34210
    },
    {
      "epoch": 7.948896631823461,
      "grad_norm": 0.943946361541748,
      "learning_rate": 1.0268292682926828e-05,
      "loss": 0.0557,
      "step": 34220
    },
    {
      "epoch": 7.951219512195122,
      "grad_norm": 2.237197160720825,
      "learning_rate": 1.0256678281068525e-05,
      "loss": 0.0773,
      "step": 34230
    },
    {
      "epoch": 7.953542392566783,
      "grad_norm": 1.0908355712890625,
      "learning_rate": 1.0245063879210221e-05,
      "loss": 0.0985,
      "step": 34240
    },
    {
      "epoch": 7.955865272938444,
      "grad_norm": 0.4825263023376465,
      "learning_rate": 1.0233449477351918e-05,
      "loss": 0.0624,
      "step": 34250
    },
    {
      "epoch": 7.958188153310105,
      "grad_norm": 0.4639248549938202,
      "learning_rate": 1.0221835075493614e-05,
      "loss": 0.0743,
      "step": 34260
    },
    {
      "epoch": 7.960511033681765,
      "grad_norm": 0.9317923188209534,
      "learning_rate": 1.0210220673635309e-05,
      "loss": 0.1114,
      "step": 34270
    },
    {
      "epoch": 7.9628339140534266,
      "grad_norm": 1.4239295721054077,
      "learning_rate": 1.0198606271777005e-05,
      "loss": 0.1545,
      "step": 34280
    },
    {
      "epoch": 7.965156794425087,
      "grad_norm": 1.0397183895111084,
      "learning_rate": 1.01869918699187e-05,
      "loss": 0.0676,
      "step": 34290
    },
    {
      "epoch": 7.967479674796748,
      "grad_norm": 0.9111337065696716,
      "learning_rate": 1.0175377468060396e-05,
      "loss": 0.0709,
      "step": 34300
    },
    {
      "epoch": 7.969802555168409,
      "grad_norm": 1.3510030508041382,
      "learning_rate": 1.016376306620209e-05,
      "loss": 0.0787,
      "step": 34310
    },
    {
      "epoch": 7.97212543554007,
      "grad_norm": 0.9147763848304749,
      "learning_rate": 1.0152148664343787e-05,
      "loss": 0.1443,
      "step": 34320
    },
    {
      "epoch": 7.97444831591173,
      "grad_norm": 0.6586742401123047,
      "learning_rate": 1.0140534262485482e-05,
      "loss": 0.0528,
      "step": 34330
    },
    {
      "epoch": 7.976771196283392,
      "grad_norm": 0.8130468726158142,
      "learning_rate": 1.0128919860627178e-05,
      "loss": 0.0597,
      "step": 34340
    },
    {
      "epoch": 7.979094076655052,
      "grad_norm": 1.4141165018081665,
      "learning_rate": 1.0117305458768873e-05,
      "loss": 0.1094,
      "step": 34350
    },
    {
      "epoch": 7.981416957026713,
      "grad_norm": 0.780616044998169,
      "learning_rate": 1.0105691056910569e-05,
      "loss": 0.0925,
      "step": 34360
    },
    {
      "epoch": 7.983739837398374,
      "grad_norm": 0.6920347213745117,
      "learning_rate": 1.0094076655052265e-05,
      "loss": 0.0915,
      "step": 34370
    },
    {
      "epoch": 7.986062717770035,
      "grad_norm": 1.3357702493667603,
      "learning_rate": 1.0082462253193962e-05,
      "loss": 0.1201,
      "step": 34380
    },
    {
      "epoch": 7.988385598141695,
      "grad_norm": 1.6673928499221802,
      "learning_rate": 1.0070847851335657e-05,
      "loss": 0.0845,
      "step": 34390
    },
    {
      "epoch": 7.990708478513357,
      "grad_norm": 0.6339985132217407,
      "learning_rate": 1.0059233449477353e-05,
      "loss": 0.0926,
      "step": 34400
    },
    {
      "epoch": 7.993031358885017,
      "grad_norm": 1.712536334991455,
      "learning_rate": 1.004761904761905e-05,
      "loss": 0.0965,
      "step": 34410
    },
    {
      "epoch": 7.995354239256678,
      "grad_norm": 0.9163470268249512,
      "learning_rate": 1.0036004645760744e-05,
      "loss": 0.0716,
      "step": 34420
    },
    {
      "epoch": 7.997677119628339,
      "grad_norm": 0.8475589156150818,
      "learning_rate": 1.002439024390244e-05,
      "loss": 0.0679,
      "step": 34430
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.0101537704467773,
      "learning_rate": 1.0012775842044135e-05,
      "loss": 0.0947,
      "step": 34440
    },
    {
      "epoch": 8.002322880371661,
      "grad_norm": 1.2824045419692993,
      "learning_rate": 1.0001161440185831e-05,
      "loss": 0.1066,
      "step": 34450
    },
    {
      "epoch": 8.004645760743323,
      "grad_norm": 1.4457181692123413,
      "learning_rate": 9.989547038327526e-06,
      "loss": 0.0955,
      "step": 34460
    },
    {
      "epoch": 8.006968641114982,
      "grad_norm": 1.134601354598999,
      "learning_rate": 9.977932636469222e-06,
      "loss": 0.0891,
      "step": 34470
    },
    {
      "epoch": 8.009291521486643,
      "grad_norm": 0.5932917594909668,
      "learning_rate": 9.966318234610917e-06,
      "loss": 0.0715,
      "step": 34480
    },
    {
      "epoch": 8.011614401858305,
      "grad_norm": 1.288909673690796,
      "learning_rate": 9.954703832752613e-06,
      "loss": 0.0653,
      "step": 34490
    },
    {
      "epoch": 8.013937282229966,
      "grad_norm": 0.739690363407135,
      "learning_rate": 9.94308943089431e-06,
      "loss": 0.0994,
      "step": 34500
    },
    {
      "epoch": 8.016260162601625,
      "grad_norm": 1.23030686378479,
      "learning_rate": 9.931475029036006e-06,
      "loss": 0.0882,
      "step": 34510
    },
    {
      "epoch": 8.018583042973287,
      "grad_norm": 0.6470391154289246,
      "learning_rate": 9.9198606271777e-06,
      "loss": 0.0814,
      "step": 34520
    },
    {
      "epoch": 8.020905923344948,
      "grad_norm": 0.5265902876853943,
      "learning_rate": 9.908246225319397e-06,
      "loss": 0.1209,
      "step": 34530
    },
    {
      "epoch": 8.02322880371661,
      "grad_norm": 0.7134069800376892,
      "learning_rate": 9.896631823461092e-06,
      "loss": 0.1028,
      "step": 34540
    },
    {
      "epoch": 8.025551684088269,
      "grad_norm": 0.7114716172218323,
      "learning_rate": 9.885017421602788e-06,
      "loss": 0.1042,
      "step": 34550
    },
    {
      "epoch": 8.02787456445993,
      "grad_norm": 0.6492713093757629,
      "learning_rate": 9.873403019744483e-06,
      "loss": 0.1294,
      "step": 34560
    },
    {
      "epoch": 8.030197444831591,
      "grad_norm": 0.8190442323684692,
      "learning_rate": 9.86178861788618e-06,
      "loss": 0.1554,
      "step": 34570
    },
    {
      "epoch": 8.032520325203253,
      "grad_norm": 0.6182113289833069,
      "learning_rate": 9.850174216027876e-06,
      "loss": 0.0889,
      "step": 34580
    },
    {
      "epoch": 8.034843205574912,
      "grad_norm": 0.5242627263069153,
      "learning_rate": 9.83855981416957e-06,
      "loss": 0.1403,
      "step": 34590
    },
    {
      "epoch": 8.037166085946573,
      "grad_norm": 0.8116558790206909,
      "learning_rate": 9.826945412311267e-06,
      "loss": 0.1642,
      "step": 34600
    },
    {
      "epoch": 8.039488966318235,
      "grad_norm": 0.8712359070777893,
      "learning_rate": 9.815331010452961e-06,
      "loss": 0.0675,
      "step": 34610
    },
    {
      "epoch": 8.041811846689896,
      "grad_norm": 0.8702815175056458,
      "learning_rate": 9.803716608594658e-06,
      "loss": 0.0979,
      "step": 34620
    },
    {
      "epoch": 8.044134727061556,
      "grad_norm": 2.2539892196655273,
      "learning_rate": 9.792102206736354e-06,
      "loss": 0.1155,
      "step": 34630
    },
    {
      "epoch": 8.046457607433217,
      "grad_norm": 1.4046335220336914,
      "learning_rate": 9.780487804878049e-06,
      "loss": 0.0936,
      "step": 34640
    },
    {
      "epoch": 8.048780487804878,
      "grad_norm": 2.0010223388671875,
      "learning_rate": 9.768873403019745e-06,
      "loss": 0.1686,
      "step": 34650
    },
    {
      "epoch": 8.05110336817654,
      "grad_norm": 0.9021964073181152,
      "learning_rate": 9.757259001161442e-06,
      "loss": 0.0744,
      "step": 34660
    },
    {
      "epoch": 8.053426248548199,
      "grad_norm": 1.055737018585205,
      "learning_rate": 9.745644599303136e-06,
      "loss": 0.0795,
      "step": 34670
    },
    {
      "epoch": 8.05574912891986,
      "grad_norm": 1.1560359001159668,
      "learning_rate": 9.734030197444833e-06,
      "loss": 0.0781,
      "step": 34680
    },
    {
      "epoch": 8.058072009291521,
      "grad_norm": 1.6300058364868164,
      "learning_rate": 9.722415795586527e-06,
      "loss": 0.1877,
      "step": 34690
    },
    {
      "epoch": 8.060394889663183,
      "grad_norm": 0.4823203980922699,
      "learning_rate": 9.710801393728224e-06,
      "loss": 0.119,
      "step": 34700
    },
    {
      "epoch": 8.062717770034844,
      "grad_norm": 0.612593948841095,
      "learning_rate": 9.699186991869918e-06,
      "loss": 0.0679,
      "step": 34710
    },
    {
      "epoch": 8.065040650406504,
      "grad_norm": 1.4096612930297852,
      "learning_rate": 9.687572590011615e-06,
      "loss": 0.0629,
      "step": 34720
    },
    {
      "epoch": 8.067363530778165,
      "grad_norm": 1.4025992155075073,
      "learning_rate": 9.675958188153311e-06,
      "loss": 0.1334,
      "step": 34730
    },
    {
      "epoch": 8.069686411149826,
      "grad_norm": 0.7195320725440979,
      "learning_rate": 9.664343786295006e-06,
      "loss": 0.1772,
      "step": 34740
    },
    {
      "epoch": 8.072009291521487,
      "grad_norm": 1.1103368997573853,
      "learning_rate": 9.652729384436702e-06,
      "loss": 0.0568,
      "step": 34750
    },
    {
      "epoch": 8.074332171893147,
      "grad_norm": 1.1926730871200562,
      "learning_rate": 9.641114982578397e-06,
      "loss": 0.1077,
      "step": 34760
    },
    {
      "epoch": 8.076655052264808,
      "grad_norm": 1.0014599561691284,
      "learning_rate": 9.629500580720093e-06,
      "loss": 0.0699,
      "step": 34770
    },
    {
      "epoch": 8.07897793263647,
      "grad_norm": 1.680687427520752,
      "learning_rate": 9.61788617886179e-06,
      "loss": 0.0915,
      "step": 34780
    },
    {
      "epoch": 8.08130081300813,
      "grad_norm": 0.9574683308601379,
      "learning_rate": 9.606271777003486e-06,
      "loss": 0.1201,
      "step": 34790
    },
    {
      "epoch": 8.08362369337979,
      "grad_norm": 1.1834616661071777,
      "learning_rate": 9.59465737514518e-06,
      "loss": 0.0831,
      "step": 34800
    },
    {
      "epoch": 8.085946573751452,
      "grad_norm": 0.6981713771820068,
      "learning_rate": 9.583042973286877e-06,
      "loss": 0.1336,
      "step": 34810
    },
    {
      "epoch": 8.088269454123113,
      "grad_norm": 1.1272186040878296,
      "learning_rate": 9.571428571428572e-06,
      "loss": 0.1192,
      "step": 34820
    },
    {
      "epoch": 8.090592334494774,
      "grad_norm": 0.570168673992157,
      "learning_rate": 9.559814169570268e-06,
      "loss": 0.0753,
      "step": 34830
    },
    {
      "epoch": 8.092915214866434,
      "grad_norm": 0.9433478713035583,
      "learning_rate": 9.548199767711963e-06,
      "loss": 0.0698,
      "step": 34840
    },
    {
      "epoch": 8.095238095238095,
      "grad_norm": 0.9877097606658936,
      "learning_rate": 9.536585365853659e-06,
      "loss": 0.0728,
      "step": 34850
    },
    {
      "epoch": 8.097560975609756,
      "grad_norm": 1.7746580839157104,
      "learning_rate": 9.524970963995354e-06,
      "loss": 0.0922,
      "step": 34860
    },
    {
      "epoch": 8.099883855981417,
      "grad_norm": 1.6938045024871826,
      "learning_rate": 9.51335656213705e-06,
      "loss": 0.0804,
      "step": 34870
    },
    {
      "epoch": 8.102206736353077,
      "grad_norm": 0.8633895516395569,
      "learning_rate": 9.501742160278745e-06,
      "loss": 0.1405,
      "step": 34880
    },
    {
      "epoch": 8.104529616724738,
      "grad_norm": 1.97015380859375,
      "learning_rate": 9.490127758420441e-06,
      "loss": 0.0944,
      "step": 34890
    },
    {
      "epoch": 8.1068524970964,
      "grad_norm": 0.8258682489395142,
      "learning_rate": 9.478513356562137e-06,
      "loss": 0.0823,
      "step": 34900
    },
    {
      "epoch": 8.10917537746806,
      "grad_norm": 0.7569752931594849,
      "learning_rate": 9.466898954703834e-06,
      "loss": 0.1305,
      "step": 34910
    },
    {
      "epoch": 8.111498257839722,
      "grad_norm": 0.7007680535316467,
      "learning_rate": 9.45528455284553e-06,
      "loss": 0.0994,
      "step": 34920
    },
    {
      "epoch": 8.113821138211382,
      "grad_norm": 0.658845067024231,
      "learning_rate": 9.443670150987225e-06,
      "loss": 0.0603,
      "step": 34930
    },
    {
      "epoch": 8.116144018583043,
      "grad_norm": 0.8327887058258057,
      "learning_rate": 9.432055749128921e-06,
      "loss": 0.0595,
      "step": 34940
    },
    {
      "epoch": 8.118466898954704,
      "grad_norm": 0.6204711198806763,
      "learning_rate": 9.420441347270616e-06,
      "loss": 0.0622,
      "step": 34950
    },
    {
      "epoch": 8.120789779326365,
      "grad_norm": 1.3324729204177856,
      "learning_rate": 9.408826945412312e-06,
      "loss": 0.0795,
      "step": 34960
    },
    {
      "epoch": 8.123112659698025,
      "grad_norm": 0.8073261976242065,
      "learning_rate": 9.397212543554007e-06,
      "loss": 0.1696,
      "step": 34970
    },
    {
      "epoch": 8.125435540069686,
      "grad_norm": 0.9742655158042908,
      "learning_rate": 9.385598141695703e-06,
      "loss": 0.0514,
      "step": 34980
    },
    {
      "epoch": 8.127758420441348,
      "grad_norm": 0.739520788192749,
      "learning_rate": 9.373983739837398e-06,
      "loss": 0.122,
      "step": 34990
    },
    {
      "epoch": 8.130081300813009,
      "grad_norm": 1.3663994073867798,
      "learning_rate": 9.362369337979094e-06,
      "loss": 0.0644,
      "step": 35000
    },
    {
      "epoch": 8.132404181184668,
      "grad_norm": 0.32557645440101624,
      "learning_rate": 9.350754936120789e-06,
      "loss": 0.0563,
      "step": 35010
    },
    {
      "epoch": 8.13472706155633,
      "grad_norm": 0.8359687328338623,
      "learning_rate": 9.339140534262485e-06,
      "loss": 0.0926,
      "step": 35020
    },
    {
      "epoch": 8.137049941927991,
      "grad_norm": 2.081294536590576,
      "learning_rate": 9.327526132404182e-06,
      "loss": 0.1013,
      "step": 35030
    },
    {
      "epoch": 8.139372822299652,
      "grad_norm": 0.5760351419448853,
      "learning_rate": 9.315911730545878e-06,
      "loss": 0.064,
      "step": 35040
    },
    {
      "epoch": 8.141695702671312,
      "grad_norm": 1.0800763368606567,
      "learning_rate": 9.304297328687574e-06,
      "loss": 0.0682,
      "step": 35050
    },
    {
      "epoch": 8.144018583042973,
      "grad_norm": 1.1791653633117676,
      "learning_rate": 9.292682926829269e-06,
      "loss": 0.0922,
      "step": 35060
    },
    {
      "epoch": 8.146341463414634,
      "grad_norm": 0.5576620697975159,
      "learning_rate": 9.281068524970965e-06,
      "loss": 0.0532,
      "step": 35070
    },
    {
      "epoch": 8.148664343786296,
      "grad_norm": 0.9165366888046265,
      "learning_rate": 9.26945412311266e-06,
      "loss": 0.0929,
      "step": 35080
    },
    {
      "epoch": 8.150987224157955,
      "grad_norm": 0.4851435720920563,
      "learning_rate": 9.257839721254356e-06,
      "loss": 0.0741,
      "step": 35090
    },
    {
      "epoch": 8.153310104529616,
      "grad_norm": 1.3439671993255615,
      "learning_rate": 9.246225319396051e-06,
      "loss": 0.1079,
      "step": 35100
    },
    {
      "epoch": 8.155632984901278,
      "grad_norm": 1.5007798671722412,
      "learning_rate": 9.234610917537748e-06,
      "loss": 0.0651,
      "step": 35110
    },
    {
      "epoch": 8.157955865272939,
      "grad_norm": 1.3947771787643433,
      "learning_rate": 9.222996515679442e-06,
      "loss": 0.1433,
      "step": 35120
    },
    {
      "epoch": 8.160278745644598,
      "grad_norm": 0.8487992286682129,
      "learning_rate": 9.211382113821139e-06,
      "loss": 0.0736,
      "step": 35130
    },
    {
      "epoch": 8.16260162601626,
      "grad_norm": 1.7408838272094727,
      "learning_rate": 9.199767711962833e-06,
      "loss": 0.0629,
      "step": 35140
    },
    {
      "epoch": 8.164924506387921,
      "grad_norm": 0.6603082418441772,
      "learning_rate": 9.18815331010453e-06,
      "loss": 0.0664,
      "step": 35150
    },
    {
      "epoch": 8.167247386759582,
      "grad_norm": 1.717829942703247,
      "learning_rate": 9.176538908246226e-06,
      "loss": 0.109,
      "step": 35160
    },
    {
      "epoch": 8.169570267131244,
      "grad_norm": 1.3205324411392212,
      "learning_rate": 9.164924506387922e-06,
      "loss": 0.0713,
      "step": 35170
    },
    {
      "epoch": 8.171893147502903,
      "grad_norm": 0.7485778331756592,
      "learning_rate": 9.153310104529617e-06,
      "loss": 0.0578,
      "step": 35180
    },
    {
      "epoch": 8.174216027874564,
      "grad_norm": Infinity,
      "learning_rate": 9.142857142857144e-06,
      "loss": 0.1827,
      "step": 35190
    },
    {
      "epoch": 8.176538908246226,
      "grad_norm": 1.06780207157135,
      "learning_rate": 9.13124274099884e-06,
      "loss": 0.0732,
      "step": 35200
    },
    {
      "epoch": 8.178861788617887,
      "grad_norm": 1.5340118408203125,
      "learning_rate": 9.119628339140535e-06,
      "loss": 0.1129,
      "step": 35210
    },
    {
      "epoch": 8.181184668989546,
      "grad_norm": 2.040530204772949,
      "learning_rate": 9.108013937282231e-06,
      "loss": 0.0993,
      "step": 35220
    },
    {
      "epoch": 8.183507549361208,
      "grad_norm": 0.3507877588272095,
      "learning_rate": 9.096399535423926e-06,
      "loss": 0.1359,
      "step": 35230
    },
    {
      "epoch": 8.185830429732869,
      "grad_norm": 0.775288999080658,
      "learning_rate": 9.084785133565622e-06,
      "loss": 0.1269,
      "step": 35240
    },
    {
      "epoch": 8.18815331010453,
      "grad_norm": 1.04689621925354,
      "learning_rate": 9.073170731707317e-06,
      "loss": 0.0921,
      "step": 35250
    },
    {
      "epoch": 8.19047619047619,
      "grad_norm": 1.0580347776412964,
      "learning_rate": 9.061556329849013e-06,
      "loss": 0.0615,
      "step": 35260
    },
    {
      "epoch": 8.192799070847851,
      "grad_norm": 1.1548279523849487,
      "learning_rate": 9.049941927990708e-06,
      "loss": 0.0904,
      "step": 35270
    },
    {
      "epoch": 8.195121951219512,
      "grad_norm": 0.8718679547309875,
      "learning_rate": 9.038327526132404e-06,
      "loss": 0.0619,
      "step": 35280
    },
    {
      "epoch": 8.197444831591174,
      "grad_norm": 0.5965259671211243,
      "learning_rate": 9.026713124274099e-06,
      "loss": 0.089,
      "step": 35290
    },
    {
      "epoch": 8.199767711962833,
      "grad_norm": 0.6236518025398254,
      "learning_rate": 9.015098722415795e-06,
      "loss": 0.0785,
      "step": 35300
    },
    {
      "epoch": 8.202090592334494,
      "grad_norm": 0.8804647326469421,
      "learning_rate": 9.003484320557492e-06,
      "loss": 0.0978,
      "step": 35310
    },
    {
      "epoch": 8.204413472706156,
      "grad_norm": 1.4680125713348389,
      "learning_rate": 8.991869918699188e-06,
      "loss": 0.0853,
      "step": 35320
    },
    {
      "epoch": 8.206736353077817,
      "grad_norm": 1.1513206958770752,
      "learning_rate": 8.980255516840883e-06,
      "loss": 0.0612,
      "step": 35330
    },
    {
      "epoch": 8.209059233449477,
      "grad_norm": 2.352450370788574,
      "learning_rate": 8.96864111498258e-06,
      "loss": 0.0847,
      "step": 35340
    },
    {
      "epoch": 8.211382113821138,
      "grad_norm": 1.356523871421814,
      "learning_rate": 8.957026713124276e-06,
      "loss": 0.1155,
      "step": 35350
    },
    {
      "epoch": 8.213704994192799,
      "grad_norm": 0.7371684312820435,
      "learning_rate": 8.94541231126597e-06,
      "loss": 0.1484,
      "step": 35360
    },
    {
      "epoch": 8.21602787456446,
      "grad_norm": 1.037840723991394,
      "learning_rate": 8.933797909407667e-06,
      "loss": 0.0744,
      "step": 35370
    },
    {
      "epoch": 8.218350754936122,
      "grad_norm": 0.8836139440536499,
      "learning_rate": 8.922183507549361e-06,
      "loss": 0.0568,
      "step": 35380
    },
    {
      "epoch": 8.220673635307781,
      "grad_norm": 0.6921191811561584,
      "learning_rate": 8.910569105691058e-06,
      "loss": 0.0916,
      "step": 35390
    },
    {
      "epoch": 8.222996515679442,
      "grad_norm": 0.9974117875099182,
      "learning_rate": 8.898954703832752e-06,
      "loss": 0.1273,
      "step": 35400
    },
    {
      "epoch": 8.225319396051104,
      "grad_norm": 1.1264441013336182,
      "learning_rate": 8.887340301974449e-06,
      "loss": 0.1111,
      "step": 35410
    },
    {
      "epoch": 8.227642276422765,
      "grad_norm": 0.5559046864509583,
      "learning_rate": 8.875725900116143e-06,
      "loss": 0.0653,
      "step": 35420
    },
    {
      "epoch": 8.229965156794425,
      "grad_norm": 2.269103527069092,
      "learning_rate": 8.86411149825784e-06,
      "loss": 0.1028,
      "step": 35430
    },
    {
      "epoch": 8.232288037166086,
      "grad_norm": 0.8177542686462402,
      "learning_rate": 8.852497096399536e-06,
      "loss": 0.0865,
      "step": 35440
    },
    {
      "epoch": 8.234610917537747,
      "grad_norm": 0.6261855363845825,
      "learning_rate": 8.840882694541232e-06,
      "loss": 0.046,
      "step": 35450
    },
    {
      "epoch": 8.236933797909408,
      "grad_norm": 0.48731884360313416,
      "learning_rate": 8.829268292682927e-06,
      "loss": 0.0762,
      "step": 35460
    },
    {
      "epoch": 8.239256678281068,
      "grad_norm": 0.49479562044143677,
      "learning_rate": 8.817653890824624e-06,
      "loss": 0.0693,
      "step": 35470
    },
    {
      "epoch": 8.24157955865273,
      "grad_norm": 1.2978591918945312,
      "learning_rate": 8.806039488966318e-06,
      "loss": 0.1732,
      "step": 35480
    },
    {
      "epoch": 8.24390243902439,
      "grad_norm": 3.2690651416778564,
      "learning_rate": 8.794425087108015e-06,
      "loss": 0.1897,
      "step": 35490
    },
    {
      "epoch": 8.246225319396052,
      "grad_norm": 0.7745635509490967,
      "learning_rate": 8.78281068524971e-06,
      "loss": 0.0893,
      "step": 35500
    },
    {
      "epoch": 8.248548199767711,
      "grad_norm": 1.1900449991226196,
      "learning_rate": 8.771196283391406e-06,
      "loss": 0.1581,
      "step": 35510
    },
    {
      "epoch": 8.250871080139373,
      "grad_norm": 0.7991219162940979,
      "learning_rate": 8.759581881533102e-06,
      "loss": 0.1061,
      "step": 35520
    },
    {
      "epoch": 8.253193960511034,
      "grad_norm": 0.615108072757721,
      "learning_rate": 8.747967479674797e-06,
      "loss": 0.0473,
      "step": 35530
    },
    {
      "epoch": 8.255516840882695,
      "grad_norm": 2.417614459991455,
      "learning_rate": 8.736353077816493e-06,
      "loss": 0.1186,
      "step": 35540
    },
    {
      "epoch": 8.257839721254355,
      "grad_norm": 0.7619746923446655,
      "learning_rate": 8.724738675958188e-06,
      "loss": 0.1019,
      "step": 35550
    },
    {
      "epoch": 8.260162601626016,
      "grad_norm": 1.2523610591888428,
      "learning_rate": 8.713124274099884e-06,
      "loss": 0.0771,
      "step": 35560
    },
    {
      "epoch": 8.262485481997677,
      "grad_norm": 1.0622658729553223,
      "learning_rate": 8.70150987224158e-06,
      "loss": 0.0659,
      "step": 35570
    },
    {
      "epoch": 8.264808362369338,
      "grad_norm": 0.5112230777740479,
      "learning_rate": 8.689895470383277e-06,
      "loss": 0.1641,
      "step": 35580
    },
    {
      "epoch": 8.267131242740998,
      "grad_norm": 0.6169946193695068,
      "learning_rate": 8.678281068524971e-06,
      "loss": 0.1038,
      "step": 35590
    },
    {
      "epoch": 8.26945412311266,
      "grad_norm": 0.5008828639984131,
      "learning_rate": 8.666666666666668e-06,
      "loss": 0.0414,
      "step": 35600
    },
    {
      "epoch": 8.27177700348432,
      "grad_norm": 0.7520794868469238,
      "learning_rate": 8.655052264808363e-06,
      "loss": 0.0631,
      "step": 35610
    },
    {
      "epoch": 8.274099883855982,
      "grad_norm": 0.5376835465431213,
      "learning_rate": 8.643437862950059e-06,
      "loss": 0.1146,
      "step": 35620
    },
    {
      "epoch": 8.276422764227643,
      "grad_norm": 1.0709664821624756,
      "learning_rate": 8.631823461091754e-06,
      "loss": 0.0981,
      "step": 35630
    },
    {
      "epoch": 8.278745644599303,
      "grad_norm": 0.49888867139816284,
      "learning_rate": 8.62020905923345e-06,
      "loss": 0.1372,
      "step": 35640
    },
    {
      "epoch": 8.281068524970964,
      "grad_norm": 0.897817075252533,
      "learning_rate": 8.608594657375145e-06,
      "loss": 0.0973,
      "step": 35650
    },
    {
      "epoch": 8.283391405342625,
      "grad_norm": 0.40355855226516724,
      "learning_rate": 8.596980255516841e-06,
      "loss": 0.0782,
      "step": 35660
    },
    {
      "epoch": 8.285714285714286,
      "grad_norm": 1.0686345100402832,
      "learning_rate": 8.585365853658537e-06,
      "loss": 0.101,
      "step": 35670
    },
    {
      "epoch": 8.288037166085946,
      "grad_norm": 0.9409120678901672,
      "learning_rate": 8.573751451800232e-06,
      "loss": 0.1074,
      "step": 35680
    },
    {
      "epoch": 8.290360046457607,
      "grad_norm": 0.933691143989563,
      "learning_rate": 8.562137049941928e-06,
      "loss": 0.0672,
      "step": 35690
    },
    {
      "epoch": 8.292682926829269,
      "grad_norm": 0.7268785834312439,
      "learning_rate": 8.550522648083625e-06,
      "loss": 0.1962,
      "step": 35700
    },
    {
      "epoch": 8.29500580720093,
      "grad_norm": 0.926965057849884,
      "learning_rate": 8.538908246225321e-06,
      "loss": 0.1529,
      "step": 35710
    },
    {
      "epoch": 8.29732868757259,
      "grad_norm": 0.6537745594978333,
      "learning_rate": 8.527293844367016e-06,
      "loss": 0.1109,
      "step": 35720
    },
    {
      "epoch": 8.29965156794425,
      "grad_norm": 0.6995164155960083,
      "learning_rate": 8.515679442508712e-06,
      "loss": 0.0682,
      "step": 35730
    },
    {
      "epoch": 8.301974448315912,
      "grad_norm": 1.1958223581314087,
      "learning_rate": 8.504065040650407e-06,
      "loss": 0.1408,
      "step": 35740
    },
    {
      "epoch": 8.304297328687573,
      "grad_norm": 0.8717446327209473,
      "learning_rate": 8.492450638792103e-06,
      "loss": 0.065,
      "step": 35750
    },
    {
      "epoch": 8.306620209059233,
      "grad_norm": 1.3664934635162354,
      "learning_rate": 8.480836236933798e-06,
      "loss": 0.057,
      "step": 35760
    },
    {
      "epoch": 8.308943089430894,
      "grad_norm": 0.9869570136070251,
      "learning_rate": 8.469221835075494e-06,
      "loss": 0.0575,
      "step": 35770
    },
    {
      "epoch": 8.311265969802555,
      "grad_norm": 0.6635473370552063,
      "learning_rate": 8.457607433217189e-06,
      "loss": 0.0528,
      "step": 35780
    },
    {
      "epoch": 8.313588850174217,
      "grad_norm": 1.0502461194992065,
      "learning_rate": 8.445993031358885e-06,
      "loss": 0.086,
      "step": 35790
    },
    {
      "epoch": 8.315911730545876,
      "grad_norm": 1.0321224927902222,
      "learning_rate": 8.43437862950058e-06,
      "loss": 0.0461,
      "step": 35800
    },
    {
      "epoch": 8.318234610917537,
      "grad_norm": 1.8294531106948853,
      "learning_rate": 8.422764227642276e-06,
      "loss": 0.1679,
      "step": 35810
    },
    {
      "epoch": 8.320557491289199,
      "grad_norm": 1.0962408781051636,
      "learning_rate": 8.411149825783973e-06,
      "loss": 0.1172,
      "step": 35820
    },
    {
      "epoch": 8.32288037166086,
      "grad_norm": 2.0944886207580566,
      "learning_rate": 8.399535423925669e-06,
      "loss": 0.0602,
      "step": 35830
    },
    {
      "epoch": 8.32520325203252,
      "grad_norm": 1.406384825706482,
      "learning_rate": 8.387921022067365e-06,
      "loss": 0.0721,
      "step": 35840
    },
    {
      "epoch": 8.32752613240418,
      "grad_norm": 1.2698827981948853,
      "learning_rate": 8.37630662020906e-06,
      "loss": 0.0966,
      "step": 35850
    },
    {
      "epoch": 8.329849012775842,
      "grad_norm": 2.314788341522217,
      "learning_rate": 8.364692218350756e-06,
      "loss": 0.0913,
      "step": 35860
    },
    {
      "epoch": 8.332171893147503,
      "grad_norm": 0.44955819845199585,
      "learning_rate": 8.353077816492451e-06,
      "loss": 0.0736,
      "step": 35870
    },
    {
      "epoch": 8.334494773519165,
      "grad_norm": 0.8986459970474243,
      "learning_rate": 8.341463414634147e-06,
      "loss": 0.0801,
      "step": 35880
    },
    {
      "epoch": 8.336817653890824,
      "grad_norm": 0.6603270769119263,
      "learning_rate": 8.329849012775842e-06,
      "loss": 0.0695,
      "step": 35890
    },
    {
      "epoch": 8.339140534262485,
      "grad_norm": 0.5557457804679871,
      "learning_rate": 8.318234610917539e-06,
      "loss": 0.0467,
      "step": 35900
    },
    {
      "epoch": 8.341463414634147,
      "grad_norm": 0.7586123943328857,
      "learning_rate": 8.306620209059233e-06,
      "loss": 0.0532,
      "step": 35910
    },
    {
      "epoch": 8.343786295005808,
      "grad_norm": 0.4316787123680115,
      "learning_rate": 8.29500580720093e-06,
      "loss": 0.043,
      "step": 35920
    },
    {
      "epoch": 8.346109175377467,
      "grad_norm": 0.9159392714500427,
      "learning_rate": 8.283391405342624e-06,
      "loss": 0.0885,
      "step": 35930
    },
    {
      "epoch": 8.348432055749129,
      "grad_norm": 0.658887505531311,
      "learning_rate": 8.27177700348432e-06,
      "loss": 0.0526,
      "step": 35940
    },
    {
      "epoch": 8.35075493612079,
      "grad_norm": 1.4474529027938843,
      "learning_rate": 8.260162601626017e-06,
      "loss": 0.0875,
      "step": 35950
    },
    {
      "epoch": 8.353077816492451,
      "grad_norm": 1.5432342290878296,
      "learning_rate": 8.248548199767713e-06,
      "loss": 0.1458,
      "step": 35960
    },
    {
      "epoch": 8.35540069686411,
      "grad_norm": 2.526503324508667,
      "learning_rate": 8.236933797909408e-06,
      "loss": 0.0735,
      "step": 35970
    },
    {
      "epoch": 8.357723577235772,
      "grad_norm": 0.8446708917617798,
      "learning_rate": 8.225319396051104e-06,
      "loss": 0.108,
      "step": 35980
    },
    {
      "epoch": 8.360046457607433,
      "grad_norm": 1.562827467918396,
      "learning_rate": 8.2137049941928e-06,
      "loss": 0.0645,
      "step": 35990
    },
    {
      "epoch": 8.362369337979095,
      "grad_norm": 0.3705667555332184,
      "learning_rate": 8.202090592334495e-06,
      "loss": 0.0376,
      "step": 36000
    },
    {
      "epoch": 8.364692218350754,
      "grad_norm": 0.38388362526893616,
      "learning_rate": 8.190476190476192e-06,
      "loss": 0.0889,
      "step": 36010
    },
    {
      "epoch": 8.367015098722415,
      "grad_norm": 0.7958050966262817,
      "learning_rate": 8.178861788617886e-06,
      "loss": 0.061,
      "step": 36020
    },
    {
      "epoch": 8.369337979094077,
      "grad_norm": 0.6619385480880737,
      "learning_rate": 8.167247386759583e-06,
      "loss": 0.0767,
      "step": 36030
    },
    {
      "epoch": 8.371660859465738,
      "grad_norm": 1.0914636850357056,
      "learning_rate": 8.155632984901277e-06,
      "loss": 0.1618,
      "step": 36040
    },
    {
      "epoch": 8.373983739837398,
      "grad_norm": 1.1072280406951904,
      "learning_rate": 8.144018583042974e-06,
      "loss": 0.0725,
      "step": 36050
    },
    {
      "epoch": 8.376306620209059,
      "grad_norm": 1.544973373413086,
      "learning_rate": 8.132404181184669e-06,
      "loss": 0.1067,
      "step": 36060
    },
    {
      "epoch": 8.37862950058072,
      "grad_norm": 1.0968631505966187,
      "learning_rate": 8.120789779326365e-06,
      "loss": 0.1414,
      "step": 36070
    },
    {
      "epoch": 8.380952380952381,
      "grad_norm": 1.205917239189148,
      "learning_rate": 8.10917537746806e-06,
      "loss": 0.0554,
      "step": 36080
    },
    {
      "epoch": 8.383275261324043,
      "grad_norm": 0.9216338396072388,
      "learning_rate": 8.097560975609756e-06,
      "loss": 0.0688,
      "step": 36090
    },
    {
      "epoch": 8.385598141695702,
      "grad_norm": 0.9978001117706299,
      "learning_rate": 8.085946573751452e-06,
      "loss": 0.0582,
      "step": 36100
    },
    {
      "epoch": 8.387921022067363,
      "grad_norm": 0.4381139278411865,
      "learning_rate": 8.074332171893149e-06,
      "loss": 0.0597,
      "step": 36110
    },
    {
      "epoch": 8.390243902439025,
      "grad_norm": 0.7098525166511536,
      "learning_rate": 8.062717770034843e-06,
      "loss": 0.1168,
      "step": 36120
    },
    {
      "epoch": 8.392566782810686,
      "grad_norm": 1.7831828594207764,
      "learning_rate": 8.05110336817654e-06,
      "loss": 0.0638,
      "step": 36130
    },
    {
      "epoch": 8.394889663182346,
      "grad_norm": 1.6067429780960083,
      "learning_rate": 8.039488966318234e-06,
      "loss": 0.1037,
      "step": 36140
    },
    {
      "epoch": 8.397212543554007,
      "grad_norm": 0.9512251615524292,
      "learning_rate": 8.02787456445993e-06,
      "loss": 0.0959,
      "step": 36150
    },
    {
      "epoch": 8.399535423925668,
      "grad_norm": 1.9897487163543701,
      "learning_rate": 8.016260162601627e-06,
      "loss": 0.098,
      "step": 36160
    },
    {
      "epoch": 8.40185830429733,
      "grad_norm": 0.7233157753944397,
      "learning_rate": 8.004645760743322e-06,
      "loss": 0.0724,
      "step": 36170
    },
    {
      "epoch": 8.404181184668989,
      "grad_norm": 1.547463297843933,
      "learning_rate": 7.993031358885018e-06,
      "loss": 0.0816,
      "step": 36180
    },
    {
      "epoch": 8.40650406504065,
      "grad_norm": 1.5551544427871704,
      "learning_rate": 7.981416957026713e-06,
      "loss": 0.0815,
      "step": 36190
    },
    {
      "epoch": 8.408826945412311,
      "grad_norm": 1.836513876914978,
      "learning_rate": 7.96980255516841e-06,
      "loss": 0.0907,
      "step": 36200
    },
    {
      "epoch": 8.411149825783973,
      "grad_norm": 1.3403451442718506,
      "learning_rate": 7.958188153310104e-06,
      "loss": 0.132,
      "step": 36210
    },
    {
      "epoch": 8.413472706155632,
      "grad_norm": 0.5463868975639343,
      "learning_rate": 7.9465737514518e-06,
      "loss": 0.0779,
      "step": 36220
    },
    {
      "epoch": 8.415795586527294,
      "grad_norm": 0.38612625002861023,
      "learning_rate": 7.934959349593497e-06,
      "loss": 0.0545,
      "step": 36230
    },
    {
      "epoch": 8.418118466898955,
      "grad_norm": 0.7802693247795105,
      "learning_rate": 7.923344947735193e-06,
      "loss": 0.092,
      "step": 36240
    },
    {
      "epoch": 8.420441347270616,
      "grad_norm": 2.7306206226348877,
      "learning_rate": 7.911730545876888e-06,
      "loss": 0.0565,
      "step": 36250
    },
    {
      "epoch": 8.422764227642276,
      "grad_norm": 0.9621632695198059,
      "learning_rate": 7.900116144018584e-06,
      "loss": 0.104,
      "step": 36260
    },
    {
      "epoch": 8.425087108013937,
      "grad_norm": 2.541626453399658,
      "learning_rate": 7.888501742160279e-06,
      "loss": 0.0768,
      "step": 36270
    },
    {
      "epoch": 8.427409988385598,
      "grad_norm": 1.8759697675704956,
      "learning_rate": 7.876887340301975e-06,
      "loss": 0.0825,
      "step": 36280
    },
    {
      "epoch": 8.42973286875726,
      "grad_norm": 0.6115087866783142,
      "learning_rate": 7.86527293844367e-06,
      "loss": 0.0846,
      "step": 36290
    },
    {
      "epoch": 8.43205574912892,
      "grad_norm": 1.6685255765914917,
      "learning_rate": 7.853658536585366e-06,
      "loss": 0.1372,
      "step": 36300
    },
    {
      "epoch": 8.43437862950058,
      "grad_norm": 1.2451926469802856,
      "learning_rate": 7.842044134727062e-06,
      "loss": 0.0713,
      "step": 36310
    },
    {
      "epoch": 8.436701509872242,
      "grad_norm": 1.0423035621643066,
      "learning_rate": 7.830429732868757e-06,
      "loss": 0.0386,
      "step": 36320
    },
    {
      "epoch": 8.439024390243903,
      "grad_norm": 0.517595112323761,
      "learning_rate": 7.818815331010453e-06,
      "loss": 0.0521,
      "step": 36330
    },
    {
      "epoch": 8.441347270615564,
      "grad_norm": 1.1646784543991089,
      "learning_rate": 7.807200929152148e-06,
      "loss": 0.1278,
      "step": 36340
    },
    {
      "epoch": 8.443670150987224,
      "grad_norm": 1.4922699928283691,
      "learning_rate": 7.795586527293845e-06,
      "loss": 0.063,
      "step": 36350
    },
    {
      "epoch": 8.445993031358885,
      "grad_norm": 1.4899420738220215,
      "learning_rate": 7.783972125435541e-06,
      "loss": 0.0576,
      "step": 36360
    },
    {
      "epoch": 8.448315911730546,
      "grad_norm": 2.3112051486968994,
      "learning_rate": 7.772357723577237e-06,
      "loss": 0.1183,
      "step": 36370
    },
    {
      "epoch": 8.450638792102207,
      "grad_norm": 1.1383832693099976,
      "learning_rate": 7.760743321718932e-06,
      "loss": 0.1046,
      "step": 36380
    },
    {
      "epoch": 8.452961672473867,
      "grad_norm": 0.9282578825950623,
      "learning_rate": 7.749128919860628e-06,
      "loss": 0.1029,
      "step": 36390
    },
    {
      "epoch": 8.455284552845528,
      "grad_norm": 0.5312709808349609,
      "learning_rate": 7.737514518002323e-06,
      "loss": 0.1207,
      "step": 36400
    },
    {
      "epoch": 8.45760743321719,
      "grad_norm": 0.48937711119651794,
      "learning_rate": 7.72590011614402e-06,
      "loss": 0.0696,
      "step": 36410
    },
    {
      "epoch": 8.45993031358885,
      "grad_norm": 1.0384598970413208,
      "learning_rate": 7.714285714285714e-06,
      "loss": 0.1367,
      "step": 36420
    },
    {
      "epoch": 8.46225319396051,
      "grad_norm": 1.384558081626892,
      "learning_rate": 7.70267131242741e-06,
      "loss": 0.0608,
      "step": 36430
    },
    {
      "epoch": 8.464576074332172,
      "grad_norm": 1.323923945426941,
      "learning_rate": 7.691056910569105e-06,
      "loss": 0.0882,
      "step": 36440
    },
    {
      "epoch": 8.466898954703833,
      "grad_norm": 1.0564841032028198,
      "learning_rate": 7.679442508710801e-06,
      "loss": 0.0505,
      "step": 36450
    },
    {
      "epoch": 8.469221835075494,
      "grad_norm": 0.49962690472602844,
      "learning_rate": 7.667828106852496e-06,
      "loss": 0.0725,
      "step": 36460
    },
    {
      "epoch": 8.471544715447154,
      "grad_norm": 1.5114588737487793,
      "learning_rate": 7.656213704994192e-06,
      "loss": 0.0576,
      "step": 36470
    },
    {
      "epoch": 8.473867595818815,
      "grad_norm": 0.39529579877853394,
      "learning_rate": 7.644599303135889e-06,
      "loss": 0.1563,
      "step": 36480
    },
    {
      "epoch": 8.476190476190476,
      "grad_norm": 2.049927234649658,
      "learning_rate": 7.632984901277585e-06,
      "loss": 0.0763,
      "step": 36490
    },
    {
      "epoch": 8.478513356562138,
      "grad_norm": 1.4734169244766235,
      "learning_rate": 7.621370499419281e-06,
      "loss": 0.1625,
      "step": 36500
    },
    {
      "epoch": 8.480836236933797,
      "grad_norm": 0.5479782819747925,
      "learning_rate": 7.609756097560976e-06,
      "loss": 0.0949,
      "step": 36510
    },
    {
      "epoch": 8.483159117305458,
      "grad_norm": 0.6055739521980286,
      "learning_rate": 7.598141695702672e-06,
      "loss": 0.0624,
      "step": 36520
    },
    {
      "epoch": 8.48548199767712,
      "grad_norm": 0.8531414866447449,
      "learning_rate": 7.586527293844367e-06,
      "loss": 0.1155,
      "step": 36530
    },
    {
      "epoch": 8.487804878048781,
      "grad_norm": 1.1110261678695679,
      "learning_rate": 7.574912891986064e-06,
      "loss": 0.1027,
      "step": 36540
    },
    {
      "epoch": 8.490127758420442,
      "grad_norm": 0.522759735584259,
      "learning_rate": 7.563298490127758e-06,
      "loss": 0.0657,
      "step": 36550
    },
    {
      "epoch": 8.492450638792102,
      "grad_norm": 1.0002496242523193,
      "learning_rate": 7.551684088269455e-06,
      "loss": 0.0647,
      "step": 36560
    },
    {
      "epoch": 8.494773519163763,
      "grad_norm": 0.3744734525680542,
      "learning_rate": 7.540069686411149e-06,
      "loss": 0.0953,
      "step": 36570
    },
    {
      "epoch": 8.497096399535424,
      "grad_norm": 0.9612186551094055,
      "learning_rate": 7.528455284552846e-06,
      "loss": 0.1035,
      "step": 36580
    },
    {
      "epoch": 8.499419279907086,
      "grad_norm": 2.3878440856933594,
      "learning_rate": 7.516840882694541e-06,
      "loss": 0.0719,
      "step": 36590
    },
    {
      "epoch": 8.501742160278745,
      "grad_norm": 0.7006442546844482,
      "learning_rate": 7.505226480836238e-06,
      "loss": 0.0411,
      "step": 36600
    },
    {
      "epoch": 8.504065040650406,
      "grad_norm": 1.2062548398971558,
      "learning_rate": 7.493612078977932e-06,
      "loss": 0.0977,
      "step": 36610
    },
    {
      "epoch": 8.506387921022068,
      "grad_norm": 0.29462525248527527,
      "learning_rate": 7.481997677119629e-06,
      "loss": 0.0458,
      "step": 36620
    },
    {
      "epoch": 8.508710801393729,
      "grad_norm": 0.6786454916000366,
      "learning_rate": 7.470383275261325e-06,
      "loss": 0.0698,
      "step": 36630
    },
    {
      "epoch": 8.511033681765388,
      "grad_norm": 0.8514771461486816,
      "learning_rate": 7.45876887340302e-06,
      "loss": 0.0945,
      "step": 36640
    },
    {
      "epoch": 8.51335656213705,
      "grad_norm": 1.0042005777359009,
      "learning_rate": 7.447154471544716e-06,
      "loss": 0.1135,
      "step": 36650
    },
    {
      "epoch": 8.515679442508711,
      "grad_norm": 2.2897045612335205,
      "learning_rate": 7.436701509872242e-06,
      "loss": 0.0932,
      "step": 36660
    },
    {
      "epoch": 8.518002322880372,
      "grad_norm": 1.5921143293380737,
      "learning_rate": 7.4250871080139385e-06,
      "loss": 0.0629,
      "step": 36670
    },
    {
      "epoch": 8.520325203252032,
      "grad_norm": 0.5484467148780823,
      "learning_rate": 7.413472706155633e-06,
      "loss": 0.1131,
      "step": 36680
    },
    {
      "epoch": 8.522648083623693,
      "grad_norm": 0.630606472492218,
      "learning_rate": 7.4018583042973295e-06,
      "loss": 0.064,
      "step": 36690
    },
    {
      "epoch": 8.524970963995354,
      "grad_norm": 0.581607460975647,
      "learning_rate": 7.390243902439024e-06,
      "loss": 0.0524,
      "step": 36700
    },
    {
      "epoch": 8.527293844367016,
      "grad_norm": 1.6217286586761475,
      "learning_rate": 7.3786295005807205e-06,
      "loss": 0.1095,
      "step": 36710
    },
    {
      "epoch": 8.529616724738675,
      "grad_norm": 1.2160682678222656,
      "learning_rate": 7.367015098722416e-06,
      "loss": 0.1444,
      "step": 36720
    },
    {
      "epoch": 8.531939605110336,
      "grad_norm": 1.4821823835372925,
      "learning_rate": 7.355400696864112e-06,
      "loss": 0.087,
      "step": 36730
    },
    {
      "epoch": 8.534262485481998,
      "grad_norm": 0.5404691696166992,
      "learning_rate": 7.343786295005807e-06,
      "loss": 0.0735,
      "step": 36740
    },
    {
      "epoch": 8.536585365853659,
      "grad_norm": 1.0695514678955078,
      "learning_rate": 7.3321718931475035e-06,
      "loss": 0.079,
      "step": 36750
    },
    {
      "epoch": 8.538908246225319,
      "grad_norm": 1.1772618293762207,
      "learning_rate": 7.320557491289198e-06,
      "loss": 0.1215,
      "step": 36760
    },
    {
      "epoch": 8.54123112659698,
      "grad_norm": 0.5223404765129089,
      "learning_rate": 7.3089430894308945e-06,
      "loss": 0.0847,
      "step": 36770
    },
    {
      "epoch": 8.543554006968641,
      "grad_norm": 0.5949164628982544,
      "learning_rate": 7.297328687572591e-06,
      "loss": 0.0889,
      "step": 36780
    },
    {
      "epoch": 8.545876887340302,
      "grad_norm": 0.6370581984519958,
      "learning_rate": 7.285714285714286e-06,
      "loss": 0.069,
      "step": 36790
    },
    {
      "epoch": 8.548199767711964,
      "grad_norm": 1.04542076587677,
      "learning_rate": 7.274099883855983e-06,
      "loss": 0.0881,
      "step": 36800
    },
    {
      "epoch": 8.550522648083623,
      "grad_norm": 1.3025872707366943,
      "learning_rate": 7.262485481997677e-06,
      "loss": 0.1162,
      "step": 36810
    },
    {
      "epoch": 8.552845528455284,
      "grad_norm": 0.9095262885093689,
      "learning_rate": 7.250871080139374e-06,
      "loss": 0.0867,
      "step": 36820
    },
    {
      "epoch": 8.555168408826946,
      "grad_norm": 0.860752522945404,
      "learning_rate": 7.2392566782810685e-06,
      "loss": 0.1005,
      "step": 36830
    },
    {
      "epoch": 8.557491289198607,
      "grad_norm": 0.9599931836128235,
      "learning_rate": 7.227642276422765e-06,
      "loss": 0.0817,
      "step": 36840
    },
    {
      "epoch": 8.559814169570267,
      "grad_norm": 0.6866453289985657,
      "learning_rate": 7.21602787456446e-06,
      "loss": 0.074,
      "step": 36850
    },
    {
      "epoch": 8.562137049941928,
      "grad_norm": 1.471942663192749,
      "learning_rate": 7.204413472706157e-06,
      "loss": 0.1548,
      "step": 36860
    },
    {
      "epoch": 8.564459930313589,
      "grad_norm": 1.2457903623580933,
      "learning_rate": 7.192799070847851e-06,
      "loss": 0.1027,
      "step": 36870
    },
    {
      "epoch": 8.56678281068525,
      "grad_norm": 0.8403962850570679,
      "learning_rate": 7.181184668989548e-06,
      "loss": 0.1202,
      "step": 36880
    },
    {
      "epoch": 8.56910569105691,
      "grad_norm": 1.0982446670532227,
      "learning_rate": 7.1695702671312424e-06,
      "loss": 0.0946,
      "step": 36890
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.7180554270744324,
      "learning_rate": 7.157955865272939e-06,
      "loss": 0.0926,
      "step": 36900
    },
    {
      "epoch": 8.573751451800232,
      "grad_norm": 0.6405520439147949,
      "learning_rate": 7.146341463414634e-06,
      "loss": 0.0771,
      "step": 36910
    },
    {
      "epoch": 8.576074332171894,
      "grad_norm": 1.4663933515548706,
      "learning_rate": 7.13472706155633e-06,
      "loss": 0.0688,
      "step": 36920
    },
    {
      "epoch": 8.578397212543553,
      "grad_norm": 0.5296487808227539,
      "learning_rate": 7.123112659698025e-06,
      "loss": 0.1273,
      "step": 36930
    },
    {
      "epoch": 8.580720092915215,
      "grad_norm": 1.4340869188308716,
      "learning_rate": 7.111498257839722e-06,
      "loss": 0.0657,
      "step": 36940
    },
    {
      "epoch": 8.583042973286876,
      "grad_norm": 1.0400766134262085,
      "learning_rate": 7.099883855981418e-06,
      "loss": 0.1357,
      "step": 36950
    },
    {
      "epoch": 8.585365853658537,
      "grad_norm": 1.5948193073272705,
      "learning_rate": 7.088269454123113e-06,
      "loss": 0.0476,
      "step": 36960
    },
    {
      "epoch": 8.587688734030197,
      "grad_norm": 0.7308796644210815,
      "learning_rate": 7.076655052264809e-06,
      "loss": 0.0561,
      "step": 36970
    },
    {
      "epoch": 8.590011614401858,
      "grad_norm": 0.6508436799049377,
      "learning_rate": 7.065040650406504e-06,
      "loss": 0.0835,
      "step": 36980
    },
    {
      "epoch": 8.59233449477352,
      "grad_norm": 0.5106594562530518,
      "learning_rate": 7.0534262485482e-06,
      "loss": 0.0547,
      "step": 36990
    },
    {
      "epoch": 8.59465737514518,
      "grad_norm": 2.1372714042663574,
      "learning_rate": 7.041811846689896e-06,
      "loss": 0.0739,
      "step": 37000
    },
    {
      "epoch": 8.59698025551684,
      "grad_norm": 2.166003465652466,
      "learning_rate": 7.030197444831592e-06,
      "loss": 0.1047,
      "step": 37010
    },
    {
      "epoch": 8.599303135888501,
      "grad_norm": 0.49780189990997314,
      "learning_rate": 7.018583042973287e-06,
      "loss": 0.1129,
      "step": 37020
    },
    {
      "epoch": 8.601626016260163,
      "grad_norm": 1.1178187131881714,
      "learning_rate": 7.006968641114983e-06,
      "loss": 0.0777,
      "step": 37030
    },
    {
      "epoch": 8.603948896631824,
      "grad_norm": 0.4206540584564209,
      "learning_rate": 6.995354239256678e-06,
      "loss": 0.0875,
      "step": 37040
    },
    {
      "epoch": 8.606271777003485,
      "grad_norm": 0.4523097574710846,
      "learning_rate": 6.983739837398374e-06,
      "loss": 0.0644,
      "step": 37050
    },
    {
      "epoch": 8.608594657375145,
      "grad_norm": 1.044796109199524,
      "learning_rate": 6.97212543554007e-06,
      "loss": 0.0407,
      "step": 37060
    },
    {
      "epoch": 8.610917537746806,
      "grad_norm": 1.091987133026123,
      "learning_rate": 6.960511033681766e-06,
      "loss": 0.0995,
      "step": 37070
    },
    {
      "epoch": 8.613240418118467,
      "grad_norm": 0.8010898232460022,
      "learning_rate": 6.948896631823461e-06,
      "loss": 0.0705,
      "step": 37080
    },
    {
      "epoch": 8.615563298490128,
      "grad_norm": 0.6893733143806458,
      "learning_rate": 6.937282229965157e-06,
      "loss": 0.0748,
      "step": 37090
    },
    {
      "epoch": 8.617886178861788,
      "grad_norm": 1.241073489189148,
      "learning_rate": 6.925667828106853e-06,
      "loss": 0.0458,
      "step": 37100
    },
    {
      "epoch": 8.62020905923345,
      "grad_norm": 0.9601914286613464,
      "learning_rate": 6.914053426248548e-06,
      "loss": 0.073,
      "step": 37110
    },
    {
      "epoch": 8.62253193960511,
      "grad_norm": 1.2046751976013184,
      "learning_rate": 6.9024390243902445e-06,
      "loss": 0.0649,
      "step": 37120
    },
    {
      "epoch": 8.624854819976772,
      "grad_norm": 0.8712780475616455,
      "learning_rate": 6.89082462253194e-06,
      "loss": 0.1112,
      "step": 37130
    },
    {
      "epoch": 8.627177700348431,
      "grad_norm": 1.219820499420166,
      "learning_rate": 6.879210220673636e-06,
      "loss": 0.075,
      "step": 37140
    },
    {
      "epoch": 8.629500580720093,
      "grad_norm": 3.635374069213867,
      "learning_rate": 6.867595818815331e-06,
      "loss": 0.0973,
      "step": 37150
    },
    {
      "epoch": 8.631823461091754,
      "grad_norm": 1.5043984651565552,
      "learning_rate": 6.855981416957027e-06,
      "loss": 0.0729,
      "step": 37160
    },
    {
      "epoch": 8.634146341463415,
      "grad_norm": 0.8824848532676697,
      "learning_rate": 6.844367015098722e-06,
      "loss": 0.1101,
      "step": 37170
    },
    {
      "epoch": 8.636469221835075,
      "grad_norm": 0.9527410268783569,
      "learning_rate": 6.8327526132404184e-06,
      "loss": 0.0849,
      "step": 37180
    },
    {
      "epoch": 8.638792102206736,
      "grad_norm": 1.0534428358078003,
      "learning_rate": 6.821138211382114e-06,
      "loss": 0.0526,
      "step": 37190
    },
    {
      "epoch": 8.641114982578397,
      "grad_norm": 1.494470238685608,
      "learning_rate": 6.80952380952381e-06,
      "loss": 0.0795,
      "step": 37200
    },
    {
      "epoch": 8.643437862950059,
      "grad_norm": 1.7092394828796387,
      "learning_rate": 6.797909407665505e-06,
      "loss": 0.083,
      "step": 37210
    },
    {
      "epoch": 8.64576074332172,
      "grad_norm": 0.858891487121582,
      "learning_rate": 6.786295005807201e-06,
      "loss": 0.0627,
      "step": 37220
    },
    {
      "epoch": 8.64808362369338,
      "grad_norm": 0.7870383858680725,
      "learning_rate": 6.774680603948896e-06,
      "loss": 0.0511,
      "step": 37230
    },
    {
      "epoch": 8.65040650406504,
      "grad_norm": 0.7683233618736267,
      "learning_rate": 6.763066202090592e-06,
      "loss": 0.0819,
      "step": 37240
    },
    {
      "epoch": 8.652729384436702,
      "grad_norm": 0.45776069164276123,
      "learning_rate": 6.751451800232288e-06,
      "loss": 0.0829,
      "step": 37250
    },
    {
      "epoch": 8.655052264808361,
      "grad_norm": 0.5275644659996033,
      "learning_rate": 6.739837398373984e-06,
      "loss": 0.0887,
      "step": 37260
    },
    {
      "epoch": 8.657375145180023,
      "grad_norm": 0.9121360778808594,
      "learning_rate": 6.728222996515681e-06,
      "loss": 0.0605,
      "step": 37270
    },
    {
      "epoch": 8.659698025551684,
      "grad_norm": 2.0329155921936035,
      "learning_rate": 6.716608594657375e-06,
      "loss": 0.1159,
      "step": 37280
    },
    {
      "epoch": 8.662020905923345,
      "grad_norm": 0.7195011377334595,
      "learning_rate": 6.704994192799072e-06,
      "loss": 0.0889,
      "step": 37290
    },
    {
      "epoch": 8.664343786295007,
      "grad_norm": 0.615821361541748,
      "learning_rate": 6.693379790940766e-06,
      "loss": 0.1126,
      "step": 37300
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 0.47343647480010986,
      "learning_rate": 6.681765389082463e-06,
      "loss": 0.1031,
      "step": 37310
    },
    {
      "epoch": 8.668989547038327,
      "grad_norm": 0.9672093987464905,
      "learning_rate": 6.670150987224158e-06,
      "loss": 0.115,
      "step": 37320
    },
    {
      "epoch": 8.671312427409989,
      "grad_norm": 1.809083342552185,
      "learning_rate": 6.658536585365855e-06,
      "loss": 0.0879,
      "step": 37330
    },
    {
      "epoch": 8.67363530778165,
      "grad_norm": 0.72007155418396,
      "learning_rate": 6.646922183507549e-06,
      "loss": 0.0728,
      "step": 37340
    },
    {
      "epoch": 8.67595818815331,
      "grad_norm": 0.8478176593780518,
      "learning_rate": 6.635307781649246e-06,
      "loss": 0.0792,
      "step": 37350
    },
    {
      "epoch": 8.67828106852497,
      "grad_norm": 1.513659119606018,
      "learning_rate": 6.62369337979094e-06,
      "loss": 0.0563,
      "step": 37360
    },
    {
      "epoch": 8.680603948896632,
      "grad_norm": 1.415734887123108,
      "learning_rate": 6.612078977932637e-06,
      "loss": 0.1288,
      "step": 37370
    },
    {
      "epoch": 8.682926829268293,
      "grad_norm": 0.9518864750862122,
      "learning_rate": 6.600464576074332e-06,
      "loss": 0.0961,
      "step": 37380
    },
    {
      "epoch": 8.685249709639953,
      "grad_norm": 1.4089184999465942,
      "learning_rate": 6.588850174216029e-06,
      "loss": 0.1143,
      "step": 37390
    },
    {
      "epoch": 8.687572590011614,
      "grad_norm": 0.8111583590507507,
      "learning_rate": 6.577235772357723e-06,
      "loss": 0.1044,
      "step": 37400
    },
    {
      "epoch": 8.689895470383275,
      "grad_norm": 1.4024300575256348,
      "learning_rate": 6.56562137049942e-06,
      "loss": 0.0746,
      "step": 37410
    },
    {
      "epoch": 8.692218350754937,
      "grad_norm": 0.9432094693183899,
      "learning_rate": 6.554006968641116e-06,
      "loss": 0.0958,
      "step": 37420
    },
    {
      "epoch": 8.694541231126596,
      "grad_norm": 0.718977689743042,
      "learning_rate": 6.542392566782811e-06,
      "loss": 0.0956,
      "step": 37430
    },
    {
      "epoch": 8.696864111498257,
      "grad_norm": 2.213496446609497,
      "learning_rate": 6.530778164924507e-06,
      "loss": 0.0729,
      "step": 37440
    },
    {
      "epoch": 8.699186991869919,
      "grad_norm": 1.2311192750930786,
      "learning_rate": 6.5191637630662025e-06,
      "loss": 0.0831,
      "step": 37450
    },
    {
      "epoch": 8.70150987224158,
      "grad_norm": 1.2397140264511108,
      "learning_rate": 6.507549361207899e-06,
      "loss": 0.1182,
      "step": 37460
    },
    {
      "epoch": 8.703832752613241,
      "grad_norm": 1.2885736227035522,
      "learning_rate": 6.495934959349594e-06,
      "loss": 0.0834,
      "step": 37470
    },
    {
      "epoch": 8.7061556329849,
      "grad_norm": 1.0987151861190796,
      "learning_rate": 6.48432055749129e-06,
      "loss": 0.0643,
      "step": 37480
    },
    {
      "epoch": 8.708478513356562,
      "grad_norm": 0.7935259342193604,
      "learning_rate": 6.472706155632985e-06,
      "loss": 0.0858,
      "step": 37490
    },
    {
      "epoch": 8.710801393728223,
      "grad_norm": 1.0442575216293335,
      "learning_rate": 6.461091753774681e-06,
      "loss": 0.0675,
      "step": 37500
    },
    {
      "epoch": 8.713124274099885,
      "grad_norm": 0.6497892737388611,
      "learning_rate": 6.4494773519163765e-06,
      "loss": 0.11,
      "step": 37510
    },
    {
      "epoch": 8.715447154471544,
      "grad_norm": 0.9583202004432678,
      "learning_rate": 6.437862950058073e-06,
      "loss": 0.1492,
      "step": 37520
    },
    {
      "epoch": 8.717770034843205,
      "grad_norm": 0.7421072721481323,
      "learning_rate": 6.4262485481997675e-06,
      "loss": 0.0921,
      "step": 37530
    },
    {
      "epoch": 8.720092915214867,
      "grad_norm": 1.3315343856811523,
      "learning_rate": 6.414634146341464e-06,
      "loss": 0.0921,
      "step": 37540
    },
    {
      "epoch": 8.722415795586528,
      "grad_norm": 0.5980079174041748,
      "learning_rate": 6.403019744483159e-06,
      "loss": 0.138,
      "step": 37550
    },
    {
      "epoch": 8.724738675958188,
      "grad_norm": 0.4316438138484955,
      "learning_rate": 6.391405342624855e-06,
      "loss": 0.1058,
      "step": 37560
    },
    {
      "epoch": 8.727061556329849,
      "grad_norm": 0.8299515843391418,
      "learning_rate": 6.3797909407665505e-06,
      "loss": 0.0813,
      "step": 37570
    },
    {
      "epoch": 8.72938443670151,
      "grad_norm": 2.0132834911346436,
      "learning_rate": 6.368176538908247e-06,
      "loss": 0.1527,
      "step": 37580
    },
    {
      "epoch": 8.731707317073171,
      "grad_norm": 2.1989095211029053,
      "learning_rate": 6.356562137049943e-06,
      "loss": 0.0958,
      "step": 37590
    },
    {
      "epoch": 8.734030197444831,
      "grad_norm": 0.7806954979896545,
      "learning_rate": 6.344947735191638e-06,
      "loss": 0.0995,
      "step": 37600
    },
    {
      "epoch": 8.736353077816492,
      "grad_norm": 0.6548776030540466,
      "learning_rate": 6.333333333333334e-06,
      "loss": 0.1674,
      "step": 37610
    },
    {
      "epoch": 8.738675958188153,
      "grad_norm": 0.8079995512962341,
      "learning_rate": 6.321718931475029e-06,
      "loss": 0.1742,
      "step": 37620
    },
    {
      "epoch": 8.740998838559815,
      "grad_norm": 0.5918996930122375,
      "learning_rate": 6.310104529616725e-06,
      "loss": 0.1058,
      "step": 37630
    },
    {
      "epoch": 8.743321718931474,
      "grad_norm": 1.555166244506836,
      "learning_rate": 6.298490127758421e-06,
      "loss": 0.086,
      "step": 37640
    },
    {
      "epoch": 8.745644599303136,
      "grad_norm": 1.185739517211914,
      "learning_rate": 6.286875725900117e-06,
      "loss": 0.1233,
      "step": 37650
    },
    {
      "epoch": 8.747967479674797,
      "grad_norm": 1.218904733657837,
      "learning_rate": 6.275261324041812e-06,
      "loss": 0.1169,
      "step": 37660
    },
    {
      "epoch": 8.750290360046458,
      "grad_norm": 0.857025682926178,
      "learning_rate": 6.263646922183508e-06,
      "loss": 0.0902,
      "step": 37670
    },
    {
      "epoch": 8.752613240418118,
      "grad_norm": 0.5942018628120422,
      "learning_rate": 6.252032520325203e-06,
      "loss": 0.1131,
      "step": 37680
    },
    {
      "epoch": 8.754936120789779,
      "grad_norm": 1.0809837579727173,
      "learning_rate": 6.240418118466899e-06,
      "loss": 0.124,
      "step": 37690
    },
    {
      "epoch": 8.75725900116144,
      "grad_norm": 0.559013843536377,
      "learning_rate": 6.228803716608595e-06,
      "loss": 0.0733,
      "step": 37700
    },
    {
      "epoch": 8.759581881533101,
      "grad_norm": 0.7059126496315002,
      "learning_rate": 6.217189314750291e-06,
      "loss": 0.0788,
      "step": 37710
    },
    {
      "epoch": 8.761904761904763,
      "grad_norm": 2.1055116653442383,
      "learning_rate": 6.205574912891987e-06,
      "loss": 0.1196,
      "step": 37720
    },
    {
      "epoch": 8.764227642276422,
      "grad_norm": 1.0212091207504272,
      "learning_rate": 6.193960511033682e-06,
      "loss": 0.0924,
      "step": 37730
    },
    {
      "epoch": 8.766550522648084,
      "grad_norm": 0.605236828327179,
      "learning_rate": 6.182346109175378e-06,
      "loss": 0.0894,
      "step": 37740
    },
    {
      "epoch": 8.768873403019745,
      "grad_norm": 1.64102041721344,
      "learning_rate": 6.170731707317073e-06,
      "loss": 0.0583,
      "step": 37750
    },
    {
      "epoch": 8.771196283391406,
      "grad_norm": 0.9900071024894714,
      "learning_rate": 6.159117305458769e-06,
      "loss": 0.1098,
      "step": 37760
    },
    {
      "epoch": 8.773519163763066,
      "grad_norm": 1.7553226947784424,
      "learning_rate": 6.147502903600465e-06,
      "loss": 0.0762,
      "step": 37770
    },
    {
      "epoch": 8.775842044134727,
      "grad_norm": 0.7509774565696716,
      "learning_rate": 6.135888501742161e-06,
      "loss": 0.0753,
      "step": 37780
    },
    {
      "epoch": 8.778164924506388,
      "grad_norm": 1.1547216176986694,
      "learning_rate": 6.124274099883856e-06,
      "loss": 0.0403,
      "step": 37790
    },
    {
      "epoch": 8.78048780487805,
      "grad_norm": 1.1315032243728638,
      "learning_rate": 6.112659698025552e-06,
      "loss": 0.1054,
      "step": 37800
    },
    {
      "epoch": 8.782810685249709,
      "grad_norm": 0.8572806119918823,
      "learning_rate": 6.101045296167247e-06,
      "loss": 0.0961,
      "step": 37810
    },
    {
      "epoch": 8.78513356562137,
      "grad_norm": 1.4729872941970825,
      "learning_rate": 6.0894308943089435e-06,
      "loss": 0.1138,
      "step": 37820
    },
    {
      "epoch": 8.787456445993032,
      "grad_norm": 1.2976796627044678,
      "learning_rate": 6.077816492450639e-06,
      "loss": 0.1887,
      "step": 37830
    },
    {
      "epoch": 8.789779326364693,
      "grad_norm": 1.527950644493103,
      "learning_rate": 6.0662020905923354e-06,
      "loss": 0.0607,
      "step": 37840
    },
    {
      "epoch": 8.792102206736352,
      "grad_norm": 2.140897750854492,
      "learning_rate": 6.054587688734031e-06,
      "loss": 0.0705,
      "step": 37850
    },
    {
      "epoch": 8.794425087108014,
      "grad_norm": 1.5187013149261475,
      "learning_rate": 6.0429732868757265e-06,
      "loss": 0.0521,
      "step": 37860
    },
    {
      "epoch": 8.796747967479675,
      "grad_norm": 0.727925717830658,
      "learning_rate": 6.031358885017422e-06,
      "loss": 0.1396,
      "step": 37870
    },
    {
      "epoch": 8.799070847851336,
      "grad_norm": 1.0330328941345215,
      "learning_rate": 6.0197444831591175e-06,
      "loss": 0.0799,
      "step": 37880
    },
    {
      "epoch": 8.801393728222996,
      "grad_norm": 0.501055121421814,
      "learning_rate": 6.008130081300813e-06,
      "loss": 0.1047,
      "step": 37890
    },
    {
      "epoch": 8.803716608594657,
      "grad_norm": 1.001799464225769,
      "learning_rate": 5.9965156794425086e-06,
      "loss": 0.0661,
      "step": 37900
    },
    {
      "epoch": 8.806039488966318,
      "grad_norm": 1.8208309412002563,
      "learning_rate": 5.984901277584205e-06,
      "loss": 0.0772,
      "step": 37910
    },
    {
      "epoch": 8.80836236933798,
      "grad_norm": 0.9903547167778015,
      "learning_rate": 5.9732868757259004e-06,
      "loss": 0.142,
      "step": 37920
    },
    {
      "epoch": 8.810685249709639,
      "grad_norm": 1.2307811975479126,
      "learning_rate": 5.961672473867596e-06,
      "loss": 0.1423,
      "step": 37930
    },
    {
      "epoch": 8.8130081300813,
      "grad_norm": 1.7507777214050293,
      "learning_rate": 5.9500580720092915e-06,
      "loss": 0.1047,
      "step": 37940
    },
    {
      "epoch": 8.815331010452962,
      "grad_norm": 0.9354134798049927,
      "learning_rate": 5.938443670150987e-06,
      "loss": 0.0804,
      "step": 37950
    },
    {
      "epoch": 8.817653890824623,
      "grad_norm": 2.1741034984588623,
      "learning_rate": 5.9268292682926825e-06,
      "loss": 0.1494,
      "step": 37960
    },
    {
      "epoch": 8.819976771196284,
      "grad_norm": 0.917112410068512,
      "learning_rate": 5.915214866434379e-06,
      "loss": 0.0851,
      "step": 37970
    },
    {
      "epoch": 8.822299651567944,
      "grad_norm": 1.6270662546157837,
      "learning_rate": 5.903600464576075e-06,
      "loss": 0.0722,
      "step": 37980
    },
    {
      "epoch": 8.824622531939605,
      "grad_norm": 0.9283517003059387,
      "learning_rate": 5.891986062717771e-06,
      "loss": 0.111,
      "step": 37990
    },
    {
      "epoch": 8.826945412311266,
      "grad_norm": 0.9143903851509094,
      "learning_rate": 5.880371660859466e-06,
      "loss": 0.0812,
      "step": 38000
    },
    {
      "epoch": 8.829268292682928,
      "grad_norm": 1.1460689306259155,
      "learning_rate": 5.868757259001162e-06,
      "loss": 0.1324,
      "step": 38010
    },
    {
      "epoch": 8.831591173054587,
      "grad_norm": 1.4740543365478516,
      "learning_rate": 5.857142857142857e-06,
      "loss": 0.1004,
      "step": 38020
    },
    {
      "epoch": 8.833914053426248,
      "grad_norm": 0.6557267904281616,
      "learning_rate": 5.845528455284553e-06,
      "loss": 0.0876,
      "step": 38030
    },
    {
      "epoch": 8.83623693379791,
      "grad_norm": 1.092942476272583,
      "learning_rate": 5.833914053426249e-06,
      "loss": 0.0718,
      "step": 38040
    },
    {
      "epoch": 8.838559814169571,
      "grad_norm": 0.5869165658950806,
      "learning_rate": 5.822299651567945e-06,
      "loss": 0.0656,
      "step": 38050
    },
    {
      "epoch": 8.84088269454123,
      "grad_norm": 1.2575381994247437,
      "learning_rate": 5.81068524970964e-06,
      "loss": 0.0956,
      "step": 38060
    },
    {
      "epoch": 8.843205574912892,
      "grad_norm": 0.6990114450454712,
      "learning_rate": 5.799070847851336e-06,
      "loss": 0.0993,
      "step": 38070
    },
    {
      "epoch": 8.845528455284553,
      "grad_norm": 1.268408179283142,
      "learning_rate": 5.787456445993031e-06,
      "loss": 0.1096,
      "step": 38080
    },
    {
      "epoch": 8.847851335656214,
      "grad_norm": 0.8953127264976501,
      "learning_rate": 5.775842044134727e-06,
      "loss": 0.0655,
      "step": 38090
    },
    {
      "epoch": 8.850174216027874,
      "grad_norm": 1.6367652416229248,
      "learning_rate": 5.764227642276423e-06,
      "loss": 0.0717,
      "step": 38100
    },
    {
      "epoch": 8.852497096399535,
      "grad_norm": 0.4921935498714447,
      "learning_rate": 5.752613240418119e-06,
      "loss": 0.0948,
      "step": 38110
    },
    {
      "epoch": 8.854819976771196,
      "grad_norm": 0.35625430941581726,
      "learning_rate": 5.740998838559814e-06,
      "loss": 0.1471,
      "step": 38120
    },
    {
      "epoch": 8.857142857142858,
      "grad_norm": 0.7206029891967773,
      "learning_rate": 5.72938443670151e-06,
      "loss": 0.0971,
      "step": 38130
    },
    {
      "epoch": 8.859465737514519,
      "grad_norm": 0.8213923573493958,
      "learning_rate": 5.717770034843206e-06,
      "loss": 0.1065,
      "step": 38140
    },
    {
      "epoch": 8.861788617886178,
      "grad_norm": 1.1901023387908936,
      "learning_rate": 5.706155632984902e-06,
      "loss": 0.0619,
      "step": 38150
    },
    {
      "epoch": 8.86411149825784,
      "grad_norm": 1.5257686376571655,
      "learning_rate": 5.694541231126597e-06,
      "loss": 0.1398,
      "step": 38160
    },
    {
      "epoch": 8.866434378629501,
      "grad_norm": 1.077803134918213,
      "learning_rate": 5.6829268292682935e-06,
      "loss": 0.0959,
      "step": 38170
    },
    {
      "epoch": 8.86875725900116,
      "grad_norm": 0.5228690505027771,
      "learning_rate": 5.671312427409989e-06,
      "loss": 0.1198,
      "step": 38180
    },
    {
      "epoch": 8.871080139372822,
      "grad_norm": 1.7284448146820068,
      "learning_rate": 5.6596980255516846e-06,
      "loss": 0.1002,
      "step": 38190
    },
    {
      "epoch": 8.873403019744483,
      "grad_norm": 2.4079527854919434,
      "learning_rate": 5.64808362369338e-06,
      "loss": 0.099,
      "step": 38200
    },
    {
      "epoch": 8.875725900116144,
      "grad_norm": 0.8176579475402832,
      "learning_rate": 5.636469221835076e-06,
      "loss": 0.095,
      "step": 38210
    },
    {
      "epoch": 8.878048780487806,
      "grad_norm": 0.669975996017456,
      "learning_rate": 5.624854819976771e-06,
      "loss": 0.0831,
      "step": 38220
    },
    {
      "epoch": 8.880371660859465,
      "grad_norm": 1.0303295850753784,
      "learning_rate": 5.6132404181184675e-06,
      "loss": 0.0813,
      "step": 38230
    },
    {
      "epoch": 8.882694541231126,
      "grad_norm": 0.4563010036945343,
      "learning_rate": 5.601626016260163e-06,
      "loss": 0.0795,
      "step": 38240
    },
    {
      "epoch": 8.885017421602788,
      "grad_norm": 1.6316049098968506,
      "learning_rate": 5.5900116144018585e-06,
      "loss": 0.0819,
      "step": 38250
    },
    {
      "epoch": 8.887340301974449,
      "grad_norm": 1.186926007270813,
      "learning_rate": 5.578397212543554e-06,
      "loss": 0.0926,
      "step": 38260
    },
    {
      "epoch": 8.889663182346109,
      "grad_norm": 1.7511745691299438,
      "learning_rate": 5.5667828106852496e-06,
      "loss": 0.0996,
      "step": 38270
    },
    {
      "epoch": 8.89198606271777,
      "grad_norm": 0.6483609676361084,
      "learning_rate": 5.555168408826945e-06,
      "loss": 0.0552,
      "step": 38280
    },
    {
      "epoch": 8.894308943089431,
      "grad_norm": 1.3682491779327393,
      "learning_rate": 5.5435540069686414e-06,
      "loss": 0.1112,
      "step": 38290
    },
    {
      "epoch": 8.896631823461092,
      "grad_norm": 0.9204638004302979,
      "learning_rate": 5.531939605110338e-06,
      "loss": 0.1197,
      "step": 38300
    },
    {
      "epoch": 8.898954703832752,
      "grad_norm": 0.6306434273719788,
      "learning_rate": 5.520325203252033e-06,
      "loss": 0.0518,
      "step": 38310
    },
    {
      "epoch": 8.901277584204413,
      "grad_norm": 1.0527631044387817,
      "learning_rate": 5.508710801393729e-06,
      "loss": 0.1324,
      "step": 38320
    },
    {
      "epoch": 8.903600464576074,
      "grad_norm": 1.0327728986740112,
      "learning_rate": 5.497096399535424e-06,
      "loss": 0.1429,
      "step": 38330
    },
    {
      "epoch": 8.905923344947736,
      "grad_norm": 1.475602149963379,
      "learning_rate": 5.48548199767712e-06,
      "loss": 0.1362,
      "step": 38340
    },
    {
      "epoch": 8.908246225319395,
      "grad_norm": 0.8442221283912659,
      "learning_rate": 5.473867595818815e-06,
      "loss": 0.0675,
      "step": 38350
    },
    {
      "epoch": 8.910569105691057,
      "grad_norm": 1.984391689300537,
      "learning_rate": 5.462253193960512e-06,
      "loss": 0.1083,
      "step": 38360
    },
    {
      "epoch": 8.912891986062718,
      "grad_norm": 0.993766188621521,
      "learning_rate": 5.450638792102207e-06,
      "loss": 0.1294,
      "step": 38370
    },
    {
      "epoch": 8.915214866434379,
      "grad_norm": 1.098974585533142,
      "learning_rate": 5.439024390243903e-06,
      "loss": 0.0998,
      "step": 38380
    },
    {
      "epoch": 8.91753774680604,
      "grad_norm": 0.6534239649772644,
      "learning_rate": 5.427409988385598e-06,
      "loss": 0.0793,
      "step": 38390
    },
    {
      "epoch": 8.9198606271777,
      "grad_norm": 0.5006698369979858,
      "learning_rate": 5.415795586527294e-06,
      "loss": 0.0468,
      "step": 38400
    },
    {
      "epoch": 8.922183507549361,
      "grad_norm": 1.4949506521224976,
      "learning_rate": 5.404181184668989e-06,
      "loss": 0.0748,
      "step": 38410
    },
    {
      "epoch": 8.924506387921022,
      "grad_norm": 1.0618523359298706,
      "learning_rate": 5.392566782810685e-06,
      "loss": 0.0732,
      "step": 38420
    },
    {
      "epoch": 8.926829268292684,
      "grad_norm": 1.131996989250183,
      "learning_rate": 5.380952380952381e-06,
      "loss": 0.0788,
      "step": 38430
    },
    {
      "epoch": 8.929152148664343,
      "grad_norm": 1.0674844980239868,
      "learning_rate": 5.369337979094077e-06,
      "loss": 0.1259,
      "step": 38440
    },
    {
      "epoch": 8.931475029036005,
      "grad_norm": 1.7036726474761963,
      "learning_rate": 5.357723577235772e-06,
      "loss": 0.0962,
      "step": 38450
    },
    {
      "epoch": 8.933797909407666,
      "grad_norm": 2.4086990356445312,
      "learning_rate": 5.346109175377469e-06,
      "loss": 0.1504,
      "step": 38460
    },
    {
      "epoch": 8.936120789779327,
      "grad_norm": 1.7637152671813965,
      "learning_rate": 5.334494773519164e-06,
      "loss": 0.1163,
      "step": 38470
    },
    {
      "epoch": 8.938443670150987,
      "grad_norm": 0.581418514251709,
      "learning_rate": 5.32288037166086e-06,
      "loss": 0.0925,
      "step": 38480
    },
    {
      "epoch": 8.940766550522648,
      "grad_norm": 1.2334485054016113,
      "learning_rate": 5.311265969802555e-06,
      "loss": 0.0628,
      "step": 38490
    },
    {
      "epoch": 8.94308943089431,
      "grad_norm": 0.7001454830169678,
      "learning_rate": 5.299651567944252e-06,
      "loss": 0.1122,
      "step": 38500
    },
    {
      "epoch": 8.94541231126597,
      "grad_norm": 0.6813988089561462,
      "learning_rate": 5.288037166085947e-06,
      "loss": 0.0938,
      "step": 38510
    },
    {
      "epoch": 8.94773519163763,
      "grad_norm": 0.8230463266372681,
      "learning_rate": 5.276422764227643e-06,
      "loss": 0.052,
      "step": 38520
    },
    {
      "epoch": 8.950058072009291,
      "grad_norm": 0.9334096908569336,
      "learning_rate": 5.264808362369338e-06,
      "loss": 0.1085,
      "step": 38530
    },
    {
      "epoch": 8.952380952380953,
      "grad_norm": 0.2638304829597473,
      "learning_rate": 5.253193960511034e-06,
      "loss": 0.0782,
      "step": 38540
    },
    {
      "epoch": 8.954703832752614,
      "grad_norm": 0.9222418069839478,
      "learning_rate": 5.241579558652729e-06,
      "loss": 0.0342,
      "step": 38550
    },
    {
      "epoch": 8.957026713124273,
      "grad_norm": 1.0394654273986816,
      "learning_rate": 5.2299651567944256e-06,
      "loss": 0.1442,
      "step": 38560
    },
    {
      "epoch": 8.959349593495935,
      "grad_norm": 1.092565655708313,
      "learning_rate": 5.218350754936121e-06,
      "loss": 0.062,
      "step": 38570
    },
    {
      "epoch": 8.961672473867596,
      "grad_norm": 1.4028421640396118,
      "learning_rate": 5.206736353077817e-06,
      "loss": 0.0608,
      "step": 38580
    },
    {
      "epoch": 8.963995354239257,
      "grad_norm": 1.1929941177368164,
      "learning_rate": 5.195121951219512e-06,
      "loss": 0.0807,
      "step": 38590
    },
    {
      "epoch": 8.966318234610917,
      "grad_norm": 0.5724892616271973,
      "learning_rate": 5.183507549361208e-06,
      "loss": 0.0799,
      "step": 38600
    },
    {
      "epoch": 8.968641114982578,
      "grad_norm": 0.39861783385276794,
      "learning_rate": 5.171893147502903e-06,
      "loss": 0.0367,
      "step": 38610
    },
    {
      "epoch": 8.97096399535424,
      "grad_norm": 1.113970398902893,
      "learning_rate": 5.1602787456445995e-06,
      "loss": 0.061,
      "step": 38620
    },
    {
      "epoch": 8.9732868757259,
      "grad_norm": 1.454280138015747,
      "learning_rate": 5.148664343786296e-06,
      "loss": 0.0809,
      "step": 38630
    },
    {
      "epoch": 8.975609756097562,
      "grad_norm": 1.0525009632110596,
      "learning_rate": 5.137049941927991e-06,
      "loss": 0.0895,
      "step": 38640
    },
    {
      "epoch": 8.977932636469221,
      "grad_norm": 0.41537290811538696,
      "learning_rate": 5.125435540069687e-06,
      "loss": 0.1294,
      "step": 38650
    },
    {
      "epoch": 8.980255516840883,
      "grad_norm": 1.2025378942489624,
      "learning_rate": 5.1138211382113825e-06,
      "loss": 0.1311,
      "step": 38660
    },
    {
      "epoch": 8.982578397212544,
      "grad_norm": 0.2840721607208252,
      "learning_rate": 5.102206736353078e-06,
      "loss": 0.0522,
      "step": 38670
    },
    {
      "epoch": 8.984901277584205,
      "grad_norm": 0.5581360459327698,
      "learning_rate": 5.0905923344947735e-06,
      "loss": 0.0602,
      "step": 38680
    },
    {
      "epoch": 8.987224157955865,
      "grad_norm": 1.4356061220169067,
      "learning_rate": 5.07897793263647e-06,
      "loss": 0.0512,
      "step": 38690
    },
    {
      "epoch": 8.989547038327526,
      "grad_norm": 1.1452620029449463,
      "learning_rate": 5.067363530778165e-06,
      "loss": 0.0548,
      "step": 38700
    },
    {
      "epoch": 8.991869918699187,
      "grad_norm": 0.7564339637756348,
      "learning_rate": 5.055749128919861e-06,
      "loss": 0.1256,
      "step": 38710
    },
    {
      "epoch": 8.994192799070849,
      "grad_norm": 0.7228018045425415,
      "learning_rate": 5.044134727061556e-06,
      "loss": 0.0622,
      "step": 38720
    },
    {
      "epoch": 8.996515679442508,
      "grad_norm": 1.4584382772445679,
      "learning_rate": 5.032520325203252e-06,
      "loss": 0.1277,
      "step": 38730
    },
    {
      "epoch": 8.99883855981417,
      "grad_norm": 2.022095203399658,
      "learning_rate": 5.0209059233449475e-06,
      "loss": 0.093,
      "step": 38740
    }
  ],
  "logging_steps": 10,
  "max_steps": 43050,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.60440576488766e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
